// Code generated by smithy-swift-codegen. DO NOT EDIT!



/// <p>Information required for human workers to complete a labeling task.</p>
public struct HumanTaskConfig: Equatable {
    /// <p>Configures how labels are consolidated across human workers.</p>
    public let annotationConsolidationConfig: AnnotationConsolidationConfig?
    /// <p>Defines the maximum number of data objects that can be labeled by human workers at the
    ///             same time. Also referred to as batch size. Each object may have more than one worker at one time.
    ///             The default value is 1000 objects.</p>
    public let maxConcurrentTaskCount: Int?
    /// <p>The number of human workers that will label an object. </p>
    public let numberOfHumanWorkersPerDataObject: Int?
    /// <p>The Amazon Resource Name (ARN) of a Lambda function that is run before a data object
    ///             is sent to a human worker. Use this function to provide input to a custom labeling
    ///             job.</p>
    ///         <p>For <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-task-types.html">built-in
    ///                 task types</a>, use one of the following Amazon SageMaker Ground Truth Lambda function ARNs for
    ///                 <code>PreHumanTaskLambdaArn</code>. For custom labeling workflows, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step3.html#sms-custom-templates-step3-prelambda">Pre-annotation Lambda</a>. </p>
    ///
    ///
    ///
    ///          <p>
    ///             <b>Bounding box</b> - Finds the most similar boxes from
    ///                     different workers based on the Jaccard index of the boxes.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-BoundingBox</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///
    ///           <p>
    ///             <b>Image classification</b> - Uses a variant of the Expectation
    ///                     Maximization approach to estimate the true class of an image based on
    ///                     annotations from individual workers.</p>
    ///
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-ImageMultiClass</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///             <p>
    ///             <b>Multi-label image classification</b> - Uses a variant of the Expectation
    ///                     Maximization approach to estimate the true classes of an image based on
    ///                     annotations from individual workers.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-ImageMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///          </ul>
    ///
    ///             <p>
    ///             <b>Semantic segmentation</b> - Treats each pixel in an image as
    ///                     a multi-class classification and treats pixel annotations from workers as
    ///                     "votes" for the correct label.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-SemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///             <p>
    ///             <b>Text classification</b> - Uses a variant of the Expectation
    ///                     Maximization approach to estimate the true class of text based on annotations
    ///                     from individual workers.</p>
    ///             <ul>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-TextMultiClass</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///             <p>
    ///             <b>Multi-label text classification</b> - Uses a variant of the
    ///                     Expectation Maximization approach to estimate the true classes of text based on
    ///                     annotations from individual workers.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-TextMultiClassMultiLabel</code>
    ///                </p>
    ///             </li>
    ///          </ul>
    ///
    ///             <p>
    ///             <b>Named entity recognition</b> - Groups similar selections and
    ///                     calculates aggregate boundaries, resolving to most-assigned label.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-NamedEntityRecognition</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///
    ///
    ///
    ///         <p>
    ///             <b>Video Classification</b> - Use this task type when you need workers to classify videos using
    ///             predefined labels that you specify. Workers are shown videos and are asked to choose one
    ///             label for each video.</p>
    ///
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-VideoMultiClass</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///         <p>
    ///             <b>Video Frame Object Detection</b> - Use this task type to
    ///             have workers identify and locate objects in a sequence of video frames (images extracted
    ///             from a video) using bounding boxes. For example, you can use this task to ask workers to
    ///             identify and localize various objects in a series of video frames, such as cars, bikes,
    ///             and pedestrians.</p>
    ///
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-VideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///         <p>
    ///             <b>Video Frame Object Tracking</b> - Use this task type to
    ///             have workers track the movement of objects in a sequence of video frames (images
    ///             extracted from a video) using bounding boxes. For example, you can use this task to ask
    ///             workers to track the movement of objects, such as cars, bikes, and pedestrians. </p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-VideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///
    ///
    ///
    ///         <p>
    ///             <b>3D Point Cloud Modalities</b>
    ///          </p>
    ///         <p>Use the following pre-annotation lambdas for 3D point cloud labeling modality tasks.
    ///             See <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-point-cloud-task-types.html">3D Point Cloud Task types
    ///             </a> to learn more. </p>
    ///
    ///
    ///         <p>
    ///             <b>3D Point Cloud Object Detection</b> -
    ///         Use this task type when you want workers to classify objects in a 3D point cloud by
    ///         drawing 3D cuboids around objects. For example, you can use this task type to ask workers
    ///         to identify different types of objects in a point cloud, such as cars, bikes, and pedestrians.</p>
    ///                 <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-3DPointCloudObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///         <p>
    ///             <b>3D Point Cloud Object Tracking</b> -
    ///         Use this task type when you want workers to draw 3D cuboids around objects
    ///         that appear in a sequence of 3D point cloud frames.
    ///         For example, you can use this task type to ask workers to track
    ///         the movement of vehicles across multiple point cloud frames.
    ///         </p>
    ///                 <ul>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-3DPointCloudObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///
    ///
    ///         <p>
    ///             <b>3D Point Cloud Semantic Segmentation</b> -
    ///             Use this task type when you want workers to create a point-level semantic segmentation masks by
    ///             painting objects in a 3D point cloud using different colors where each color is assigned to one of
    ///             the classes you specify.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-3DPointCloudSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///         <p>
    ///             <b>Use the following ARNs for Label Verification and Adjustment Jobs</b>
    ///          </p>
    ///         <p>Use label verification and adjustment jobs to review and adjust labels. To learn more,
    ///             see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-verification-data.html">Verify and Adjust Labels </a>.</p>
    ///
    ///             <p>
    ///             <b>Bounding box verification</b> - Uses a variant of the
    ///                 Expectation Maximization approach to estimate the true class of verification
    ///                 judgement for bounding box labels based on annotations from individual
    ///                 workers.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-VerificationBoundingBox</code>
    ///                </p>
    ///             </li>
    ///          </ul>
    ///
    ///             <p>
    ///             <b>Bounding box adjustment</b> - Finds the most similar boxes
    ///                     from different workers based on the Jaccard index of the adjusted
    ///                     annotations.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-AdjustmentBoundingBox</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///             <p>
    ///             <b>Semantic segmentation verification</b> - Uses a variant of
    ///                     the Expectation Maximization approach to estimate the true class of verification
    ///                     judgment for semantic segmentation labels based on annotations from individual
    ///                     workers.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-VerificationSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///             <p>
    ///             <b>Semantic segmentation adjustment</b> - Treats each pixel in
    ///                     an image as a multi-class classification and treats pixel adjusted annotations
    ///                     from workers as "votes" for the correct label.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-AdjustmentSemanticSegmentation</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///
    ///
    ///
    ///         <p>
    ///             <b>Video Frame Object Detection Adjustment</b> -
    ///             Use this task type when you want workers to adjust bounding boxes that workers have added
    ///             to video frames to classify and localize objects in a sequence of video frames.</p>
    ///
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-AdjustmentVideoObjectDetection</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///         <p>
    ///             <b>Video Frame Object Tracking Adjustment</b> -
    ///             Use this task type when you want workers to adjust bounding boxes that workers have added
    ///             to video frames to track object movement across a sequence of video frames.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-AdjustmentVideoObjectTracking</code>
    ///                 </p>
    ///             </li>
    ///          </ul>
    ///
    ///
    ///
    ///
    ///         <p>
    ///             <b>3D point cloud object detection adjustment</b> - Adjust
    ///             3D cuboids in a point cloud frame. </p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-Adjustment3DPointCloudObjectDetection</code>
    ///                </p>
    ///             </li>
    ///          </ul>
    ///
    ///         <p>
    ///             <b>3D point cloud object tracking adjustment</b> - Adjust 3D
    ///             cuboids across a sequence of point cloud frames. </p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-Adjustment3DPointCloudObjectTracking</code>
    ///                </p>
    ///             </li>
    ///          </ul>
    ///
    ///         <p>
    ///             <b>3D point cloud semantic segmentation adjustment</b> -
    ///             Adjust semantic segmentation masks in a 3D point cloud. </p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                   <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
    ///                </p>
    ///             </li>
    ///          </ul>
    public let preHumanTaskLambdaArn: String?
    /// <p>The price that you pay for each task performed by an Amazon Mechanical Turk worker.</p>
    public let publicWorkforceTaskPrice: PublicWorkforceTaskPrice?
    /// <p>The length of time that a task remains available for labeling by human workers. The
    ///             default and maximum values for this parameter depend on the type of workforce you
    ///             use.</p>
    ///         <ul>
    ///             <li>
    ///                 <p>If you choose the Amazon Mechanical Turk workforce, the maximum is 12 hours (43,200 seconds).
    ///                     The default is 6 hours (21,600 seconds).</p>
    ///             </li>
    ///             <li>
    ///                 <p>If you choose a private or vendor workforce, the default value is 10 days
    ///                     (864,000 seconds). For most users, the maximum is also 10 days. If you want to
    ///                     change this limit, contact AWS Support.</p>
    ///             </li>
    ///          </ul>
    public let taskAvailabilityLifetimeInSeconds: Int?
    /// <p>A description of the task for your human workers.</p>
    public let taskDescription: String?
    /// <p>Keywords used to describe the task so that workers on Amazon Mechanical Turk can
    ///             discover the task.</p>
    public let taskKeywords: [String]?
    /// <p>The amount of time that a worker has to complete a task. </p>
    ///         <p>If you create a custom labeling job, the maximum value for this parameter is 8 hours
    ///             (28,800 seconds).</p>
    ///         <p>If you create a labeling job using a <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-task-types.html">built-in task type</a> the maximum
    ///             for this parameter depends on the task type you use:</p>
    ///         <ul>
    ///             <li>
    ///                 <p>For <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-label-images.html">image</a> and
    ///                     <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-label-text.html">text</a> labeling jobs,
    ///                     the maximum is 8 hours (28,800 seconds).</p>
    ///             </li>
    ///             <li>
    ///                 <p>For <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-point-cloud.html">3D point cloud</a> and <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-video.html">video frame</a> labeling jobs,
    ///                     the maximum is 7 days (604,800 seconds). If you want to change these limits,
    ///                     contact AWS Support.</p>
    ///             </li>
    ///          </ul>
    public let taskTimeLimitInSeconds: Int?
    /// <p>A title for the task for your human workers.</p>
    public let taskTitle: String?
    /// <p>Information about the user interface that workers use to complete the labeling
    ///             task.</p>
    public let uiConfig: UiConfig?
    /// <p>The Amazon Resource Name (ARN) of the work team assigned to complete the tasks.</p>
    public let workteamArn: String?

    public init (
        annotationConsolidationConfig: AnnotationConsolidationConfig? = nil,
        maxConcurrentTaskCount: Int? = nil,
        numberOfHumanWorkersPerDataObject: Int? = nil,
        preHumanTaskLambdaArn: String? = nil,
        publicWorkforceTaskPrice: PublicWorkforceTaskPrice? = nil,
        taskAvailabilityLifetimeInSeconds: Int? = nil,
        taskDescription: String? = nil,
        taskKeywords: [String]? = nil,
        taskTimeLimitInSeconds: Int? = nil,
        taskTitle: String? = nil,
        uiConfig: UiConfig? = nil,
        workteamArn: String? = nil
    )
    {
        self.annotationConsolidationConfig = annotationConsolidationConfig
        self.maxConcurrentTaskCount = maxConcurrentTaskCount
        self.numberOfHumanWorkersPerDataObject = numberOfHumanWorkersPerDataObject
        self.preHumanTaskLambdaArn = preHumanTaskLambdaArn
        self.publicWorkforceTaskPrice = publicWorkforceTaskPrice
        self.taskAvailabilityLifetimeInSeconds = taskAvailabilityLifetimeInSeconds
        self.taskDescription = taskDescription
        self.taskKeywords = taskKeywords
        self.taskTimeLimitInSeconds = taskTimeLimitInSeconds
        self.taskTitle = taskTitle
        self.uiConfig = uiConfig
        self.workteamArn = workteamArn
    }
}

extension HumanTaskConfig: CustomDebugStringConvertible {
    public var debugDescription: String {
        "HumanTaskConfig(annotationConsolidationConfig: \(String(describing: annotationConsolidationConfig)), maxConcurrentTaskCount: \(String(describing: maxConcurrentTaskCount)), numberOfHumanWorkersPerDataObject: \(String(describing: numberOfHumanWorkersPerDataObject)), preHumanTaskLambdaArn: \(String(describing: preHumanTaskLambdaArn)), publicWorkforceTaskPrice: \(String(describing: publicWorkforceTaskPrice)), taskAvailabilityLifetimeInSeconds: \(String(describing: taskAvailabilityLifetimeInSeconds)), taskDescription: \(String(describing: taskDescription)), taskKeywords: \(String(describing: taskKeywords)), taskTimeLimitInSeconds: \(String(describing: taskTimeLimitInSeconds)), taskTitle: \(String(describing: taskTitle)), uiConfig: \(String(describing: uiConfig)), workteamArn: \(String(describing: workteamArn)))"}
}
