// Code generated by smithy-swift-codegen. DO NOT EDIT!
import AWSClientRuntime
import ClientRuntime

extension TranscribeStreamingClientTypes.Alternative: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case entities = "Entities"
        case items = "Items"
        case transcript = "Transcript"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let entities = entities {
            var entitiesContainer = encodeContainer.nestedUnkeyedContainer(forKey: .entities)
            for entitylist0 in entities {
                try entitiesContainer.encode(entitylist0)
            }
        }
        if let items = items {
            var itemsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .items)
            for itemlist0 in items {
                try itemsContainer.encode(itemlist0)
            }
        }
        if let transcript = self.transcript {
            try encodeContainer.encode(transcript, forKey: .transcript)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let transcriptDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .transcript)
        transcript = transcriptDecoded
        let itemsContainer = try containerValues.decodeIfPresent([TranscribeStreamingClientTypes.Item?].self, forKey: .items)
        var itemsDecoded0:[TranscribeStreamingClientTypes.Item]? = nil
        if let itemsContainer = itemsContainer {
            itemsDecoded0 = [TranscribeStreamingClientTypes.Item]()
            for structure0 in itemsContainer {
                if let structure0 = structure0 {
                    itemsDecoded0?.append(structure0)
                }
            }
        }
        items = itemsDecoded0
        let entitiesContainer = try containerValues.decodeIfPresent([TranscribeStreamingClientTypes.Entity?].self, forKey: .entities)
        var entitiesDecoded0:[TranscribeStreamingClientTypes.Entity]? = nil
        if let entitiesContainer = entitiesContainer {
            entitiesDecoded0 = [TranscribeStreamingClientTypes.Entity]()
            for structure0 in entitiesContainer {
                if let structure0 = structure0 {
                    entitiesDecoded0?.append(structure0)
                }
            }
        }
        entities = entitiesDecoded0
    }
}

extension TranscribeStreamingClientTypes {
    /// A list of possible transcriptions for the audio.
    public struct Alternative: Swift.Equatable {
        /// Contains the entities identified as personally identifiable information (PII) in the transcription output.
        public var entities: [TranscribeStreamingClientTypes.Entity]?
        /// One or more alternative interpretations of the input audio.
        public var items: [TranscribeStreamingClientTypes.Item]?
        /// The text that was transcribed from the audio.
        public var transcript: Swift.String?

        public init (
            entities: [TranscribeStreamingClientTypes.Entity]? = nil,
            items: [TranscribeStreamingClientTypes.Item]? = nil,
            transcript: Swift.String? = nil
        )
        {
            self.entities = entities
            self.items = items
            self.transcript = transcript
        }
    }

}

extension TranscribeStreamingClientTypes.AudioEvent: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case audioChunk = "AudioChunk"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let audioChunk = self.audioChunk {
            try encodeContainer.encode(audioChunk.base64EncodedString(), forKey: .audioChunk)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let audioChunkDecoded = try containerValues.decodeIfPresent(ClientRuntime.Data.self, forKey: .audioChunk)
        audioChunk = audioChunkDecoded
    }
}

extension TranscribeStreamingClientTypes {
    /// Provides a wrapper for the audio chunks that you are sending. For information on audio encoding in Amazon Transcribe, see [Speech input](https://docs.aws.amazon.com/transcribe/latest/dg/input.html). For information on audio encoding formats in Amazon Transcribe Medical, see [Speech input](https://docs.aws.amazon.com/transcribe/latest/dg/input-med.html).
    public struct AudioEvent: Swift.Equatable {
        /// An audio blob that contains the next part of the audio that you want to transcribe. The maximum audio chunk size is 32 KB.
        public var audioChunk: ClientRuntime.Data?

        public init (
            audioChunk: ClientRuntime.Data? = nil
        )
        {
            self.audioChunk = audioChunk
        }
    }

}

extension TranscribeStreamingClientTypes.AudioStream: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case audioevent = "AudioEvent"
        case sdkUnknown
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var container = encoder.container(keyedBy: CodingKeys.self)
        switch self {
            case let .audioevent(audioevent):
                try container.encode(audioevent, forKey: .audioevent)
            case let .sdkUnknown(sdkUnknown):
                try container.encode(sdkUnknown, forKey: .sdkUnknown)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let values = try decoder.container(keyedBy: CodingKeys.self)
        let audioeventDecoded = try values.decodeIfPresent(TranscribeStreamingClientTypes.AudioEvent.self, forKey: .audioevent)
        if let audioevent = audioeventDecoded {
            self = .audioevent(audioevent)
            return
        }
        self = .sdkUnknown("")
    }
}

extension TranscribeStreamingClientTypes {
    /// Represents the audio stream from your application to Amazon Transcribe.
    public enum AudioStream: Swift.Equatable {
        /// A blob of audio from your application. You audio stream consists of one or more audio events. For information on audio encoding formats in Amazon Transcribe, see [Speech input](https://docs.aws.amazon.com/transcribe/latest/dg/input.html). For information on audio encoding formats in Amazon Transcribe Medical, see [Speech input](https://docs.aws.amazon.com/transcribe/latest/dg/input-med.html). For more information on stream encoding in Amazon Transcribe, see [Event stream encoding](https://docs.aws.amazon.com/transcribe/latest/dg/event-stream.html). For information on stream encoding in Amazon Transcribe Medical, see [Event stream encoding](https://docs.aws.amazon.com/transcribe/latest/dg/event-stream-med.html).
        case audioevent(TranscribeStreamingClientTypes.AudioEvent)
        case sdkUnknown(Swift.String)
    }

}

extension BadRequestException: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let message = self.message {
            try encodeContainer.encode(message, forKey: .message)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension BadRequestException {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: BadRequestExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// One or more arguments to the StartStreamTranscription or StartMedicalStreamTranscription operation was invalid. For example, MediaEncoding was not set to a valid encoding, or LanguageCode was not set to a valid code. Check the parameters and try your request again.
public struct BadRequestException: AWSClientRuntime.AWSHttpServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct BadRequestExceptionBody: Swift.Equatable {
    let message: Swift.String?
}

extension BadRequestExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension ConflictException: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let message = self.message {
            try encodeContainer.encode(message, forKey: .message)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension ConflictException {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: ConflictExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// A new stream started with the same session ID. The current stream has been terminated.
public struct ConflictException: AWSClientRuntime.AWSHttpServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct ConflictExceptionBody: Swift.Equatable {
    let message: Swift.String?
}

extension ConflictExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension TranscribeStreamingClientTypes {
    public enum ContentIdentificationType: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case pii
        case sdkUnknown(Swift.String)

        public static var allCases: [ContentIdentificationType] {
            return [
                .pii,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .pii: return "PII"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = ContentIdentificationType(rawValue: rawValue) ?? ContentIdentificationType.sdkUnknown(rawValue)
        }
    }
}

extension TranscribeStreamingClientTypes {
    public enum ContentRedactionType: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case pii
        case sdkUnknown(Swift.String)

        public static var allCases: [ContentRedactionType] {
            return [
                .pii,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .pii: return "PII"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = ContentRedactionType(rawValue: rawValue) ?? ContentRedactionType.sdkUnknown(rawValue)
        }
    }
}

extension TranscribeStreamingClientTypes.Entity: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case category = "Category"
        case confidence = "Confidence"
        case content = "Content"
        case endTime = "EndTime"
        case startTime = "StartTime"
        case type = "Type"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let category = self.category {
            try encodeContainer.encode(category, forKey: .category)
        }
        if let confidence = self.confidence {
            try encodeContainer.encode(confidence, forKey: .confidence)
        }
        if let content = self.content {
            try encodeContainer.encode(content, forKey: .content)
        }
        if endTime != 0.0 {
            try encodeContainer.encode(endTime, forKey: .endTime)
        }
        if startTime != 0.0 {
            try encodeContainer.encode(startTime, forKey: .startTime)
        }
        if let type = self.type {
            try encodeContainer.encode(type, forKey: .type)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let startTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .startTime) ?? 0.0
        startTime = startTimeDecoded
        let endTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .endTime) ?? 0.0
        endTime = endTimeDecoded
        let categoryDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .category)
        category = categoryDecoded
        let typeDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .type)
        type = typeDecoded
        let contentDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .content)
        content = contentDecoded
        let confidenceDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .confidence)
        confidence = confidenceDecoded
    }
}

extension TranscribeStreamingClientTypes {
    /// The entity identified as personally identifiable information (PII).
    public struct Entity: Swift.Equatable {
        /// The category of information identified in this entity; for example, PII.
        public var category: Swift.String?
        /// A value between zero and one that Amazon Transcribe assigns to PII identified in the source audio. Larger values indicate a higher confidence in PII identification.
        public var confidence: Swift.Double?
        /// The words in the transcription output that have been identified as a PII entity.
        public var content: Swift.String?
        /// The end time of speech that was identified as PII.
        public var endTime: Swift.Double
        /// The start time of speech that was identified as PII.
        public var startTime: Swift.Double
        /// The type of PII identified in this entity; for example, name or credit card number.
        public var type: Swift.String?

        public init (
            category: Swift.String? = nil,
            confidence: Swift.Double? = nil,
            content: Swift.String? = nil,
            endTime: Swift.Double = 0.0,
            startTime: Swift.Double = 0.0,
            type: Swift.String? = nil
        )
        {
            self.category = category
            self.confidence = confidence
            self.content = content
            self.endTime = endTime
            self.startTime = startTime
            self.type = type
        }
    }

}

extension InternalFailureException: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let message = self.message {
            try encodeContainer.encode(message, forKey: .message)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension InternalFailureException {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: InternalFailureExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// A problem occurred while processing the audio. Amazon Transcribe or Amazon Transcribe Medical terminated processing. Try your request again.
public struct InternalFailureException: AWSClientRuntime.AWSHttpServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .server
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct InternalFailureExceptionBody: Swift.Equatable {
    let message: Swift.String?
}

extension InternalFailureExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension TranscribeStreamingClientTypes.Item: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case confidence = "Confidence"
        case content = "Content"
        case endTime = "EndTime"
        case speaker = "Speaker"
        case stable = "Stable"
        case startTime = "StartTime"
        case type = "Type"
        case vocabularyFilterMatch = "VocabularyFilterMatch"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let confidence = self.confidence {
            try encodeContainer.encode(confidence, forKey: .confidence)
        }
        if let content = self.content {
            try encodeContainer.encode(content, forKey: .content)
        }
        if endTime != 0.0 {
            try encodeContainer.encode(endTime, forKey: .endTime)
        }
        if let speaker = self.speaker {
            try encodeContainer.encode(speaker, forKey: .speaker)
        }
        if let stable = self.stable {
            try encodeContainer.encode(stable, forKey: .stable)
        }
        if startTime != 0.0 {
            try encodeContainer.encode(startTime, forKey: .startTime)
        }
        if let type = self.type {
            try encodeContainer.encode(type.rawValue, forKey: .type)
        }
        if vocabularyFilterMatch != false {
            try encodeContainer.encode(vocabularyFilterMatch, forKey: .vocabularyFilterMatch)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let startTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .startTime) ?? 0.0
        startTime = startTimeDecoded
        let endTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .endTime) ?? 0.0
        endTime = endTimeDecoded
        let typeDecoded = try containerValues.decodeIfPresent(TranscribeStreamingClientTypes.ItemType.self, forKey: .type)
        type = typeDecoded
        let contentDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .content)
        content = contentDecoded
        let vocabularyFilterMatchDecoded = try containerValues.decodeIfPresent(Swift.Bool.self, forKey: .vocabularyFilterMatch) ?? false
        vocabularyFilterMatch = vocabularyFilterMatchDecoded
        let speakerDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .speaker)
        speaker = speakerDecoded
        let confidenceDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .confidence)
        confidence = confidenceDecoded
        let stableDecoded = try containerValues.decodeIfPresent(Swift.Bool.self, forKey: .stable)
        stable = stableDecoded
    }
}

extension TranscribeStreamingClientTypes {
    /// A word, phrase, or punctuation mark that is transcribed from the input audio.
    public struct Item: Swift.Equatable {
        /// A value between zero and one for an item that is a confidence score that Amazon Transcribe assigns to each word or phrase that it transcribes.
        public var confidence: Swift.Double?
        /// The word or punctuation that was recognized in the input audio.
        public var content: Swift.String?
        /// The offset from the beginning of the audio stream to the end of the audio that resulted in the item.
        public var endTime: Swift.Double
        /// If speaker identification is enabled, shows the speakers identified in the media stream.
        public var speaker: Swift.String?
        /// If partial result stabilization has been enabled, indicates whether the word or phrase in the item is stable. If Stable is true, the result is stable.
        public var stable: Swift.Bool?
        /// The offset from the beginning of the audio stream to the beginning of the audio that resulted in the item.
        public var startTime: Swift.Double
        /// The type of the item. PRONUNCIATION indicates that the item is a word that was recognized in the input audio. PUNCTUATION indicates that the item was interpreted as a pause in the input audio.
        public var type: TranscribeStreamingClientTypes.ItemType?
        /// Indicates whether a word in the item matches a word in the vocabulary filter you've chosen for your media stream. If true then a word in the item matches your vocabulary filter.
        public var vocabularyFilterMatch: Swift.Bool

        public init (
            confidence: Swift.Double? = nil,
            content: Swift.String? = nil,
            endTime: Swift.Double = 0.0,
            speaker: Swift.String? = nil,
            stable: Swift.Bool? = nil,
            startTime: Swift.Double = 0.0,
            type: TranscribeStreamingClientTypes.ItemType? = nil,
            vocabularyFilterMatch: Swift.Bool = false
        )
        {
            self.confidence = confidence
            self.content = content
            self.endTime = endTime
            self.speaker = speaker
            self.stable = stable
            self.startTime = startTime
            self.type = type
            self.vocabularyFilterMatch = vocabularyFilterMatch
        }
    }

}

extension TranscribeStreamingClientTypes {
    public enum ItemType: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case pronunciation
        case punctuation
        case sdkUnknown(Swift.String)

        public static var allCases: [ItemType] {
            return [
                .pronunciation,
                .punctuation,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .pronunciation: return "pronunciation"
            case .punctuation: return "punctuation"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = ItemType(rawValue: rawValue) ?? ItemType.sdkUnknown(rawValue)
        }
    }
}

extension TranscribeStreamingClientTypes {
    public enum LanguageCode: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case deDe
        case enAu
        case enGb
        case enUs
        case esUs
        case frCa
        case frFr
        case itIt
        case jaJp
        case koKr
        case ptBr
        case zhCn
        case sdkUnknown(Swift.String)

        public static var allCases: [LanguageCode] {
            return [
                .deDe,
                .enAu,
                .enGb,
                .enUs,
                .esUs,
                .frCa,
                .frFr,
                .itIt,
                .jaJp,
                .koKr,
                .ptBr,
                .zhCn,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .deDe: return "de-DE"
            case .enAu: return "en-AU"
            case .enGb: return "en-GB"
            case .enUs: return "en-US"
            case .esUs: return "es-US"
            case .frCa: return "fr-CA"
            case .frFr: return "fr-FR"
            case .itIt: return "it-IT"
            case .jaJp: return "ja-JP"
            case .koKr: return "ko-KR"
            case .ptBr: return "pt-BR"
            case .zhCn: return "zh-CN"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = LanguageCode(rawValue: rawValue) ?? LanguageCode.sdkUnknown(rawValue)
        }
    }
}

extension TranscribeStreamingClientTypes.LanguageWithScore: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case languageCode = "LanguageCode"
        case score = "Score"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let languageCode = self.languageCode {
            try encodeContainer.encode(languageCode.rawValue, forKey: .languageCode)
        }
        if score != 0.0 {
            try encodeContainer.encode(score, forKey: .score)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let languageCodeDecoded = try containerValues.decodeIfPresent(TranscribeStreamingClientTypes.LanguageCode.self, forKey: .languageCode)
        languageCode = languageCodeDecoded
        let scoreDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .score) ?? 0.0
        score = scoreDecoded
    }
}

extension TranscribeStreamingClientTypes {
    /// The language codes of the identified languages and their associated confidence scores. The confidence score is a value between zero and one; a larger value indicates a higher confidence in the identified language.
    public struct LanguageWithScore: Swift.Equatable {
        /// The language code of the language identified by Amazon Transcribe.
        public var languageCode: TranscribeStreamingClientTypes.LanguageCode?
        /// The confidence score for the associated language code. Confidence scores are values between zero and one; larger values indicate a higher confidence in the identified language.
        public var score: Swift.Double

        public init (
            languageCode: TranscribeStreamingClientTypes.LanguageCode? = nil,
            score: Swift.Double = 0.0
        )
        {
            self.languageCode = languageCode
            self.score = score
        }
    }

}

extension LimitExceededException: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let message = self.message {
            try encodeContainer.encode(message, forKey: .message)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension LimitExceededException {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: LimitExceededExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// You have exceeded the maximum number of concurrent transcription streams, are starting transcription streams too quickly, or the maximum audio length of 4 hours. Wait until a stream has finished processing, or break your audio stream into smaller chunks and try your request again.
public struct LimitExceededException: AWSClientRuntime.AWSHttpServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct LimitExceededExceptionBody: Swift.Equatable {
    let message: Swift.String?
}

extension LimitExceededExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension TranscribeStreamingClientTypes {
    public enum MediaEncoding: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case flac
        case oggOpus
        case pcm
        case sdkUnknown(Swift.String)

        public static var allCases: [MediaEncoding] {
            return [
                .flac,
                .oggOpus,
                .pcm,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .flac: return "flac"
            case .oggOpus: return "ogg-opus"
            case .pcm: return "pcm"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = MediaEncoding(rawValue: rawValue) ?? MediaEncoding.sdkUnknown(rawValue)
        }
    }
}

extension TranscribeStreamingClientTypes.MedicalAlternative: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case entities = "Entities"
        case items = "Items"
        case transcript = "Transcript"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let entities = entities {
            var entitiesContainer = encodeContainer.nestedUnkeyedContainer(forKey: .entities)
            for medicalentitylist0 in entities {
                try entitiesContainer.encode(medicalentitylist0)
            }
        }
        if let items = items {
            var itemsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .items)
            for medicalitemlist0 in items {
                try itemsContainer.encode(medicalitemlist0)
            }
        }
        if let transcript = self.transcript {
            try encodeContainer.encode(transcript, forKey: .transcript)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let transcriptDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .transcript)
        transcript = transcriptDecoded
        let itemsContainer = try containerValues.decodeIfPresent([TranscribeStreamingClientTypes.MedicalItem?].self, forKey: .items)
        var itemsDecoded0:[TranscribeStreamingClientTypes.MedicalItem]? = nil
        if let itemsContainer = itemsContainer {
            itemsDecoded0 = [TranscribeStreamingClientTypes.MedicalItem]()
            for structure0 in itemsContainer {
                if let structure0 = structure0 {
                    itemsDecoded0?.append(structure0)
                }
            }
        }
        items = itemsDecoded0
        let entitiesContainer = try containerValues.decodeIfPresent([TranscribeStreamingClientTypes.MedicalEntity?].self, forKey: .entities)
        var entitiesDecoded0:[TranscribeStreamingClientTypes.MedicalEntity]? = nil
        if let entitiesContainer = entitiesContainer {
            entitiesDecoded0 = [TranscribeStreamingClientTypes.MedicalEntity]()
            for structure0 in entitiesContainer {
                if let structure0 = structure0 {
                    entitiesDecoded0?.append(structure0)
                }
            }
        }
        entities = entitiesDecoded0
    }
}

extension TranscribeStreamingClientTypes {
    /// A list of possible transcriptions for the audio.
    public struct MedicalAlternative: Swift.Equatable {
        /// Contains the medical entities identified as personal health information in the transcription output.
        public var entities: [TranscribeStreamingClientTypes.MedicalEntity]?
        /// A list of objects that contains words and punctuation marks that represents one or more interpretations of the input audio.
        public var items: [TranscribeStreamingClientTypes.MedicalItem]?
        /// The text that was transcribed from the audio.
        public var transcript: Swift.String?

        public init (
            entities: [TranscribeStreamingClientTypes.MedicalEntity]? = nil,
            items: [TranscribeStreamingClientTypes.MedicalItem]? = nil,
            transcript: Swift.String? = nil
        )
        {
            self.entities = entities
            self.items = items
            self.transcript = transcript
        }
    }

}

extension TranscribeStreamingClientTypes {
    public enum MedicalContentIdentificationType: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case phi
        case sdkUnknown(Swift.String)

        public static var allCases: [MedicalContentIdentificationType] {
            return [
                .phi,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .phi: return "PHI"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = MedicalContentIdentificationType(rawValue: rawValue) ?? MedicalContentIdentificationType.sdkUnknown(rawValue)
        }
    }
}

extension TranscribeStreamingClientTypes.MedicalEntity: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case category = "Category"
        case confidence = "Confidence"
        case content = "Content"
        case endTime = "EndTime"
        case startTime = "StartTime"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let category = self.category {
            try encodeContainer.encode(category, forKey: .category)
        }
        if let confidence = self.confidence {
            try encodeContainer.encode(confidence, forKey: .confidence)
        }
        if let content = self.content {
            try encodeContainer.encode(content, forKey: .content)
        }
        if endTime != 0.0 {
            try encodeContainer.encode(endTime, forKey: .endTime)
        }
        if startTime != 0.0 {
            try encodeContainer.encode(startTime, forKey: .startTime)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let startTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .startTime) ?? 0.0
        startTime = startTimeDecoded
        let endTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .endTime) ?? 0.0
        endTime = endTimeDecoded
        let categoryDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .category)
        category = categoryDecoded
        let contentDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .content)
        content = contentDecoded
        let confidenceDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .confidence)
        confidence = confidenceDecoded
    }
}

extension TranscribeStreamingClientTypes {
    /// The medical entity identified as personal health information.
    public struct MedicalEntity: Swift.Equatable {
        /// The type of personal health information of the medical entity.
        public var category: Swift.String?
        /// A value between zero and one that Amazon Transcribe Medical assigned to the personal health information that it identified in the source audio. Larger values indicate that Amazon Transcribe Medical has higher confidence in the personal health information that it identified.
        public var confidence: Swift.Double?
        /// The word or words in the transcription output that have been identified as a medical entity.
        public var content: Swift.String?
        /// The end time of the speech that was identified as a medical entity.
        public var endTime: Swift.Double
        /// The start time of the speech that was identified as a medical entity.
        public var startTime: Swift.Double

        public init (
            category: Swift.String? = nil,
            confidence: Swift.Double? = nil,
            content: Swift.String? = nil,
            endTime: Swift.Double = 0.0,
            startTime: Swift.Double = 0.0
        )
        {
            self.category = category
            self.confidence = confidence
            self.content = content
            self.endTime = endTime
            self.startTime = startTime
        }
    }

}

extension TranscribeStreamingClientTypes.MedicalItem: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case confidence = "Confidence"
        case content = "Content"
        case endTime = "EndTime"
        case speaker = "Speaker"
        case startTime = "StartTime"
        case type = "Type"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let confidence = self.confidence {
            try encodeContainer.encode(confidence, forKey: .confidence)
        }
        if let content = self.content {
            try encodeContainer.encode(content, forKey: .content)
        }
        if endTime != 0.0 {
            try encodeContainer.encode(endTime, forKey: .endTime)
        }
        if let speaker = self.speaker {
            try encodeContainer.encode(speaker, forKey: .speaker)
        }
        if startTime != 0.0 {
            try encodeContainer.encode(startTime, forKey: .startTime)
        }
        if let type = self.type {
            try encodeContainer.encode(type.rawValue, forKey: .type)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let startTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .startTime) ?? 0.0
        startTime = startTimeDecoded
        let endTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .endTime) ?? 0.0
        endTime = endTimeDecoded
        let typeDecoded = try containerValues.decodeIfPresent(TranscribeStreamingClientTypes.ItemType.self, forKey: .type)
        type = typeDecoded
        let contentDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .content)
        content = contentDecoded
        let confidenceDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .confidence)
        confidence = confidenceDecoded
        let speakerDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .speaker)
        speaker = speakerDecoded
    }
}

extension TranscribeStreamingClientTypes {
    /// A word, phrase, or punctuation mark that is transcribed from the input audio.
    public struct MedicalItem: Swift.Equatable {
        /// A value between 0 and 1 for an item that is a confidence score that Amazon Transcribe Medical assigns to each word that it transcribes.
        public var confidence: Swift.Double?
        /// The word or punctuation mark that was recognized in the input audio.
        public var content: Swift.String?
        /// The number of seconds into an audio stream that indicates the creation time of an item.
        public var endTime: Swift.Double
        /// If speaker identification is enabled, shows the integer values that correspond to the different speakers identified in the stream. For example, if the value of Speaker in the stream is either a 0 or a 1, that indicates that Amazon Transcribe Medical has identified two speakers in the stream. The value of 0 corresponds to one speaker and the value of 1 corresponds to the other speaker.
        public var speaker: Swift.String?
        /// The number of seconds into an audio stream that indicates the creation time of an item.
        public var startTime: Swift.Double
        /// The type of the item. PRONUNCIATION indicates that the item is a word that was recognized in the input audio. PUNCTUATION indicates that the item was interpreted as a pause in the input audio, such as a period to indicate the end of a sentence.
        public var type: TranscribeStreamingClientTypes.ItemType?

        public init (
            confidence: Swift.Double? = nil,
            content: Swift.String? = nil,
            endTime: Swift.Double = 0.0,
            speaker: Swift.String? = nil,
            startTime: Swift.Double = 0.0,
            type: TranscribeStreamingClientTypes.ItemType? = nil
        )
        {
            self.confidence = confidence
            self.content = content
            self.endTime = endTime
            self.speaker = speaker
            self.startTime = startTime
            self.type = type
        }
    }

}

extension TranscribeStreamingClientTypes.MedicalResult: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case alternatives = "Alternatives"
        case channelId = "ChannelId"
        case endTime = "EndTime"
        case isPartial = "IsPartial"
        case resultId = "ResultId"
        case startTime = "StartTime"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let alternatives = alternatives {
            var alternativesContainer = encodeContainer.nestedUnkeyedContainer(forKey: .alternatives)
            for medicalalternativelist0 in alternatives {
                try alternativesContainer.encode(medicalalternativelist0)
            }
        }
        if let channelId = self.channelId {
            try encodeContainer.encode(channelId, forKey: .channelId)
        }
        if endTime != 0.0 {
            try encodeContainer.encode(endTime, forKey: .endTime)
        }
        if isPartial != false {
            try encodeContainer.encode(isPartial, forKey: .isPartial)
        }
        if let resultId = self.resultId {
            try encodeContainer.encode(resultId, forKey: .resultId)
        }
        if startTime != 0.0 {
            try encodeContainer.encode(startTime, forKey: .startTime)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let resultIdDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .resultId)
        resultId = resultIdDecoded
        let startTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .startTime) ?? 0.0
        startTime = startTimeDecoded
        let endTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .endTime) ?? 0.0
        endTime = endTimeDecoded
        let isPartialDecoded = try containerValues.decodeIfPresent(Swift.Bool.self, forKey: .isPartial) ?? false
        isPartial = isPartialDecoded
        let alternativesContainer = try containerValues.decodeIfPresent([TranscribeStreamingClientTypes.MedicalAlternative?].self, forKey: .alternatives)
        var alternativesDecoded0:[TranscribeStreamingClientTypes.MedicalAlternative]? = nil
        if let alternativesContainer = alternativesContainer {
            alternativesDecoded0 = [TranscribeStreamingClientTypes.MedicalAlternative]()
            for structure0 in alternativesContainer {
                if let structure0 = structure0 {
                    alternativesDecoded0?.append(structure0)
                }
            }
        }
        alternatives = alternativesDecoded0
        let channelIdDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .channelId)
        channelId = channelIdDecoded
    }
}

extension TranscribeStreamingClientTypes {
    /// The results of transcribing a portion of the input audio stream.
    public struct MedicalResult: Swift.Equatable {
        /// A list of possible transcriptions of the audio. Each alternative typically contains one Item that contains the result of the transcription.
        public var alternatives: [TranscribeStreamingClientTypes.MedicalAlternative]?
        /// When channel identification is enabled, Amazon Transcribe Medical transcribes the speech from each audio channel separately. You can use ChannelId to retrieve the transcription results for a single channel in your audio stream.
        public var channelId: Swift.String?
        /// The time, in seconds, from the beginning of the audio stream to the end of the result.
        public var endTime: Swift.Double
        /// Amazon Transcribe Medical divides the incoming audio stream into segments at natural points in the audio. Transcription results are returned based on these segments. The IsPartial field is true to indicate that Amazon Transcribe Medical has additional transcription data to send. The IsPartial field is false to indicate that this is the last transcription result for the segment.
        public var isPartial: Swift.Bool
        /// A unique identifier for the result.
        public var resultId: Swift.String?
        /// The time, in seconds, from the beginning of the audio stream to the beginning of the result.
        public var startTime: Swift.Double

        public init (
            alternatives: [TranscribeStreamingClientTypes.MedicalAlternative]? = nil,
            channelId: Swift.String? = nil,
            endTime: Swift.Double = 0.0,
            isPartial: Swift.Bool = false,
            resultId: Swift.String? = nil,
            startTime: Swift.Double = 0.0
        )
        {
            self.alternatives = alternatives
            self.channelId = channelId
            self.endTime = endTime
            self.isPartial = isPartial
            self.resultId = resultId
            self.startTime = startTime
        }
    }

}

extension TranscribeStreamingClientTypes.MedicalTranscript: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case results = "Results"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let results = results {
            var resultsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .results)
            for medicalresultlist0 in results {
                try resultsContainer.encode(medicalresultlist0)
            }
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let resultsContainer = try containerValues.decodeIfPresent([TranscribeStreamingClientTypes.MedicalResult?].self, forKey: .results)
        var resultsDecoded0:[TranscribeStreamingClientTypes.MedicalResult]? = nil
        if let resultsContainer = resultsContainer {
            resultsDecoded0 = [TranscribeStreamingClientTypes.MedicalResult]()
            for structure0 in resultsContainer {
                if let structure0 = structure0 {
                    resultsDecoded0?.append(structure0)
                }
            }
        }
        results = resultsDecoded0
    }
}

extension TranscribeStreamingClientTypes {
    /// The medical transcript in a [MedicalTranscriptEvent].
    public struct MedicalTranscript: Swift.Equatable {
        /// [MedicalResult] objects that contain the results of transcribing a portion of the input audio stream. The array can be empty.
        public var results: [TranscribeStreamingClientTypes.MedicalResult]?

        public init (
            results: [TranscribeStreamingClientTypes.MedicalResult]? = nil
        )
        {
            self.results = results
        }
    }

}

extension TranscribeStreamingClientTypes.MedicalTranscriptEvent: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case transcript = "Transcript"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let transcript = self.transcript {
            try encodeContainer.encode(transcript, forKey: .transcript)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let transcriptDecoded = try containerValues.decodeIfPresent(TranscribeStreamingClientTypes.MedicalTranscript.self, forKey: .transcript)
        transcript = transcriptDecoded
    }
}

extension TranscribeStreamingClientTypes {
    /// Represents a set of transcription results from the server to the client. It contains one or more segments of the transcription.
    public struct MedicalTranscriptEvent: Swift.Equatable {
        /// The transcription of the audio stream. The transcription is composed of all of the items in the results list.
        public var transcript: TranscribeStreamingClientTypes.MedicalTranscript?

        public init (
            transcript: TranscribeStreamingClientTypes.MedicalTranscript? = nil
        )
        {
            self.transcript = transcript
        }
    }

}

extension TranscribeStreamingClientTypes.MedicalTranscriptResultStream: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case badrequestexception = "BadRequestException"
        case conflictexception = "ConflictException"
        case internalfailureexception = "InternalFailureException"
        case limitexceededexception = "LimitExceededException"
        case serviceunavailableexception = "ServiceUnavailableException"
        case transcriptevent = "TranscriptEvent"
        case sdkUnknown
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var container = encoder.container(keyedBy: CodingKeys.self)
        switch self {
            case let .badrequestexception(badrequestexception):
                try container.encode(badrequestexception, forKey: .badrequestexception)
            case let .conflictexception(conflictexception):
                try container.encode(conflictexception, forKey: .conflictexception)
            case let .internalfailureexception(internalfailureexception):
                try container.encode(internalfailureexception, forKey: .internalfailureexception)
            case let .limitexceededexception(limitexceededexception):
                try container.encode(limitexceededexception, forKey: .limitexceededexception)
            case let .serviceunavailableexception(serviceunavailableexception):
                try container.encode(serviceunavailableexception, forKey: .serviceunavailableexception)
            case let .transcriptevent(transcriptevent):
                try container.encode(transcriptevent, forKey: .transcriptevent)
            case let .sdkUnknown(sdkUnknown):
                try container.encode(sdkUnknown, forKey: .sdkUnknown)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let values = try decoder.container(keyedBy: CodingKeys.self)
        let transcripteventDecoded = try values.decodeIfPresent(TranscribeStreamingClientTypes.MedicalTranscriptEvent.self, forKey: .transcriptevent)
        if let transcriptevent = transcripteventDecoded {
            self = .transcriptevent(transcriptevent)
            return
        }
        let badrequestexceptionDecoded = try values.decodeIfPresent(BadRequestException.self, forKey: .badrequestexception)
        if let badrequestexception = badrequestexceptionDecoded {
            self = .badrequestexception(badrequestexception)
            return
        }
        let limitexceededexceptionDecoded = try values.decodeIfPresent(LimitExceededException.self, forKey: .limitexceededexception)
        if let limitexceededexception = limitexceededexceptionDecoded {
            self = .limitexceededexception(limitexceededexception)
            return
        }
        let internalfailureexceptionDecoded = try values.decodeIfPresent(InternalFailureException.self, forKey: .internalfailureexception)
        if let internalfailureexception = internalfailureexceptionDecoded {
            self = .internalfailureexception(internalfailureexception)
            return
        }
        let conflictexceptionDecoded = try values.decodeIfPresent(ConflictException.self, forKey: .conflictexception)
        if let conflictexception = conflictexceptionDecoded {
            self = .conflictexception(conflictexception)
            return
        }
        let serviceunavailableexceptionDecoded = try values.decodeIfPresent(ServiceUnavailableException.self, forKey: .serviceunavailableexception)
        if let serviceunavailableexception = serviceunavailableexceptionDecoded {
            self = .serviceunavailableexception(serviceunavailableexception)
            return
        }
        self = .sdkUnknown("")
    }
}

extension TranscribeStreamingClientTypes {
    /// Represents the transcription result stream from Amazon Transcribe Medical to your application.
    public enum MedicalTranscriptResultStream: Swift.Equatable {
        /// A portion of the transcription of the audio stream. Events are sent periodically from Amazon Transcribe Medical to your application. The event can be a partial transcription of a section of the audio stream, or it can be the entire transcription of that portion of the audio stream.
        case transcriptevent(TranscribeStreamingClientTypes.MedicalTranscriptEvent)
        /// One or more arguments to the StartStreamTranscription or StartMedicalStreamTranscription operation was invalid. For example, MediaEncoding was not set to a valid encoding, or LanguageCode was not set to a valid code. Check the parameters and try your request again.
        case badrequestexception(BadRequestException)
        /// You have exceeded the maximum number of concurrent transcription streams, are starting transcription streams too quickly, or the maximum audio length of 4 hours. Wait until a stream has finished processing, or break your audio stream into smaller chunks and try your request again.
        case limitexceededexception(LimitExceededException)
        /// A problem occurred while processing the audio. Amazon Transcribe or Amazon Transcribe Medical terminated processing. Try your request again.
        case internalfailureexception(InternalFailureException)
        /// A new stream started with the same session ID. The current stream has been terminated.
        case conflictexception(ConflictException)
        /// Service is currently unavailable. Try your request later.
        case serviceunavailableexception(ServiceUnavailableException)
        case sdkUnknown(Swift.String)
    }

}

extension TranscribeStreamingClientTypes {
    public enum PartialResultsStability: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case high
        case low
        case medium
        case sdkUnknown(Swift.String)

        public static var allCases: [PartialResultsStability] {
            return [
                .high,
                .low,
                .medium,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .high: return "high"
            case .low: return "low"
            case .medium: return "medium"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = PartialResultsStability(rawValue: rawValue) ?? PartialResultsStability.sdkUnknown(rawValue)
        }
    }
}

extension TranscribeStreamingClientTypes.Result: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case alternatives = "Alternatives"
        case channelId = "ChannelId"
        case endTime = "EndTime"
        case isPartial = "IsPartial"
        case languageCode = "LanguageCode"
        case languageIdentification = "LanguageIdentification"
        case resultId = "ResultId"
        case startTime = "StartTime"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let alternatives = alternatives {
            var alternativesContainer = encodeContainer.nestedUnkeyedContainer(forKey: .alternatives)
            for alternativelist0 in alternatives {
                try alternativesContainer.encode(alternativelist0)
            }
        }
        if let channelId = self.channelId {
            try encodeContainer.encode(channelId, forKey: .channelId)
        }
        if endTime != 0.0 {
            try encodeContainer.encode(endTime, forKey: .endTime)
        }
        if isPartial != false {
            try encodeContainer.encode(isPartial, forKey: .isPartial)
        }
        if let languageCode = self.languageCode {
            try encodeContainer.encode(languageCode.rawValue, forKey: .languageCode)
        }
        if let languageIdentification = languageIdentification {
            var languageIdentificationContainer = encodeContainer.nestedUnkeyedContainer(forKey: .languageIdentification)
            for languageidentification0 in languageIdentification {
                try languageIdentificationContainer.encode(languageidentification0)
            }
        }
        if let resultId = self.resultId {
            try encodeContainer.encode(resultId, forKey: .resultId)
        }
        if startTime != 0.0 {
            try encodeContainer.encode(startTime, forKey: .startTime)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let resultIdDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .resultId)
        resultId = resultIdDecoded
        let startTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .startTime) ?? 0.0
        startTime = startTimeDecoded
        let endTimeDecoded = try containerValues.decodeIfPresent(Swift.Double.self, forKey: .endTime) ?? 0.0
        endTime = endTimeDecoded
        let isPartialDecoded = try containerValues.decodeIfPresent(Swift.Bool.self, forKey: .isPartial) ?? false
        isPartial = isPartialDecoded
        let alternativesContainer = try containerValues.decodeIfPresent([TranscribeStreamingClientTypes.Alternative?].self, forKey: .alternatives)
        var alternativesDecoded0:[TranscribeStreamingClientTypes.Alternative]? = nil
        if let alternativesContainer = alternativesContainer {
            alternativesDecoded0 = [TranscribeStreamingClientTypes.Alternative]()
            for structure0 in alternativesContainer {
                if let structure0 = structure0 {
                    alternativesDecoded0?.append(structure0)
                }
            }
        }
        alternatives = alternativesDecoded0
        let channelIdDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .channelId)
        channelId = channelIdDecoded
        let languageCodeDecoded = try containerValues.decodeIfPresent(TranscribeStreamingClientTypes.LanguageCode.self, forKey: .languageCode)
        languageCode = languageCodeDecoded
        let languageIdentificationContainer = try containerValues.decodeIfPresent([TranscribeStreamingClientTypes.LanguageWithScore?].self, forKey: .languageIdentification)
        var languageIdentificationDecoded0:[TranscribeStreamingClientTypes.LanguageWithScore]? = nil
        if let languageIdentificationContainer = languageIdentificationContainer {
            languageIdentificationDecoded0 = [TranscribeStreamingClientTypes.LanguageWithScore]()
            for structure0 in languageIdentificationContainer {
                if let structure0 = structure0 {
                    languageIdentificationDecoded0?.append(structure0)
                }
            }
        }
        languageIdentification = languageIdentificationDecoded0
    }
}

extension TranscribeStreamingClientTypes {
    /// The result of transcribing a portion of the input audio stream.
    public struct Result: Swift.Equatable {
        /// A list of possible transcriptions for the audio. Each alternative typically contains one item that contains the result of the transcription.
        public var alternatives: [TranscribeStreamingClientTypes.Alternative]?
        /// When channel identification is enabled, Amazon Transcribe transcribes the speech from each audio channel separately. You can use ChannelId to retrieve the transcription results for a single channel in your audio stream.
        public var channelId: Swift.String?
        /// The offset in seconds from the beginning of the audio stream to the end of the result.
        public var endTime: Swift.Double
        /// Amazon Transcribe divides the incoming audio stream into segments at natural points in the audio. Transcription results are returned based on these segments. The IsPartial field is true to indicate that Amazon Transcribe has additional transcription data to send, false to indicate that this is the last transcription result for the segment.
        public var isPartial: Swift.Bool
        /// The language code of the identified language in your media stream.
        public var languageCode: TranscribeStreamingClientTypes.LanguageCode?
        /// The language code of the dominant language identified in your media.
        public var languageIdentification: [TranscribeStreamingClientTypes.LanguageWithScore]?
        /// A unique identifier for the result.
        public var resultId: Swift.String?
        /// The offset in seconds from the beginning of the audio stream to the beginning of the result.
        public var startTime: Swift.Double

        public init (
            alternatives: [TranscribeStreamingClientTypes.Alternative]? = nil,
            channelId: Swift.String? = nil,
            endTime: Swift.Double = 0.0,
            isPartial: Swift.Bool = false,
            languageCode: TranscribeStreamingClientTypes.LanguageCode? = nil,
            languageIdentification: [TranscribeStreamingClientTypes.LanguageWithScore]? = nil,
            resultId: Swift.String? = nil,
            startTime: Swift.Double = 0.0
        )
        {
            self.alternatives = alternatives
            self.channelId = channelId
            self.endTime = endTime
            self.isPartial = isPartial
            self.languageCode = languageCode
            self.languageIdentification = languageIdentification
            self.resultId = resultId
            self.startTime = startTime
        }
    }

}

extension ServiceUnavailableException: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let message = self.message {
            try encodeContainer.encode(message, forKey: .message)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension ServiceUnavailableException {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: ServiceUnavailableExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// Service is currently unavailable. Try your request later.
public struct ServiceUnavailableException: AWSClientRuntime.AWSHttpServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .server
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct ServiceUnavailableExceptionBody: Swift.Equatable {
    let message: Swift.String?
}

extension ServiceUnavailableExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension TranscribeStreamingClientTypes {
    public enum Specialty: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case cardiology
        case neurology
        case oncology
        case primarycare
        case radiology
        case urology
        case sdkUnknown(Swift.String)

        public static var allCases: [Specialty] {
            return [
                .cardiology,
                .neurology,
                .oncology,
                .primarycare,
                .radiology,
                .urology,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .cardiology: return "CARDIOLOGY"
            case .neurology: return "NEUROLOGY"
            case .oncology: return "ONCOLOGY"
            case .primarycare: return "PRIMARYCARE"
            case .radiology: return "RADIOLOGY"
            case .urology: return "UROLOGY"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = Specialty(rawValue: rawValue) ?? Specialty.sdkUnknown(rawValue)
        }
    }
}

public struct StartMedicalStreamTranscriptionInputBodyMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "StartMedicalStreamTranscriptionInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<StartMedicalStreamTranscriptionInput>,
                  next: H) async throws -> ClientRuntime.OperationOutput<StartMedicalStreamTranscriptionOutputResponse>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context
    {
        do {
            let encoder = context.getEncoder()
            if let audioStream = input.operationInput.audioStream {
                let audioStreamdata = try encoder.encode(audioStream)
                let audioStreambody = ClientRuntime.HttpBody.data(audioStreamdata)
                input.builder.withBody(audioStreambody)
            } else {
                if encoder is JSONEncoder {
                    // Encode an empty body as an empty structure in JSON
                    let audioStreamdata = "{}".data(using: .utf8)!
                    let audioStreambody = ClientRuntime.HttpBody.data(audioStreamdata)
                    input.builder.withBody(audioStreambody)
                }
            }
        } catch let err {
            throw SdkError<StartMedicalStreamTranscriptionOutputError>.client(ClientRuntime.ClientError.serializationFailed(err.localizedDescription))
        }
        return try await next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<StartMedicalStreamTranscriptionInput>
    public typealias MOutput = ClientRuntime.OperationOutput<StartMedicalStreamTranscriptionOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
}

extension StartMedicalStreamTranscriptionInput: Swift.Encodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case audioStream = "AudioStream"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let audioStream = self.audioStream {
            try encodeContainer.encode(audioStream, forKey: .audioStream)
        }
    }
}

extension StartMedicalStreamTranscriptionInput: ClientRuntime.HeaderProvider {
    public var headers: ClientRuntime.Headers {
        var items = ClientRuntime.Headers()
        if let contentIdentificationType = contentIdentificationType {
            items.add(Header(name: "x-amzn-transcribe-content-identification-type", value: Swift.String(contentIdentificationType.rawValue)))
        }
        if enableChannelIdentification != false {
            items.add(Header(name: "x-amzn-transcribe-enable-channel-identification", value: Swift.String(enableChannelIdentification)))
        }
        if let languageCode = languageCode {
            items.add(Header(name: "x-amzn-transcribe-language-code", value: Swift.String(languageCode.rawValue)))
        }
        if let mediaEncoding = mediaEncoding {
            items.add(Header(name: "x-amzn-transcribe-media-encoding", value: Swift.String(mediaEncoding.rawValue)))
        }
        if let mediaSampleRateHertz = mediaSampleRateHertz {
            items.add(Header(name: "x-amzn-transcribe-sample-rate", value: Swift.String(mediaSampleRateHertz)))
        }
        if let numberOfChannels = numberOfChannels {
            items.add(Header(name: "x-amzn-transcribe-number-of-channels", value: Swift.String(numberOfChannels)))
        }
        if let sessionId = sessionId {
            items.add(Header(name: "x-amzn-transcribe-session-id", value: Swift.String(sessionId)))
        }
        if showSpeakerLabel != false {
            items.add(Header(name: "x-amzn-transcribe-show-speaker-label", value: Swift.String(showSpeakerLabel)))
        }
        if let specialty = specialty {
            items.add(Header(name: "x-amzn-transcribe-specialty", value: Swift.String(specialty.rawValue)))
        }
        if let type = type {
            items.add(Header(name: "x-amzn-transcribe-type", value: Swift.String(type.rawValue)))
        }
        if let vocabularyName = vocabularyName {
            items.add(Header(name: "x-amzn-transcribe-vocabulary-name", value: Swift.String(vocabularyName)))
        }
        return items
    }
}

extension StartMedicalStreamTranscriptionInput: ClientRuntime.URLPathProvider {
    public var urlPath: Swift.String? {
        return "/medical-stream-transcription"
    }
}

public struct StartMedicalStreamTranscriptionInput: Swift.Equatable {
    /// Represents the audio stream from your application to Amazon Transcribe.
    /// This member is required.
    public var audioStream: TranscribeStreamingClientTypes.AudioStream?
    /// Set this field to PHI to identify personal health information in the transcription output.
    public var contentIdentificationType: TranscribeStreamingClientTypes.MedicalContentIdentificationType?
    /// When true, instructs Amazon Transcribe Medical to process each audio channel separately and then merge the transcription output of each channel into a single transcription. Amazon Transcribe Medical also produces a transcription of each item. An item includes the start time, end time, and any alternative transcriptions. You can't set both ShowSpeakerLabel and EnableChannelIdentification in the same request. If you set both, your request returns a BadRequestException.
    public var enableChannelIdentification: Swift.Bool
    /// Indicates the source language used in the input audio stream. For Amazon Transcribe Medical, this is US English (en-US).
    /// This member is required.
    public var languageCode: TranscribeStreamingClientTypes.LanguageCode?
    /// The encoding used for the input audio.
    /// This member is required.
    public var mediaEncoding: TranscribeStreamingClientTypes.MediaEncoding?
    /// The sample rate of the input audio (in Hertz). Amazon Transcribe medical supports a range from 16,000 Hz to 48,000 Hz. Note that the sample rate you specify must match that of your audio.
    /// This member is required.
    public var mediaSampleRateHertz: Swift.Int?
    /// The number of channels that are in your audio stream.
    public var numberOfChannels: Swift.Int?
    /// Optional. An identifier for the transcription session. If you don't provide a session ID, Amazon Transcribe generates one for you and returns it in the response.
    public var sessionId: Swift.String?
    /// When true, enables speaker identification in your real-time stream.
    public var showSpeakerLabel: Swift.Bool
    /// The medical specialty of the clinician or provider.
    /// This member is required.
    public var specialty: TranscribeStreamingClientTypes.Specialty?
    /// The type of input audio. Choose DICTATION for a provider dictating patient notes. Choose CONVERSATION for a dialogue between a patient and one or more medical professionanls.
    /// This member is required.
    public var type: TranscribeStreamingClientTypes.ModelType?
    /// The name of the medical custom vocabulary to use when processing the real-time stream.
    public var vocabularyName: Swift.String?

    public init (
        audioStream: TranscribeStreamingClientTypes.AudioStream? = nil,
        contentIdentificationType: TranscribeStreamingClientTypes.MedicalContentIdentificationType? = nil,
        enableChannelIdentification: Swift.Bool = false,
        languageCode: TranscribeStreamingClientTypes.LanguageCode? = nil,
        mediaEncoding: TranscribeStreamingClientTypes.MediaEncoding? = nil,
        mediaSampleRateHertz: Swift.Int? = nil,
        numberOfChannels: Swift.Int? = nil,
        sessionId: Swift.String? = nil,
        showSpeakerLabel: Swift.Bool = false,
        specialty: TranscribeStreamingClientTypes.Specialty? = nil,
        type: TranscribeStreamingClientTypes.ModelType? = nil,
        vocabularyName: Swift.String? = nil
    )
    {
        self.audioStream = audioStream
        self.contentIdentificationType = contentIdentificationType
        self.enableChannelIdentification = enableChannelIdentification
        self.languageCode = languageCode
        self.mediaEncoding = mediaEncoding
        self.mediaSampleRateHertz = mediaSampleRateHertz
        self.numberOfChannels = numberOfChannels
        self.sessionId = sessionId
        self.showSpeakerLabel = showSpeakerLabel
        self.specialty = specialty
        self.type = type
        self.vocabularyName = vocabularyName
    }
}

struct StartMedicalStreamTranscriptionInputBody: Swift.Equatable {
    let audioStream: TranscribeStreamingClientTypes.AudioStream?
}

extension StartMedicalStreamTranscriptionInputBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case audioStream = "AudioStream"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let audioStreamDecoded = try containerValues.decodeIfPresent(TranscribeStreamingClientTypes.AudioStream.self, forKey: .audioStream)
        audioStream = audioStreamDecoded
    }
}

extension StartMedicalStreamTranscriptionOutputError: ClientRuntime.HttpResponseBinding {
    public init(httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        let errorDetails = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension StartMedicalStreamTranscriptionOutputError {
    public init(errorType: Swift.String?, httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        switch errorType {
        case "BadRequestException" : self = .badRequestException(try BadRequestException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ConflictException" : self = .conflictException(try ConflictException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InternalFailureException" : self = .internalFailureException(try InternalFailureException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "LimitExceededException" : self = .limitExceededException(try LimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ServiceUnavailableException" : self = .serviceUnavailableException(try ServiceUnavailableException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum StartMedicalStreamTranscriptionOutputError: Swift.Error, Swift.Equatable {
    case badRequestException(BadRequestException)
    case conflictException(ConflictException)
    case internalFailureException(InternalFailureException)
    case limitExceededException(LimitExceededException)
    case serviceUnavailableException(ServiceUnavailableException)
    case unknown(UnknownAWSHttpServiceError)
}

extension StartMedicalStreamTranscriptionOutputResponse: ClientRuntime.HttpResponseBinding {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        if let contentIdentificationTypeHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-content-identification-type") {
            self.contentIdentificationType = TranscribeStreamingClientTypes.MedicalContentIdentificationType(rawValue: contentIdentificationTypeHeaderValue)
        } else {
            self.contentIdentificationType = nil
        }
        if let enableChannelIdentificationHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-enable-channel-identification") {
            self.enableChannelIdentification = Swift.Bool(enableChannelIdentificationHeaderValue) ?? false
        } else {
            self.enableChannelIdentification = false
        }
        if let languageCodeHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-language-code") {
            self.languageCode = TranscribeStreamingClientTypes.LanguageCode(rawValue: languageCodeHeaderValue)
        } else {
            self.languageCode = nil
        }
        if let mediaEncodingHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-media-encoding") {
            self.mediaEncoding = TranscribeStreamingClientTypes.MediaEncoding(rawValue: mediaEncodingHeaderValue)
        } else {
            self.mediaEncoding = nil
        }
        if let mediaSampleRateHertzHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-sample-rate") {
            self.mediaSampleRateHertz = Swift.Int(mediaSampleRateHertzHeaderValue) ?? 0
        } else {
            self.mediaSampleRateHertz = nil
        }
        if let numberOfChannelsHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-number-of-channels") {
            self.numberOfChannels = Swift.Int(numberOfChannelsHeaderValue) ?? 0
        } else {
            self.numberOfChannels = nil
        }
        if let requestIdHeaderValue = httpResponse.headers.value(for: "x-amzn-request-id") {
            self.requestId = requestIdHeaderValue
        } else {
            self.requestId = nil
        }
        if let sessionIdHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-session-id") {
            self.sessionId = sessionIdHeaderValue
        } else {
            self.sessionId = nil
        }
        if let showSpeakerLabelHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-show-speaker-label") {
            self.showSpeakerLabel = Swift.Bool(showSpeakerLabelHeaderValue) ?? false
        } else {
            self.showSpeakerLabel = false
        }
        if let specialtyHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-specialty") {
            self.specialty = TranscribeStreamingClientTypes.Specialty(rawValue: specialtyHeaderValue)
        } else {
            self.specialty = nil
        }
        if let typeHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-type") {
            self.type = TranscribeStreamingClientTypes.ModelType(rawValue: typeHeaderValue)
        } else {
            self.type = nil
        }
        if let vocabularyNameHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-vocabulary-name") {
            self.vocabularyName = vocabularyNameHeaderValue
        } else {
            self.vocabularyName = nil
        }
        if case .stream(let reader) = httpResponse.body {
            let data = reader.toBytes().toData()
            if let responseDecoder = decoder {
                let output: TranscribeStreamingClientTypes.MedicalTranscriptResultStream = try responseDecoder.decode(responseBody: data)
                self.transcriptResultStream = output
            } else {
                self.transcriptResultStream = nil
            }
        } else {
            self.transcriptResultStream = nil
        }
    }
}

public struct StartMedicalStreamTranscriptionOutputResponse: Swift.Equatable {
    /// If the value is PHI, indicates that you've configured your stream to identify personal health information.
    public var contentIdentificationType: TranscribeStreamingClientTypes.MedicalContentIdentificationType?
    /// Shows whether channel identification has been enabled in the stream.
    public var enableChannelIdentification: Swift.Bool
    /// The language code for the response transcript. For Amazon Transcribe Medical, this is US English (en-US).
    public var languageCode: TranscribeStreamingClientTypes.LanguageCode?
    /// The encoding used for the input audio stream.
    public var mediaEncoding: TranscribeStreamingClientTypes.MediaEncoding?
    /// The sample rate of the input audio, in Hertz (Hz).
    public var mediaSampleRateHertz: Swift.Int?
    /// The number of channels identified in the stream.
    public var numberOfChannels: Swift.Int?
    /// An identifier for the streaming transcription.
    public var requestId: Swift.String?
    /// Optional. An identifier for the transcription session. If you don't provide a session ID, Amazon Transcribe generates one for you and returns it in the response.
    public var sessionId: Swift.String?
    /// Shows whether speaker identification was enabled in the stream.
    public var showSpeakerLabel: Swift.Bool
    /// The specialty in the medical domain.
    public var specialty: TranscribeStreamingClientTypes.Specialty?
    /// Represents the stream of transcription events from Amazon Transcribe Medical to your application.
    public var transcriptResultStream: TranscribeStreamingClientTypes.MedicalTranscriptResultStream?
    /// The type of audio that was transcribed.
    public var type: TranscribeStreamingClientTypes.ModelType?
    /// The name of the vocabulary used when processing the stream.
    public var vocabularyName: Swift.String?

    public init (
        contentIdentificationType: TranscribeStreamingClientTypes.MedicalContentIdentificationType? = nil,
        enableChannelIdentification: Swift.Bool = false,
        languageCode: TranscribeStreamingClientTypes.LanguageCode? = nil,
        mediaEncoding: TranscribeStreamingClientTypes.MediaEncoding? = nil,
        mediaSampleRateHertz: Swift.Int? = nil,
        numberOfChannels: Swift.Int? = nil,
        requestId: Swift.String? = nil,
        sessionId: Swift.String? = nil,
        showSpeakerLabel: Swift.Bool = false,
        specialty: TranscribeStreamingClientTypes.Specialty? = nil,
        transcriptResultStream: TranscribeStreamingClientTypes.MedicalTranscriptResultStream? = nil,
        type: TranscribeStreamingClientTypes.ModelType? = nil,
        vocabularyName: Swift.String? = nil
    )
    {
        self.contentIdentificationType = contentIdentificationType
        self.enableChannelIdentification = enableChannelIdentification
        self.languageCode = languageCode
        self.mediaEncoding = mediaEncoding
        self.mediaSampleRateHertz = mediaSampleRateHertz
        self.numberOfChannels = numberOfChannels
        self.requestId = requestId
        self.sessionId = sessionId
        self.showSpeakerLabel = showSpeakerLabel
        self.specialty = specialty
        self.transcriptResultStream = transcriptResultStream
        self.type = type
        self.vocabularyName = vocabularyName
    }
}

struct StartMedicalStreamTranscriptionOutputResponseBody: Swift.Equatable {
    let transcriptResultStream: TranscribeStreamingClientTypes.MedicalTranscriptResultStream?
}

extension StartMedicalStreamTranscriptionOutputResponseBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case transcriptResultStream = "TranscriptResultStream"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let transcriptResultStreamDecoded = try containerValues.decodeIfPresent(TranscribeStreamingClientTypes.MedicalTranscriptResultStream.self, forKey: .transcriptResultStream)
        transcriptResultStream = transcriptResultStreamDecoded
    }
}

public struct StartStreamTranscriptionInputBodyMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "StartStreamTranscriptionInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<StartStreamTranscriptionInput>,
                  next: H) async throws -> ClientRuntime.OperationOutput<StartStreamTranscriptionOutputResponse>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context
    {
        do {
            let encoder = context.getEncoder()
            if let audioStream = input.operationInput.audioStream {
                let audioStreamdata = try encoder.encode(audioStream)
                let audioStreambody = ClientRuntime.HttpBody.data(audioStreamdata)
                input.builder.withBody(audioStreambody)
            } else {
                if encoder is JSONEncoder {
                    // Encode an empty body as an empty structure in JSON
                    let audioStreamdata = "{}".data(using: .utf8)!
                    let audioStreambody = ClientRuntime.HttpBody.data(audioStreamdata)
                    input.builder.withBody(audioStreambody)
                }
            }
        } catch let err {
            throw SdkError<StartStreamTranscriptionOutputError>.client(ClientRuntime.ClientError.serializationFailed(err.localizedDescription))
        }
        return try await next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<StartStreamTranscriptionInput>
    public typealias MOutput = ClientRuntime.OperationOutput<StartStreamTranscriptionOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
}

extension StartStreamTranscriptionInput: Swift.Encodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case audioStream = "AudioStream"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let audioStream = self.audioStream {
            try encodeContainer.encode(audioStream, forKey: .audioStream)
        }
    }
}

extension StartStreamTranscriptionInput: ClientRuntime.HeaderProvider {
    public var headers: ClientRuntime.Headers {
        var items = ClientRuntime.Headers()
        if let contentIdentificationType = contentIdentificationType {
            items.add(Header(name: "x-amzn-transcribe-content-identification-type", value: Swift.String(contentIdentificationType.rawValue)))
        }
        if let contentRedactionType = contentRedactionType {
            items.add(Header(name: "x-amzn-transcribe-content-redaction-type", value: Swift.String(contentRedactionType.rawValue)))
        }
        if enableChannelIdentification != false {
            items.add(Header(name: "x-amzn-transcribe-enable-channel-identification", value: Swift.String(enableChannelIdentification)))
        }
        if enablePartialResultsStabilization != false {
            items.add(Header(name: "x-amzn-transcribe-enable-partial-results-stabilization", value: Swift.String(enablePartialResultsStabilization)))
        }
        if identifyLanguage != false {
            items.add(Header(name: "x-amzn-transcribe-identify-language", value: Swift.String(identifyLanguage)))
        }
        if let languageCode = languageCode {
            items.add(Header(name: "x-amzn-transcribe-language-code", value: Swift.String(languageCode.rawValue)))
        }
        if let languageModelName = languageModelName {
            items.add(Header(name: "x-amzn-transcribe-language-model-name", value: Swift.String(languageModelName)))
        }
        if let languageOptions = languageOptions {
            items.add(Header(name: "x-amzn-transcribe-language-options", value: Swift.String(languageOptions)))
        }
        if let mediaEncoding = mediaEncoding {
            items.add(Header(name: "x-amzn-transcribe-media-encoding", value: Swift.String(mediaEncoding.rawValue)))
        }
        if let mediaSampleRateHertz = mediaSampleRateHertz {
            items.add(Header(name: "x-amzn-transcribe-sample-rate", value: Swift.String(mediaSampleRateHertz)))
        }
        if let numberOfChannels = numberOfChannels {
            items.add(Header(name: "x-amzn-transcribe-number-of-channels", value: Swift.String(numberOfChannels)))
        }
        if let partialResultsStability = partialResultsStability {
            items.add(Header(name: "x-amzn-transcribe-partial-results-stability", value: Swift.String(partialResultsStability.rawValue)))
        }
        if let piiEntityTypes = piiEntityTypes {
            items.add(Header(name: "x-amzn-transcribe-pii-entity-types", value: Swift.String(piiEntityTypes)))
        }
        if let preferredLanguage = preferredLanguage {
            items.add(Header(name: "x-amzn-transcribe-preferred-language", value: Swift.String(preferredLanguage.rawValue)))
        }
        if let sessionId = sessionId {
            items.add(Header(name: "x-amzn-transcribe-session-id", value: Swift.String(sessionId)))
        }
        if showSpeakerLabel != false {
            items.add(Header(name: "x-amzn-transcribe-show-speaker-label", value: Swift.String(showSpeakerLabel)))
        }
        if let vocabularyFilterMethod = vocabularyFilterMethod {
            items.add(Header(name: "x-amzn-transcribe-vocabulary-filter-method", value: Swift.String(vocabularyFilterMethod.rawValue)))
        }
        if let vocabularyFilterName = vocabularyFilterName {
            items.add(Header(name: "x-amzn-transcribe-vocabulary-filter-name", value: Swift.String(vocabularyFilterName)))
        }
        if let vocabularyFilterNames = vocabularyFilterNames {
            items.add(Header(name: "x-amzn-transcribe-vocabulary-filter-names", value: Swift.String(vocabularyFilterNames)))
        }
        if let vocabularyName = vocabularyName {
            items.add(Header(name: "x-amzn-transcribe-vocabulary-name", value: Swift.String(vocabularyName)))
        }
        if let vocabularyNames = vocabularyNames {
            items.add(Header(name: "x-amzn-transcribe-vocabulary-names", value: Swift.String(vocabularyNames)))
        }
        return items
    }
}

extension StartStreamTranscriptionInput: ClientRuntime.URLPathProvider {
    public var urlPath: Swift.String? {
        return "/stream-transcription"
    }
}

public struct StartStreamTranscriptionInput: Swift.Equatable {
    /// PCM-encoded stream of audio blobs. The audio stream is encoded as an HTTP/2 data frame.
    /// This member is required.
    public var audioStream: TranscribeStreamingClientTypes.AudioStream?
    /// Set this field to PII to identify personally identifiable information (PII) in the transcription output. Content identification is performed only upon complete transcription of the audio segments. You can’t set both ContentIdentificationType and ContentRedactionType in the same request. If you set both, your request returns a BadRequestException.
    public var contentIdentificationType: TranscribeStreamingClientTypes.ContentIdentificationType?
    /// Set this field to PII to redact personally identifiable information (PII) in the transcription output. Content redaction is performed only upon complete transcription of the audio segments. You can’t set both ContentRedactionType and ContentIdentificationType in the same request. If you set both, your request returns a BadRequestException.
    public var contentRedactionType: TranscribeStreamingClientTypes.ContentRedactionType?
    /// When true, instructs Amazon Transcribe to process each audio channel separately, then merges the transcription output of each channel into a single transcription. Amazon Transcribe also produces a transcription of each item. An item includes the start time, end time, and any alternative transcriptions.
    public var enableChannelIdentification: Swift.Bool
    /// When true, instructs Amazon Transcribe to present transcription results that have the partial results stabilized. Normally, any word or phrase from one partial result can change in a subsequent partial result. With partial results stabilization enabled, only the last few words of one partial result can change in another partial result.
    public var enablePartialResultsStabilization: Swift.Bool
    /// Optional. Set this value to true to enable language identification for your media stream.
    public var identifyLanguage: Swift.Bool
    /// The language code of the input audio stream.
    public var languageCode: TranscribeStreamingClientTypes.LanguageCode?
    /// The name of the language model you want to use.
    public var languageModelName: Swift.String?
    /// An object containing a list of languages that might be present in your audio. You must provide two or more language codes to help Amazon Transcribe identify the correct language of your media stream with the highest possible accuracy. You can only select one variant per language; for example, you can't include both en-US and en-UK in the same request. You can only use this parameter if you've set IdentifyLanguage to truein your request.
    public var languageOptions: Swift.String?
    /// The encoding used for the input audio.
    /// This member is required.
    public var mediaEncoding: TranscribeStreamingClientTypes.MediaEncoding?
    /// The sample rate of the input audio (in Hertz). Low-quality audio, such as telephone audio, is typically around 8,000 Hz. High-quality audio typically ranges from 16,000 Hz to 48,000 Hz. Note that the sample rate you specify must match that of your audio.
    /// This member is required.
    public var mediaSampleRateHertz: Swift.Int?
    /// The number of channels that are in your audio stream.
    public var numberOfChannels: Swift.Int?
    /// You can use this field to set the stability level of the transcription results. A higher stability level means that the transcription results are less likely to change. Higher stability levels can come with lower overall transcription accuracy.
    public var partialResultsStability: TranscribeStreamingClientTypes.PartialResultsStability?
    /// List the PII entity types you want to identify or redact. In order to specify entity types, you must have either ContentIdentificationType or ContentRedactionType enabled. PIIEntityTypes must be comma-separated; the available values are: BANK_ACCOUNT_NUMBER, BANK_ROUTING, CREDIT_DEBIT_NUMBER, CREDIT_DEBIT_CVV, CREDIT_DEBIT_EXPIRY, PIN, EMAIL, ADDRESS, NAME, PHONE, SSN, and ALL. PiiEntityTypes is an optional parameter with a default value of ALL.
    public var piiEntityTypes: Swift.String?
    /// Optional. From the subset of languages codes you provided for LanguageOptions, you can select one preferred language for your transcription. You can only use this parameter if you've set IdentifyLanguage to truein your request.
    public var preferredLanguage: TranscribeStreamingClientTypes.LanguageCode?
    /// A identifier for the transcription session. Use this parameter when you want to retry a session. If you don't provide a session ID, Amazon Transcribe will generate one for you and return it in the response.
    public var sessionId: Swift.String?
    /// When true, enables speaker identification in your media stream.
    public var showSpeakerLabel: Swift.Bool
    /// The manner in which you use your vocabulary filter to filter words in your transcript. Remove removes filtered words from your transcription results. Mask masks filtered words with a *** in your transcription results. Tag keeps the filtered words in your transcription results and tags them. The tag appears as VocabularyFilterMatch equal to True.
    public var vocabularyFilterMethod: TranscribeStreamingClientTypes.VocabularyFilterMethod?
    /// The name of the vocabulary filter you want to use with your transcription. This operation is not intended for use in conjunction with the IdentifyLanguage operation. If you're using IdentifyLanguage in your request and want to use one or more vocabulary filters with your transcription, use the VocabularyFilterNames operation instead.
    public var vocabularyFilterName: Swift.String?
    /// The names of the vocabulary filters you want to use with your transcription. Note that if the vocabulary filters you specify are in languages that don't match the language identified in your media, your job fails. This operation is only intended for use in conjunction with the IdentifyLanguage operation. If you're not using IdentifyLanguage in your request and want to use a vocabulary filter with your transcription, use the VocabularyFilterName operation instead.
    public var vocabularyFilterNames: Swift.String?
    /// The name of the custom vocabulary you want to use with your transcription. This operation is not intended for use in conjunction with the IdentifyLanguage operation. If you're using IdentifyLanguage in your request and want to use one or more custom vocabularies with your transcription, use the VocabularyNames operation instead.
    public var vocabularyName: Swift.String?
    /// The names of the custom vocabularies you want to use with your transcription. Note that if the custom vocabularies you specify are in languages that don't match the language identified in your media, your job fails. This operation is only intended for use in conjunction with the IdentifyLanguage operation. If you're not using IdentifyLanguage in your request and want to use a custom vocabulary with your transcription, use the VocabularyName operation instead.
    public var vocabularyNames: Swift.String?

    public init (
        audioStream: TranscribeStreamingClientTypes.AudioStream? = nil,
        contentIdentificationType: TranscribeStreamingClientTypes.ContentIdentificationType? = nil,
        contentRedactionType: TranscribeStreamingClientTypes.ContentRedactionType? = nil,
        enableChannelIdentification: Swift.Bool = false,
        enablePartialResultsStabilization: Swift.Bool = false,
        identifyLanguage: Swift.Bool = false,
        languageCode: TranscribeStreamingClientTypes.LanguageCode? = nil,
        languageModelName: Swift.String? = nil,
        languageOptions: Swift.String? = nil,
        mediaEncoding: TranscribeStreamingClientTypes.MediaEncoding? = nil,
        mediaSampleRateHertz: Swift.Int? = nil,
        numberOfChannels: Swift.Int? = nil,
        partialResultsStability: TranscribeStreamingClientTypes.PartialResultsStability? = nil,
        piiEntityTypes: Swift.String? = nil,
        preferredLanguage: TranscribeStreamingClientTypes.LanguageCode? = nil,
        sessionId: Swift.String? = nil,
        showSpeakerLabel: Swift.Bool = false,
        vocabularyFilterMethod: TranscribeStreamingClientTypes.VocabularyFilterMethod? = nil,
        vocabularyFilterName: Swift.String? = nil,
        vocabularyFilterNames: Swift.String? = nil,
        vocabularyName: Swift.String? = nil,
        vocabularyNames: Swift.String? = nil
    )
    {
        self.audioStream = audioStream
        self.contentIdentificationType = contentIdentificationType
        self.contentRedactionType = contentRedactionType
        self.enableChannelIdentification = enableChannelIdentification
        self.enablePartialResultsStabilization = enablePartialResultsStabilization
        self.identifyLanguage = identifyLanguage
        self.languageCode = languageCode
        self.languageModelName = languageModelName
        self.languageOptions = languageOptions
        self.mediaEncoding = mediaEncoding
        self.mediaSampleRateHertz = mediaSampleRateHertz
        self.numberOfChannels = numberOfChannels
        self.partialResultsStability = partialResultsStability
        self.piiEntityTypes = piiEntityTypes
        self.preferredLanguage = preferredLanguage
        self.sessionId = sessionId
        self.showSpeakerLabel = showSpeakerLabel
        self.vocabularyFilterMethod = vocabularyFilterMethod
        self.vocabularyFilterName = vocabularyFilterName
        self.vocabularyFilterNames = vocabularyFilterNames
        self.vocabularyName = vocabularyName
        self.vocabularyNames = vocabularyNames
    }
}

struct StartStreamTranscriptionInputBody: Swift.Equatable {
    let audioStream: TranscribeStreamingClientTypes.AudioStream?
}

extension StartStreamTranscriptionInputBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case audioStream = "AudioStream"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let audioStreamDecoded = try containerValues.decodeIfPresent(TranscribeStreamingClientTypes.AudioStream.self, forKey: .audioStream)
        audioStream = audioStreamDecoded
    }
}

extension StartStreamTranscriptionOutputError: ClientRuntime.HttpResponseBinding {
    public init(httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        let errorDetails = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension StartStreamTranscriptionOutputError {
    public init(errorType: Swift.String?, httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        switch errorType {
        case "BadRequestException" : self = .badRequestException(try BadRequestException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ConflictException" : self = .conflictException(try ConflictException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InternalFailureException" : self = .internalFailureException(try InternalFailureException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "LimitExceededException" : self = .limitExceededException(try LimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ServiceUnavailableException" : self = .serviceUnavailableException(try ServiceUnavailableException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum StartStreamTranscriptionOutputError: Swift.Error, Swift.Equatable {
    case badRequestException(BadRequestException)
    case conflictException(ConflictException)
    case internalFailureException(InternalFailureException)
    case limitExceededException(LimitExceededException)
    case serviceUnavailableException(ServiceUnavailableException)
    case unknown(UnknownAWSHttpServiceError)
}

extension StartStreamTranscriptionOutputResponse: ClientRuntime.HttpResponseBinding {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        if let contentIdentificationTypeHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-content-identification-type") {
            self.contentIdentificationType = TranscribeStreamingClientTypes.ContentIdentificationType(rawValue: contentIdentificationTypeHeaderValue)
        } else {
            self.contentIdentificationType = nil
        }
        if let contentRedactionTypeHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-content-redaction-type") {
            self.contentRedactionType = TranscribeStreamingClientTypes.ContentRedactionType(rawValue: contentRedactionTypeHeaderValue)
        } else {
            self.contentRedactionType = nil
        }
        if let enableChannelIdentificationHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-enable-channel-identification") {
            self.enableChannelIdentification = Swift.Bool(enableChannelIdentificationHeaderValue) ?? false
        } else {
            self.enableChannelIdentification = false
        }
        if let enablePartialResultsStabilizationHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-enable-partial-results-stabilization") {
            self.enablePartialResultsStabilization = Swift.Bool(enablePartialResultsStabilizationHeaderValue) ?? false
        } else {
            self.enablePartialResultsStabilization = false
        }
        if let identifyLanguageHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-identify-language") {
            self.identifyLanguage = Swift.Bool(identifyLanguageHeaderValue) ?? false
        } else {
            self.identifyLanguage = false
        }
        if let languageCodeHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-language-code") {
            self.languageCode = TranscribeStreamingClientTypes.LanguageCode(rawValue: languageCodeHeaderValue)
        } else {
            self.languageCode = nil
        }
        if let languageModelNameHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-language-model-name") {
            self.languageModelName = languageModelNameHeaderValue
        } else {
            self.languageModelName = nil
        }
        if let languageOptionsHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-language-options") {
            self.languageOptions = languageOptionsHeaderValue
        } else {
            self.languageOptions = nil
        }
        if let mediaEncodingHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-media-encoding") {
            self.mediaEncoding = TranscribeStreamingClientTypes.MediaEncoding(rawValue: mediaEncodingHeaderValue)
        } else {
            self.mediaEncoding = nil
        }
        if let mediaSampleRateHertzHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-sample-rate") {
            self.mediaSampleRateHertz = Swift.Int(mediaSampleRateHertzHeaderValue) ?? 0
        } else {
            self.mediaSampleRateHertz = nil
        }
        if let numberOfChannelsHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-number-of-channels") {
            self.numberOfChannels = Swift.Int(numberOfChannelsHeaderValue) ?? 0
        } else {
            self.numberOfChannels = nil
        }
        if let partialResultsStabilityHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-partial-results-stability") {
            self.partialResultsStability = TranscribeStreamingClientTypes.PartialResultsStability(rawValue: partialResultsStabilityHeaderValue)
        } else {
            self.partialResultsStability = nil
        }
        if let piiEntityTypesHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-pii-entity-types") {
            self.piiEntityTypes = piiEntityTypesHeaderValue
        } else {
            self.piiEntityTypes = nil
        }
        if let preferredLanguageHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-preferred-language") {
            self.preferredLanguage = TranscribeStreamingClientTypes.LanguageCode(rawValue: preferredLanguageHeaderValue)
        } else {
            self.preferredLanguage = nil
        }
        if let requestIdHeaderValue = httpResponse.headers.value(for: "x-amzn-request-id") {
            self.requestId = requestIdHeaderValue
        } else {
            self.requestId = nil
        }
        if let sessionIdHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-session-id") {
            self.sessionId = sessionIdHeaderValue
        } else {
            self.sessionId = nil
        }
        if let showSpeakerLabelHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-show-speaker-label") {
            self.showSpeakerLabel = Swift.Bool(showSpeakerLabelHeaderValue) ?? false
        } else {
            self.showSpeakerLabel = false
        }
        if let vocabularyFilterMethodHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-vocabulary-filter-method") {
            self.vocabularyFilterMethod = TranscribeStreamingClientTypes.VocabularyFilterMethod(rawValue: vocabularyFilterMethodHeaderValue)
        } else {
            self.vocabularyFilterMethod = nil
        }
        if let vocabularyFilterNameHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-vocabulary-filter-name") {
            self.vocabularyFilterName = vocabularyFilterNameHeaderValue
        } else {
            self.vocabularyFilterName = nil
        }
        if let vocabularyFilterNamesHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-vocabulary-filter-names") {
            self.vocabularyFilterNames = vocabularyFilterNamesHeaderValue
        } else {
            self.vocabularyFilterNames = nil
        }
        if let vocabularyNameHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-vocabulary-name") {
            self.vocabularyName = vocabularyNameHeaderValue
        } else {
            self.vocabularyName = nil
        }
        if let vocabularyNamesHeaderValue = httpResponse.headers.value(for: "x-amzn-transcribe-vocabulary-names") {
            self.vocabularyNames = vocabularyNamesHeaderValue
        } else {
            self.vocabularyNames = nil
        }
        if case .stream(let reader) = httpResponse.body {
            let data = reader.toBytes().toData()
            if let responseDecoder = decoder {
                let output: TranscribeStreamingClientTypes.TranscriptResultStream = try responseDecoder.decode(responseBody: data)
                self.transcriptResultStream = output
            } else {
                self.transcriptResultStream = nil
            }
        } else {
            self.transcriptResultStream = nil
        }
    }
}

public struct StartStreamTranscriptionOutputResponse: Swift.Equatable {
    /// Shows whether content identification was enabled in this stream.
    public var contentIdentificationType: TranscribeStreamingClientTypes.ContentIdentificationType?
    /// Shows whether content redaction was enabled in this stream.
    public var contentRedactionType: TranscribeStreamingClientTypes.ContentRedactionType?
    /// Shows whether channel identification was enabled in the stream.
    public var enableChannelIdentification: Swift.Bool
    /// Shows whether partial results stabilization was enabled in the transcription.
    public var enablePartialResultsStabilization: Swift.Bool
    /// The language code of the language identified in your media stream.
    public var identifyLanguage: Swift.Bool
    /// The language code of the input audio stream.
    public var languageCode: TranscribeStreamingClientTypes.LanguageCode?
    /// The name of the custom language model used in the transcription.
    public var languageModelName: Swift.String?
    /// The language codes used in the identification of your media stream's predominant language.
    public var languageOptions: Swift.String?
    /// The encoding used for the input audio stream.
    public var mediaEncoding: TranscribeStreamingClientTypes.MediaEncoding?
    /// The sample rate, in Hertz (Hz), for the input audio stream.
    public var mediaSampleRateHertz: Swift.Int?
    /// The number of channels identified in the stream.
    public var numberOfChannels: Swift.Int?
    /// If partial results stabilization has been enabled in the stream, shows the stability level.
    public var partialResultsStability: TranscribeStreamingClientTypes.PartialResultsStability?
    /// Lists the PII entity types you specified in your request.
    public var piiEntityTypes: Swift.String?
    /// The preferred language you specified in your request.
    public var preferredLanguage: TranscribeStreamingClientTypes.LanguageCode?
    /// An identifier for the transcription.
    public var requestId: Swift.String?
    /// An identifier for a specific transcription session.
    public var sessionId: Swift.String?
    /// Shows whether speaker identification was enabled in the transcription.
    public var showSpeakerLabel: Swift.Bool
    /// Represents the stream of transcription events from Amazon Transcribe to your application.
    public var transcriptResultStream: TranscribeStreamingClientTypes.TranscriptResultStream?
    /// The vocabulary filtering method used when processing the stream.
    public var vocabularyFilterMethod: TranscribeStreamingClientTypes.VocabularyFilterMethod?
    /// The name of the vocabulary filter used when processing the stream.
    public var vocabularyFilterName: Swift.String?
    /// The name of the vocabulary filter used when processing the stream.
    public var vocabularyFilterNames: Swift.String?
    /// The name of the custom vocabulary used when processing the stream.
    public var vocabularyName: Swift.String?
    /// The name of the custom vocabulary used when processing the stream.
    public var vocabularyNames: Swift.String?

    public init (
        contentIdentificationType: TranscribeStreamingClientTypes.ContentIdentificationType? = nil,
        contentRedactionType: TranscribeStreamingClientTypes.ContentRedactionType? = nil,
        enableChannelIdentification: Swift.Bool = false,
        enablePartialResultsStabilization: Swift.Bool = false,
        identifyLanguage: Swift.Bool = false,
        languageCode: TranscribeStreamingClientTypes.LanguageCode? = nil,
        languageModelName: Swift.String? = nil,
        languageOptions: Swift.String? = nil,
        mediaEncoding: TranscribeStreamingClientTypes.MediaEncoding? = nil,
        mediaSampleRateHertz: Swift.Int? = nil,
        numberOfChannels: Swift.Int? = nil,
        partialResultsStability: TranscribeStreamingClientTypes.PartialResultsStability? = nil,
        piiEntityTypes: Swift.String? = nil,
        preferredLanguage: TranscribeStreamingClientTypes.LanguageCode? = nil,
        requestId: Swift.String? = nil,
        sessionId: Swift.String? = nil,
        showSpeakerLabel: Swift.Bool = false,
        transcriptResultStream: TranscribeStreamingClientTypes.TranscriptResultStream? = nil,
        vocabularyFilterMethod: TranscribeStreamingClientTypes.VocabularyFilterMethod? = nil,
        vocabularyFilterName: Swift.String? = nil,
        vocabularyFilterNames: Swift.String? = nil,
        vocabularyName: Swift.String? = nil,
        vocabularyNames: Swift.String? = nil
    )
    {
        self.contentIdentificationType = contentIdentificationType
        self.contentRedactionType = contentRedactionType
        self.enableChannelIdentification = enableChannelIdentification
        self.enablePartialResultsStabilization = enablePartialResultsStabilization
        self.identifyLanguage = identifyLanguage
        self.languageCode = languageCode
        self.languageModelName = languageModelName
        self.languageOptions = languageOptions
        self.mediaEncoding = mediaEncoding
        self.mediaSampleRateHertz = mediaSampleRateHertz
        self.numberOfChannels = numberOfChannels
        self.partialResultsStability = partialResultsStability
        self.piiEntityTypes = piiEntityTypes
        self.preferredLanguage = preferredLanguage
        self.requestId = requestId
        self.sessionId = sessionId
        self.showSpeakerLabel = showSpeakerLabel
        self.transcriptResultStream = transcriptResultStream
        self.vocabularyFilterMethod = vocabularyFilterMethod
        self.vocabularyFilterName = vocabularyFilterName
        self.vocabularyFilterNames = vocabularyFilterNames
        self.vocabularyName = vocabularyName
        self.vocabularyNames = vocabularyNames
    }
}

struct StartStreamTranscriptionOutputResponseBody: Swift.Equatable {
    let transcriptResultStream: TranscribeStreamingClientTypes.TranscriptResultStream?
}

extension StartStreamTranscriptionOutputResponseBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case transcriptResultStream = "TranscriptResultStream"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let transcriptResultStreamDecoded = try containerValues.decodeIfPresent(TranscribeStreamingClientTypes.TranscriptResultStream.self, forKey: .transcriptResultStream)
        transcriptResultStream = transcriptResultStreamDecoded
    }
}

extension TranscribeStreamingClientTypes.Transcript: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case results = "Results"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let results = results {
            var resultsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .results)
            for resultlist0 in results {
                try resultsContainer.encode(resultlist0)
            }
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let resultsContainer = try containerValues.decodeIfPresent([TranscribeStreamingClientTypes.Result?].self, forKey: .results)
        var resultsDecoded0:[TranscribeStreamingClientTypes.Result]? = nil
        if let resultsContainer = resultsContainer {
            resultsDecoded0 = [TranscribeStreamingClientTypes.Result]()
            for structure0 in resultsContainer {
                if let structure0 = structure0 {
                    resultsDecoded0?.append(structure0)
                }
            }
        }
        results = resultsDecoded0
    }
}

extension TranscribeStreamingClientTypes {
    /// The transcription in a [TranscriptEvent].
    public struct Transcript: Swift.Equatable {
        /// [Result] objects that contain the results of transcribing a portion of the input audio stream. The array can be empty.
        public var results: [TranscribeStreamingClientTypes.Result]?

        public init (
            results: [TranscribeStreamingClientTypes.Result]? = nil
        )
        {
            self.results = results
        }
    }

}

extension TranscribeStreamingClientTypes.TranscriptEvent: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case transcript = "Transcript"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let transcript = self.transcript {
            try encodeContainer.encode(transcript, forKey: .transcript)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let transcriptDecoded = try containerValues.decodeIfPresent(TranscribeStreamingClientTypes.Transcript.self, forKey: .transcript)
        transcript = transcriptDecoded
    }
}

extension TranscribeStreamingClientTypes {
    /// Represents a set of transcription results from the server to the client. It contains one or more segments of the transcription.
    public struct TranscriptEvent: Swift.Equatable {
        /// The transcription of the audio stream. The transcription is composed of all of the items in the results list.
        public var transcript: TranscribeStreamingClientTypes.Transcript?

        public init (
            transcript: TranscribeStreamingClientTypes.Transcript? = nil
        )
        {
            self.transcript = transcript
        }
    }

}

extension TranscribeStreamingClientTypes.TranscriptResultStream: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case badrequestexception = "BadRequestException"
        case conflictexception = "ConflictException"
        case internalfailureexception = "InternalFailureException"
        case limitexceededexception = "LimitExceededException"
        case serviceunavailableexception = "ServiceUnavailableException"
        case transcriptevent = "TranscriptEvent"
        case sdkUnknown
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var container = encoder.container(keyedBy: CodingKeys.self)
        switch self {
            case let .badrequestexception(badrequestexception):
                try container.encode(badrequestexception, forKey: .badrequestexception)
            case let .conflictexception(conflictexception):
                try container.encode(conflictexception, forKey: .conflictexception)
            case let .internalfailureexception(internalfailureexception):
                try container.encode(internalfailureexception, forKey: .internalfailureexception)
            case let .limitexceededexception(limitexceededexception):
                try container.encode(limitexceededexception, forKey: .limitexceededexception)
            case let .serviceunavailableexception(serviceunavailableexception):
                try container.encode(serviceunavailableexception, forKey: .serviceunavailableexception)
            case let .transcriptevent(transcriptevent):
                try container.encode(transcriptevent, forKey: .transcriptevent)
            case let .sdkUnknown(sdkUnknown):
                try container.encode(sdkUnknown, forKey: .sdkUnknown)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let values = try decoder.container(keyedBy: CodingKeys.self)
        let transcripteventDecoded = try values.decodeIfPresent(TranscribeStreamingClientTypes.TranscriptEvent.self, forKey: .transcriptevent)
        if let transcriptevent = transcripteventDecoded {
            self = .transcriptevent(transcriptevent)
            return
        }
        let badrequestexceptionDecoded = try values.decodeIfPresent(BadRequestException.self, forKey: .badrequestexception)
        if let badrequestexception = badrequestexceptionDecoded {
            self = .badrequestexception(badrequestexception)
            return
        }
        let limitexceededexceptionDecoded = try values.decodeIfPresent(LimitExceededException.self, forKey: .limitexceededexception)
        if let limitexceededexception = limitexceededexceptionDecoded {
            self = .limitexceededexception(limitexceededexception)
            return
        }
        let internalfailureexceptionDecoded = try values.decodeIfPresent(InternalFailureException.self, forKey: .internalfailureexception)
        if let internalfailureexception = internalfailureexceptionDecoded {
            self = .internalfailureexception(internalfailureexception)
            return
        }
        let conflictexceptionDecoded = try values.decodeIfPresent(ConflictException.self, forKey: .conflictexception)
        if let conflictexception = conflictexceptionDecoded {
            self = .conflictexception(conflictexception)
            return
        }
        let serviceunavailableexceptionDecoded = try values.decodeIfPresent(ServiceUnavailableException.self, forKey: .serviceunavailableexception)
        if let serviceunavailableexception = serviceunavailableexceptionDecoded {
            self = .serviceunavailableexception(serviceunavailableexception)
            return
        }
        self = .sdkUnknown("")
    }
}

extension TranscribeStreamingClientTypes {
    /// Represents the transcription result stream from Amazon Transcribe to your application.
    public enum TranscriptResultStream: Swift.Equatable {
        /// A portion of the transcription of the audio stream. Events are sent periodically from Amazon Transcribe to your application. The event can be a partial transcription of a section of the audio stream, or it can be the entire transcription of that portion of the audio stream.
        case transcriptevent(TranscribeStreamingClientTypes.TranscriptEvent)
        /// A client error occurred when the stream was created. Check the parameters of the request and try your request again.
        case badrequestexception(BadRequestException)
        /// Your client has exceeded one of the Amazon Transcribe limits, typically the limit on audio length. Break your audio stream into smaller chunks and try your request again.
        case limitexceededexception(LimitExceededException)
        /// A problem occurred while processing the audio. Amazon Transcribe terminated processing.
        case internalfailureexception(InternalFailureException)
        /// A new stream started with the same session ID. The current stream has been terminated.
        case conflictexception(ConflictException)
        /// Service is currently unavailable. Try your request later.
        case serviceunavailableexception(ServiceUnavailableException)
        case sdkUnknown(Swift.String)
    }

}

extension TranscribeStreamingClientTypes {
    public enum ModelType: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case conversation
        case dictation
        case sdkUnknown(Swift.String)

        public static var allCases: [ModelType] {
            return [
                .conversation,
                .dictation,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .conversation: return "CONVERSATION"
            case .dictation: return "DICTATION"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = ModelType(rawValue: rawValue) ?? ModelType.sdkUnknown(rawValue)
        }
    }
}

extension TranscribeStreamingClientTypes {
    public enum VocabularyFilterMethod: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case mask
        case remove
        case tag
        case sdkUnknown(Swift.String)

        public static var allCases: [VocabularyFilterMethod] {
            return [
                .mask,
                .remove,
                .tag,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .mask: return "mask"
            case .remove: return "remove"
            case .tag: return "tag"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = VocabularyFilterMethod(rawValue: rawValue) ?? VocabularyFilterMethod.sdkUnknown(rawValue)
        }
    }
}
