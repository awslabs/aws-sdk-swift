// Code generated by smithy-swift-codegen. DO NOT EDIT!
import AWSClientRuntime
import ClientRuntime

extension ClientLimitExceededException: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "ClientLimitExceededException(message: \(Swift.String(describing: message)))"}
}

extension ClientLimitExceededException: AWSClientRuntime.AWSHttpServiceError {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: ClientLimitExceededExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>Kinesis Video Streams has throttled the request because you have exceeded a limit. Try making the call later. For information about limits, see <a href="http://docs.aws.amazon.com/kinesisvideostreams/latest/dg/limits.html">Kinesis Video Streams Limits</a>.</p>
public struct ClientLimitExceededException: ClientRuntime.ServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct ClientLimitExceededExceptionBody: Swift.Equatable {
    public let message: Swift.String?
}

extension ClientLimitExceededExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes.ClipFragmentSelector: Swift.Codable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case fragmentSelectorType = "FragmentSelectorType"
        case timestampRange = "TimestampRange"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let fragmentSelectorType = fragmentSelectorType {
            try encodeContainer.encode(fragmentSelectorType.rawValue, forKey: .fragmentSelectorType)
        }
        if let timestampRange = timestampRange {
            try encodeContainer.encode(timestampRange, forKey: .timestampRange)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let fragmentSelectorTypeDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.ClipFragmentSelectorType.self, forKey: .fragmentSelectorType)
        fragmentSelectorType = fragmentSelectorTypeDecoded
        let timestampRangeDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.ClipTimestampRange.self, forKey: .timestampRange)
        timestampRange = timestampRangeDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes.ClipFragmentSelector: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "ClipFragmentSelector(fragmentSelectorType: \(Swift.String(describing: fragmentSelectorType)), timestampRange: \(Swift.String(describing: timestampRange)))"}
}

extension KinesisVideoArchivedMediaClientTypes {
    /// <p>Describes the timestamp range and timestamp origin of a range of fragments.</p>
    ///         <p>Fragments that have duplicate producer timestamps are deduplicated. This means that if
    ///             producers are producing a stream of fragments with producer timestamps that are
    ///             approximately equal to the true clock time, the clip will contain all of the fragments
    ///             within the requested timestamp range. If some fragments are ingested within the same
    ///             time range and very different points in time, only the oldest ingested collection of
    ///             fragments are returned.</p>
    public struct ClipFragmentSelector: Swift.Equatable {
        /// <p>The origin of the timestamps to use (Server or Producer).</p>
        public let fragmentSelectorType: KinesisVideoArchivedMediaClientTypes.ClipFragmentSelectorType?
        /// <p>The range of timestamps to return.</p>
        public let timestampRange: KinesisVideoArchivedMediaClientTypes.ClipTimestampRange?

        public init (
            fragmentSelectorType: KinesisVideoArchivedMediaClientTypes.ClipFragmentSelectorType? = nil,
            timestampRange: KinesisVideoArchivedMediaClientTypes.ClipTimestampRange? = nil
        )
        {
            self.fragmentSelectorType = fragmentSelectorType
            self.timestampRange = timestampRange
        }
    }

}

extension KinesisVideoArchivedMediaClientTypes {
    public enum ClipFragmentSelectorType: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case producerTimestamp
        case serverTimestamp
        case sdkUnknown(Swift.String)

        public static var allCases: [ClipFragmentSelectorType] {
            return [
                .producerTimestamp,
                .serverTimestamp,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .producerTimestamp: return "PRODUCER_TIMESTAMP"
            case .serverTimestamp: return "SERVER_TIMESTAMP"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = ClipFragmentSelectorType(rawValue: rawValue) ?? ClipFragmentSelectorType.sdkUnknown(rawValue)
        }
    }
}

extension KinesisVideoArchivedMediaClientTypes.ClipTimestampRange: Swift.Codable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case endTimestamp = "EndTimestamp"
        case startTimestamp = "StartTimestamp"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let endTimestamp = endTimestamp {
            try encodeContainer.encode(endTimestamp.timeIntervalSince1970, forKey: .endTimestamp)
        }
        if let startTimestamp = startTimestamp {
            try encodeContainer.encode(startTimestamp.timeIntervalSince1970, forKey: .startTimestamp)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let startTimestampDecoded = try containerValues.decodeIfPresent(ClientRuntime.Date.self, forKey: .startTimestamp)
        startTimestamp = startTimestampDecoded
        let endTimestampDecoded = try containerValues.decodeIfPresent(ClientRuntime.Date.self, forKey: .endTimestamp)
        endTimestamp = endTimestampDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes.ClipTimestampRange: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "ClipTimestampRange(endTimestamp: \(Swift.String(describing: endTimestamp)), startTimestamp: \(Swift.String(describing: startTimestamp)))"}
}

extension KinesisVideoArchivedMediaClientTypes {
    /// <p>The range of timestamps for which to return fragments.</p>
    public struct ClipTimestampRange: Swift.Equatable {
        /// <p>The end of the timestamp range for the requested media.</p>
        ///         <p>This value must be within 24 hours of the specified <code>StartTimestamp</code>, and
        ///             it must be later than the <code>StartTimestamp</code> value. If
        ///                 <code>FragmentSelectorType</code> for the request is <code>SERVER_TIMESTAMP</code>,
        ///             this value must be in the past. </p>
        ///         <p>This value is inclusive. The <code>EndTimestamp</code> is compared to the (starting)
        ///             timestamp of the fragment. Fragments that start before the <code>EndTimestamp</code>
        ///             value and continue past it are included in the session. </p>
        public let endTimestamp: ClientRuntime.Date?
        /// <p>The starting timestamp in the range of timestamps for which to return fragments. </p>
        ///         <p>Only fragments that start exactly at or after <code>StartTimestamp</code> are included
        ///             in the session. Fragments that start before <code>StartTimestamp</code> and continue
        ///             past it aren't included in the session. If <code>FragmentSelectorType</code> is
        ///                 <code>SERVER_TIMESTAMP</code>, the <code>StartTimestamp</code> must be later than
        ///             the stream head. </p>
        public let startTimestamp: ClientRuntime.Date?

        public init (
            endTimestamp: ClientRuntime.Date? = nil,
            startTimestamp: ClientRuntime.Date? = nil
        )
        {
            self.endTimestamp = endTimestamp
            self.startTimestamp = startTimestamp
        }
    }

}

extension KinesisVideoArchivedMediaClientTypes {
    public enum ContainerFormat: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case fragmentedMp4
        case mpegTs
        case sdkUnknown(Swift.String)

        public static var allCases: [ContainerFormat] {
            return [
                .fragmentedMp4,
                .mpegTs,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .fragmentedMp4: return "FRAGMENTED_MP4"
            case .mpegTs: return "MPEG_TS"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = ContainerFormat(rawValue: rawValue) ?? ContainerFormat.sdkUnknown(rawValue)
        }
    }
}

extension KinesisVideoArchivedMediaClientTypes {
    public enum DASHDisplayFragmentNumber: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case always
        case never
        case sdkUnknown(Swift.String)

        public static var allCases: [DASHDisplayFragmentNumber] {
            return [
                .always,
                .never,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .always: return "ALWAYS"
            case .never: return "NEVER"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = DASHDisplayFragmentNumber(rawValue: rawValue) ?? DASHDisplayFragmentNumber.sdkUnknown(rawValue)
        }
    }
}

extension KinesisVideoArchivedMediaClientTypes {
    public enum DASHDisplayFragmentTimestamp: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case always
        case never
        case sdkUnknown(Swift.String)

        public static var allCases: [DASHDisplayFragmentTimestamp] {
            return [
                .always,
                .never,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .always: return "ALWAYS"
            case .never: return "NEVER"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = DASHDisplayFragmentTimestamp(rawValue: rawValue) ?? DASHDisplayFragmentTimestamp.sdkUnknown(rawValue)
        }
    }
}

extension KinesisVideoArchivedMediaClientTypes.DASHFragmentSelector: Swift.Codable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case fragmentSelectorType = "FragmentSelectorType"
        case timestampRange = "TimestampRange"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let fragmentSelectorType = fragmentSelectorType {
            try encodeContainer.encode(fragmentSelectorType.rawValue, forKey: .fragmentSelectorType)
        }
        if let timestampRange = timestampRange {
            try encodeContainer.encode(timestampRange, forKey: .timestampRange)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let fragmentSelectorTypeDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.DASHFragmentSelectorType.self, forKey: .fragmentSelectorType)
        fragmentSelectorType = fragmentSelectorTypeDecoded
        let timestampRangeDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.DASHTimestampRange.self, forKey: .timestampRange)
        timestampRange = timestampRangeDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes.DASHFragmentSelector: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "DASHFragmentSelector(fragmentSelectorType: \(Swift.String(describing: fragmentSelectorType)), timestampRange: \(Swift.String(describing: timestampRange)))"}
}

extension KinesisVideoArchivedMediaClientTypes {
    /// <p>Contains the range of timestamps for the requested media, and the source of the
    ///             timestamps. </p>
    public struct DASHFragmentSelector: Swift.Equatable {
        /// <p>The source of the timestamps for the requested media.</p>
        ///         <p>When <code>FragmentSelectorType</code> is set to <code>PRODUCER_TIMESTAMP</code> and
        ///                 <a>GetDASHStreamingSessionURLInput$PlaybackMode</a> is
        ///                 <code>ON_DEMAND</code> or <code>LIVE_REPLAY</code>, the first fragment ingested with
        ///             a producer timestamp within the specified <a>FragmentSelector$TimestampRange</a> is included in the media playlist. In
        ///             addition, the fragments with producer timestamps within the <code>TimestampRange</code>
        ///             ingested immediately following the first fragment (up to the <a>GetDASHStreamingSessionURLInput$MaxManifestFragmentResults</a> value) are
        ///             included. </p>
        ///         <p>Fragments that have duplicate producer timestamps are deduplicated. This means that if
        ///             producers are producing a stream of fragments with producer timestamps that are
        ///             approximately equal to the true clock time, the MPEG-DASH manifest will contain all of
        ///             the fragments within the requested timestamp range. If some fragments are ingested
        ///             within the same time range and very different points in time, only the oldest ingested
        ///             collection of fragments are returned.</p>
        ///         <p>When <code>FragmentSelectorType</code> is set to <code>PRODUCER_TIMESTAMP</code> and
        ///                 <a>GetDASHStreamingSessionURLInput$PlaybackMode</a> is <code>LIVE</code>,
        ///             the producer timestamps are used in the MP4 fragments and for deduplication. But the
        ///             most recently ingested fragments based on server timestamps are included in the
        ///             MPEG-DASH manifest. This means that even if fragments ingested in the past have producer
        ///             timestamps with values now, they are not included in the HLS media playlist.</p>
        ///         <p>The default is <code>SERVER_TIMESTAMP</code>.</p>
        public let fragmentSelectorType: KinesisVideoArchivedMediaClientTypes.DASHFragmentSelectorType?
        /// <p>The start and end of the timestamp range for the requested media.</p>
        ///         <p>This value should not be present if <code>PlaybackType</code> is
        ///             <code>LIVE</code>.</p>
        public let timestampRange: KinesisVideoArchivedMediaClientTypes.DASHTimestampRange?

        public init (
            fragmentSelectorType: KinesisVideoArchivedMediaClientTypes.DASHFragmentSelectorType? = nil,
            timestampRange: KinesisVideoArchivedMediaClientTypes.DASHTimestampRange? = nil
        )
        {
            self.fragmentSelectorType = fragmentSelectorType
            self.timestampRange = timestampRange
        }
    }

}

extension KinesisVideoArchivedMediaClientTypes {
    public enum DASHFragmentSelectorType: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case producerTimestamp
        case serverTimestamp
        case sdkUnknown(Swift.String)

        public static var allCases: [DASHFragmentSelectorType] {
            return [
                .producerTimestamp,
                .serverTimestamp,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .producerTimestamp: return "PRODUCER_TIMESTAMP"
            case .serverTimestamp: return "SERVER_TIMESTAMP"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = DASHFragmentSelectorType(rawValue: rawValue) ?? DASHFragmentSelectorType.sdkUnknown(rawValue)
        }
    }
}

extension KinesisVideoArchivedMediaClientTypes {
    public enum DASHPlaybackMode: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case live
        case liveReplay
        case onDemand
        case sdkUnknown(Swift.String)

        public static var allCases: [DASHPlaybackMode] {
            return [
                .live,
                .liveReplay,
                .onDemand,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .live: return "LIVE"
            case .liveReplay: return "LIVE_REPLAY"
            case .onDemand: return "ON_DEMAND"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = DASHPlaybackMode(rawValue: rawValue) ?? DASHPlaybackMode.sdkUnknown(rawValue)
        }
    }
}

extension KinesisVideoArchivedMediaClientTypes.DASHTimestampRange: Swift.Codable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case endTimestamp = "EndTimestamp"
        case startTimestamp = "StartTimestamp"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let endTimestamp = endTimestamp {
            try encodeContainer.encode(endTimestamp.timeIntervalSince1970, forKey: .endTimestamp)
        }
        if let startTimestamp = startTimestamp {
            try encodeContainer.encode(startTimestamp.timeIntervalSince1970, forKey: .startTimestamp)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let startTimestampDecoded = try containerValues.decodeIfPresent(ClientRuntime.Date.self, forKey: .startTimestamp)
        startTimestamp = startTimestampDecoded
        let endTimestampDecoded = try containerValues.decodeIfPresent(ClientRuntime.Date.self, forKey: .endTimestamp)
        endTimestamp = endTimestampDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes.DASHTimestampRange: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "DASHTimestampRange(endTimestamp: \(Swift.String(describing: endTimestamp)), startTimestamp: \(Swift.String(describing: startTimestamp)))"}
}

extension KinesisVideoArchivedMediaClientTypes {
    /// <p>The start and end of the timestamp range for the requested media.</p>
    ///         <p>This value should not be present if <code>PlaybackType</code> is
    ///             <code>LIVE</code>.</p>
    ///         <p>The values in <code>DASHimestampRange</code> are inclusive. Fragments that start
    ///             exactly at or after the start time are included in the session. Fragments that start
    ///             before the start time and continue past it are not included in the session.</p>
    public struct DASHTimestampRange: Swift.Equatable {
        /// <p>The end of the timestamp range for the requested media. This value must be within 24
        ///             hours of the specified <code>StartTimestamp</code>, and it must be later than the
        ///                 <code>StartTimestamp</code> value.</p>
        ///         <p>If <code>FragmentSelectorType</code> for the request is <code>SERVER_TIMESTAMP</code>,
        ///             this value must be in the past.</p>
        ///
        ///         <p>The <code>EndTimestamp</code> value is required for <code>ON_DEMAND</code> mode, but
        ///             optional for <code>LIVE_REPLAY</code> mode. If the <code>EndTimestamp</code> is not set
        ///             for <code>LIVE_REPLAY</code> mode then the session will continue to include newly
        ///             ingested fragments until the session expires.</p>
        ///         <note>
        ///             <p>This value is inclusive. The <code>EndTimestamp</code> is compared to the
        ///                 (starting) timestamp of the fragment. Fragments that start before the
        ///                     <code>EndTimestamp</code> value and continue past it are included in the
        ///                 session.</p>
        ///         </note>
        public let endTimestamp: ClientRuntime.Date?
        /// <p>The start of the timestamp range for the requested media.</p>
        ///         <p>If the <code>DASHTimestampRange</code> value is specified, the
        ///                 <code>StartTimestamp</code> value is required.</p>
        ///         <p>Only fragments that start exactly at or after <code>StartTimestamp</code> are included
        ///             in the session. Fragments that start before <code>StartTimestamp</code> and continue
        ///             past it aren't included in the session. If <code>FragmentSelectorType</code> is
        ///                 <code>SERVER_TIMESTAMP</code>, the <code>StartTimestamp</code> must be later than
        ///             the stream head. </p>
        public let startTimestamp: ClientRuntime.Date?

        public init (
            endTimestamp: ClientRuntime.Date? = nil,
            startTimestamp: ClientRuntime.Date? = nil
        )
        {
            self.endTimestamp = endTimestamp
            self.startTimestamp = startTimestamp
        }
    }

}

extension KinesisVideoArchivedMediaClientTypes.Fragment: Swift.Codable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case fragmentLengthInMilliseconds = "FragmentLengthInMilliseconds"
        case fragmentNumber = "FragmentNumber"
        case fragmentSizeInBytes = "FragmentSizeInBytes"
        case producerTimestamp = "ProducerTimestamp"
        case serverTimestamp = "ServerTimestamp"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if fragmentLengthInMilliseconds != 0 {
            try encodeContainer.encode(fragmentLengthInMilliseconds, forKey: .fragmentLengthInMilliseconds)
        }
        if let fragmentNumber = fragmentNumber {
            try encodeContainer.encode(fragmentNumber, forKey: .fragmentNumber)
        }
        if fragmentSizeInBytes != 0 {
            try encodeContainer.encode(fragmentSizeInBytes, forKey: .fragmentSizeInBytes)
        }
        if let producerTimestamp = producerTimestamp {
            try encodeContainer.encode(producerTimestamp.timeIntervalSince1970, forKey: .producerTimestamp)
        }
        if let serverTimestamp = serverTimestamp {
            try encodeContainer.encode(serverTimestamp.timeIntervalSince1970, forKey: .serverTimestamp)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let fragmentNumberDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .fragmentNumber)
        fragmentNumber = fragmentNumberDecoded
        let fragmentSizeInBytesDecoded = try containerValues.decode(Swift.Int.self, forKey: .fragmentSizeInBytes)
        fragmentSizeInBytes = fragmentSizeInBytesDecoded
        let producerTimestampDecoded = try containerValues.decodeIfPresent(ClientRuntime.Date.self, forKey: .producerTimestamp)
        producerTimestamp = producerTimestampDecoded
        let serverTimestampDecoded = try containerValues.decodeIfPresent(ClientRuntime.Date.self, forKey: .serverTimestamp)
        serverTimestamp = serverTimestampDecoded
        let fragmentLengthInMillisecondsDecoded = try containerValues.decode(Swift.Int.self, forKey: .fragmentLengthInMilliseconds)
        fragmentLengthInMilliseconds = fragmentLengthInMillisecondsDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes.Fragment: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "Fragment(fragmentLengthInMilliseconds: \(Swift.String(describing: fragmentLengthInMilliseconds)), fragmentNumber: \(Swift.String(describing: fragmentNumber)), fragmentSizeInBytes: \(Swift.String(describing: fragmentSizeInBytes)), producerTimestamp: \(Swift.String(describing: producerTimestamp)), serverTimestamp: \(Swift.String(describing: serverTimestamp)))"}
}

extension KinesisVideoArchivedMediaClientTypes {
    /// <p>Represents a segment of video or other time-delimited data.</p>
    public struct Fragment: Swift.Equatable {
        /// <p>The playback duration or other time value associated with the fragment.</p>
        public let fragmentLengthInMilliseconds: Swift.Int
        /// <p>The unique identifier of the fragment. This value monotonically increases based on the
        ///             ingestion order.</p>
        public let fragmentNumber: Swift.String?
        /// <p>The total fragment size, including information about the fragment and contained media
        ///             data.</p>
        public let fragmentSizeInBytes: Swift.Int
        /// <p>The timestamp from the producer corresponding to the fragment.</p>
        public let producerTimestamp: ClientRuntime.Date?
        /// <p>The timestamp from the AWS server corresponding to the fragment.</p>
        public let serverTimestamp: ClientRuntime.Date?

        public init (
            fragmentLengthInMilliseconds: Swift.Int = 0,
            fragmentNumber: Swift.String? = nil,
            fragmentSizeInBytes: Swift.Int = 0,
            producerTimestamp: ClientRuntime.Date? = nil,
            serverTimestamp: ClientRuntime.Date? = nil
        )
        {
            self.fragmentLengthInMilliseconds = fragmentLengthInMilliseconds
            self.fragmentNumber = fragmentNumber
            self.fragmentSizeInBytes = fragmentSizeInBytes
            self.producerTimestamp = producerTimestamp
            self.serverTimestamp = serverTimestamp
        }
    }

}

extension KinesisVideoArchivedMediaClientTypes.FragmentSelector: Swift.Codable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case fragmentSelectorType = "FragmentSelectorType"
        case timestampRange = "TimestampRange"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let fragmentSelectorType = fragmentSelectorType {
            try encodeContainer.encode(fragmentSelectorType.rawValue, forKey: .fragmentSelectorType)
        }
        if let timestampRange = timestampRange {
            try encodeContainer.encode(timestampRange, forKey: .timestampRange)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let fragmentSelectorTypeDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.FragmentSelectorType.self, forKey: .fragmentSelectorType)
        fragmentSelectorType = fragmentSelectorTypeDecoded
        let timestampRangeDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.TimestampRange.self, forKey: .timestampRange)
        timestampRange = timestampRangeDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes.FragmentSelector: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "FragmentSelector(fragmentSelectorType: \(Swift.String(describing: fragmentSelectorType)), timestampRange: \(Swift.String(describing: timestampRange)))"}
}

extension KinesisVideoArchivedMediaClientTypes {
    /// <p>Describes the timestamp range and timestamp origin of a range of fragments.</p>
    ///         <p>Only fragments with a start timestamp greater than or equal to the given start time
    ///             and less than or equal to the end time are returned. For example, if a stream contains
    ///             fragments with the following start timestamps: </p>
    ///         <ul>
    ///             <li>
    ///                 <p>00:00:00</p>
    ///             </li>
    ///             <li>
    ///                 <p>00:00:02</p>
    ///             </li>
    ///             <li>
    ///                 <p>00:00:04</p>
    ///             </li>
    ///             <li>
    ///                 <p>00:00:06</p>
    ///             </li>
    ///          </ul>
    ///         <p> A fragment selector range with a start time of 00:00:01 and end time of 00:00:04
    ///             would return the fragments with start times of 00:00:02 and 00:00:04. </p>
    public struct FragmentSelector: Swift.Equatable {
        /// <p>The origin of the timestamps to use (Server or Producer).</p>
        public let fragmentSelectorType: KinesisVideoArchivedMediaClientTypes.FragmentSelectorType?
        /// <p>The range of timestamps to return.</p>
        public let timestampRange: KinesisVideoArchivedMediaClientTypes.TimestampRange?

        public init (
            fragmentSelectorType: KinesisVideoArchivedMediaClientTypes.FragmentSelectorType? = nil,
            timestampRange: KinesisVideoArchivedMediaClientTypes.TimestampRange? = nil
        )
        {
            self.fragmentSelectorType = fragmentSelectorType
            self.timestampRange = timestampRange
        }
    }

}

extension KinesisVideoArchivedMediaClientTypes {
    public enum FragmentSelectorType: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case producerTimestamp
        case serverTimestamp
        case sdkUnknown(Swift.String)

        public static var allCases: [FragmentSelectorType] {
            return [
                .producerTimestamp,
                .serverTimestamp,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .producerTimestamp: return "PRODUCER_TIMESTAMP"
            case .serverTimestamp: return "SERVER_TIMESTAMP"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = FragmentSelectorType(rawValue: rawValue) ?? FragmentSelectorType.sdkUnknown(rawValue)
        }
    }
}

public struct GetClipInputBodyMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetClipInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetClipInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetClipOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = ClientRuntime.HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientRuntime.ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetClipInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetClipOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetClipOutputError>
}

extension GetClipInput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "GetClipInput(clipFragmentSelector: \(Swift.String(describing: clipFragmentSelector)), streamARN: \(Swift.String(describing: streamARN)), streamName: \(Swift.String(describing: streamName)))"}
}

extension GetClipInput: Swift.Encodable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case clipFragmentSelector = "ClipFragmentSelector"
        case streamARN = "StreamARN"
        case streamName = "StreamName"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let clipFragmentSelector = clipFragmentSelector {
            try encodeContainer.encode(clipFragmentSelector, forKey: .clipFragmentSelector)
        }
        if let streamARN = streamARN {
            try encodeContainer.encode(streamARN, forKey: .streamARN)
        }
        if let streamName = streamName {
            try encodeContainer.encode(streamName, forKey: .streamName)
        }
    }
}

public struct GetClipInputHeadersMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetClipInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetClipInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetClipOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetClipInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetClipOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetClipOutputError>
}

public struct GetClipInputQueryItemMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetClipInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetClipInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetClipOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetClipInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetClipOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetClipOutputError>
}

public struct GetClipInput: Swift.Equatable {
    /// <p>The time range of the requested clip and the source of the timestamps.</p>
    public let clipFragmentSelector: KinesisVideoArchivedMediaClientTypes.ClipFragmentSelector?
    /// <p>The Amazon Resource Name (ARN) of the stream for which to retrieve the media clip. </p>
    ///         <p>You must specify either the StreamName or the StreamARN. </p>
    public let streamARN: Swift.String?
    /// <p>The name of the stream for which to retrieve the media clip. </p>
    ///         <p>You must specify either the StreamName or the StreamARN. </p>
    public let streamName: Swift.String?

    public init (
        clipFragmentSelector: KinesisVideoArchivedMediaClientTypes.ClipFragmentSelector? = nil,
        streamARN: Swift.String? = nil,
        streamName: Swift.String? = nil
    )
    {
        self.clipFragmentSelector = clipFragmentSelector
        self.streamARN = streamARN
        self.streamName = streamName
    }
}

struct GetClipInputBody: Swift.Equatable {
    public let streamName: Swift.String?
    public let streamARN: Swift.String?
    public let clipFragmentSelector: KinesisVideoArchivedMediaClientTypes.ClipFragmentSelector?
}

extension GetClipInputBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case clipFragmentSelector = "ClipFragmentSelector"
        case streamARN = "StreamARN"
        case streamName = "StreamName"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let streamNameDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .streamName)
        streamName = streamNameDecoded
        let streamARNDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .streamARN)
        streamARN = streamARNDecoded
        let clipFragmentSelectorDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.ClipFragmentSelector.self, forKey: .clipFragmentSelector)
        clipFragmentSelector = clipFragmentSelectorDecoded
    }
}

extension GetClipOutputError: ClientRuntime.HttpResponseBinding {
    public init(httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        let errorDetails = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension GetClipOutputError {
    public init(errorType: Swift.String?, httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        switch errorType {
        case "ClientLimitExceededException" : self = .clientLimitExceededException(try ClientLimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidCodecPrivateDataException" : self = .invalidCodecPrivateDataException(try InvalidCodecPrivateDataException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidMediaFrameException" : self = .invalidMediaFrameException(try InvalidMediaFrameException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "MissingCodecPrivateDataException" : self = .missingCodecPrivateDataException(try MissingCodecPrivateDataException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "NoDataRetentionException" : self = .noDataRetentionException(try NoDataRetentionException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "NotAuthorizedException" : self = .notAuthorizedException(try NotAuthorizedException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "UnsupportedStreamMediaTypeException" : self = .unsupportedStreamMediaTypeException(try UnsupportedStreamMediaTypeException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum GetClipOutputError: Swift.Error, Swift.Equatable {
    case clientLimitExceededException(ClientLimitExceededException)
    case invalidArgumentException(InvalidArgumentException)
    case invalidCodecPrivateDataException(InvalidCodecPrivateDataException)
    case invalidMediaFrameException(InvalidMediaFrameException)
    case missingCodecPrivateDataException(MissingCodecPrivateDataException)
    case noDataRetentionException(NoDataRetentionException)
    case notAuthorizedException(NotAuthorizedException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unsupportedStreamMediaTypeException(UnsupportedStreamMediaTypeException)
    case unknown(UnknownAWSHttpServiceError)
}

extension GetClipOutputResponse: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "GetClipOutputResponse(contentType: \(Swift.String(describing: contentType)), payload: \(Swift.String(describing: payload)))"}
}

extension GetClipOutputResponse: ClientRuntime.HttpResponseBinding {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        if let contentTypeHeaderValue = httpResponse.headers.value(for: "Content-Type") {
            self.contentType = contentTypeHeaderValue
        } else {
            self.contentType = nil
        }
        if case .stream(let reader) = httpResponse.body {
            let data = reader
            self.payload = data
        } else {
            self.payload = nil
        }
    }
}

public struct GetClipOutputResponse: Swift.Equatable {
    /// <p>The content type of the media in the requested clip.</p>
    public let contentType: Swift.String?
    /// <p>Traditional MP4 file that contains the media clip from the specified video stream. The
    ///             output will contain the first 100 MB or the first 200 fragments from the specified start
    ///             timestamp. For more information, see <a href="https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/limits.html">Kinesis
    ///                 Video Streams Limits</a>. </p>
    public let payload: ClientRuntime.ByteStream?

    public init (
        contentType: Swift.String? = nil,
        payload: ClientRuntime.ByteStream? = nil
    )
    {
        self.contentType = contentType
        self.payload = payload
    }
}

struct GetClipOutputResponseBody: Swift.Equatable {
    public let payload: ClientRuntime.ByteStream?
}

extension GetClipOutputResponseBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case payload = "Payload"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let payloadDecoded = try containerValues.decodeIfPresent(ClientRuntime.ByteStream.self, forKey: .payload)
        payload = payloadDecoded
    }
}

public struct GetDASHStreamingSessionURLInputBodyMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetDASHStreamingSessionURLInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetDASHStreamingSessionURLInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetDASHStreamingSessionURLOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = ClientRuntime.HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientRuntime.ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetDASHStreamingSessionURLInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetDASHStreamingSessionURLOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetDASHStreamingSessionURLOutputError>
}

extension GetDASHStreamingSessionURLInput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "GetDASHStreamingSessionURLInput(dASHFragmentSelector: \(Swift.String(describing: dASHFragmentSelector)), displayFragmentNumber: \(Swift.String(describing: displayFragmentNumber)), displayFragmentTimestamp: \(Swift.String(describing: displayFragmentTimestamp)), expires: \(Swift.String(describing: expires)), maxManifestFragmentResults: \(Swift.String(describing: maxManifestFragmentResults)), playbackMode: \(Swift.String(describing: playbackMode)), streamARN: \(Swift.String(describing: streamARN)), streamName: \(Swift.String(describing: streamName)))"}
}

extension GetDASHStreamingSessionURLInput: Swift.Encodable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case dASHFragmentSelector = "DASHFragmentSelector"
        case displayFragmentNumber = "DisplayFragmentNumber"
        case displayFragmentTimestamp = "DisplayFragmentTimestamp"
        case expires = "Expires"
        case maxManifestFragmentResults = "MaxManifestFragmentResults"
        case playbackMode = "PlaybackMode"
        case streamARN = "StreamARN"
        case streamName = "StreamName"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let dASHFragmentSelector = dASHFragmentSelector {
            try encodeContainer.encode(dASHFragmentSelector, forKey: .dASHFragmentSelector)
        }
        if let displayFragmentNumber = displayFragmentNumber {
            try encodeContainer.encode(displayFragmentNumber.rawValue, forKey: .displayFragmentNumber)
        }
        if let displayFragmentTimestamp = displayFragmentTimestamp {
            try encodeContainer.encode(displayFragmentTimestamp.rawValue, forKey: .displayFragmentTimestamp)
        }
        if let expires = expires {
            try encodeContainer.encode(expires, forKey: .expires)
        }
        if let maxManifestFragmentResults = maxManifestFragmentResults {
            try encodeContainer.encode(maxManifestFragmentResults, forKey: .maxManifestFragmentResults)
        }
        if let playbackMode = playbackMode {
            try encodeContainer.encode(playbackMode.rawValue, forKey: .playbackMode)
        }
        if let streamARN = streamARN {
            try encodeContainer.encode(streamARN, forKey: .streamARN)
        }
        if let streamName = streamName {
            try encodeContainer.encode(streamName, forKey: .streamName)
        }
    }
}

public struct GetDASHStreamingSessionURLInputHeadersMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetDASHStreamingSessionURLInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetDASHStreamingSessionURLInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetDASHStreamingSessionURLOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetDASHStreamingSessionURLInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetDASHStreamingSessionURLOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetDASHStreamingSessionURLOutputError>
}

public struct GetDASHStreamingSessionURLInputQueryItemMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetDASHStreamingSessionURLInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetDASHStreamingSessionURLInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetDASHStreamingSessionURLOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetDASHStreamingSessionURLInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetDASHStreamingSessionURLOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetDASHStreamingSessionURLOutputError>
}

public struct GetDASHStreamingSessionURLInput: Swift.Equatable {
    /// <p>The time range of the requested fragment and the source of the timestamps.</p>
    ///         <p>This parameter is required if <code>PlaybackMode</code> is <code>ON_DEMAND</code> or
    ///                 <code>LIVE_REPLAY</code>. This parameter is optional if PlaybackMode is<code></code>
    ///             <code>LIVE</code>. If <code>PlaybackMode</code> is <code>LIVE</code>, the
    ///                 <code>FragmentSelectorType</code> can be set, but the <code>TimestampRange</code>
    ///             should not be set. If <code>PlaybackMode</code> is <code>ON_DEMAND</code> or
    ///                 <code>LIVE_REPLAY</code>, both <code>FragmentSelectorType</code> and
    ///                 <code>TimestampRange</code> must be set.</p>
    public let dASHFragmentSelector: KinesisVideoArchivedMediaClientTypes.DASHFragmentSelector?
    /// <p>Fragments are identified in the manifest file based on their sequence number in the
    ///             session. If DisplayFragmentNumber is set to <code>ALWAYS</code>, the Kinesis Video
    ///             Streams fragment number is added to each S element in the manifest file with the
    ///             attribute name kvs:fn. These fragment numbers can be used for logging or for use with
    ///             other APIs (e.g. <code>GetMedia</code> and <code>GetMediaForFragmentList</code>). A
    ///             custom MPEG-DASH media player is necessary to leverage these this custom
    ///             attribute.</p>
    ///         <p>The default value is <code>NEVER</code>.</p>
    public let displayFragmentNumber: KinesisVideoArchivedMediaClientTypes.DASHDisplayFragmentNumber?
    /// <p>Per the MPEG-DASH specification, the wall-clock time of fragments in the manifest file
    ///             can be derived using attributes in the manifest itself. However, typically, MPEG-DASH
    ///             compatible media players do not properly handle gaps in the media timeline. Kinesis
    ///             Video Streams adjusts the media timeline in the manifest file to enable playback of
    ///             media with discontinuities. Therefore, the wall-clock time derived from the manifest
    ///             file may be inaccurate. If DisplayFragmentTimestamp is set to <code>ALWAYS</code>, the
    ///             accurate fragment timestamp is added to each S element in the manifest file with the
    ///             attribute name kvs:ts. A custom MPEG-DASH media player is necessary to leverage this
    ///             custom attribute.</p>
    ///         <p>The default value is <code>NEVER</code>. When <a>DASHFragmentSelector</a>
    ///             is <code>SERVER_TIMESTAMP</code>, the timestamps will be the server start timestamps.
    ///             Similarly, when <a>DASHFragmentSelector</a> is
    ///                 <code>PRODUCER_TIMESTAMP</code>, the timestamps will be the producer start
    ///             timestamps. </p>
    public let displayFragmentTimestamp: KinesisVideoArchivedMediaClientTypes.DASHDisplayFragmentTimestamp?
    /// <p>The time in seconds until the requested session expires. This value can be between 300
    ///             (5 minutes) and 43200 (12 hours).</p>
    ///         <p>When a session expires, no new calls to <code>GetDashManifest</code>,
    ///                 <code>GetMP4InitFragment</code>, or <code>GetMP4MediaFragment</code> can be made for
    ///             that session.</p>
    ///         <p>The default is 300 (5 minutes).</p>
    public let expires: Swift.Int?
    /// <p>The maximum number of fragments that are returned in the MPEG-DASH manifest.</p>
    ///         <p>When the <code>PlaybackMode</code> is <code>LIVE</code>, the most recent fragments are
    ///             returned up to this value. When the <code>PlaybackMode</code> is <code>ON_DEMAND</code>,
    ///             the oldest fragments are returned, up to this maximum number.</p>
    ///         <p>When there are a higher number of fragments available in a live MPEG-DASH manifest,
    ///             video players often buffer content before starting playback. Increasing the buffer size
    ///             increases the playback latency, but it decreases the likelihood that rebuffering will
    ///             occur during playback. We recommend that a live MPEG-DASH manifest have a minimum of 3
    ///             fragments and a maximum of 10 fragments.</p>
    ///         <p>The default is 5 fragments if <code>PlaybackMode</code> is <code>LIVE</code> or
    ///                 <code>LIVE_REPLAY</code>, and 1,000 if <code>PlaybackMode</code> is
    ///                 <code>ON_DEMAND</code>. </p>
    ///         <p>The maximum value of 1,000 fragments corresponds to more than 16 minutes of video on
    ///             streams with 1-second fragments, and more than 2 1/2 hours of video on streams with
    ///             10-second fragments.</p>
    public let maxManifestFragmentResults: Swift.Int?
    /// <p>Whether to retrieve live, live replay, or archived, on-demand data.</p>
    ///         <p>Features of the three types of sessions include the following:</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                     <b>
    ///                         <code>LIVE</code>
    ///                     </b>: For sessions of this type, the MPEG-DASH manifest is continually
    ///                     updated with the latest fragments as they become available. We recommend that
    ///                     the media player retrieve a new manifest on a one-second interval. When this
    ///                     type of session is played in a media player, the user interface typically
    ///                     displays a "live" notification, with no scrubber control for choosing the
    ///                     position in the playback window to display.</p>
    ///                 <note>
    ///                     <p>In <code>LIVE</code> mode, the newest available fragments are included in
    ///                         an MPEG-DASH manifest, even if there is a gap between fragments (that is, if
    ///                         a fragment is missing). A gap like this might cause a media player to halt
    ///                         or cause a jump in playback. In this mode, fragments are not added to the
    ///                         MPEG-DASH manifest if they are older than the newest fragment in the
    ///                         playlist. If the missing fragment becomes available after a subsequent
    ///                         fragment is added to the manifest, the older fragment is not added, and the
    ///                         gap is not filled.</p>
    ///                 </note>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <b>
    ///                         <code>LIVE_REPLAY</code>
    ///                     </b>: For sessions of this type, the MPEG-DASH manifest is updated
    ///                     similarly to how it is updated for <code>LIVE</code> mode except that it starts
    ///                     by including fragments from a given start time. Instead of fragments being added
    ///                     as they are ingested, fragments are added as the duration of the next fragment
    ///                     elapses. For example, if the fragments in the session are two seconds long, then
    ///                     a new fragment is added to the manifest every two seconds. This mode is useful
    ///                     to be able to start playback from when an event is detected and continue live
    ///                     streaming media that has not yet been ingested as of the time of the session
    ///                     creation. This mode is also useful to stream previously archived media without
    ///                     being limited by the 1,000 fragment limit in the <code>ON_DEMAND</code> mode.
    ///                 </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <b>
    ///                         <code>ON_DEMAND</code>
    ///                     </b>: For sessions of this type, the MPEG-DASH manifest contains all the
    ///                     fragments for the session, up to the number that is specified in
    ///                         <code>MaxManifestFragmentResults</code>. The manifest must be retrieved only
    ///                     once for each session. When this type of session is played in a media player,
    ///                     the user interface typically displays a scrubber control for choosing the
    ///                     position in the playback window to display.</p>
    ///             </li>
    ///          </ul>
    ///         <p>In all playback modes, if <code>FragmentSelectorType</code> is
    ///                 <code>PRODUCER_TIMESTAMP</code>, and if there are multiple fragments with the same
    ///             start timestamp, the fragment that has the larger fragment number (that is, the newer
    ///             fragment) is included in the MPEG-DASH manifest. The other fragments are not included.
    ///             Fragments that have different timestamps but have overlapping durations are still
    ///             included in the MPEG-DASH manifest. This can lead to unexpected behavior in the media
    ///             player.</p>
    ///         <p>The default is <code>LIVE</code>.</p>
    public let playbackMode: KinesisVideoArchivedMediaClientTypes.DASHPlaybackMode?
    /// <p>The Amazon Resource Name (ARN) of the stream for which to retrieve the MPEG-DASH
    ///             manifest URL.</p>
    ///         <p>You must specify either the <code>StreamName</code> or the
    ///             <code>StreamARN</code>.</p>
    public let streamARN: Swift.String?
    /// <p>The name of the stream for which to retrieve the MPEG-DASH manifest URL.</p>
    ///         <p>You must specify either the <code>StreamName</code> or the
    ///             <code>StreamARN</code>.</p>
    public let streamName: Swift.String?

    public init (
        dASHFragmentSelector: KinesisVideoArchivedMediaClientTypes.DASHFragmentSelector? = nil,
        displayFragmentNumber: KinesisVideoArchivedMediaClientTypes.DASHDisplayFragmentNumber? = nil,
        displayFragmentTimestamp: KinesisVideoArchivedMediaClientTypes.DASHDisplayFragmentTimestamp? = nil,
        expires: Swift.Int? = nil,
        maxManifestFragmentResults: Swift.Int? = nil,
        playbackMode: KinesisVideoArchivedMediaClientTypes.DASHPlaybackMode? = nil,
        streamARN: Swift.String? = nil,
        streamName: Swift.String? = nil
    )
    {
        self.dASHFragmentSelector = dASHFragmentSelector
        self.displayFragmentNumber = displayFragmentNumber
        self.displayFragmentTimestamp = displayFragmentTimestamp
        self.expires = expires
        self.maxManifestFragmentResults = maxManifestFragmentResults
        self.playbackMode = playbackMode
        self.streamARN = streamARN
        self.streamName = streamName
    }
}

struct GetDASHStreamingSessionURLInputBody: Swift.Equatable {
    public let streamName: Swift.String?
    public let streamARN: Swift.String?
    public let playbackMode: KinesisVideoArchivedMediaClientTypes.DASHPlaybackMode?
    public let displayFragmentTimestamp: KinesisVideoArchivedMediaClientTypes.DASHDisplayFragmentTimestamp?
    public let displayFragmentNumber: KinesisVideoArchivedMediaClientTypes.DASHDisplayFragmentNumber?
    public let dASHFragmentSelector: KinesisVideoArchivedMediaClientTypes.DASHFragmentSelector?
    public let expires: Swift.Int?
    public let maxManifestFragmentResults: Swift.Int?
}

extension GetDASHStreamingSessionURLInputBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case dASHFragmentSelector = "DASHFragmentSelector"
        case displayFragmentNumber = "DisplayFragmentNumber"
        case displayFragmentTimestamp = "DisplayFragmentTimestamp"
        case expires = "Expires"
        case maxManifestFragmentResults = "MaxManifestFragmentResults"
        case playbackMode = "PlaybackMode"
        case streamARN = "StreamARN"
        case streamName = "StreamName"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let streamNameDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .streamName)
        streamName = streamNameDecoded
        let streamARNDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .streamARN)
        streamARN = streamARNDecoded
        let playbackModeDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.DASHPlaybackMode.self, forKey: .playbackMode)
        playbackMode = playbackModeDecoded
        let displayFragmentTimestampDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.DASHDisplayFragmentTimestamp.self, forKey: .displayFragmentTimestamp)
        displayFragmentTimestamp = displayFragmentTimestampDecoded
        let displayFragmentNumberDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.DASHDisplayFragmentNumber.self, forKey: .displayFragmentNumber)
        displayFragmentNumber = displayFragmentNumberDecoded
        let dASHFragmentSelectorDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.DASHFragmentSelector.self, forKey: .dASHFragmentSelector)
        dASHFragmentSelector = dASHFragmentSelectorDecoded
        let expiresDecoded = try containerValues.decodeIfPresent(Swift.Int.self, forKey: .expires)
        expires = expiresDecoded
        let maxManifestFragmentResultsDecoded = try containerValues.decodeIfPresent(Swift.Int.self, forKey: .maxManifestFragmentResults)
        maxManifestFragmentResults = maxManifestFragmentResultsDecoded
    }
}

extension GetDASHStreamingSessionURLOutputError: ClientRuntime.HttpResponseBinding {
    public init(httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        let errorDetails = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension GetDASHStreamingSessionURLOutputError {
    public init(errorType: Swift.String?, httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        switch errorType {
        case "ClientLimitExceededException" : self = .clientLimitExceededException(try ClientLimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidCodecPrivateDataException" : self = .invalidCodecPrivateDataException(try InvalidCodecPrivateDataException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "MissingCodecPrivateDataException" : self = .missingCodecPrivateDataException(try MissingCodecPrivateDataException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "NoDataRetentionException" : self = .noDataRetentionException(try NoDataRetentionException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "NotAuthorizedException" : self = .notAuthorizedException(try NotAuthorizedException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "UnsupportedStreamMediaTypeException" : self = .unsupportedStreamMediaTypeException(try UnsupportedStreamMediaTypeException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum GetDASHStreamingSessionURLOutputError: Swift.Error, Swift.Equatable {
    case clientLimitExceededException(ClientLimitExceededException)
    case invalidArgumentException(InvalidArgumentException)
    case invalidCodecPrivateDataException(InvalidCodecPrivateDataException)
    case missingCodecPrivateDataException(MissingCodecPrivateDataException)
    case noDataRetentionException(NoDataRetentionException)
    case notAuthorizedException(NotAuthorizedException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unsupportedStreamMediaTypeException(UnsupportedStreamMediaTypeException)
    case unknown(UnknownAWSHttpServiceError)
}

extension GetDASHStreamingSessionURLOutputResponse: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "GetDASHStreamingSessionURLOutputResponse(dASHStreamingSessionURL: \(Swift.String(describing: dASHStreamingSessionURL)))"}
}

extension GetDASHStreamingSessionURLOutputResponse: ClientRuntime.HttpResponseBinding {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: GetDASHStreamingSessionURLOutputResponseBody = try responseDecoder.decode(responseBody: data)
            self.dASHStreamingSessionURL = output.dASHStreamingSessionURL
        } else {
            self.dASHStreamingSessionURL = nil
        }
    }
}

public struct GetDASHStreamingSessionURLOutputResponse: Swift.Equatable {
    /// <p>The URL (containing the session token) that a media player can use to retrieve the
    ///             MPEG-DASH manifest.</p>
    public let dASHStreamingSessionURL: Swift.String?

    public init (
        dASHStreamingSessionURL: Swift.String? = nil
    )
    {
        self.dASHStreamingSessionURL = dASHStreamingSessionURL
    }
}

struct GetDASHStreamingSessionURLOutputResponseBody: Swift.Equatable {
    public let dASHStreamingSessionURL: Swift.String?
}

extension GetDASHStreamingSessionURLOutputResponseBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case dASHStreamingSessionURL = "DASHStreamingSessionURL"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let dASHStreamingSessionURLDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .dASHStreamingSessionURL)
        dASHStreamingSessionURL = dASHStreamingSessionURLDecoded
    }
}

public struct GetHLSStreamingSessionURLInputBodyMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetHLSStreamingSessionURLInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetHLSStreamingSessionURLInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetHLSStreamingSessionURLOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = ClientRuntime.HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientRuntime.ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetHLSStreamingSessionURLInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetHLSStreamingSessionURLOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetHLSStreamingSessionURLOutputError>
}

extension GetHLSStreamingSessionURLInput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "GetHLSStreamingSessionURLInput(containerFormat: \(Swift.String(describing: containerFormat)), discontinuityMode: \(Swift.String(describing: discontinuityMode)), displayFragmentTimestamp: \(Swift.String(describing: displayFragmentTimestamp)), expires: \(Swift.String(describing: expires)), hLSFragmentSelector: \(Swift.String(describing: hLSFragmentSelector)), maxMediaPlaylistFragmentResults: \(Swift.String(describing: maxMediaPlaylistFragmentResults)), playbackMode: \(Swift.String(describing: playbackMode)), streamARN: \(Swift.String(describing: streamARN)), streamName: \(Swift.String(describing: streamName)))"}
}

extension GetHLSStreamingSessionURLInput: Swift.Encodable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case containerFormat = "ContainerFormat"
        case discontinuityMode = "DiscontinuityMode"
        case displayFragmentTimestamp = "DisplayFragmentTimestamp"
        case expires = "Expires"
        case hLSFragmentSelector = "HLSFragmentSelector"
        case maxMediaPlaylistFragmentResults = "MaxMediaPlaylistFragmentResults"
        case playbackMode = "PlaybackMode"
        case streamARN = "StreamARN"
        case streamName = "StreamName"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let containerFormat = containerFormat {
            try encodeContainer.encode(containerFormat.rawValue, forKey: .containerFormat)
        }
        if let discontinuityMode = discontinuityMode {
            try encodeContainer.encode(discontinuityMode.rawValue, forKey: .discontinuityMode)
        }
        if let displayFragmentTimestamp = displayFragmentTimestamp {
            try encodeContainer.encode(displayFragmentTimestamp.rawValue, forKey: .displayFragmentTimestamp)
        }
        if let expires = expires {
            try encodeContainer.encode(expires, forKey: .expires)
        }
        if let hLSFragmentSelector = hLSFragmentSelector {
            try encodeContainer.encode(hLSFragmentSelector, forKey: .hLSFragmentSelector)
        }
        if let maxMediaPlaylistFragmentResults = maxMediaPlaylistFragmentResults {
            try encodeContainer.encode(maxMediaPlaylistFragmentResults, forKey: .maxMediaPlaylistFragmentResults)
        }
        if let playbackMode = playbackMode {
            try encodeContainer.encode(playbackMode.rawValue, forKey: .playbackMode)
        }
        if let streamARN = streamARN {
            try encodeContainer.encode(streamARN, forKey: .streamARN)
        }
        if let streamName = streamName {
            try encodeContainer.encode(streamName, forKey: .streamName)
        }
    }
}

public struct GetHLSStreamingSessionURLInputHeadersMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetHLSStreamingSessionURLInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetHLSStreamingSessionURLInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetHLSStreamingSessionURLOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetHLSStreamingSessionURLInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetHLSStreamingSessionURLOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetHLSStreamingSessionURLOutputError>
}

public struct GetHLSStreamingSessionURLInputQueryItemMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetHLSStreamingSessionURLInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetHLSStreamingSessionURLInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetHLSStreamingSessionURLOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetHLSStreamingSessionURLInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetHLSStreamingSessionURLOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetHLSStreamingSessionURLOutputError>
}

public struct GetHLSStreamingSessionURLInput: Swift.Equatable {
    /// <p>Specifies which format should be used for packaging the media. Specifying the
    ///                 <code>FRAGMENTED_MP4</code> container format packages the media into MP4 fragments
    ///             (fMP4 or CMAF). This is the recommended packaging because there is minimal packaging
    ///             overhead. The other container format option is <code>MPEG_TS</code>. HLS has supported
    ///             MPEG TS chunks since it was released and is sometimes the only supported packaging on
    ///             older HLS players. MPEG TS typically has a 5-25 percent packaging overhead. This means
    ///             MPEG TS typically requires 5-25 percent more bandwidth and cost than fMP4.</p>
    ///         <p>The default is <code>FRAGMENTED_MP4</code>.</p>
    public let containerFormat: KinesisVideoArchivedMediaClientTypes.ContainerFormat?
    /// <p>Specifies when flags marking discontinuities between fragments are added to the media
    ///             playlists.</p>
    ///         <p>Media players typically build a timeline of media content to play, based on the
    ///             timestamps of each fragment. This means that if there is any overlap or gap between
    ///             fragments (as is typical if <a>HLSFragmentSelector</a> is set to
    ///                 <code>SERVER_TIMESTAMP</code>), the media player timeline will also have small gaps
    ///             between fragments in some places, and will overwrite frames in other places. Gaps in the
    ///             media player timeline can cause playback to stall and overlaps can cause playback to be
    ///             jittery. When there are discontinuity flags between fragments, the media player is
    ///             expected to reset the timeline, resulting in the next fragment being played immediately
    ///             after the previous fragment. </p>
    ///         <p>The following modes are supported:</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                     <code>ALWAYS</code>: a discontinuity marker is placed between every fragment in
    ///                     the HLS media playlist. It is recommended to use a value of <code>ALWAYS</code>
    ///                     if the fragment timestamps are not accurate.</p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>NEVER</code>: no discontinuity markers are placed anywhere. It is
    ///                     recommended to use a value of <code>NEVER</code> to ensure the media player
    ///                     timeline most accurately maps to the producer timestamps. </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <code>ON_DISCONTINUITY</code>: a discontinuity marker is placed between
    ///                     fragments that have a gap or overlap of more than 50 milliseconds. For most
    ///                     playback scenarios, it is recommended to use a value of
    ///                         <code>ON_DISCONTINUITY</code> so that the media player timeline is only
    ///                     reset when there is a significant issue with the media timeline (e.g. a missing
    ///                     fragment).</p>
    ///             </li>
    ///          </ul>
    ///         <p>The default is <code>ALWAYS</code> when <a>HLSFragmentSelector</a> is set
    ///             to <code>SERVER_TIMESTAMP</code>, and <code>NEVER</code> when it is set to
    ///                 <code>PRODUCER_TIMESTAMP</code>.</p>
    public let discontinuityMode: KinesisVideoArchivedMediaClientTypes.HLSDiscontinuityMode?
    /// <p>Specifies when the fragment start timestamps should be included in the HLS media
    ///             playlist. Typically, media players report the playhead position as a time relative to
    ///             the start of the first fragment in the playback session. However, when the start
    ///             timestamps are included in the HLS media playlist, some media players might report the
    ///             current playhead as an absolute time based on the fragment timestamps. This can be
    ///             useful for creating a playback experience that shows viewers the wall-clock time of the
    ///             media.</p>
    ///         <p>The default is <code>NEVER</code>. When <a>HLSFragmentSelector</a> is
    ///                 <code>SERVER_TIMESTAMP</code>, the timestamps will be the server start timestamps.
    ///             Similarly, when <a>HLSFragmentSelector</a> is
    ///             <code>PRODUCER_TIMESTAMP</code>, the timestamps will be the producer start timestamps.
    ///         </p>
    public let displayFragmentTimestamp: KinesisVideoArchivedMediaClientTypes.HLSDisplayFragmentTimestamp?
    /// <p>The time in seconds until the requested session expires. This value can be between 300
    ///             (5 minutes) and 43200 (12 hours).</p>
    ///         <p>When a session expires, no new calls to <code>GetHLSMasterPlaylist</code>,
    ///                 <code>GetHLSMediaPlaylist</code>, <code>GetMP4InitFragment</code>,
    ///                 <code>GetMP4MediaFragment</code>, or <code>GetTSFragment</code> can be made for that
    ///             session.</p>
    ///         <p>The default is 300 (5 minutes).</p>
    public let expires: Swift.Int?
    /// <p>The time range of the requested fragment and the source of the timestamps.</p>
    ///         <p>This parameter is required if <code>PlaybackMode</code> is <code>ON_DEMAND</code> or
    ///                 <code>LIVE_REPLAY</code>. This parameter is optional if PlaybackMode is<code></code>
    ///             <code>LIVE</code>. If <code>PlaybackMode</code> is <code>LIVE</code>, the
    ///                 <code>FragmentSelectorType</code> can be set, but the <code>TimestampRange</code>
    ///             should not be set. If <code>PlaybackMode</code> is <code>ON_DEMAND</code> or
    ///                 <code>LIVE_REPLAY</code>, both <code>FragmentSelectorType</code> and
    ///                 <code>TimestampRange</code> must be set.</p>
    public let hLSFragmentSelector: KinesisVideoArchivedMediaClientTypes.HLSFragmentSelector?
    /// <p>The maximum number of fragments that are returned in the HLS media playlists.</p>
    ///         <p>When the <code>PlaybackMode</code> is <code>LIVE</code>, the most recent fragments are
    ///             returned up to this value. When the <code>PlaybackMode</code> is <code>ON_DEMAND</code>,
    ///             the oldest fragments are returned, up to this maximum number.</p>
    ///         <p>When there are a higher number of fragments available in a live HLS media playlist,
    ///             video players often buffer content before starting playback. Increasing the buffer size
    ///             increases the playback latency, but it decreases the likelihood that rebuffering will
    ///             occur during playback. We recommend that a live HLS media playlist have a minimum of 3
    ///             fragments and a maximum of 10 fragments.</p>
    ///         <p>The default is 5 fragments if <code>PlaybackMode</code> is <code>LIVE</code> or
    ///                 <code>LIVE_REPLAY</code>, and 1,000 if <code>PlaybackMode</code> is
    ///                 <code>ON_DEMAND</code>. </p>
    ///         <p>The maximum value of 5,000 fragments corresponds to more than 80 minutes of video on
    ///             streams with 1-second fragments, and more than 13 hours of video on streams with
    ///             10-second fragments.</p>
    public let maxMediaPlaylistFragmentResults: Swift.Int?
    /// <p>Whether to retrieve live, live replay, or archived, on-demand data.</p>
    ///         <p>Features of the three types of sessions include the following:</p>
    ///         <ul>
    ///             <li>
    ///                 <p>
    ///                     <b>
    ///                         <code>LIVE</code>
    ///                     </b>: For sessions of this type, the HLS media playlist is continually
    ///                     updated with the latest fragments as they become available. We recommend that
    ///                     the media player retrieve a new playlist on a one-second interval. When this
    ///                     type of session is played in a media player, the user interface typically
    ///                     displays a "live" notification, with no scrubber control for choosing the
    ///                     position in the playback window to display.</p>
    ///                 <note>
    ///                     <p>In <code>LIVE</code> mode, the newest available fragments are included in
    ///                         an HLS media playlist, even if there is a gap between fragments (that is, if
    ///                         a fragment is missing). A gap like this might cause a media player to halt
    ///                         or cause a jump in playback. In this mode, fragments are not added to the
    ///                         HLS media playlist if they are older than the newest fragment in the
    ///                         playlist. If the missing fragment becomes available after a subsequent
    ///                         fragment is added to the playlist, the older fragment is not added, and the
    ///                         gap is not filled.</p>
    ///                 </note>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <b>
    ///                         <code>LIVE_REPLAY</code>
    ///                     </b>: For sessions of this type, the HLS media playlist is updated
    ///                     similarly to how it is updated for <code>LIVE</code> mode except that it starts
    ///                     by including fragments from a given start time. Instead of fragments being added
    ///                     as they are ingested, fragments are added as the duration of the next fragment
    ///                     elapses. For example, if the fragments in the session are two seconds long, then
    ///                     a new fragment is added to the media playlist every two seconds. This mode is
    ///                     useful to be able to start playback from when an event is detected and continue
    ///                     live streaming media that has not yet been ingested as of the time of the
    ///                     session creation. This mode is also useful to stream previously archived media
    ///                     without being limited by the 1,000 fragment limit in the <code>ON_DEMAND</code>
    ///                     mode. </p>
    ///             </li>
    ///             <li>
    ///                 <p>
    ///                     <b>
    ///                         <code>ON_DEMAND</code>
    ///                     </b>: For sessions of this type, the HLS media playlist contains all the
    ///                     fragments for the session, up to the number that is specified in
    ///                         <code>MaxMediaPlaylistFragmentResults</code>. The playlist must be retrieved
    ///                     only once for each session. When this type of session is played in a media
    ///                     player, the user interface typically displays a scrubber control for choosing
    ///                     the position in the playback window to display.</p>
    ///             </li>
    ///          </ul>
    ///         <p>In all playback modes, if <code>FragmentSelectorType</code> is
    ///                 <code>PRODUCER_TIMESTAMP</code>, and if there are multiple fragments with the same
    ///             start timestamp, the fragment that has the largest fragment number (that is, the newest
    ///             fragment) is included in the HLS media playlist. The other fragments are not included.
    ///             Fragments that have different timestamps but have overlapping durations are still
    ///             included in the HLS media playlist. This can lead to unexpected behavior in the media
    ///             player.</p>
    ///         <p>The default is <code>LIVE</code>.</p>
    public let playbackMode: KinesisVideoArchivedMediaClientTypes.HLSPlaybackMode?
    /// <p>The Amazon Resource Name (ARN) of the stream for which to retrieve the HLS master
    ///             playlist URL.</p>
    ///         <p>You must specify either the <code>StreamName</code> or the
    ///             <code>StreamARN</code>.</p>
    public let streamARN: Swift.String?
    /// <p>The name of the stream for which to retrieve the HLS master playlist URL.</p>
    ///         <p>You must specify either the <code>StreamName</code> or the
    ///             <code>StreamARN</code>.</p>
    public let streamName: Swift.String?

    public init (
        containerFormat: KinesisVideoArchivedMediaClientTypes.ContainerFormat? = nil,
        discontinuityMode: KinesisVideoArchivedMediaClientTypes.HLSDiscontinuityMode? = nil,
        displayFragmentTimestamp: KinesisVideoArchivedMediaClientTypes.HLSDisplayFragmentTimestamp? = nil,
        expires: Swift.Int? = nil,
        hLSFragmentSelector: KinesisVideoArchivedMediaClientTypes.HLSFragmentSelector? = nil,
        maxMediaPlaylistFragmentResults: Swift.Int? = nil,
        playbackMode: KinesisVideoArchivedMediaClientTypes.HLSPlaybackMode? = nil,
        streamARN: Swift.String? = nil,
        streamName: Swift.String? = nil
    )
    {
        self.containerFormat = containerFormat
        self.discontinuityMode = discontinuityMode
        self.displayFragmentTimestamp = displayFragmentTimestamp
        self.expires = expires
        self.hLSFragmentSelector = hLSFragmentSelector
        self.maxMediaPlaylistFragmentResults = maxMediaPlaylistFragmentResults
        self.playbackMode = playbackMode
        self.streamARN = streamARN
        self.streamName = streamName
    }
}

struct GetHLSStreamingSessionURLInputBody: Swift.Equatable {
    public let streamName: Swift.String?
    public let streamARN: Swift.String?
    public let playbackMode: KinesisVideoArchivedMediaClientTypes.HLSPlaybackMode?
    public let hLSFragmentSelector: KinesisVideoArchivedMediaClientTypes.HLSFragmentSelector?
    public let containerFormat: KinesisVideoArchivedMediaClientTypes.ContainerFormat?
    public let discontinuityMode: KinesisVideoArchivedMediaClientTypes.HLSDiscontinuityMode?
    public let displayFragmentTimestamp: KinesisVideoArchivedMediaClientTypes.HLSDisplayFragmentTimestamp?
    public let expires: Swift.Int?
    public let maxMediaPlaylistFragmentResults: Swift.Int?
}

extension GetHLSStreamingSessionURLInputBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case containerFormat = "ContainerFormat"
        case discontinuityMode = "DiscontinuityMode"
        case displayFragmentTimestamp = "DisplayFragmentTimestamp"
        case expires = "Expires"
        case hLSFragmentSelector = "HLSFragmentSelector"
        case maxMediaPlaylistFragmentResults = "MaxMediaPlaylistFragmentResults"
        case playbackMode = "PlaybackMode"
        case streamARN = "StreamARN"
        case streamName = "StreamName"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let streamNameDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .streamName)
        streamName = streamNameDecoded
        let streamARNDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .streamARN)
        streamARN = streamARNDecoded
        let playbackModeDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.HLSPlaybackMode.self, forKey: .playbackMode)
        playbackMode = playbackModeDecoded
        let hLSFragmentSelectorDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.HLSFragmentSelector.self, forKey: .hLSFragmentSelector)
        hLSFragmentSelector = hLSFragmentSelectorDecoded
        let containerFormatDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.ContainerFormat.self, forKey: .containerFormat)
        containerFormat = containerFormatDecoded
        let discontinuityModeDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.HLSDiscontinuityMode.self, forKey: .discontinuityMode)
        discontinuityMode = discontinuityModeDecoded
        let displayFragmentTimestampDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.HLSDisplayFragmentTimestamp.self, forKey: .displayFragmentTimestamp)
        displayFragmentTimestamp = displayFragmentTimestampDecoded
        let expiresDecoded = try containerValues.decodeIfPresent(Swift.Int.self, forKey: .expires)
        expires = expiresDecoded
        let maxMediaPlaylistFragmentResultsDecoded = try containerValues.decodeIfPresent(Swift.Int.self, forKey: .maxMediaPlaylistFragmentResults)
        maxMediaPlaylistFragmentResults = maxMediaPlaylistFragmentResultsDecoded
    }
}

extension GetHLSStreamingSessionURLOutputError: ClientRuntime.HttpResponseBinding {
    public init(httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        let errorDetails = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension GetHLSStreamingSessionURLOutputError {
    public init(errorType: Swift.String?, httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        switch errorType {
        case "ClientLimitExceededException" : self = .clientLimitExceededException(try ClientLimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidCodecPrivateDataException" : self = .invalidCodecPrivateDataException(try InvalidCodecPrivateDataException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "MissingCodecPrivateDataException" : self = .missingCodecPrivateDataException(try MissingCodecPrivateDataException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "NoDataRetentionException" : self = .noDataRetentionException(try NoDataRetentionException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "NotAuthorizedException" : self = .notAuthorizedException(try NotAuthorizedException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "UnsupportedStreamMediaTypeException" : self = .unsupportedStreamMediaTypeException(try UnsupportedStreamMediaTypeException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum GetHLSStreamingSessionURLOutputError: Swift.Error, Swift.Equatable {
    case clientLimitExceededException(ClientLimitExceededException)
    case invalidArgumentException(InvalidArgumentException)
    case invalidCodecPrivateDataException(InvalidCodecPrivateDataException)
    case missingCodecPrivateDataException(MissingCodecPrivateDataException)
    case noDataRetentionException(NoDataRetentionException)
    case notAuthorizedException(NotAuthorizedException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unsupportedStreamMediaTypeException(UnsupportedStreamMediaTypeException)
    case unknown(UnknownAWSHttpServiceError)
}

extension GetHLSStreamingSessionURLOutputResponse: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "GetHLSStreamingSessionURLOutputResponse(hLSStreamingSessionURL: \(Swift.String(describing: hLSStreamingSessionURL)))"}
}

extension GetHLSStreamingSessionURLOutputResponse: ClientRuntime.HttpResponseBinding {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: GetHLSStreamingSessionURLOutputResponseBody = try responseDecoder.decode(responseBody: data)
            self.hLSStreamingSessionURL = output.hLSStreamingSessionURL
        } else {
            self.hLSStreamingSessionURL = nil
        }
    }
}

public struct GetHLSStreamingSessionURLOutputResponse: Swift.Equatable {
    /// <p>The URL (containing the session token) that a media player can use to retrieve the HLS
    ///             master playlist.</p>
    public let hLSStreamingSessionURL: Swift.String?

    public init (
        hLSStreamingSessionURL: Swift.String? = nil
    )
    {
        self.hLSStreamingSessionURL = hLSStreamingSessionURL
    }
}

struct GetHLSStreamingSessionURLOutputResponseBody: Swift.Equatable {
    public let hLSStreamingSessionURL: Swift.String?
}

extension GetHLSStreamingSessionURLOutputResponseBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case hLSStreamingSessionURL = "HLSStreamingSessionURL"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let hLSStreamingSessionURLDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .hLSStreamingSessionURL)
        hLSStreamingSessionURL = hLSStreamingSessionURLDecoded
    }
}

public struct GetMediaForFragmentListInputBodyMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetMediaForFragmentListInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetMediaForFragmentListInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetMediaForFragmentListOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = ClientRuntime.HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientRuntime.ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetMediaForFragmentListInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetMediaForFragmentListOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetMediaForFragmentListOutputError>
}

extension GetMediaForFragmentListInput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "GetMediaForFragmentListInput(fragments: \(Swift.String(describing: fragments)), streamARN: \(Swift.String(describing: streamARN)), streamName: \(Swift.String(describing: streamName)))"}
}

extension GetMediaForFragmentListInput: Swift.Encodable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case fragments = "Fragments"
        case streamARN = "StreamARN"
        case streamName = "StreamName"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let fragments = fragments {
            var fragmentsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .fragments)
            for fragmentnumberlist0 in fragments {
                try fragmentsContainer.encode(fragmentnumberlist0)
            }
        }
        if let streamARN = streamARN {
            try encodeContainer.encode(streamARN, forKey: .streamARN)
        }
        if let streamName = streamName {
            try encodeContainer.encode(streamName, forKey: .streamName)
        }
    }
}

public struct GetMediaForFragmentListInputHeadersMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetMediaForFragmentListInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetMediaForFragmentListInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetMediaForFragmentListOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetMediaForFragmentListInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetMediaForFragmentListOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetMediaForFragmentListOutputError>
}

public struct GetMediaForFragmentListInputQueryItemMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "GetMediaForFragmentListInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<GetMediaForFragmentListInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<GetMediaForFragmentListOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<GetMediaForFragmentListInput>
    public typealias MOutput = ClientRuntime.OperationOutput<GetMediaForFragmentListOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<GetMediaForFragmentListOutputError>
}

public struct GetMediaForFragmentListInput: Swift.Equatable {
    /// <p>A list of the numbers of fragments for which to retrieve media. You retrieve these
    ///             values with <a>ListFragments</a>.</p>
    public let fragments: [Swift.String]?
    /// <p>The Amazon Resource Name (ARN) of the stream from which to retrieve fragment media. Specify either this parameter or the <code>StreamName</code> parameter.</p>
    public let streamARN: Swift.String?
    /// <p>The name of the stream from which to retrieve fragment media. Specify either this parameter or the <code>StreamARN</code> parameter.</p>
    public let streamName: Swift.String?

    public init (
        fragments: [Swift.String]? = nil,
        streamARN: Swift.String? = nil,
        streamName: Swift.String? = nil
    )
    {
        self.fragments = fragments
        self.streamARN = streamARN
        self.streamName = streamName
    }
}

struct GetMediaForFragmentListInputBody: Swift.Equatable {
    public let streamName: Swift.String?
    public let streamARN: Swift.String?
    public let fragments: [Swift.String]?
}

extension GetMediaForFragmentListInputBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case fragments = "Fragments"
        case streamARN = "StreamARN"
        case streamName = "StreamName"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let streamNameDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .streamName)
        streamName = streamNameDecoded
        let streamARNDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .streamARN)
        streamARN = streamARNDecoded
        let fragmentsContainer = try containerValues.decodeIfPresent([Swift.String?].self, forKey: .fragments)
        var fragmentsDecoded0:[Swift.String]? = nil
        if let fragmentsContainer = fragmentsContainer {
            fragmentsDecoded0 = [Swift.String]()
            for string0 in fragmentsContainer {
                if let string0 = string0 {
                    fragmentsDecoded0?.append(string0)
                }
            }
        }
        fragments = fragmentsDecoded0
    }
}

extension GetMediaForFragmentListOutputError: ClientRuntime.HttpResponseBinding {
    public init(httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        let errorDetails = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension GetMediaForFragmentListOutputError {
    public init(errorType: Swift.String?, httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        switch errorType {
        case "ClientLimitExceededException" : self = .clientLimitExceededException(try ClientLimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "NotAuthorizedException" : self = .notAuthorizedException(try NotAuthorizedException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum GetMediaForFragmentListOutputError: Swift.Error, Swift.Equatable {
    case clientLimitExceededException(ClientLimitExceededException)
    case invalidArgumentException(InvalidArgumentException)
    case notAuthorizedException(NotAuthorizedException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unknown(UnknownAWSHttpServiceError)
}

extension GetMediaForFragmentListOutputResponse: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "GetMediaForFragmentListOutputResponse(contentType: \(Swift.String(describing: contentType)), payload: \(Swift.String(describing: payload)))"}
}

extension GetMediaForFragmentListOutputResponse: ClientRuntime.HttpResponseBinding {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        if let contentTypeHeaderValue = httpResponse.headers.value(for: "Content-Type") {
            self.contentType = contentTypeHeaderValue
        } else {
            self.contentType = nil
        }
        if case .stream(let reader) = httpResponse.body {
            let data = reader
            self.payload = data
        } else {
            self.payload = nil
        }
    }
}

public struct GetMediaForFragmentListOutputResponse: Swift.Equatable {
    /// <p>The content type of the requested media.</p>
    public let contentType: Swift.String?
    /// <p>The payload that Kinesis Video Streams returns is a sequence of chunks from the
    ///             specified stream. For information about the chunks, see <a href="http://docs.aws.amazon.com/kinesisvideostreams/latest/dg/API_dataplane_PutMedia.html">PutMedia</a>. The chunks that Kinesis Video Streams returns in the
    ///                 <code>GetMediaForFragmentList</code> call also include the following additional
    ///             Matroska (MKV) tags: </p>
    ///         <ul>
    ///             <li>
    ///                 <p>AWS_KINESISVIDEO_FRAGMENT_NUMBER - Fragment number returned in the
    ///                     chunk.</p>
    ///             </li>
    ///             <li>
    ///                 <p>AWS_KINESISVIDEO_SERVER_SIDE_TIMESTAMP - Server-side timestamp of the
    ///                     fragment.</p>
    ///             </li>
    ///             <li>
    ///                 <p>AWS_KINESISVIDEO_PRODUCER_SIDE_TIMESTAMP - Producer-side timestamp of the
    ///                     fragment.</p>
    ///             </li>
    ///          </ul>
    ///         <p>The following tags will be included if an exception occurs:</p>
    ///         <ul>
    ///             <li>
    ///                 <p>AWS_KINESISVIDEO_FRAGMENT_NUMBER - The number of the fragment that threw the
    ///                     exception</p>
    ///             </li>
    ///             <li>
    ///                 <p>AWS_KINESISVIDEO_EXCEPTION_ERROR_CODE - The integer code of the
    ///                     exception</p>
    ///             </li>
    ///             <li>
    ///                 <p>AWS_KINESISVIDEO_EXCEPTION_MESSAGE - A text description of the
    ///                     exception</p>
    ///             </li>
    ///          </ul>
    public let payload: ClientRuntime.ByteStream?

    public init (
        contentType: Swift.String? = nil,
        payload: ClientRuntime.ByteStream? = nil
    )
    {
        self.contentType = contentType
        self.payload = payload
    }
}

struct GetMediaForFragmentListOutputResponseBody: Swift.Equatable {
    public let payload: ClientRuntime.ByteStream?
}

extension GetMediaForFragmentListOutputResponseBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case payload = "Payload"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let payloadDecoded = try containerValues.decodeIfPresent(ClientRuntime.ByteStream.self, forKey: .payload)
        payload = payloadDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes {
    public enum HLSDiscontinuityMode: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case always
        case never
        case onDiscontinuity
        case sdkUnknown(Swift.String)

        public static var allCases: [HLSDiscontinuityMode] {
            return [
                .always,
                .never,
                .onDiscontinuity,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .always: return "ALWAYS"
            case .never: return "NEVER"
            case .onDiscontinuity: return "ON_DISCONTINUITY"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = HLSDiscontinuityMode(rawValue: rawValue) ?? HLSDiscontinuityMode.sdkUnknown(rawValue)
        }
    }
}

extension KinesisVideoArchivedMediaClientTypes {
    public enum HLSDisplayFragmentTimestamp: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case always
        case never
        case sdkUnknown(Swift.String)

        public static var allCases: [HLSDisplayFragmentTimestamp] {
            return [
                .always,
                .never,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .always: return "ALWAYS"
            case .never: return "NEVER"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = HLSDisplayFragmentTimestamp(rawValue: rawValue) ?? HLSDisplayFragmentTimestamp.sdkUnknown(rawValue)
        }
    }
}

extension KinesisVideoArchivedMediaClientTypes.HLSFragmentSelector: Swift.Codable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case fragmentSelectorType = "FragmentSelectorType"
        case timestampRange = "TimestampRange"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let fragmentSelectorType = fragmentSelectorType {
            try encodeContainer.encode(fragmentSelectorType.rawValue, forKey: .fragmentSelectorType)
        }
        if let timestampRange = timestampRange {
            try encodeContainer.encode(timestampRange, forKey: .timestampRange)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let fragmentSelectorTypeDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.HLSFragmentSelectorType.self, forKey: .fragmentSelectorType)
        fragmentSelectorType = fragmentSelectorTypeDecoded
        let timestampRangeDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.HLSTimestampRange.self, forKey: .timestampRange)
        timestampRange = timestampRangeDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes.HLSFragmentSelector: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "HLSFragmentSelector(fragmentSelectorType: \(Swift.String(describing: fragmentSelectorType)), timestampRange: \(Swift.String(describing: timestampRange)))"}
}

extension KinesisVideoArchivedMediaClientTypes {
    /// <p>Contains the range of timestamps for the requested media, and the source of the
    ///             timestamps.</p>
    public struct HLSFragmentSelector: Swift.Equatable {
        /// <p>The source of the timestamps for the requested media.</p>
        ///         <p>When <code>FragmentSelectorType</code> is set to <code>PRODUCER_TIMESTAMP</code> and
        ///                 <a>GetHLSStreamingSessionURLInput$PlaybackMode</a> is
        ///                 <code>ON_DEMAND</code> or <code>LIVE_REPLAY</code>, the first fragment ingested with
        ///             a producer timestamp within the specified <a>FragmentSelector$TimestampRange</a> is included in the media playlist. In
        ///             addition, the fragments with producer timestamps within the <code>TimestampRange</code>
        ///             ingested immediately following the first fragment (up to the <a>GetHLSStreamingSessionURLInput$MaxMediaPlaylistFragmentResults</a> value)
        ///             are included. </p>
        ///         <p>Fragments that have duplicate producer timestamps are deduplicated. This means that if
        ///             producers are producing a stream of fragments with producer timestamps that are
        ///             approximately equal to the true clock time, the HLS media playlists will contain all of
        ///             the fragments within the requested timestamp range. If some fragments are ingested
        ///             within the same time range and very different points in time, only the oldest ingested
        ///             collection of fragments are returned.</p>
        ///         <p>When <code>FragmentSelectorType</code> is set to <code>PRODUCER_TIMESTAMP</code> and
        ///                 <a>GetHLSStreamingSessionURLInput$PlaybackMode</a> is <code>LIVE</code>,
        ///             the producer timestamps are used in the MP4 fragments and for deduplication. But the
        ///             most recently ingested fragments based on server timestamps are included in the HLS
        ///             media playlist. This means that even if fragments ingested in the past have producer
        ///             timestamps with values now, they are not included in the HLS media playlist.</p>
        ///         <p>The default is <code>SERVER_TIMESTAMP</code>.</p>
        public let fragmentSelectorType: KinesisVideoArchivedMediaClientTypes.HLSFragmentSelectorType?
        /// <p>The start and end of the timestamp range for the requested media.</p>
        ///         <p>This value should not be present if <code>PlaybackType</code> is
        ///             <code>LIVE</code>.</p>
        public let timestampRange: KinesisVideoArchivedMediaClientTypes.HLSTimestampRange?

        public init (
            fragmentSelectorType: KinesisVideoArchivedMediaClientTypes.HLSFragmentSelectorType? = nil,
            timestampRange: KinesisVideoArchivedMediaClientTypes.HLSTimestampRange? = nil
        )
        {
            self.fragmentSelectorType = fragmentSelectorType
            self.timestampRange = timestampRange
        }
    }

}

extension KinesisVideoArchivedMediaClientTypes {
    public enum HLSFragmentSelectorType: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case producerTimestamp
        case serverTimestamp
        case sdkUnknown(Swift.String)

        public static var allCases: [HLSFragmentSelectorType] {
            return [
                .producerTimestamp,
                .serverTimestamp,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .producerTimestamp: return "PRODUCER_TIMESTAMP"
            case .serverTimestamp: return "SERVER_TIMESTAMP"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = HLSFragmentSelectorType(rawValue: rawValue) ?? HLSFragmentSelectorType.sdkUnknown(rawValue)
        }
    }
}

extension KinesisVideoArchivedMediaClientTypes {
    public enum HLSPlaybackMode: Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Codable, Swift.Hashable {
        case live
        case liveReplay
        case onDemand
        case sdkUnknown(Swift.String)

        public static var allCases: [HLSPlaybackMode] {
            return [
                .live,
                .liveReplay,
                .onDemand,
                .sdkUnknown("")
            ]
        }
        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }
        public var rawValue: Swift.String {
            switch self {
            case .live: return "LIVE"
            case .liveReplay: return "LIVE_REPLAY"
            case .onDemand: return "ON_DEMAND"
            case let .sdkUnknown(s): return s
            }
        }
        public init(from decoder: Swift.Decoder) throws {
            let container = try decoder.singleValueContainer()
            let rawValue = try container.decode(RawValue.self)
            self = HLSPlaybackMode(rawValue: rawValue) ?? HLSPlaybackMode.sdkUnknown(rawValue)
        }
    }
}

extension KinesisVideoArchivedMediaClientTypes.HLSTimestampRange: Swift.Codable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case endTimestamp = "EndTimestamp"
        case startTimestamp = "StartTimestamp"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let endTimestamp = endTimestamp {
            try encodeContainer.encode(endTimestamp.timeIntervalSince1970, forKey: .endTimestamp)
        }
        if let startTimestamp = startTimestamp {
            try encodeContainer.encode(startTimestamp.timeIntervalSince1970, forKey: .startTimestamp)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let startTimestampDecoded = try containerValues.decodeIfPresent(ClientRuntime.Date.self, forKey: .startTimestamp)
        startTimestamp = startTimestampDecoded
        let endTimestampDecoded = try containerValues.decodeIfPresent(ClientRuntime.Date.self, forKey: .endTimestamp)
        endTimestamp = endTimestampDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes.HLSTimestampRange: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "HLSTimestampRange(endTimestamp: \(Swift.String(describing: endTimestamp)), startTimestamp: \(Swift.String(describing: startTimestamp)))"}
}

extension KinesisVideoArchivedMediaClientTypes {
    /// <p>The start and end of the timestamp range for the requested media.</p>
    ///         <p>This value should not be present if <code>PlaybackType</code> is
    ///             <code>LIVE</code>.</p>
    public struct HLSTimestampRange: Swift.Equatable {
        /// <p>The end of the timestamp range for the requested media. This value must be within 24
        ///             hours of the specified <code>StartTimestamp</code>, and it must be later than the
        ///                 <code>StartTimestamp</code> value.</p>
        ///         <p>If <code>FragmentSelectorType</code> for the request is <code>SERVER_TIMESTAMP</code>,
        ///             this value must be in the past.</p>
        ///         <p>The <code>EndTimestamp</code> value is required for <code>ON_DEMAND</code> mode, but
        ///             optional for <code>LIVE_REPLAY</code> mode. If the <code>EndTimestamp</code> is not set
        ///             for <code>LIVE_REPLAY</code> mode then the session will continue to include newly
        ///             ingested fragments until the session expires.</p>
        ///         <note>
        ///             <p>This value is inclusive. The <code>EndTimestamp</code> is compared to the
        ///                 (starting) timestamp of the fragment. Fragments that start before the
        ///                     <code>EndTimestamp</code> value and continue past it are included in the
        ///                 session.</p>
        ///         </note>
        public let endTimestamp: ClientRuntime.Date?
        /// <p>The start of the timestamp range for the requested media.</p>
        ///         <p>If the <code>HLSTimestampRange</code> value is specified, the
        ///                 <code>StartTimestamp</code> value is required. </p>
        ///         <p>Only fragments that start exactly at or after <code>StartTimestamp</code> are included
        ///             in the session. Fragments that start before <code>StartTimestamp</code> and continue
        ///             past it aren't included in the session. If <code>FragmentSelectorType</code> is
        ///                 <code>SERVER_TIMESTAMP</code>, the <code>StartTimestamp</code> must be later than
        ///             the stream head. </p>
        public let startTimestamp: ClientRuntime.Date?

        public init (
            endTimestamp: ClientRuntime.Date? = nil,
            startTimestamp: ClientRuntime.Date? = nil
        )
        {
            self.endTimestamp = endTimestamp
            self.startTimestamp = startTimestamp
        }
    }

}

extension InvalidArgumentException: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "InvalidArgumentException(message: \(Swift.String(describing: message)))"}
}

extension InvalidArgumentException: AWSClientRuntime.AWSHttpServiceError {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: InvalidArgumentExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>A specified parameter exceeds its restrictions, is not supported, or can't be
///             used.</p>
public struct InvalidArgumentException: ClientRuntime.ServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct InvalidArgumentExceptionBody: Swift.Equatable {
    public let message: Swift.String?
}

extension InvalidArgumentExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension InvalidCodecPrivateDataException: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "InvalidCodecPrivateDataException(message: \(Swift.String(describing: message)))"}
}

extension InvalidCodecPrivateDataException: AWSClientRuntime.AWSHttpServiceError {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: InvalidCodecPrivateDataExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>The codec private data in at least one of the tracks of the video stream is not valid
///             for this operation.</p>
public struct InvalidCodecPrivateDataException: ClientRuntime.ServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct InvalidCodecPrivateDataExceptionBody: Swift.Equatable {
    public let message: Swift.String?
}

extension InvalidCodecPrivateDataExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension InvalidMediaFrameException: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "InvalidMediaFrameException(message: \(Swift.String(describing: message)))"}
}

extension InvalidMediaFrameException: AWSClientRuntime.AWSHttpServiceError {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: InvalidMediaFrameExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>One or more frames in the requested clip could not be parsed based on the specified
///             codec.</p>
public struct InvalidMediaFrameException: ClientRuntime.ServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct InvalidMediaFrameExceptionBody: Swift.Equatable {
    public let message: Swift.String?
}

extension InvalidMediaFrameExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

public struct ListFragmentsInputBodyMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "ListFragmentsInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<ListFragmentsInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<ListFragmentsOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = ClientRuntime.HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientRuntime.ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<ListFragmentsInput>
    public typealias MOutput = ClientRuntime.OperationOutput<ListFragmentsOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<ListFragmentsOutputError>
}

extension ListFragmentsInput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "ListFragmentsInput(fragmentSelector: \(Swift.String(describing: fragmentSelector)), maxResults: \(Swift.String(describing: maxResults)), nextToken: \(Swift.String(describing: nextToken)), streamARN: \(Swift.String(describing: streamARN)), streamName: \(Swift.String(describing: streamName)))"}
}

extension ListFragmentsInput: Swift.Encodable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case fragmentSelector = "FragmentSelector"
        case maxResults = "MaxResults"
        case nextToken = "NextToken"
        case streamARN = "StreamARN"
        case streamName = "StreamName"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let fragmentSelector = fragmentSelector {
            try encodeContainer.encode(fragmentSelector, forKey: .fragmentSelector)
        }
        if let maxResults = maxResults {
            try encodeContainer.encode(maxResults, forKey: .maxResults)
        }
        if let nextToken = nextToken {
            try encodeContainer.encode(nextToken, forKey: .nextToken)
        }
        if let streamARN = streamARN {
            try encodeContainer.encode(streamARN, forKey: .streamARN)
        }
        if let streamName = streamName {
            try encodeContainer.encode(streamName, forKey: .streamName)
        }
    }
}

public struct ListFragmentsInputHeadersMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "ListFragmentsInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<ListFragmentsInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<ListFragmentsOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<ListFragmentsInput>
    public typealias MOutput = ClientRuntime.OperationOutput<ListFragmentsOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<ListFragmentsOutputError>
}

public struct ListFragmentsInputQueryItemMiddleware: ClientRuntime.Middleware {
    public let id: Swift.String = "ListFragmentsInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: ClientRuntime.SerializeStepInput<ListFragmentsInput>,
                  next: H) -> Swift.Result<ClientRuntime.OperationOutput<ListFragmentsOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = ClientRuntime.SerializeStepInput<ListFragmentsInput>
    public typealias MOutput = ClientRuntime.OperationOutput<ListFragmentsOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = ClientRuntime.SdkError<ListFragmentsOutputError>
}

public struct ListFragmentsInput: Swift.Equatable {
    /// <p>Describes the timestamp range and timestamp origin for the range of fragments to
    ///             return.</p>
    public let fragmentSelector: KinesisVideoArchivedMediaClientTypes.FragmentSelector?
    /// <p>The total number of fragments to return. If the total number of fragments available is
    ///             more than the value specified in <code>max-results</code>, then a <a>ListFragmentsOutput$NextToken</a> is provided in the output that you can use
    ///             to resume pagination.</p>
    public let maxResults: Swift.Int?
    /// <p>A token to specify where to start paginating. This is the <a>ListFragmentsOutput$NextToken</a> from a previously truncated
    ///             response.</p>
    public let nextToken: Swift.String?
    /// <p>The Amazon Resource Name (ARN) of the stream from which to retrieve a fragment list. Specify either this parameter or the <code>StreamName</code> parameter.</p>
    public let streamARN: Swift.String?
    /// <p>The name of the stream from which to retrieve a fragment list. Specify either this parameter or the <code>StreamARN</code> parameter.</p>
    public let streamName: Swift.String?

    public init (
        fragmentSelector: KinesisVideoArchivedMediaClientTypes.FragmentSelector? = nil,
        maxResults: Swift.Int? = nil,
        nextToken: Swift.String? = nil,
        streamARN: Swift.String? = nil,
        streamName: Swift.String? = nil
    )
    {
        self.fragmentSelector = fragmentSelector
        self.maxResults = maxResults
        self.nextToken = nextToken
        self.streamARN = streamARN
        self.streamName = streamName
    }
}

struct ListFragmentsInputBody: Swift.Equatable {
    public let streamName: Swift.String?
    public let streamARN: Swift.String?
    public let maxResults: Swift.Int?
    public let nextToken: Swift.String?
    public let fragmentSelector: KinesisVideoArchivedMediaClientTypes.FragmentSelector?
}

extension ListFragmentsInputBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case fragmentSelector = "FragmentSelector"
        case maxResults = "MaxResults"
        case nextToken = "NextToken"
        case streamARN = "StreamARN"
        case streamName = "StreamName"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let streamNameDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .streamName)
        streamName = streamNameDecoded
        let streamARNDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .streamARN)
        streamARN = streamARNDecoded
        let maxResultsDecoded = try containerValues.decodeIfPresent(Swift.Int.self, forKey: .maxResults)
        maxResults = maxResultsDecoded
        let nextTokenDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .nextToken)
        nextToken = nextTokenDecoded
        let fragmentSelectorDecoded = try containerValues.decodeIfPresent(KinesisVideoArchivedMediaClientTypes.FragmentSelector.self, forKey: .fragmentSelector)
        fragmentSelector = fragmentSelectorDecoded
    }
}

extension ListFragmentsOutputError: ClientRuntime.HttpResponseBinding {
    public init(httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        let errorDetails = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension ListFragmentsOutputError {
    public init(errorType: Swift.String?, httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        switch errorType {
        case "ClientLimitExceededException" : self = .clientLimitExceededException(try ClientLimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "NotAuthorizedException" : self = .notAuthorizedException(try NotAuthorizedException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum ListFragmentsOutputError: Swift.Error, Swift.Equatable {
    case clientLimitExceededException(ClientLimitExceededException)
    case invalidArgumentException(InvalidArgumentException)
    case notAuthorizedException(NotAuthorizedException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unknown(UnknownAWSHttpServiceError)
}

extension ListFragmentsOutputResponse: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "ListFragmentsOutputResponse(fragments: \(Swift.String(describing: fragments)), nextToken: \(Swift.String(describing: nextToken)))"}
}

extension ListFragmentsOutputResponse: ClientRuntime.HttpResponseBinding {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: ListFragmentsOutputResponseBody = try responseDecoder.decode(responseBody: data)
            self.fragments = output.fragments
            self.nextToken = output.nextToken
        } else {
            self.fragments = nil
            self.nextToken = nil
        }
    }
}

public struct ListFragmentsOutputResponse: Swift.Equatable {
    /// <p>A list of archived <a>Fragment</a> objects from the stream that meet the
    ///             selector criteria. Results are in no specific order, even across pages.</p>
    public let fragments: [KinesisVideoArchivedMediaClientTypes.Fragment]?
    /// <p>If the returned list is truncated, the operation returns this token to use to retrieve
    ///             the next page of results. This value is <code>null</code> when there are no more results
    ///             to return.</p>
    public let nextToken: Swift.String?

    public init (
        fragments: [KinesisVideoArchivedMediaClientTypes.Fragment]? = nil,
        nextToken: Swift.String? = nil
    )
    {
        self.fragments = fragments
        self.nextToken = nextToken
    }
}

struct ListFragmentsOutputResponseBody: Swift.Equatable {
    public let fragments: [KinesisVideoArchivedMediaClientTypes.Fragment]?
    public let nextToken: Swift.String?
}

extension ListFragmentsOutputResponseBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case fragments = "Fragments"
        case nextToken = "NextToken"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let fragmentsContainer = try containerValues.decodeIfPresent([KinesisVideoArchivedMediaClientTypes.Fragment?].self, forKey: .fragments)
        var fragmentsDecoded0:[KinesisVideoArchivedMediaClientTypes.Fragment]? = nil
        if let fragmentsContainer = fragmentsContainer {
            fragmentsDecoded0 = [KinesisVideoArchivedMediaClientTypes.Fragment]()
            for structure0 in fragmentsContainer {
                if let structure0 = structure0 {
                    fragmentsDecoded0?.append(structure0)
                }
            }
        }
        fragments = fragmentsDecoded0
        let nextTokenDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .nextToken)
        nextToken = nextTokenDecoded
    }
}

extension MissingCodecPrivateDataException: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "MissingCodecPrivateDataException(message: \(Swift.String(describing: message)))"}
}

extension MissingCodecPrivateDataException: AWSClientRuntime.AWSHttpServiceError {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: MissingCodecPrivateDataExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>No codec private data was found in at least one of tracks of the video stream.</p>
public struct MissingCodecPrivateDataException: ClientRuntime.ServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct MissingCodecPrivateDataExceptionBody: Swift.Equatable {
    public let message: Swift.String?
}

extension MissingCodecPrivateDataExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension NoDataRetentionException: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "NoDataRetentionException(message: \(Swift.String(describing: message)))"}
}

extension NoDataRetentionException: AWSClientRuntime.AWSHttpServiceError {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: NoDataRetentionExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>A streaming session was requested for a stream that does not retain data (that is, has
///             a <code>DataRetentionInHours</code> of 0). </p>
public struct NoDataRetentionException: ClientRuntime.ServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct NoDataRetentionExceptionBody: Swift.Equatable {
    public let message: Swift.String?
}

extension NoDataRetentionExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension NotAuthorizedException: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "NotAuthorizedException(message: \(Swift.String(describing: message)))"}
}

extension NotAuthorizedException: AWSClientRuntime.AWSHttpServiceError {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: NotAuthorizedExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>Status Code: 403, The caller is not authorized to perform an operation on the given
///             stream, or the token has expired.</p>
public struct NotAuthorizedException: ClientRuntime.ServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct NotAuthorizedExceptionBody: Swift.Equatable {
    public let message: Swift.String?
}

extension NotAuthorizedExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension ResourceNotFoundException: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "ResourceNotFoundException(message: \(Swift.String(describing: message)))"}
}

extension ResourceNotFoundException: AWSClientRuntime.AWSHttpServiceError {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: ResourceNotFoundExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>
///             <code>GetMedia</code> throws this error when Kinesis Video Streams can't find the stream
///             that you specified.</p>
///         <p>
///             <code>GetHLSStreamingSessionURL</code> and <code>GetDASHStreamingSessionURL</code> throw
///             this error if a session with a <code>PlaybackMode</code> of <code>ON_DEMAND</code> or
///                 <code>LIVE_REPLAY</code>is requested for a stream that has no fragments within the
///             requested time range, or if a session with a <code>PlaybackMode</code> of
///                 <code>LIVE</code> is requested for a stream that has no fragments within the last 30
///             seconds.</p>
public struct ResourceNotFoundException: ClientRuntime.ServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct ResourceNotFoundExceptionBody: Swift.Equatable {
    public let message: Swift.String?
}

extension ResourceNotFoundExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes.TimestampRange: Swift.Codable, ClientRuntime.Reflection {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case endTimestamp = "EndTimestamp"
        case startTimestamp = "StartTimestamp"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let endTimestamp = endTimestamp {
            try encodeContainer.encode(endTimestamp.timeIntervalSince1970, forKey: .endTimestamp)
        }
        if let startTimestamp = startTimestamp {
            try encodeContainer.encode(startTimestamp.timeIntervalSince1970, forKey: .startTimestamp)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let startTimestampDecoded = try containerValues.decodeIfPresent(ClientRuntime.Date.self, forKey: .startTimestamp)
        startTimestamp = startTimestampDecoded
        let endTimestampDecoded = try containerValues.decodeIfPresent(ClientRuntime.Date.self, forKey: .endTimestamp)
        endTimestamp = endTimestampDecoded
    }
}

extension KinesisVideoArchivedMediaClientTypes.TimestampRange: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "TimestampRange(endTimestamp: \(Swift.String(describing: endTimestamp)), startTimestamp: \(Swift.String(describing: startTimestamp)))"}
}

extension KinesisVideoArchivedMediaClientTypes {
    /// <p>The range of timestamps for which to return fragments.</p>
    public struct TimestampRange: Swift.Equatable {
        /// <p>The ending timestamp in the range of timestamps for which to return fragments.</p>
        public let endTimestamp: ClientRuntime.Date?
        /// <p>The starting timestamp in the range of timestamps for which to return
        ///             fragments.</p>
        public let startTimestamp: ClientRuntime.Date?

        public init (
            endTimestamp: ClientRuntime.Date? = nil,
            startTimestamp: ClientRuntime.Date? = nil
        )
        {
            self.endTimestamp = endTimestamp
            self.startTimestamp = startTimestamp
        }
    }

}

extension UnsupportedStreamMediaTypeException: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "UnsupportedStreamMediaTypeException(message: \(Swift.String(describing: message)))"}
}

extension UnsupportedStreamMediaTypeException: AWSClientRuntime.AWSHttpServiceError {
    public init (httpResponse: ClientRuntime.HttpResponse, decoder: ClientRuntime.ResponseDecoder? = nil, message: Swift.String? = nil, requestID: Swift.String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: UnsupportedStreamMediaTypeExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>The type of the media (for example, h.264 or h.265 video or ACC or G.711 audio) could
///             not be determined from the codec IDs of the tracks in the first fragment for a playback
///             session. The codec ID for track 1 should be <code>V_MPEG/ISO/AVC</code> and, optionally,
///             the codec ID for track 2 should be <code>A_AAC</code>.</p>
public struct UnsupportedStreamMediaTypeException: ClientRuntime.ServiceError, Swift.Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: ClientRuntime.HttpStatusCode?
    public var _message: Swift.String?
    public var _requestID: Swift.String?
    public var _retryable: Swift.Bool = false
    public var _isThrottling: Swift.Bool = false
    public var _type: ClientRuntime.ErrorType = .client
    public var message: Swift.String?

    public init (
        message: Swift.String? = nil
    )
    {
        self.message = message
    }
}

struct UnsupportedStreamMediaTypeExceptionBody: Swift.Equatable {
    public let message: Swift.String?
}

extension UnsupportedStreamMediaTypeExceptionBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case message = "Message"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .message)
        message = messageDecoded
    }
}
