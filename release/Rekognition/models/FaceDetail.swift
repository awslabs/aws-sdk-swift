// Code generated by smithy-swift-codegen. DO NOT EDIT!



/// <p>Structure containing attributes of the face that the algorithm detected.</p>
///          <p>A <code>FaceDetail</code> object contains either the default facial attributes or all facial attributes.
///       The default attributes are <code>BoundingBox</code>, <code>Confidence</code>, <code>Landmarks</code>, <code>Pose</code>, and <code>Quality</code>.</p>
///          <p>
///             <a>GetFaceDetection</a> is the only Amazon Rekognition Video stored video operation that can return a <code>FaceDetail</code> object with all attributes.
///       To specify which attributes to return, use the <code>FaceAttributes</code> input parameter for <a>StartFaceDetection</a>.
///       The following Amazon Rekognition Video operations return only the default attributes. The corresponding Start operations
///         don't have a <code>FaceAttributes</code> input parameter.</p>
///          <ul>
///             <li>
///                <p>GetCelebrityRecognition</p>
///             </li>
///             <li>
///                <p>GetPersonTracking</p>
///             </li>
///             <li>
///                <p>GetFaceSearch</p>
///             </li>
///          </ul>
///          <p>The Amazon Rekognition Image <a>DetectFaces</a> and <a>IndexFaces</a> operations
///       can return all facial attributes. To specify which attributes to return, use the
///       <code>Attributes</code> input parameter for <code>DetectFaces</code>. For <code>IndexFaces</code>, use the
///       <code>DetectAttributes</code> input parameter.</p>
public struct FaceDetail: Equatable {
    /// <p>The estimated age range, in years, for the face. Low represents the lowest estimated
    ///       age and High represents the highest estimated age.</p>
    public let ageRange: AgeRange?
    /// <p>Indicates whether or not the face has a beard, and the confidence level in the
    ///       determination.</p>
    public let beard: Beard?
    /// <p>Bounding box of the face. Default attribute.</p>
    public let boundingBox: BoundingBox?
    /// <p>Confidence level that the bounding box contains a face (and not a different object such
    ///       as a tree). Default attribute.</p>
    public let confidence: Float?
    /// <p>The emotions that appear to be expressed on the face, and the confidence level in the determination.
    ///       The API is only making a determination of the physical appearance of a person's face. It is not a determination
    ///       of the personâ€™s internal emotional state and should not be used in such a way. For example, a person pretending to have
    ///       a sad face might not be sad emotionally.</p>
    public let emotions: [Emotion]?
    /// <p>Indicates whether or not the face is wearing eye glasses, and the confidence level in
    ///       the determination.</p>
    public let eyeglasses: Eyeglasses?
    /// <p>Indicates whether or not the eyes on the face are open, and the confidence level in the
    ///       determination.</p>
    public let eyesOpen: EyeOpen?
    /// <p>The predicted gender of a detected face.
    ///     </p>
    public let gender: Gender?
    /// <p>Indicates the location of landmarks on the face. Default attribute.</p>
    public let landmarks: [Landmark]?
    /// <p>Indicates whether or not the mouth on the face is open, and the confidence level in the
    ///       determination.</p>
    public let mouthOpen: MouthOpen?
    /// <p>Indicates whether or not the face has a mustache, and the confidence level in the
    ///       determination.</p>
    public let mustache: Mustache?
    /// <p>Indicates the pose of the face as determined by its pitch, roll, and yaw. Default attribute.</p>
    public let pose: Pose?
    /// <p>Identifies image brightness and sharpness. Default attribute.</p>
    public let quality: ImageQuality?
    /// <p>Indicates whether or not the face is smiling, and the confidence level in the
    ///       determination.</p>
    public let smile: Smile?
    /// <p>Indicates whether or not the face is wearing sunglasses, and the confidence level in
    ///       the determination.</p>
    public let sunglasses: Sunglasses?

    public init (
        ageRange: AgeRange? = nil,
        beard: Beard? = nil,
        boundingBox: BoundingBox? = nil,
        confidence: Float? = nil,
        emotions: [Emotion]? = nil,
        eyeglasses: Eyeglasses? = nil,
        eyesOpen: EyeOpen? = nil,
        gender: Gender? = nil,
        landmarks: [Landmark]? = nil,
        mouthOpen: MouthOpen? = nil,
        mustache: Mustache? = nil,
        pose: Pose? = nil,
        quality: ImageQuality? = nil,
        smile: Smile? = nil,
        sunglasses: Sunglasses? = nil
    )
    {
        self.ageRange = ageRange
        self.beard = beard
        self.boundingBox = boundingBox
        self.confidence = confidence
        self.emotions = emotions
        self.eyeglasses = eyeglasses
        self.eyesOpen = eyesOpen
        self.gender = gender
        self.landmarks = landmarks
        self.mouthOpen = mouthOpen
        self.mustache = mustache
        self.pose = pose
        self.quality = quality
        self.smile = smile
        self.sunglasses = sunglasses
    }
}

extension FaceDetail: CustomDebugStringConvertible {
    public var debugDescription: String {
        "FaceDetail(ageRange: \(String(describing: ageRange)), beard: \(String(describing: beard)), boundingBox: \(String(describing: boundingBox)), confidence: \(String(describing: confidence)), emotions: \(String(describing: emotions)), eyeglasses: \(String(describing: eyeglasses)), eyesOpen: \(String(describing: eyesOpen)), gender: \(String(describing: gender)), landmarks: \(String(describing: landmarks)), mouthOpen: \(String(describing: mouthOpen)), mustache: \(String(describing: mustache)), pose: \(String(describing: pose)), quality: \(String(describing: quality)), smile: \(String(describing: smile)), sunglasses: \(String(describing: sunglasses)))"}
}
