// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct CompareFacesOutputResponse: Equatable {
    /// <p>An array of faces in the target image that match the source image face. Each
    ///         <code>CompareFacesMatch</code> object provides the bounding box, the confidence level that
    ///       the bounding box contains a face, and the similarity score for the face in the bounding box
    ///       and the face in the source image.</p>
    public let faceMatches: [CompareFacesMatch]?
    /// <p>The face in the source image that was used for comparison.</p>
    public let sourceImageFace: ComparedSourceImageFace?
    /// <p>The value of <code>SourceImageOrientationCorrection</code> is always null.</p>
    ///          <p>If the input image is in .jpeg format, it might contain exchangeable image file format (Exif) metadata
    ///       that includes the image's orientation. Amazon Rekognition uses this orientation information to perform
    ///       image correction. The bounding box coordinates are translated to represent object locations
    ///       after the orientation information in the Exif metadata is used to correct the image orientation.
    ///       Images in .png format don't contain Exif metadata.</p>
    ///          <p>Amazon Rekognition doesn’t perform image correction for images in .png format and
    ///       .jpeg images without orientation information in the image Exif metadata. The bounding box
    ///       coordinates aren't translated and represent the object locations before the image is rotated.
    ///     </p>
    public let sourceImageOrientationCorrection: OrientationCorrection?
    /// <p>The value of <code>TargetImageOrientationCorrection</code> is always null.</p>
    ///          <p>If the input image is in .jpeg format, it might contain exchangeable image file format (Exif) metadata
    ///       that includes the image's orientation. Amazon Rekognition uses this orientation information to perform
    ///       image correction. The bounding box coordinates are translated to represent object locations
    ///       after the orientation information in the Exif metadata is used to correct the image orientation.
    ///       Images in .png format don't contain Exif metadata.</p>
    ///          <p>Amazon Rekognition doesn’t perform image correction for images in .png format and
    ///       .jpeg images without orientation information in the image Exif metadata. The bounding box
    ///       coordinates aren't translated and represent the object locations before the image is rotated.
    ///     </p>
    public let targetImageOrientationCorrection: OrientationCorrection?
    /// <p>An array of faces in the target image that did not match the source image
    ///       face.</p>
    public let unmatchedFaces: [ComparedFace]?

    public init (
        faceMatches: [CompareFacesMatch]? = nil,
        sourceImageFace: ComparedSourceImageFace? = nil,
        sourceImageOrientationCorrection: OrientationCorrection? = nil,
        targetImageOrientationCorrection: OrientationCorrection? = nil,
        unmatchedFaces: [ComparedFace]? = nil
    )
    {
        self.faceMatches = faceMatches
        self.sourceImageFace = sourceImageFace
        self.sourceImageOrientationCorrection = sourceImageOrientationCorrection
        self.targetImageOrientationCorrection = targetImageOrientationCorrection
        self.unmatchedFaces = unmatchedFaces
    }
}

extension CompareFacesOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "CompareFacesOutputResponse(faceMatches: \(String(describing: faceMatches)), sourceImageFace: \(String(describing: sourceImageFace)), sourceImageOrientationCorrection: \(String(describing: sourceImageOrientationCorrection)), targetImageOrientationCorrection: \(String(describing: targetImageOrientationCorrection)), unmatchedFaces: \(String(describing: unmatchedFaces)))"}
}
