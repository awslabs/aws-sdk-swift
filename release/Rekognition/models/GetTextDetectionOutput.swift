// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct GetTextDetectionOutput: Equatable {
    /// <p>Current status of the text detection job.</p>
    public let jobStatus: VideoJobStatus?
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent
    ///         request to retrieve the next set of text.</p>
    public let nextToken: String?
    /// <p>If the job fails, <code>StatusMessage</code> provides a descriptive error message.</p>
    public let statusMessage: String?
    /// <p>An array of text detected in the video. Each element contains the detected text, the time in milliseconds
    ///       from the start of the video that the text was detected, and where it was detected on the screen.</p>
    public let textDetections: [TextDetectionResult]?
    /// <p>Version number of the text detection model that was used to detect text.</p>
    public let textModelVersion: String?
    /// <p>Information about a video that Amazon Rekognition analyzed. <code>Videometadata</code> is returned in
    ///             every page of paginated responses from a Amazon Rekognition video operation.</p>
    public let videoMetadata: VideoMetadata?

    public init (
        jobStatus: VideoJobStatus? = nil,
        nextToken: String? = nil,
        statusMessage: String? = nil,
        textDetections: [TextDetectionResult]? = nil,
        textModelVersion: String? = nil,
        videoMetadata: VideoMetadata? = nil
    )
    {
        self.jobStatus = jobStatus
        self.nextToken = nextToken
        self.statusMessage = statusMessage
        self.textDetections = textDetections
        self.textModelVersion = textModelVersion
        self.videoMetadata = videoMetadata
    }
}
