// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct RecognizeCelebritiesOutput: Equatable {
    /// <p>Details about each celebrity found in the image. Amazon Rekognition can detect a maximum of 64
    ///       celebrities in an image.</p>
    public let celebrityFaces: [Celebrity]?
    /// <p>The orientation of the input image (counterclockwise direction). If your application
    ///       displays the image, you can use this value to correct the orientation. The bounding box
    ///       coordinates returned in <code>CelebrityFaces</code> and <code>UnrecognizedFaces</code>
    ///       represent face locations before the image orientation is corrected. </p>
    ///          <note>
    ///             <p>If the input image is in .jpeg format, it might contain exchangeable image (Exif)
    ///         metadata that includes the image's orientation. If so, and the Exif metadata for the input
    ///         image populates the orientation field, the value of <code>OrientationCorrection</code> is
    ///         null. The <code>CelebrityFaces</code> and <code>UnrecognizedFaces</code> bounding box
    ///         coordinates represent face locations after Exif metadata is used to correct the image
    ///         orientation. Images in .png format don't contain Exif metadata. </p>
    ///          </note>
    public let orientationCorrection: OrientationCorrection?
    /// <p>Details about each unrecognized face in the image.</p>
    public let unrecognizedFaces: [ComparedFace]?

    public init (
        celebrityFaces: [Celebrity]? = nil,
        orientationCorrection: OrientationCorrection? = nil,
        unrecognizedFaces: [ComparedFace]? = nil
    )
    {
        self.celebrityFaces = celebrityFaces
        self.orientationCorrection = orientationCorrection
        self.unrecognizedFaces = unrecognizedFaces
    }
}
