// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct GetFaceDetectionOutput: Equatable {
    /// <p>An array of faces detected in the video. Each element contains a detected face's details and the time,
    ///        in milliseconds from the start of the video, the face was detected. </p>
    public let faces: [FaceDetection]?
    /// <p>The current status of the face detection job.</p>
    public let jobStatus: VideoJobStatus?
    /// <p>If the response is truncated, Amazon Rekognition returns this token that you can use in the subsequent request to retrieve the next set of faces. </p>
    public let nextToken: String?
    /// <p>If the job fails, <code>StatusMessage</code> provides a descriptive error message.</p>
    public let statusMessage: String?
    /// <p>Information about a video that Amazon Rekognition Video analyzed. <code>Videometadata</code> is returned in
    ///        every page of paginated responses from a Amazon Rekognition video operation.</p>
    public let videoMetadata: VideoMetadata?

    public init (
        faces: [FaceDetection]? = nil,
        jobStatus: VideoJobStatus? = nil,
        nextToken: String? = nil,
        statusMessage: String? = nil,
        videoMetadata: VideoMetadata? = nil
    )
    {
        self.faces = faces
        self.jobStatus = jobStatus
        self.nextToken = nextToken
        self.statusMessage = statusMessage
        self.videoMetadata = videoMetadata
    }
}
