// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct CreateCrawlerInput: Equatable {
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in
    ///       classifiers are included in a crawl, but these custom classifiers always override the default
    ///       classifiers for a given classification.</p>
    public let classifiers: [String]?
    /// <p>Crawler configuration information. This versioned JSON
    ///       string allows users to specify aspects of a crawler's behavior.
    ///       For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Configuring a Crawler</a>.</p>
    public let configuration: String?
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this
    ///       crawler.</p>
    public let crawlerSecurityConfiguration: String?
    /// <p>The AWS Glue database where results are written, such as:
    ///         <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    public let databaseName: String?
    /// <p>A description of the new crawler.</p>
    public let description: String?
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    public let lineageConfiguration: LineageConfiguration?
    /// <p>Name of the new crawler.</p>
    public let name: String?
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    public let recrawlPolicy: RecrawlPolicy?
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to
    ///       access customer resources.</p>
    public let role: String?
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run
    ///       something every day at 12:15 UTC, you would specify:
    ///       <code>cron(15 12 * * ? *)</code>.</p>
    public let schedule: String?
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    public let schemaChangePolicy: SchemaChangePolicy?
    /// <p>The table prefix used for catalog tables that are created.</p>
    public let tablePrefix: String?
    /// <p>The tags to use with this crawler request. You may use tags to limit access to the
    ///             crawler. For more information about tags in AWS Glue, see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html">AWS Tags in AWS Glue</a> in the developer
    ///             guide.</p>
    public let tags: [String:String]?
    /// <p>A list of collection of targets to crawl.</p>
    public let targets: CrawlerTargets?

    public init (
        classifiers: [String]? = nil,
        configuration: String? = nil,
        crawlerSecurityConfiguration: String? = nil,
        databaseName: String? = nil,
        description: String? = nil,
        lineageConfiguration: LineageConfiguration? = nil,
        name: String? = nil,
        recrawlPolicy: RecrawlPolicy? = nil,
        role: String? = nil,
        schedule: String? = nil,
        schemaChangePolicy: SchemaChangePolicy? = nil,
        tablePrefix: String? = nil,
        tags: [String:String]? = nil,
        targets: CrawlerTargets? = nil
    )
    {
        self.classifiers = classifiers
        self.configuration = configuration
        self.crawlerSecurityConfiguration = crawlerSecurityConfiguration
        self.databaseName = databaseName
        self.description = description
        self.lineageConfiguration = lineageConfiguration
        self.name = name
        self.recrawlPolicy = recrawlPolicy
        self.role = role
        self.schedule = schedule
        self.schemaChangePolicy = schemaChangePolicy
        self.tablePrefix = tablePrefix
        self.tags = tags
        self.targets = targets
    }
}

extension CreateCrawlerInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "CreateCrawlerInput(classifiers: \(String(describing: classifiers)), configuration: \(String(describing: configuration)), crawlerSecurityConfiguration: \(String(describing: crawlerSecurityConfiguration)), databaseName: \(String(describing: databaseName)), description: \(String(describing: description)), lineageConfiguration: \(String(describing: lineageConfiguration)), name: \(String(describing: name)), recrawlPolicy: \(String(describing: recrawlPolicy)), role: \(String(describing: role)), schedule: \(String(describing: schedule)), schemaChangePolicy: \(String(describing: schemaChangePolicy)), tablePrefix: \(String(describing: tablePrefix)), tags: \(String(describing: tags)), targets: \(String(describing: targets)))"}
}
