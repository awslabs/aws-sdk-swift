// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct StartMedicalStreamTranscriptionInput: Equatable {
    /// <p>Represents the audio stream from your application to Amazon Transcribe.</p>
    public let audioStream: AudioStream?
    /// <p>Set this field to <code>PHI</code> to identify personal health information in the
    ///             transcription output.</p>
    public let contentIdentificationType: MedicalContentIdentificationType?
    /// <p>When <code>true</code>, instructs Amazon Transcribe Medical to process each audio channel separately and
    ///             then merge the transcription output of each channel into a single transcription.</p>
    ///         <p>Amazon Transcribe Medical also produces a transcription of each item. An item includes the start time,
    ///             end time, and any alternative transcriptions.</p>
    ///         <p>You can't set both <code>ShowSpeakerLabel</code> and
    ///                 <code>EnableChannelIdentification</code> in the same request. If you set both, your
    ///             request returns a <code>BadRequestException</code>.</p>
    public let enableChannelIdentification: Bool
    /// <p> Indicates the source language used in the input audio stream. For Amazon Transcribe Medical, this is US
    ///             English (en-US). </p>
    public let languageCode: LanguageCode?
    /// <p>The encoding used for the input audio.</p>
    public let mediaEncoding: MediaEncoding?
    /// <p>The sample rate of the input audio in Hertz. Sample rates of 16000 Hz or higher are
    ///             accepted.</p>
    public let mediaSampleRateHertz: Int?
    /// <p>The number of channels that are in your audio stream.</p>
    public let numberOfChannels: Int?
    /// <p> Optional. An identifier for the transcription session. If you don't provide a session
    ///             ID, Amazon Transcribe generates one for you and returns it in the response. </p>
    public let sessionId: String?
    /// <p>When <code>true</code>, enables speaker identification in your real-time
    ///             stream.</p>
    public let showSpeakerLabel: Bool
    /// <p>The medical specialty of the clinician or provider.</p>
    public let specialty: Specialty?
    /// <p>The type of input audio. Choose <code>DICTATION</code> for a provider dictating
    ///             patient notes. Choose <code>CONVERSATION</code> for a dialogue between a patient and one
    ///             or more medical professionanls.</p>
    public let type: `Type`?
    /// <p>The name of the medical custom vocabulary to use when processing the real-time
    ///             stream.</p>
    public let vocabularyName: String?

    public init (
        audioStream: AudioStream? = nil,
        contentIdentificationType: MedicalContentIdentificationType? = nil,
        enableChannelIdentification: Bool = false,
        languageCode: LanguageCode? = nil,
        mediaEncoding: MediaEncoding? = nil,
        mediaSampleRateHertz: Int? = nil,
        numberOfChannels: Int? = nil,
        sessionId: String? = nil,
        showSpeakerLabel: Bool = false,
        specialty: Specialty? = nil,
        type: `Type`? = nil,
        vocabularyName: String? = nil
    )
    {
        self.audioStream = audioStream
        self.contentIdentificationType = contentIdentificationType
        self.enableChannelIdentification = enableChannelIdentification
        self.languageCode = languageCode
        self.mediaEncoding = mediaEncoding
        self.mediaSampleRateHertz = mediaSampleRateHertz
        self.numberOfChannels = numberOfChannels
        self.sessionId = sessionId
        self.showSpeakerLabel = showSpeakerLabel
        self.specialty = specialty
        self.type = type
        self.vocabularyName = vocabularyName
    }
}
