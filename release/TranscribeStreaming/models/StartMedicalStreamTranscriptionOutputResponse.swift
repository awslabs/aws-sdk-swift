// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct StartMedicalStreamTranscriptionOutputResponse: Equatable {
    /// <p>If the value is <code>PHI</code>, indicates that you've configured your stream to
    ///             identify personal health information.</p>
    public let contentIdentificationType: MedicalContentIdentificationType?
    /// <p>Shows whether channel identification has been enabled in the stream.</p>
    public let enableChannelIdentification: Bool
    /// <p>The language code for the response transcript. For Amazon Transcribe Medical, this is US English
    ///             (en-US).</p>
    public let languageCode: LanguageCode?
    /// <p>The encoding used for the input audio stream.</p>
    public let mediaEncoding: MediaEncoding?
    /// <p>The sample rate of the input audio in Hertz. Valid value: 16000 Hz.</p>
    public let mediaSampleRateHertz: Int?
    /// <p>The number of channels identified in the stream.</p>
    public let numberOfChannels: Int?
    /// <p>An identifier for the streaming transcription.</p>
    public let requestId: String?
    /// <p>Optional. An identifier for the transcription session. If you don't provide a session
    ///             ID, Amazon Transcribe generates one for you and returns it in the response.</p>
    public let sessionId: String?
    /// <p>Shows whether speaker identification was enabled in the stream.</p>
    public let showSpeakerLabel: Bool
    /// <p>The specialty in the medical domain.</p>
    public let specialty: Specialty?
    /// <p>Represents the stream of transcription events from Amazon Transcribe Medical to your application. </p>
    public let transcriptResultStream: MedicalTranscriptResultStream?
    /// <p>The type of audio that was transcribed. </p>
    public let type: `Type`?
    /// <p>The name of the vocabulary used when processing the stream.</p>
    public let vocabularyName: String?

    public init (
        contentIdentificationType: MedicalContentIdentificationType? = nil,
        enableChannelIdentification: Bool = false,
        languageCode: LanguageCode? = nil,
        mediaEncoding: MediaEncoding? = nil,
        mediaSampleRateHertz: Int? = nil,
        numberOfChannels: Int? = nil,
        requestId: String? = nil,
        sessionId: String? = nil,
        showSpeakerLabel: Bool = false,
        specialty: Specialty? = nil,
        transcriptResultStream: MedicalTranscriptResultStream? = nil,
        type: `Type`? = nil,
        vocabularyName: String? = nil
    )
    {
        self.contentIdentificationType = contentIdentificationType
        self.enableChannelIdentification = enableChannelIdentification
        self.languageCode = languageCode
        self.mediaEncoding = mediaEncoding
        self.mediaSampleRateHertz = mediaSampleRateHertz
        self.numberOfChannels = numberOfChannels
        self.requestId = requestId
        self.sessionId = sessionId
        self.showSpeakerLabel = showSpeakerLabel
        self.specialty = specialty
        self.transcriptResultStream = transcriptResultStream
        self.type = type
        self.vocabularyName = vocabularyName
    }
}

extension StartMedicalStreamTranscriptionOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "StartMedicalStreamTranscriptionOutputResponse(contentIdentificationType: \(String(describing: contentIdentificationType)), enableChannelIdentification: \(String(describing: enableChannelIdentification)), languageCode: \(String(describing: languageCode)), mediaEncoding: \(String(describing: mediaEncoding)), mediaSampleRateHertz: \(String(describing: mediaSampleRateHertz)), numberOfChannels: \(String(describing: numberOfChannels)), requestId: \(String(describing: requestId)), sessionId: \(String(describing: sessionId)), showSpeakerLabel: \(String(describing: showSpeakerLabel)), specialty: \(String(describing: specialty)), transcriptResultStream: \(String(describing: transcriptResultStream)), type: \(String(describing: type)), vocabularyName: \(String(describing: vocabularyName)))"}
}
