// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct StartStreamTranscriptionInput: Equatable {
    /// <p>PCM-encoded stream of audio blobs. The audio stream is encoded as an HTTP2 data
    ///       frame.</p>
    public let audioStream: AudioStream?
    /// <p>When <code>true</code>, instructs Amazon Transcribe to process each audio channel separately and then
    ///       merge the transcription output of each channel into a single transcription.</p>
    ///          <p>Amazon Transcribe also produces a transcription of each item. An item includes the start time, end
    ///       time, and any alternative transcriptions.</p>
    ///          <p>You can't set both <code>ShowSpeakerLabel</code> and
    ///         <code>EnableChannelIdentification</code> in the same request. If you set both, your request
    ///       returns a <code>BadRequestException</code>.</p>
    public let enableChannelIdentification: Bool
    /// <p>When <code>true</code>, instructs Amazon Transcribe to present transcription results that have the
    ///       partial results stabilized. Normally, any word or phrase from one partial result can change in
    ///       a subsequent partial result. With partial results stabilization enabled, only the last few
    ///       words of one partial result can change in another partial result.</p>
    public let enablePartialResultsStabilization: Bool
    /// <p>Indicates the source language used in the input audio stream.</p>
    public let languageCode: LanguageCode?
    /// <p>The encoding used for the input audio.</p>
    public let mediaEncoding: MediaEncoding?
    /// <p>The sample rate, in Hertz, of the input audio. We suggest that you use 8000 Hz for low
    ///       quality audio and 16000 Hz for high quality audio.</p>
    public let mediaSampleRateHertz: Int?
    /// <p>The number of channels that are in your audio stream.</p>
    public let numberOfChannels: Int?
    /// <p>You can use this field to set the stability level of the transcription results. A higher
    ///       stability level means that the transcription results are less likely to change. Higher
    ///       stability levels can come with lower overall transcription accuracy.</p>
    public let partialResultsStability: PartialResultsStability?
    /// <p>A identifier for the transcription session. Use this parameter when you want to retry a
    ///       session. If you don't provide a session ID, Amazon Transcribe will generate one for you and return it in
    ///       the response.</p>
    public let sessionId: String?
    /// <p>When <code>true</code>, enables speaker identification in your real-time stream.</p>
    public let showSpeakerLabel: Bool
    /// <p>The manner in which you use your vocabulary filter to filter words in your transcript.
    ///         <code>Remove</code> removes filtered words from your transcription results.
    ///         <code>Mask</code> masks those words with a <code>***</code> in your transcription results.
    ///         <code>Tag</code> keeps the filtered words in your transcription results and tags them. The
    ///       tag appears as <code>VocabularyFilterMatch</code> equal to <code>True</code>
    ///          </p>
    public let vocabularyFilterMethod: VocabularyFilterMethod?
    /// <p>The name of the vocabulary filter you've created that is unique to your AWS account.
    ///       Provide the name in this field to successfully use it in a stream.</p>
    public let vocabularyFilterName: String?
    /// <p>The name of the vocabulary to use when processing the transcription job.</p>
    public let vocabularyName: String?

    public init (
        audioStream: AudioStream? = nil,
        enableChannelIdentification: Bool = false,
        enablePartialResultsStabilization: Bool = false,
        languageCode: LanguageCode? = nil,
        mediaEncoding: MediaEncoding? = nil,
        mediaSampleRateHertz: Int? = nil,
        numberOfChannels: Int? = nil,
        partialResultsStability: PartialResultsStability? = nil,
        sessionId: String? = nil,
        showSpeakerLabel: Bool = false,
        vocabularyFilterMethod: VocabularyFilterMethod? = nil,
        vocabularyFilterName: String? = nil,
        vocabularyName: String? = nil
    )
    {
        self.audioStream = audioStream
        self.enableChannelIdentification = enableChannelIdentification
        self.enablePartialResultsStabilization = enablePartialResultsStabilization
        self.languageCode = languageCode
        self.mediaEncoding = mediaEncoding
        self.mediaSampleRateHertz = mediaSampleRateHertz
        self.numberOfChannels = numberOfChannels
        self.partialResultsStability = partialResultsStability
        self.sessionId = sessionId
        self.showSpeakerLabel = showSpeakerLabel
        self.vocabularyFilterMethod = vocabularyFilterMethod
        self.vocabularyFilterName = vocabularyFilterName
        self.vocabularyName = vocabularyName
    }
}

extension StartStreamTranscriptionInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "StartStreamTranscriptionInput(audioStream: \(String(describing: audioStream)), enableChannelIdentification: \(String(describing: enableChannelIdentification)), enablePartialResultsStabilization: \(String(describing: enablePartialResultsStabilization)), languageCode: \(String(describing: languageCode)), mediaEncoding: \(String(describing: mediaEncoding)), mediaSampleRateHertz: \(String(describing: mediaSampleRateHertz)), numberOfChannels: \(String(describing: numberOfChannels)), partialResultsStability: \(String(describing: partialResultsStability)), sessionId: \(String(describing: sessionId)), showSpeakerLabel: \(String(describing: showSpeakerLabel)), vocabularyFilterMethod: \(String(describing: vocabularyFilterMethod)), vocabularyFilterName: \(String(describing: vocabularyFilterName)), vocabularyName: \(String(describing: vocabularyName)))"}
}
