// Code generated by smithy-swift-codegen. DO NOT EDIT!
import AWSClientRuntime
import ClientRuntime

extension BufferingHints: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case intervalInSeconds = "IntervalInSeconds"
        case sizeInMBs = "SizeInMBs"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let intervalInSeconds = intervalInSeconds {
            try encodeContainer.encode(intervalInSeconds, forKey: .intervalInSeconds)
        }
        if let sizeInMBs = sizeInMBs {
            try encodeContainer.encode(sizeInMBs, forKey: .sizeInMBs)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let sizeInMBsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .sizeInMBs)
        sizeInMBs = sizeInMBsDecoded
        let intervalInSecondsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .intervalInSeconds)
        intervalInSeconds = intervalInSecondsDecoded
    }
}

extension BufferingHints: CustomDebugStringConvertible {
    public var debugDescription: String {
        "BufferingHints(intervalInSeconds: \(String(describing: intervalInSeconds)), sizeInMBs: \(String(describing: sizeInMBs)))"}
}

/// <p>Describes hints for the buffering to perform before delivering data to the
///          destination. These options are treated as hints, and therefore Kinesis Data Firehose might
///          choose to use different values when it is optimal. The <code>SizeInMBs</code> and
///             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for
///          one of them, you must also provide a value for the other.</p>
public struct BufferingHints: Equatable {
    /// <p>Buffer incoming data for the specified period of time, in seconds, before delivering
    ///          it to the destination. The default value is 300. This parameter is optional but if you
    ///          specify a value for it, you must also specify a value for <code>SizeInMBs</code>, and vice
    ///          versa.</p>
    public let intervalInSeconds: Int?
    /// <p>Buffer incoming data to the specified size, in MiBs, before delivering it to the
    ///          destination. The default value is 5. This parameter is optional but if you specify a value
    ///          for it, you must also specify a value for <code>IntervalInSeconds</code>, and vice
    ///          versa.</p>
    ///          <p>We recommend setting this parameter to a value greater than the amount of data you
    ///          typically ingest into the delivery stream in 10 seconds. For example, if you typically
    ///          ingest data at 1 MiB/sec, the value should be 10 MiB or higher.</p>
    public let sizeInMBs: Int?

    public init (
        intervalInSeconds: Int? = nil,
        sizeInMBs: Int? = nil
    )
    {
        self.intervalInSeconds = intervalInSeconds
        self.sizeInMBs = sizeInMBs
    }
}

extension CloudWatchLoggingOptions: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case enabled = "Enabled"
        case logGroupName = "LogGroupName"
        case logStreamName = "LogStreamName"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let enabled = enabled {
            try encodeContainer.encode(enabled, forKey: .enabled)
        }
        if let logGroupName = logGroupName {
            try encodeContainer.encode(logGroupName, forKey: .logGroupName)
        }
        if let logStreamName = logStreamName {
            try encodeContainer.encode(logStreamName, forKey: .logStreamName)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let enabledDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .enabled)
        enabled = enabledDecoded
        let logGroupNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .logGroupName)
        logGroupName = logGroupNameDecoded
        let logStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .logStreamName)
        logStreamName = logStreamNameDecoded
    }
}

extension CloudWatchLoggingOptions: CustomDebugStringConvertible {
    public var debugDescription: String {
        "CloudWatchLoggingOptions(enabled: \(String(describing: enabled)), logGroupName: \(String(describing: logGroupName)), logStreamName: \(String(describing: logStreamName)))"}
}

/// <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>
public struct CloudWatchLoggingOptions: Equatable {
    /// <p>Enables or disables CloudWatch logging.</p>
    public let enabled: Bool?
    /// <p>The CloudWatch group name for logging. This value is required if CloudWatch logging
    ///          is enabled.</p>
    public let logGroupName: String?
    /// <p>The CloudWatch log stream name for logging. This value is required if CloudWatch
    ///          logging is enabled.</p>
    public let logStreamName: String?

    public init (
        enabled: Bool? = nil,
        logGroupName: String? = nil,
        logStreamName: String? = nil
    )
    {
        self.enabled = enabled
        self.logGroupName = logGroupName
        self.logStreamName = logStreamName
    }
}

public enum CompressionFormat {
    case gzip
    case hadoopSnappy
    case snappy
    case uncompressed
    case zip
    case sdkUnknown(String)
}

extension CompressionFormat : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [CompressionFormat] {
        return [
            .gzip,
            .hadoopSnappy,
            .snappy,
            .uncompressed,
            .zip,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .gzip: return "GZIP"
        case .hadoopSnappy: return "HADOOP_SNAPPY"
        case .snappy: return "Snappy"
        case .uncompressed: return "UNCOMPRESSED"
        case .zip: return "ZIP"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = CompressionFormat(rawValue: rawValue) ?? CompressionFormat.sdkUnknown(rawValue)
    }
}

extension ConcurrentModificationException: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ConcurrentModificationException(message: \(String(describing: message)))"}
}

extension ConcurrentModificationException: AWSHttpServiceError {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: ConcurrentModificationExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>Another modification has already happened. Fetch <code>VersionId</code> again and use
///          it to update the destination.</p>
public struct ConcurrentModificationException: ClientRuntime.ServiceError, Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: HttpStatusCode?
    public var _message: String?
    public var _requestID: String?
    public var _retryable: Bool = false
    public var _isThrottling: Bool = false
    public var _type: ErrorType = .client
    /// <p>A message that provides information about the error.</p>
    public var message: String?

    public init (
        message: String? = nil
    )
    {
        self.message = message
    }
}

struct ConcurrentModificationExceptionBody: Equatable {
    public let message: String?
}

extension ConcurrentModificationExceptionBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case message
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(String.self, forKey: .message)
        message = messageDecoded
    }
}

public enum ContentEncoding {
    case gzip
    case `none`
    case sdkUnknown(String)
}

extension ContentEncoding : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [ContentEncoding] {
        return [
            .gzip,
            .none,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .gzip: return "GZIP"
        case .none: return "NONE"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = ContentEncoding(rawValue: rawValue) ?? ContentEncoding.sdkUnknown(rawValue)
    }
}

extension CopyCommand: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case copyOptions = "CopyOptions"
        case dataTableColumns = "DataTableColumns"
        case dataTableName = "DataTableName"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let copyOptions = copyOptions {
            try encodeContainer.encode(copyOptions, forKey: .copyOptions)
        }
        if let dataTableColumns = dataTableColumns {
            try encodeContainer.encode(dataTableColumns, forKey: .dataTableColumns)
        }
        if let dataTableName = dataTableName {
            try encodeContainer.encode(dataTableName, forKey: .dataTableName)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let dataTableNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .dataTableName)
        dataTableName = dataTableNameDecoded
        let dataTableColumnsDecoded = try containerValues.decodeIfPresent(String.self, forKey: .dataTableColumns)
        dataTableColumns = dataTableColumnsDecoded
        let copyOptionsDecoded = try containerValues.decodeIfPresent(String.self, forKey: .copyOptions)
        copyOptions = copyOptionsDecoded
    }
}

extension CopyCommand: CustomDebugStringConvertible {
    public var debugDescription: String {
        "CopyCommand(copyOptions: \(String(describing: copyOptions)), dataTableColumns: \(String(describing: dataTableColumns)), dataTableName: \(String(describing: dataTableName)))"}
}

/// <p>Describes a <code>COPY</code> command for Amazon Redshift.</p>
public struct CopyCommand: Equatable {
    /// <p>Optional parameters to use with the Amazon Redshift <code>COPY</code> command. For
    ///          more information, see the "Optional Parameters" section of <a href="https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html">Amazon Redshift COPY command</a>. Some possible
    ///          examples that would apply to Kinesis Data Firehose are as follows:</p>
    ///          <p>
    ///             <code>delimiter '\t' lzop;</code> - fields are delimited with "\t" (TAB character) and
    ///          compressed using lzop.</p>
    ///          <p>
    ///             <code>delimiter '|'</code> - fields are delimited with "|" (this is the default
    ///          delimiter).</p>
    ///          <p>
    ///             <code>delimiter '|' escape</code> - the delimiter should be escaped.</p>
    ///          <p>
    ///             <code>fixedwidth 'venueid:3,venuename:25,venuecity:12,venuestate:2,venueseats:6'</code> -
    ///          fields are fixed width in the source, with each width specified after every column in the
    ///          table.</p>
    ///          <p>
    ///             <code>JSON 's3://mybucket/jsonpaths.txt'</code> - data is in JSON format, and the path
    ///          specified is the format of the data.</p>
    ///          <p>For more examples, see <a href="https://docs.aws.amazon.com/redshift/latest/dg/r_COPY_command_examples.html">Amazon Redshift COPY command
    ///             examples</a>.</p>
    public let copyOptions: String?
    /// <p>A comma-separated list of column names.</p>
    public let dataTableColumns: String?
    /// <p>The name of the target table. The table must already exist in the database.</p>
    public let dataTableName: String?

    public init (
        copyOptions: String? = nil,
        dataTableColumns: String? = nil,
        dataTableName: String? = nil
    )
    {
        self.copyOptions = copyOptions
        self.dataTableColumns = dataTableColumns
        self.dataTableName = dataTableName
    }
}

public struct CreateDeliveryStreamInputBodyMiddleware: Middleware {
    public let id: String = "CreateDeliveryStreamInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<CreateDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<CreateDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<CreateDeliveryStreamInput>
    public typealias MOutput = OperationOutput<CreateDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<CreateDeliveryStreamOutputError>
}

extension CreateDeliveryStreamInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "CreateDeliveryStreamInput(deliveryStreamEncryptionConfigurationInput: \(String(describing: deliveryStreamEncryptionConfigurationInput)), deliveryStreamName: \(String(describing: deliveryStreamName)), deliveryStreamType: \(String(describing: deliveryStreamType)), elasticsearchDestinationConfiguration: \(String(describing: elasticsearchDestinationConfiguration)), extendedS3DestinationConfiguration: \(String(describing: extendedS3DestinationConfiguration)), httpEndpointDestinationConfiguration: \(String(describing: httpEndpointDestinationConfiguration)), kinesisStreamSourceConfiguration: \(String(describing: kinesisStreamSourceConfiguration)), redshiftDestinationConfiguration: \(String(describing: redshiftDestinationConfiguration)), s3DestinationConfiguration: \(String(describing: s3DestinationConfiguration)), splunkDestinationConfiguration: \(String(describing: splunkDestinationConfiguration)), tags: \(String(describing: tags)))"}
}

extension CreateDeliveryStreamInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamEncryptionConfigurationInput = "DeliveryStreamEncryptionConfigurationInput"
        case deliveryStreamName = "DeliveryStreamName"
        case deliveryStreamType = "DeliveryStreamType"
        case elasticsearchDestinationConfiguration = "ElasticsearchDestinationConfiguration"
        case extendedS3DestinationConfiguration = "ExtendedS3DestinationConfiguration"
        case httpEndpointDestinationConfiguration = "HttpEndpointDestinationConfiguration"
        case kinesisStreamSourceConfiguration = "KinesisStreamSourceConfiguration"
        case redshiftDestinationConfiguration = "RedshiftDestinationConfiguration"
        case s3DestinationConfiguration = "S3DestinationConfiguration"
        case splunkDestinationConfiguration = "SplunkDestinationConfiguration"
        case tags = "Tags"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deliveryStreamEncryptionConfigurationInput = deliveryStreamEncryptionConfigurationInput {
            try encodeContainer.encode(deliveryStreamEncryptionConfigurationInput, forKey: .deliveryStreamEncryptionConfigurationInput)
        }
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
        if let deliveryStreamType = deliveryStreamType {
            try encodeContainer.encode(deliveryStreamType.rawValue, forKey: .deliveryStreamType)
        }
        if let elasticsearchDestinationConfiguration = elasticsearchDestinationConfiguration {
            try encodeContainer.encode(elasticsearchDestinationConfiguration, forKey: .elasticsearchDestinationConfiguration)
        }
        if let extendedS3DestinationConfiguration = extendedS3DestinationConfiguration {
            try encodeContainer.encode(extendedS3DestinationConfiguration, forKey: .extendedS3DestinationConfiguration)
        }
        if let httpEndpointDestinationConfiguration = httpEndpointDestinationConfiguration {
            try encodeContainer.encode(httpEndpointDestinationConfiguration, forKey: .httpEndpointDestinationConfiguration)
        }
        if let kinesisStreamSourceConfiguration = kinesisStreamSourceConfiguration {
            try encodeContainer.encode(kinesisStreamSourceConfiguration, forKey: .kinesisStreamSourceConfiguration)
        }
        if let redshiftDestinationConfiguration = redshiftDestinationConfiguration {
            try encodeContainer.encode(redshiftDestinationConfiguration, forKey: .redshiftDestinationConfiguration)
        }
        if let s3DestinationConfiguration = s3DestinationConfiguration {
            try encodeContainer.encode(s3DestinationConfiguration, forKey: .s3DestinationConfiguration)
        }
        if let splunkDestinationConfiguration = splunkDestinationConfiguration {
            try encodeContainer.encode(splunkDestinationConfiguration, forKey: .splunkDestinationConfiguration)
        }
        if let tags = tags {
            var tagsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .tags)
            for tagdeliverystreaminputtaglist0 in tags {
                try tagsContainer.encode(tagdeliverystreaminputtaglist0)
            }
        }
    }
}

public struct CreateDeliveryStreamInputHeadersMiddleware: Middleware {
    public let id: String = "CreateDeliveryStreamInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<CreateDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<CreateDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<CreateDeliveryStreamInput>
    public typealias MOutput = OperationOutput<CreateDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<CreateDeliveryStreamOutputError>
}

public struct CreateDeliveryStreamInputQueryItemMiddleware: Middleware {
    public let id: String = "CreateDeliveryStreamInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<CreateDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<CreateDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<CreateDeliveryStreamInput>
    public typealias MOutput = OperationOutput<CreateDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<CreateDeliveryStreamOutputError>
}

public struct CreateDeliveryStreamInput: Equatable {
    /// <p>Used to specify the type and Amazon Resource Name (ARN) of the KMS key needed for
    ///          Server-Side Encryption (SSE).</p>
    public let deliveryStreamEncryptionConfigurationInput: DeliveryStreamEncryptionConfigurationInput?
    /// <p>The name of the delivery stream. This name must be unique per AWS account in the same
    ///          AWS Region. If the delivery streams are in different accounts or different Regions, you can
    ///          have multiple delivery streams with the same name.</p>
    public let deliveryStreamName: String?
    /// <p>The delivery stream type. This parameter can be one of the following
    ///          values:</p>
    ///          <ul>
    ///             <li>
    ///                <p>
    ///                   <code>DirectPut</code>: Provider applications access the delivery stream
    ///                directly.</p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>KinesisStreamAsSource</code>: The delivery stream uses a Kinesis data
    ///                stream as a source.</p>
    ///             </li>
    ///          </ul>
    public let deliveryStreamType: DeliveryStreamType?
    /// <p>The destination in Amazon ES. You can specify only one destination.</p>
    public let elasticsearchDestinationConfiguration: ElasticsearchDestinationConfiguration?
    /// <p>The destination in Amazon S3. You can specify only one destination.</p>
    public let extendedS3DestinationConfiguration: ExtendedS3DestinationConfiguration?
    /// <p>Enables configuring Kinesis Firehose to deliver data to any HTTP endpoint destination.
    ///          You can specify only one destination.</p>
    public let httpEndpointDestinationConfiguration: HttpEndpointDestinationConfiguration?
    /// <p>When a Kinesis data stream is used as the source for the delivery stream, a <a>KinesisStreamSourceConfiguration</a> containing the Kinesis data stream Amazon
    ///          Resource Name (ARN) and the role ARN for the source stream.</p>
    public let kinesisStreamSourceConfiguration: KinesisStreamSourceConfiguration?
    /// <p>The destination in Amazon Redshift. You can specify only one destination.</p>
    public let redshiftDestinationConfiguration: RedshiftDestinationConfiguration?
    /// <p>[Deprecated]
    ///          The destination in Amazon S3. You can specify only one destination.</p>
    @available(*, deprecated)
    public let s3DestinationConfiguration: S3DestinationConfiguration?
    /// <p>The destination in Splunk. You can specify only one destination.</p>
    public let splunkDestinationConfiguration: SplunkDestinationConfiguration?
    /// <p>A set of tags to assign to the delivery stream. A tag is a key-value pair that you can
    ///          define and assign to AWS resources. Tags are metadata. For example, you can add friendly
    ///          names and descriptions or other types of information that can help you distinguish the
    ///          delivery stream. For more information about tags, see <a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html">Using Cost Allocation Tags</a> in the AWS Billing and Cost Management User
    ///          Guide.</p>
    ///
    ///          <p>You can specify up to 50 tags when creating a delivery stream.</p>
    public let tags: [Tag]?

    public init (
        deliveryStreamEncryptionConfigurationInput: DeliveryStreamEncryptionConfigurationInput? = nil,
        deliveryStreamName: String? = nil,
        deliveryStreamType: DeliveryStreamType? = nil,
        elasticsearchDestinationConfiguration: ElasticsearchDestinationConfiguration? = nil,
        extendedS3DestinationConfiguration: ExtendedS3DestinationConfiguration? = nil,
        httpEndpointDestinationConfiguration: HttpEndpointDestinationConfiguration? = nil,
        kinesisStreamSourceConfiguration: KinesisStreamSourceConfiguration? = nil,
        redshiftDestinationConfiguration: RedshiftDestinationConfiguration? = nil,
        s3DestinationConfiguration: S3DestinationConfiguration? = nil,
        splunkDestinationConfiguration: SplunkDestinationConfiguration? = nil,
        tags: [Tag]? = nil
    )
    {
        self.deliveryStreamEncryptionConfigurationInput = deliveryStreamEncryptionConfigurationInput
        self.deliveryStreamName = deliveryStreamName
        self.deliveryStreamType = deliveryStreamType
        self.elasticsearchDestinationConfiguration = elasticsearchDestinationConfiguration
        self.extendedS3DestinationConfiguration = extendedS3DestinationConfiguration
        self.httpEndpointDestinationConfiguration = httpEndpointDestinationConfiguration
        self.kinesisStreamSourceConfiguration = kinesisStreamSourceConfiguration
        self.redshiftDestinationConfiguration = redshiftDestinationConfiguration
        self.s3DestinationConfiguration = s3DestinationConfiguration
        self.splunkDestinationConfiguration = splunkDestinationConfiguration
        self.tags = tags
    }
}

struct CreateDeliveryStreamInputBody: Equatable {
    public let deliveryStreamName: String?
    public let deliveryStreamType: DeliveryStreamType?
    public let kinesisStreamSourceConfiguration: KinesisStreamSourceConfiguration?
    public let deliveryStreamEncryptionConfigurationInput: DeliveryStreamEncryptionConfigurationInput?
    public let s3DestinationConfiguration: S3DestinationConfiguration?
    public let extendedS3DestinationConfiguration: ExtendedS3DestinationConfiguration?
    public let redshiftDestinationConfiguration: RedshiftDestinationConfiguration?
    public let elasticsearchDestinationConfiguration: ElasticsearchDestinationConfiguration?
    public let splunkDestinationConfiguration: SplunkDestinationConfiguration?
    public let httpEndpointDestinationConfiguration: HttpEndpointDestinationConfiguration?
    public let tags: [Tag]?
}

extension CreateDeliveryStreamInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamEncryptionConfigurationInput = "DeliveryStreamEncryptionConfigurationInput"
        case deliveryStreamName = "DeliveryStreamName"
        case deliveryStreamType = "DeliveryStreamType"
        case elasticsearchDestinationConfiguration = "ElasticsearchDestinationConfiguration"
        case extendedS3DestinationConfiguration = "ExtendedS3DestinationConfiguration"
        case httpEndpointDestinationConfiguration = "HttpEndpointDestinationConfiguration"
        case kinesisStreamSourceConfiguration = "KinesisStreamSourceConfiguration"
        case redshiftDestinationConfiguration = "RedshiftDestinationConfiguration"
        case s3DestinationConfiguration = "S3DestinationConfiguration"
        case splunkDestinationConfiguration = "SplunkDestinationConfiguration"
        case tags = "Tags"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
        let deliveryStreamTypeDecoded = try containerValues.decodeIfPresent(DeliveryStreamType.self, forKey: .deliveryStreamType)
        deliveryStreamType = deliveryStreamTypeDecoded
        let kinesisStreamSourceConfigurationDecoded = try containerValues.decodeIfPresent(KinesisStreamSourceConfiguration.self, forKey: .kinesisStreamSourceConfiguration)
        kinesisStreamSourceConfiguration = kinesisStreamSourceConfigurationDecoded
        let deliveryStreamEncryptionConfigurationInputDecoded = try containerValues.decodeIfPresent(DeliveryStreamEncryptionConfigurationInput.self, forKey: .deliveryStreamEncryptionConfigurationInput)
        deliveryStreamEncryptionConfigurationInput = deliveryStreamEncryptionConfigurationInputDecoded
        let s3DestinationConfigurationDecoded = try containerValues.decodeIfPresent(S3DestinationConfiguration.self, forKey: .s3DestinationConfiguration)
        s3DestinationConfiguration = s3DestinationConfigurationDecoded
        let extendedS3DestinationConfigurationDecoded = try containerValues.decodeIfPresent(ExtendedS3DestinationConfiguration.self, forKey: .extendedS3DestinationConfiguration)
        extendedS3DestinationConfiguration = extendedS3DestinationConfigurationDecoded
        let redshiftDestinationConfigurationDecoded = try containerValues.decodeIfPresent(RedshiftDestinationConfiguration.self, forKey: .redshiftDestinationConfiguration)
        redshiftDestinationConfiguration = redshiftDestinationConfigurationDecoded
        let elasticsearchDestinationConfigurationDecoded = try containerValues.decodeIfPresent(ElasticsearchDestinationConfiguration.self, forKey: .elasticsearchDestinationConfiguration)
        elasticsearchDestinationConfiguration = elasticsearchDestinationConfigurationDecoded
        let splunkDestinationConfigurationDecoded = try containerValues.decodeIfPresent(SplunkDestinationConfiguration.self, forKey: .splunkDestinationConfiguration)
        splunkDestinationConfiguration = splunkDestinationConfigurationDecoded
        let httpEndpointDestinationConfigurationDecoded = try containerValues.decodeIfPresent(HttpEndpointDestinationConfiguration.self, forKey: .httpEndpointDestinationConfiguration)
        httpEndpointDestinationConfiguration = httpEndpointDestinationConfigurationDecoded
        let tagsContainer = try containerValues.decodeIfPresent([Tag?].self, forKey: .tags)
        var tagsDecoded0:[Tag]? = nil
        if let tagsContainer = tagsContainer {
            tagsDecoded0 = [Tag]()
            for structure0 in tagsContainer {
                if let structure0 = structure0 {
                    tagsDecoded0?.append(structure0)
                }
            }
        }
        tags = tagsDecoded0
    }
}

extension CreateDeliveryStreamOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension CreateDeliveryStreamOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidKMSResourceException" : self = .invalidKMSResourceException(try InvalidKMSResourceException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "LimitExceededException" : self = .limitExceededException(try LimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceInUseException" : self = .resourceInUseException(try ResourceInUseException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum CreateDeliveryStreamOutputError: Swift.Error, Equatable {
    case invalidArgumentException(InvalidArgumentException)
    case invalidKMSResourceException(InvalidKMSResourceException)
    case limitExceededException(LimitExceededException)
    case resourceInUseException(ResourceInUseException)
    case unknown(UnknownAWSHttpServiceError)
}

extension CreateDeliveryStreamOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "CreateDeliveryStreamOutputResponse(deliveryStreamARN: \(String(describing: deliveryStreamARN)))"}
}

extension CreateDeliveryStreamOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: CreateDeliveryStreamOutputResponseBody = try responseDecoder.decode(responseBody: data)
            self.deliveryStreamARN = output.deliveryStreamARN
        } else {
            self.deliveryStreamARN = nil
        }
    }
}

public struct CreateDeliveryStreamOutputResponse: Equatable {
    /// <p>The ARN of the delivery stream.</p>
    public let deliveryStreamARN: String?

    public init (
        deliveryStreamARN: String? = nil
    )
    {
        self.deliveryStreamARN = deliveryStreamARN
    }
}

struct CreateDeliveryStreamOutputResponseBody: Equatable {
    public let deliveryStreamARN: String?
}

extension CreateDeliveryStreamOutputResponseBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamARN = "DeliveryStreamARN"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamARN)
        deliveryStreamARN = deliveryStreamARNDecoded
    }
}

extension DataFormatConversionConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case enabled = "Enabled"
        case inputFormatConfiguration = "InputFormatConfiguration"
        case outputFormatConfiguration = "OutputFormatConfiguration"
        case schemaConfiguration = "SchemaConfiguration"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let enabled = enabled {
            try encodeContainer.encode(enabled, forKey: .enabled)
        }
        if let inputFormatConfiguration = inputFormatConfiguration {
            try encodeContainer.encode(inputFormatConfiguration, forKey: .inputFormatConfiguration)
        }
        if let outputFormatConfiguration = outputFormatConfiguration {
            try encodeContainer.encode(outputFormatConfiguration, forKey: .outputFormatConfiguration)
        }
        if let schemaConfiguration = schemaConfiguration {
            try encodeContainer.encode(schemaConfiguration, forKey: .schemaConfiguration)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let schemaConfigurationDecoded = try containerValues.decodeIfPresent(SchemaConfiguration.self, forKey: .schemaConfiguration)
        schemaConfiguration = schemaConfigurationDecoded
        let inputFormatConfigurationDecoded = try containerValues.decodeIfPresent(InputFormatConfiguration.self, forKey: .inputFormatConfiguration)
        inputFormatConfiguration = inputFormatConfigurationDecoded
        let outputFormatConfigurationDecoded = try containerValues.decodeIfPresent(OutputFormatConfiguration.self, forKey: .outputFormatConfiguration)
        outputFormatConfiguration = outputFormatConfigurationDecoded
        let enabledDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .enabled)
        enabled = enabledDecoded
    }
}

extension DataFormatConversionConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "DataFormatConversionConfiguration(enabled: \(String(describing: enabled)), inputFormatConfiguration: \(String(describing: inputFormatConfiguration)), outputFormatConfiguration: \(String(describing: outputFormatConfiguration)), schemaConfiguration: \(String(describing: schemaConfiguration)))"}
}

/// <p>Specifies that you want Kinesis Data Firehose to convert data from the JSON format to
///          the Parquet or ORC format before writing it to Amazon S3. Kinesis Data Firehose uses the
///          serializer and deserializer that you specify, in addition to the column information from
///          the AWS Glue table, to deserialize your input data from JSON and then serialize it to the
///          Parquet or ORC format. For more information, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/record-format-conversion.html">Kinesis Data Firehose Record Format Conversion</a>.</p>
public struct DataFormatConversionConfiguration: Equatable {
    /// <p>Defaults to <code>true</code>. Set it to <code>false</code> if you want to disable
    ///          format conversion while preserving the configuration details.</p>
    public let enabled: Bool?
    /// <p>Specifies the deserializer that you want Kinesis Data Firehose to use to convert the
    ///          format of your data from JSON. This parameter is required if <code>Enabled</code> is set to
    ///          true.</p>
    public let inputFormatConfiguration: InputFormatConfiguration?
    /// <p>Specifies the serializer that you want Kinesis Data Firehose to use to convert the
    ///          format of your data to the Parquet or ORC format. This parameter is required if
    ///             <code>Enabled</code> is set to true.</p>
    public let outputFormatConfiguration: OutputFormatConfiguration?
    /// <p>Specifies the AWS Glue Data Catalog table that contains the column information. This
    ///          parameter is required if <code>Enabled</code> is set to true.</p>
    public let schemaConfiguration: SchemaConfiguration?

    public init (
        enabled: Bool? = nil,
        inputFormatConfiguration: InputFormatConfiguration? = nil,
        outputFormatConfiguration: OutputFormatConfiguration? = nil,
        schemaConfiguration: SchemaConfiguration? = nil
    )
    {
        self.enabled = enabled
        self.inputFormatConfiguration = inputFormatConfiguration
        self.outputFormatConfiguration = outputFormatConfiguration
        self.schemaConfiguration = schemaConfiguration
    }
}

public struct DeleteDeliveryStreamInputBodyMiddleware: Middleware {
    public let id: String = "DeleteDeliveryStreamInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<DeleteDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<DeleteDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<DeleteDeliveryStreamInput>
    public typealias MOutput = OperationOutput<DeleteDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<DeleteDeliveryStreamOutputError>
}

extension DeleteDeliveryStreamInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "DeleteDeliveryStreamInput(allowForceDelete: \(String(describing: allowForceDelete)), deliveryStreamName: \(String(describing: deliveryStreamName)))"}
}

extension DeleteDeliveryStreamInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case allowForceDelete = "AllowForceDelete"
        case deliveryStreamName = "DeliveryStreamName"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let allowForceDelete = allowForceDelete {
            try encodeContainer.encode(allowForceDelete, forKey: .allowForceDelete)
        }
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
    }
}

public struct DeleteDeliveryStreamInputHeadersMiddleware: Middleware {
    public let id: String = "DeleteDeliveryStreamInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<DeleteDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<DeleteDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<DeleteDeliveryStreamInput>
    public typealias MOutput = OperationOutput<DeleteDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<DeleteDeliveryStreamOutputError>
}

public struct DeleteDeliveryStreamInputQueryItemMiddleware: Middleware {
    public let id: String = "DeleteDeliveryStreamInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<DeleteDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<DeleteDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<DeleteDeliveryStreamInput>
    public typealias MOutput = OperationOutput<DeleteDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<DeleteDeliveryStreamOutputError>
}

public struct DeleteDeliveryStreamInput: Equatable {
    /// <p>Set this to true if you want to delete the delivery stream even if Kinesis Data Firehose
    ///          is unable to retire the grant for the CMK. Kinesis Data Firehose might be unable to retire
    ///          the grant due to a customer error, such as when the CMK or the grant are in an invalid
    ///          state. If you force deletion, you can then use the <a href="https://docs.aws.amazon.com/kms/latest/APIReference/API_RevokeGrant.html">RevokeGrant</a> operation to revoke the grant you gave to Kinesis Data Firehose. If
    ///          a failure to retire the grant happens due to an AWS KMS issue, Kinesis Data Firehose keeps
    ///          retrying the delete operation.</p>
    ///          <p>The default value is false.</p>
    public let allowForceDelete: Bool?
    /// <p>The name of the delivery stream.</p>
    public let deliveryStreamName: String?

    public init (
        allowForceDelete: Bool? = nil,
        deliveryStreamName: String? = nil
    )
    {
        self.allowForceDelete = allowForceDelete
        self.deliveryStreamName = deliveryStreamName
    }
}

struct DeleteDeliveryStreamInputBody: Equatable {
    public let deliveryStreamName: String?
    public let allowForceDelete: Bool?
}

extension DeleteDeliveryStreamInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case allowForceDelete = "AllowForceDelete"
        case deliveryStreamName = "DeliveryStreamName"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
        let allowForceDeleteDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .allowForceDelete)
        allowForceDelete = allowForceDeleteDecoded
    }
}

extension DeleteDeliveryStreamOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension DeleteDeliveryStreamOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        case "ResourceInUseException" : self = .resourceInUseException(try ResourceInUseException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum DeleteDeliveryStreamOutputError: Swift.Error, Equatable {
    case resourceInUseException(ResourceInUseException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unknown(UnknownAWSHttpServiceError)
}

extension DeleteDeliveryStreamOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "DeleteDeliveryStreamOutputResponse()"}
}

extension DeleteDeliveryStreamOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
    }
}

public struct DeleteDeliveryStreamOutputResponse: Equatable {

    public init() {}
}

struct DeleteDeliveryStreamOutputResponseBody: Equatable {
}

extension DeleteDeliveryStreamOutputResponseBody: Decodable {

    public init (from decoder: Decoder) throws {
    }
}

extension DeliveryStreamDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case createTimestamp = "CreateTimestamp"
        case deliveryStreamARN = "DeliveryStreamARN"
        case deliveryStreamEncryptionConfiguration = "DeliveryStreamEncryptionConfiguration"
        case deliveryStreamName = "DeliveryStreamName"
        case deliveryStreamStatus = "DeliveryStreamStatus"
        case deliveryStreamType = "DeliveryStreamType"
        case destinations = "Destinations"
        case failureDescription = "FailureDescription"
        case hasMoreDestinations = "HasMoreDestinations"
        case lastUpdateTimestamp = "LastUpdateTimestamp"
        case source = "Source"
        case versionId = "VersionId"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let createTimestamp = createTimestamp {
            try encodeContainer.encode(createTimestamp.timeIntervalSince1970, forKey: .createTimestamp)
        }
        if let deliveryStreamARN = deliveryStreamARN {
            try encodeContainer.encode(deliveryStreamARN, forKey: .deliveryStreamARN)
        }
        if let deliveryStreamEncryptionConfiguration = deliveryStreamEncryptionConfiguration {
            try encodeContainer.encode(deliveryStreamEncryptionConfiguration, forKey: .deliveryStreamEncryptionConfiguration)
        }
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
        if let deliveryStreamStatus = deliveryStreamStatus {
            try encodeContainer.encode(deliveryStreamStatus.rawValue, forKey: .deliveryStreamStatus)
        }
        if let deliveryStreamType = deliveryStreamType {
            try encodeContainer.encode(deliveryStreamType.rawValue, forKey: .deliveryStreamType)
        }
        if let destinations = destinations {
            var destinationsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .destinations)
            for destinationdescriptionlist0 in destinations {
                try destinationsContainer.encode(destinationdescriptionlist0)
            }
        }
        if let failureDescription = failureDescription {
            try encodeContainer.encode(failureDescription, forKey: .failureDescription)
        }
        if let hasMoreDestinations = hasMoreDestinations {
            try encodeContainer.encode(hasMoreDestinations, forKey: .hasMoreDestinations)
        }
        if let lastUpdateTimestamp = lastUpdateTimestamp {
            try encodeContainer.encode(lastUpdateTimestamp.timeIntervalSince1970, forKey: .lastUpdateTimestamp)
        }
        if let source = source {
            try encodeContainer.encode(source, forKey: .source)
        }
        if let versionId = versionId {
            try encodeContainer.encode(versionId, forKey: .versionId)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
        let deliveryStreamARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamARN)
        deliveryStreamARN = deliveryStreamARNDecoded
        let deliveryStreamStatusDecoded = try containerValues.decodeIfPresent(DeliveryStreamStatus.self, forKey: .deliveryStreamStatus)
        deliveryStreamStatus = deliveryStreamStatusDecoded
        let failureDescriptionDecoded = try containerValues.decodeIfPresent(FailureDescription.self, forKey: .failureDescription)
        failureDescription = failureDescriptionDecoded
        let deliveryStreamEncryptionConfigurationDecoded = try containerValues.decodeIfPresent(DeliveryStreamEncryptionConfiguration.self, forKey: .deliveryStreamEncryptionConfiguration)
        deliveryStreamEncryptionConfiguration = deliveryStreamEncryptionConfigurationDecoded
        let deliveryStreamTypeDecoded = try containerValues.decodeIfPresent(DeliveryStreamType.self, forKey: .deliveryStreamType)
        deliveryStreamType = deliveryStreamTypeDecoded
        let versionIdDecoded = try containerValues.decodeIfPresent(String.self, forKey: .versionId)
        versionId = versionIdDecoded
        let createTimestampDecoded = try containerValues.decodeIfPresent(Date.self, forKey: .createTimestamp)
        createTimestamp = createTimestampDecoded
        let lastUpdateTimestampDecoded = try containerValues.decodeIfPresent(Date.self, forKey: .lastUpdateTimestamp)
        lastUpdateTimestamp = lastUpdateTimestampDecoded
        let sourceDecoded = try containerValues.decodeIfPresent(SourceDescription.self, forKey: .source)
        source = sourceDecoded
        let destinationsContainer = try containerValues.decodeIfPresent([DestinationDescription?].self, forKey: .destinations)
        var destinationsDecoded0:[DestinationDescription]? = nil
        if let destinationsContainer = destinationsContainer {
            destinationsDecoded0 = [DestinationDescription]()
            for structure0 in destinationsContainer {
                if let structure0 = structure0 {
                    destinationsDecoded0?.append(structure0)
                }
            }
        }
        destinations = destinationsDecoded0
        let hasMoreDestinationsDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .hasMoreDestinations)
        hasMoreDestinations = hasMoreDestinationsDecoded
    }
}

extension DeliveryStreamDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "DeliveryStreamDescription(createTimestamp: \(String(describing: createTimestamp)), deliveryStreamARN: \(String(describing: deliveryStreamARN)), deliveryStreamEncryptionConfiguration: \(String(describing: deliveryStreamEncryptionConfiguration)), deliveryStreamName: \(String(describing: deliveryStreamName)), deliveryStreamStatus: \(String(describing: deliveryStreamStatus)), deliveryStreamType: \(String(describing: deliveryStreamType)), destinations: \(String(describing: destinations)), failureDescription: \(String(describing: failureDescription)), hasMoreDestinations: \(String(describing: hasMoreDestinations)), lastUpdateTimestamp: \(String(describing: lastUpdateTimestamp)), source: \(String(describing: source)), versionId: \(String(describing: versionId)))"}
}

/// <p>Contains information about a delivery stream.</p>
public struct DeliveryStreamDescription: Equatable {
    /// <p>The date and time that the delivery stream was created.</p>
    public let createTimestamp: Date?
    /// <p>The Amazon Resource Name (ARN) of the delivery stream. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let deliveryStreamARN: String?
    /// <p>Indicates the server-side encryption (SSE) status for the delivery stream.</p>
    public let deliveryStreamEncryptionConfiguration: DeliveryStreamEncryptionConfiguration?
    /// <p>The name of the delivery stream.</p>
    public let deliveryStreamName: String?
    /// <p>The status of the delivery stream. If the status of a delivery stream is
    ///             <code>CREATING_FAILED</code>, this status doesn't change, and you can't invoke
    ///             <code>CreateDeliveryStream</code> again on it. However, you can invoke the <a>DeleteDeliveryStream</a> operation to delete it.</p>
    public let deliveryStreamStatus: DeliveryStreamStatus?
    /// <p>The delivery stream type. This can be one of the following values:</p>
    ///          <ul>
    ///             <li>
    ///                <p>
    ///                   <code>DirectPut</code>: Provider applications access the delivery stream
    ///                directly.</p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>KinesisStreamAsSource</code>: The delivery stream uses a Kinesis data
    ///                stream as a source.</p>
    ///             </li>
    ///          </ul>
    public let deliveryStreamType: DeliveryStreamType?
    /// <p>The destinations.</p>
    public let destinations: [DestinationDescription]?
    /// <p>Provides details in case one of the following operations fails due to an error related
    ///          to KMS: <a>CreateDeliveryStream</a>, <a>DeleteDeliveryStream</a>,
    ///             <a>StartDeliveryStreamEncryption</a>, <a>StopDeliveryStreamEncryption</a>.</p>
    public let failureDescription: FailureDescription?
    /// <p>Indicates whether there are more destinations available to list.</p>
    public let hasMoreDestinations: Bool?
    /// <p>The date and time that the delivery stream was last updated.</p>
    public let lastUpdateTimestamp: Date?
    /// <p>If the <code>DeliveryStreamType</code> parameter is
    ///             <code>KinesisStreamAsSource</code>, a <a>SourceDescription</a> object
    ///          describing the source Kinesis data stream.</p>
    public let source: SourceDescription?
    /// <p>Each time the destination is updated for a delivery stream, the version ID is
    ///          changed, and the current version ID is required when updating the destination. This is so
    ///          that the service knows it is applying the changes to the correct version of the delivery
    ///          stream.</p>
    public let versionId: String?

    public init (
        createTimestamp: Date? = nil,
        deliveryStreamARN: String? = nil,
        deliveryStreamEncryptionConfiguration: DeliveryStreamEncryptionConfiguration? = nil,
        deliveryStreamName: String? = nil,
        deliveryStreamStatus: DeliveryStreamStatus? = nil,
        deliveryStreamType: DeliveryStreamType? = nil,
        destinations: [DestinationDescription]? = nil,
        failureDescription: FailureDescription? = nil,
        hasMoreDestinations: Bool? = nil,
        lastUpdateTimestamp: Date? = nil,
        source: SourceDescription? = nil,
        versionId: String? = nil
    )
    {
        self.createTimestamp = createTimestamp
        self.deliveryStreamARN = deliveryStreamARN
        self.deliveryStreamEncryptionConfiguration = deliveryStreamEncryptionConfiguration
        self.deliveryStreamName = deliveryStreamName
        self.deliveryStreamStatus = deliveryStreamStatus
        self.deliveryStreamType = deliveryStreamType
        self.destinations = destinations
        self.failureDescription = failureDescription
        self.hasMoreDestinations = hasMoreDestinations
        self.lastUpdateTimestamp = lastUpdateTimestamp
        self.source = source
        self.versionId = versionId
    }
}

extension DeliveryStreamEncryptionConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case failureDescription = "FailureDescription"
        case keyARN = "KeyARN"
        case keyType = "KeyType"
        case status = "Status"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let failureDescription = failureDescription {
            try encodeContainer.encode(failureDescription, forKey: .failureDescription)
        }
        if let keyARN = keyARN {
            try encodeContainer.encode(keyARN, forKey: .keyARN)
        }
        if let keyType = keyType {
            try encodeContainer.encode(keyType.rawValue, forKey: .keyType)
        }
        if let status = status {
            try encodeContainer.encode(status.rawValue, forKey: .status)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let keyARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .keyARN)
        keyARN = keyARNDecoded
        let keyTypeDecoded = try containerValues.decodeIfPresent(KeyType.self, forKey: .keyType)
        keyType = keyTypeDecoded
        let statusDecoded = try containerValues.decodeIfPresent(DeliveryStreamEncryptionStatus.self, forKey: .status)
        status = statusDecoded
        let failureDescriptionDecoded = try containerValues.decodeIfPresent(FailureDescription.self, forKey: .failureDescription)
        failureDescription = failureDescriptionDecoded
    }
}

extension DeliveryStreamEncryptionConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "DeliveryStreamEncryptionConfiguration(failureDescription: \(String(describing: failureDescription)), keyARN: \(String(describing: keyARN)), keyType: \(String(describing: keyType)), status: \(String(describing: status)))"}
}

/// <p>Contains information about the server-side encryption (SSE) status for the delivery
///          stream, the type customer master key (CMK) in use, if any, and the ARN of the CMK. You can
///          get <code>DeliveryStreamEncryptionConfiguration</code> by invoking the <a>DescribeDeliveryStream</a> operation. </p>
public struct DeliveryStreamEncryptionConfiguration: Equatable {
    /// <p>Provides details in case one of the following operations fails due to an error related
    ///          to KMS: <a>CreateDeliveryStream</a>, <a>DeleteDeliveryStream</a>,
    ///             <a>StartDeliveryStreamEncryption</a>, <a>StopDeliveryStreamEncryption</a>.</p>
    public let failureDescription: FailureDescription?
    /// <p>If <code>KeyType</code> is <code>CUSTOMER_MANAGED_CMK</code>, this field contains the
    ///          ARN of the customer managed CMK. If <code>KeyType</code> is <code>AWS_OWNED_CMK</code>,
    ///             <code>DeliveryStreamEncryptionConfiguration</code> doesn't contain a value for
    ///             <code>KeyARN</code>.</p>
    public let keyARN: String?
    /// <p>Indicates the type of customer master key (CMK) that is used for encryption. The default
    ///          setting is <code>AWS_OWNED_CMK</code>. For more information about CMKs, see <a href="https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys">Customer Master Keys (CMKs)</a>.</p>
    public let keyType: KeyType?
    /// <p>This is the server-side encryption (SSE) status for the delivery stream. For a full
    ///          description of the different values of this status, see <a>StartDeliveryStreamEncryption</a> and <a>StopDeliveryStreamEncryption</a>. If this status is <code>ENABLING_FAILED</code>
    ///          or <code>DISABLING_FAILED</code>, it is the status of the most recent attempt to enable or
    ///          disable SSE, respectively.</p>
    public let status: DeliveryStreamEncryptionStatus?

    public init (
        failureDescription: FailureDescription? = nil,
        keyARN: String? = nil,
        keyType: KeyType? = nil,
        status: DeliveryStreamEncryptionStatus? = nil
    )
    {
        self.failureDescription = failureDescription
        self.keyARN = keyARN
        self.keyType = keyType
        self.status = status
    }
}

extension DeliveryStreamEncryptionConfigurationInput: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case keyARN = "KeyARN"
        case keyType = "KeyType"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let keyARN = keyARN {
            try encodeContainer.encode(keyARN, forKey: .keyARN)
        }
        if let keyType = keyType {
            try encodeContainer.encode(keyType.rawValue, forKey: .keyType)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let keyARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .keyARN)
        keyARN = keyARNDecoded
        let keyTypeDecoded = try containerValues.decodeIfPresent(KeyType.self, forKey: .keyType)
        keyType = keyTypeDecoded
    }
}

extension DeliveryStreamEncryptionConfigurationInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "DeliveryStreamEncryptionConfigurationInput(keyARN: \(String(describing: keyARN)), keyType: \(String(describing: keyType)))"}
}

/// <p>Specifies the type and Amazon Resource Name (ARN) of the CMK to use for Server-Side
///          Encryption (SSE). </p>
public struct DeliveryStreamEncryptionConfigurationInput: Equatable {
    /// <p>If you set <code>KeyType</code> to <code>CUSTOMER_MANAGED_CMK</code>, you must specify
    ///          the Amazon Resource Name (ARN) of the CMK. If you set <code>KeyType</code> to
    ///             <code>AWS_OWNED_CMK</code>, Kinesis Data Firehose uses a service-account CMK.</p>
    public let keyARN: String?
    /// <p>Indicates the type of customer master key (CMK) to use for encryption. The default
    ///          setting is <code>AWS_OWNED_CMK</code>. For more information about CMKs, see <a href="https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys">Customer Master Keys (CMKs)</a>. When you invoke <a>CreateDeliveryStream</a> or <a>StartDeliveryStreamEncryption</a> with
    ///             <code>KeyType</code> set to CUSTOMER_MANAGED_CMK, Kinesis Data Firehose invokes the
    ///          Amazon KMS operation <a href="https://docs.aws.amazon.com/kms/latest/APIReference/API_CreateGrant.html">CreateGrant</a> to create a grant that allows the Kinesis Data Firehose service to
    ///          use the customer managed CMK to perform encryption and decryption. Kinesis Data Firehose
    ///          manages that grant. </p>
    ///          <p>When you invoke <a>StartDeliveryStreamEncryption</a> to change the CMK for a
    ///          delivery stream that is encrypted with a customer managed CMK, Kinesis Data Firehose
    ///          schedules the grant it had on the old CMK for retirement.</p>
    ///          <p>You can use a CMK of type CUSTOMER_MANAGED_CMK to encrypt up to 500 delivery streams. If
    ///          a <a>CreateDeliveryStream</a> or <a>StartDeliveryStreamEncryption</a>
    ///          operation exceeds this limit, Kinesis Data Firehose throws a
    ///             <code>LimitExceededException</code>. </p>
    ///          <important>
    ///             <p>To encrypt your delivery stream, use symmetric CMKs. Kinesis Data Firehose doesn't
    ///             support asymmetric CMKs. For information about symmetric and asymmetric CMKs, see <a href="https://docs.aws.amazon.com/kms/latest/developerguide/symm-asymm-concepts.html">About Symmetric and Asymmetric CMKs</a> in the AWS Key Management Service
    ///             developer guide.</p>
    ///          </important>
    public let keyType: KeyType?

    public init (
        keyARN: String? = nil,
        keyType: KeyType? = nil
    )
    {
        self.keyARN = keyARN
        self.keyType = keyType
    }
}

public enum DeliveryStreamEncryptionStatus {
    case disabled
    case disabling
    case disablingFailed
    case enabled
    case enabling
    case enablingFailed
    case sdkUnknown(String)
}

extension DeliveryStreamEncryptionStatus : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [DeliveryStreamEncryptionStatus] {
        return [
            .disabled,
            .disabling,
            .disablingFailed,
            .enabled,
            .enabling,
            .enablingFailed,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .disabled: return "DISABLED"
        case .disabling: return "DISABLING"
        case .disablingFailed: return "DISABLING_FAILED"
        case .enabled: return "ENABLED"
        case .enabling: return "ENABLING"
        case .enablingFailed: return "ENABLING_FAILED"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = DeliveryStreamEncryptionStatus(rawValue: rawValue) ?? DeliveryStreamEncryptionStatus.sdkUnknown(rawValue)
    }
}

public enum DeliveryStreamFailureType {
    case createEniFailed
    case createKmsGrantFailed
    case deleteEniFailed
    case disabledKmsKey
    case eniAccessDenied
    case invalidKmsKey
    case kmsAccessDenied
    case kmsKeyNotFound
    case kmsOptInRequired
    case retireKmsGrantFailed
    case securityGroupAccessDenied
    case securityGroupNotFound
    case subnetAccessDenied
    case subnetNotFound
    case unknownError
    case sdkUnknown(String)
}

extension DeliveryStreamFailureType : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [DeliveryStreamFailureType] {
        return [
            .createEniFailed,
            .createKmsGrantFailed,
            .deleteEniFailed,
            .disabledKmsKey,
            .eniAccessDenied,
            .invalidKmsKey,
            .kmsAccessDenied,
            .kmsKeyNotFound,
            .kmsOptInRequired,
            .retireKmsGrantFailed,
            .securityGroupAccessDenied,
            .securityGroupNotFound,
            .subnetAccessDenied,
            .subnetNotFound,
            .unknownError,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .createEniFailed: return "CREATE_ENI_FAILED"
        case .createKmsGrantFailed: return "CREATE_KMS_GRANT_FAILED"
        case .deleteEniFailed: return "DELETE_ENI_FAILED"
        case .disabledKmsKey: return "DISABLED_KMS_KEY"
        case .eniAccessDenied: return "ENI_ACCESS_DENIED"
        case .invalidKmsKey: return "INVALID_KMS_KEY"
        case .kmsAccessDenied: return "KMS_ACCESS_DENIED"
        case .kmsKeyNotFound: return "KMS_KEY_NOT_FOUND"
        case .kmsOptInRequired: return "KMS_OPT_IN_REQUIRED"
        case .retireKmsGrantFailed: return "RETIRE_KMS_GRANT_FAILED"
        case .securityGroupAccessDenied: return "SECURITY_GROUP_ACCESS_DENIED"
        case .securityGroupNotFound: return "SECURITY_GROUP_NOT_FOUND"
        case .subnetAccessDenied: return "SUBNET_ACCESS_DENIED"
        case .subnetNotFound: return "SUBNET_NOT_FOUND"
        case .unknownError: return "UNKNOWN_ERROR"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = DeliveryStreamFailureType(rawValue: rawValue) ?? DeliveryStreamFailureType.sdkUnknown(rawValue)
    }
}

public enum DeliveryStreamStatus {
    case active
    case creating
    case creatingFailed
    case deleting
    case deletingFailed
    case sdkUnknown(String)
}

extension DeliveryStreamStatus : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [DeliveryStreamStatus] {
        return [
            .active,
            .creating,
            .creatingFailed,
            .deleting,
            .deletingFailed,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .active: return "ACTIVE"
        case .creating: return "CREATING"
        case .creatingFailed: return "CREATING_FAILED"
        case .deleting: return "DELETING"
        case .deletingFailed: return "DELETING_FAILED"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = DeliveryStreamStatus(rawValue: rawValue) ?? DeliveryStreamStatus.sdkUnknown(rawValue)
    }
}

public enum DeliveryStreamType {
    case directput
    case kinesisstreamassource
    case sdkUnknown(String)
}

extension DeliveryStreamType : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [DeliveryStreamType] {
        return [
            .directput,
            .kinesisstreamassource,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .directput: return "DirectPut"
        case .kinesisstreamassource: return "KinesisStreamAsSource"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = DeliveryStreamType(rawValue: rawValue) ?? DeliveryStreamType.sdkUnknown(rawValue)
    }
}

public struct DescribeDeliveryStreamInputBodyMiddleware: Middleware {
    public let id: String = "DescribeDeliveryStreamInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<DescribeDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<DescribeDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<DescribeDeliveryStreamInput>
    public typealias MOutput = OperationOutput<DescribeDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<DescribeDeliveryStreamOutputError>
}

extension DescribeDeliveryStreamInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "DescribeDeliveryStreamInput(deliveryStreamName: \(String(describing: deliveryStreamName)), exclusiveStartDestinationId: \(String(describing: exclusiveStartDestinationId)), limit: \(String(describing: limit)))"}
}

extension DescribeDeliveryStreamInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case exclusiveStartDestinationId = "ExclusiveStartDestinationId"
        case limit = "Limit"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
        if let exclusiveStartDestinationId = exclusiveStartDestinationId {
            try encodeContainer.encode(exclusiveStartDestinationId, forKey: .exclusiveStartDestinationId)
        }
        if let limit = limit {
            try encodeContainer.encode(limit, forKey: .limit)
        }
    }
}

public struct DescribeDeliveryStreamInputHeadersMiddleware: Middleware {
    public let id: String = "DescribeDeliveryStreamInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<DescribeDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<DescribeDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<DescribeDeliveryStreamInput>
    public typealias MOutput = OperationOutput<DescribeDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<DescribeDeliveryStreamOutputError>
}

public struct DescribeDeliveryStreamInputQueryItemMiddleware: Middleware {
    public let id: String = "DescribeDeliveryStreamInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<DescribeDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<DescribeDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<DescribeDeliveryStreamInput>
    public typealias MOutput = OperationOutput<DescribeDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<DescribeDeliveryStreamOutputError>
}

public struct DescribeDeliveryStreamInput: Equatable {
    /// <p>The name of the delivery stream.</p>
    public let deliveryStreamName: String?
    /// <p>The ID of the destination to start returning the destination information. Kinesis
    ///          Data Firehose supports one destination per delivery stream.</p>
    public let exclusiveStartDestinationId: String?
    /// <p>The limit on the number of destinations to return. You can have one destination per
    ///          delivery stream.</p>
    public let limit: Int?

    public init (
        deliveryStreamName: String? = nil,
        exclusiveStartDestinationId: String? = nil,
        limit: Int? = nil
    )
    {
        self.deliveryStreamName = deliveryStreamName
        self.exclusiveStartDestinationId = exclusiveStartDestinationId
        self.limit = limit
    }
}

struct DescribeDeliveryStreamInputBody: Equatable {
    public let deliveryStreamName: String?
    public let limit: Int?
    public let exclusiveStartDestinationId: String?
}

extension DescribeDeliveryStreamInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case exclusiveStartDestinationId = "ExclusiveStartDestinationId"
        case limit = "Limit"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
        let limitDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .limit)
        limit = limitDecoded
        let exclusiveStartDestinationIdDecoded = try containerValues.decodeIfPresent(String.self, forKey: .exclusiveStartDestinationId)
        exclusiveStartDestinationId = exclusiveStartDestinationIdDecoded
    }
}

extension DescribeDeliveryStreamOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension DescribeDeliveryStreamOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum DescribeDeliveryStreamOutputError: Swift.Error, Equatable {
    case resourceNotFoundException(ResourceNotFoundException)
    case unknown(UnknownAWSHttpServiceError)
}

extension DescribeDeliveryStreamOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "DescribeDeliveryStreamOutputResponse(deliveryStreamDescription: \(String(describing: deliveryStreamDescription)))"}
}

extension DescribeDeliveryStreamOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: DescribeDeliveryStreamOutputResponseBody = try responseDecoder.decode(responseBody: data)
            self.deliveryStreamDescription = output.deliveryStreamDescription
        } else {
            self.deliveryStreamDescription = nil
        }
    }
}

public struct DescribeDeliveryStreamOutputResponse: Equatable {
    /// <p>Information about the delivery stream.</p>
    public let deliveryStreamDescription: DeliveryStreamDescription?

    public init (
        deliveryStreamDescription: DeliveryStreamDescription? = nil
    )
    {
        self.deliveryStreamDescription = deliveryStreamDescription
    }
}

struct DescribeDeliveryStreamOutputResponseBody: Equatable {
    public let deliveryStreamDescription: DeliveryStreamDescription?
}

extension DescribeDeliveryStreamOutputResponseBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamDescription = "DeliveryStreamDescription"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamDescriptionDecoded = try containerValues.decodeIfPresent(DeliveryStreamDescription.self, forKey: .deliveryStreamDescription)
        deliveryStreamDescription = deliveryStreamDescriptionDecoded
    }
}

extension Deserializer: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case hiveJsonSerDe = "HiveJsonSerDe"
        case openXJsonSerDe = "OpenXJsonSerDe"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let hiveJsonSerDe = hiveJsonSerDe {
            try encodeContainer.encode(hiveJsonSerDe, forKey: .hiveJsonSerDe)
        }
        if let openXJsonSerDe = openXJsonSerDe {
            try encodeContainer.encode(openXJsonSerDe, forKey: .openXJsonSerDe)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let openXJsonSerDeDecoded = try containerValues.decodeIfPresent(OpenXJsonSerDe.self, forKey: .openXJsonSerDe)
        openXJsonSerDe = openXJsonSerDeDecoded
        let hiveJsonSerDeDecoded = try containerValues.decodeIfPresent(HiveJsonSerDe.self, forKey: .hiveJsonSerDe)
        hiveJsonSerDe = hiveJsonSerDeDecoded
    }
}

extension Deserializer: CustomDebugStringConvertible {
    public var debugDescription: String {
        "Deserializer(hiveJsonSerDe: \(String(describing: hiveJsonSerDe)), openXJsonSerDe: \(String(describing: openXJsonSerDe)))"}
}

/// <p>The deserializer you want Kinesis Data Firehose to use for converting the input data
///          from JSON. Kinesis Data Firehose then serializes the data to its final format using the
///             <a>Serializer</a>. Kinesis Data Firehose supports two types of deserializers:
///          the <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-JSON">Apache Hive JSON SerDe</a> and the <a href="https://github.com/rcongiu/Hive-JSON-Serde">OpenX JSON SerDe</a>.</p>
public struct Deserializer: Equatable {
    /// <p>The native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for deserializing
    ///          data, which means converting it from the JSON format in preparation for serializing it to
    ///          the Parquet or ORC format. This is one of two deserializers you can choose, depending on
    ///          which one offers the functionality you need. The other option is the OpenX SerDe.</p>
    public let hiveJsonSerDe: HiveJsonSerDe?
    /// <p>The OpenX SerDe. Used by Kinesis Data Firehose for deserializing data, which means
    ///          converting it from the JSON format in preparation for serializing it to the Parquet or ORC
    ///          format. This is one of two deserializers you can choose, depending on which one offers the
    ///          functionality you need. The other option is the native Hive / HCatalog JsonSerDe.</p>
    public let openXJsonSerDe: OpenXJsonSerDe?

    public init (
        hiveJsonSerDe: HiveJsonSerDe? = nil,
        openXJsonSerDe: OpenXJsonSerDe? = nil
    )
    {
        self.hiveJsonSerDe = hiveJsonSerDe
        self.openXJsonSerDe = openXJsonSerDe
    }
}

extension DestinationDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case destinationId = "DestinationId"
        case elasticsearchDestinationDescription = "ElasticsearchDestinationDescription"
        case extendedS3DestinationDescription = "ExtendedS3DestinationDescription"
        case httpEndpointDestinationDescription = "HttpEndpointDestinationDescription"
        case redshiftDestinationDescription = "RedshiftDestinationDescription"
        case s3DestinationDescription = "S3DestinationDescription"
        case splunkDestinationDescription = "SplunkDestinationDescription"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let destinationId = destinationId {
            try encodeContainer.encode(destinationId, forKey: .destinationId)
        }
        if let elasticsearchDestinationDescription = elasticsearchDestinationDescription {
            try encodeContainer.encode(elasticsearchDestinationDescription, forKey: .elasticsearchDestinationDescription)
        }
        if let extendedS3DestinationDescription = extendedS3DestinationDescription {
            try encodeContainer.encode(extendedS3DestinationDescription, forKey: .extendedS3DestinationDescription)
        }
        if let httpEndpointDestinationDescription = httpEndpointDestinationDescription {
            try encodeContainer.encode(httpEndpointDestinationDescription, forKey: .httpEndpointDestinationDescription)
        }
        if let redshiftDestinationDescription = redshiftDestinationDescription {
            try encodeContainer.encode(redshiftDestinationDescription, forKey: .redshiftDestinationDescription)
        }
        if let s3DestinationDescription = s3DestinationDescription {
            try encodeContainer.encode(s3DestinationDescription, forKey: .s3DestinationDescription)
        }
        if let splunkDestinationDescription = splunkDestinationDescription {
            try encodeContainer.encode(splunkDestinationDescription, forKey: .splunkDestinationDescription)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let destinationIdDecoded = try containerValues.decodeIfPresent(String.self, forKey: .destinationId)
        destinationId = destinationIdDecoded
        let s3DestinationDescriptionDecoded = try containerValues.decodeIfPresent(S3DestinationDescription.self, forKey: .s3DestinationDescription)
        s3DestinationDescription = s3DestinationDescriptionDecoded
        let extendedS3DestinationDescriptionDecoded = try containerValues.decodeIfPresent(ExtendedS3DestinationDescription.self, forKey: .extendedS3DestinationDescription)
        extendedS3DestinationDescription = extendedS3DestinationDescriptionDecoded
        let redshiftDestinationDescriptionDecoded = try containerValues.decodeIfPresent(RedshiftDestinationDescription.self, forKey: .redshiftDestinationDescription)
        redshiftDestinationDescription = redshiftDestinationDescriptionDecoded
        let elasticsearchDestinationDescriptionDecoded = try containerValues.decodeIfPresent(ElasticsearchDestinationDescription.self, forKey: .elasticsearchDestinationDescription)
        elasticsearchDestinationDescription = elasticsearchDestinationDescriptionDecoded
        let splunkDestinationDescriptionDecoded = try containerValues.decodeIfPresent(SplunkDestinationDescription.self, forKey: .splunkDestinationDescription)
        splunkDestinationDescription = splunkDestinationDescriptionDecoded
        let httpEndpointDestinationDescriptionDecoded = try containerValues.decodeIfPresent(HttpEndpointDestinationDescription.self, forKey: .httpEndpointDestinationDescription)
        httpEndpointDestinationDescription = httpEndpointDestinationDescriptionDecoded
    }
}

extension DestinationDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "DestinationDescription(destinationId: \(String(describing: destinationId)), elasticsearchDestinationDescription: \(String(describing: elasticsearchDestinationDescription)), extendedS3DestinationDescription: \(String(describing: extendedS3DestinationDescription)), httpEndpointDestinationDescription: \(String(describing: httpEndpointDestinationDescription)), redshiftDestinationDescription: \(String(describing: redshiftDestinationDescription)), s3DestinationDescription: \(String(describing: s3DestinationDescription)), splunkDestinationDescription: \(String(describing: splunkDestinationDescription)))"}
}

/// <p>Describes the destination for a delivery stream.</p>
public struct DestinationDescription: Equatable {
    /// <p>The ID of the destination.</p>
    public let destinationId: String?
    /// <p>The destination in Amazon ES.</p>
    public let elasticsearchDestinationDescription: ElasticsearchDestinationDescription?
    /// <p>The destination in Amazon S3.</p>
    public let extendedS3DestinationDescription: ExtendedS3DestinationDescription?
    /// <p>Describes the specified HTTP endpoint destination.</p>
    public let httpEndpointDestinationDescription: HttpEndpointDestinationDescription?
    /// <p>The destination in Amazon Redshift.</p>
    public let redshiftDestinationDescription: RedshiftDestinationDescription?
    /// <p>[Deprecated] The destination in Amazon S3.</p>
    public let s3DestinationDescription: S3DestinationDescription?
    /// <p>The destination in Splunk.</p>
    public let splunkDestinationDescription: SplunkDestinationDescription?

    public init (
        destinationId: String? = nil,
        elasticsearchDestinationDescription: ElasticsearchDestinationDescription? = nil,
        extendedS3DestinationDescription: ExtendedS3DestinationDescription? = nil,
        httpEndpointDestinationDescription: HttpEndpointDestinationDescription? = nil,
        redshiftDestinationDescription: RedshiftDestinationDescription? = nil,
        s3DestinationDescription: S3DestinationDescription? = nil,
        splunkDestinationDescription: SplunkDestinationDescription? = nil
    )
    {
        self.destinationId = destinationId
        self.elasticsearchDestinationDescription = elasticsearchDestinationDescription
        self.extendedS3DestinationDescription = extendedS3DestinationDescription
        self.httpEndpointDestinationDescription = httpEndpointDestinationDescription
        self.redshiftDestinationDescription = redshiftDestinationDescription
        self.s3DestinationDescription = s3DestinationDescription
        self.splunkDestinationDescription = splunkDestinationDescription
    }
}

extension ElasticsearchBufferingHints: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case intervalInSeconds = "IntervalInSeconds"
        case sizeInMBs = "SizeInMBs"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let intervalInSeconds = intervalInSeconds {
            try encodeContainer.encode(intervalInSeconds, forKey: .intervalInSeconds)
        }
        if let sizeInMBs = sizeInMBs {
            try encodeContainer.encode(sizeInMBs, forKey: .sizeInMBs)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let intervalInSecondsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .intervalInSeconds)
        intervalInSeconds = intervalInSecondsDecoded
        let sizeInMBsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .sizeInMBs)
        sizeInMBs = sizeInMBsDecoded
    }
}

extension ElasticsearchBufferingHints: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ElasticsearchBufferingHints(intervalInSeconds: \(String(describing: intervalInSeconds)), sizeInMBs: \(String(describing: sizeInMBs)))"}
}

/// <p>Describes the buffering to perform before delivering data to the Amazon ES
///          destination.</p>
public struct ElasticsearchBufferingHints: Equatable {
    /// <p>Buffer incoming data for the specified period of time, in seconds, before delivering
    ///          it to the destination. The default value is 300 (5 minutes).</p>
    public let intervalInSeconds: Int?
    /// <p>Buffer incoming data to the specified size, in MBs, before delivering it to the
    ///          destination. The default value is 5.</p>
    ///          <p>We recommend setting this parameter to a value greater than the amount of data you
    ///          typically ingest into the delivery stream in 10 seconds. For example, if you typically
    ///          ingest data at 1 MB/sec, the value should be 10 MB or higher.</p>
    public let sizeInMBs: Int?

    public init (
        intervalInSeconds: Int? = nil,
        sizeInMBs: Int? = nil
    )
    {
        self.intervalInSeconds = intervalInSeconds
        self.sizeInMBs = sizeInMBs
    }
}

extension ElasticsearchDestinationConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case clusterEndpoint = "ClusterEndpoint"
        case domainARN = "DomainARN"
        case indexName = "IndexName"
        case indexRotationPeriod = "IndexRotationPeriod"
        case processingConfiguration = "ProcessingConfiguration"
        case retryOptions = "RetryOptions"
        case roleARN = "RoleARN"
        case s3BackupMode = "S3BackupMode"
        case s3Configuration = "S3Configuration"
        case typeName = "TypeName"
        case vpcConfiguration = "VpcConfiguration"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let clusterEndpoint = clusterEndpoint {
            try encodeContainer.encode(clusterEndpoint, forKey: .clusterEndpoint)
        }
        if let domainARN = domainARN {
            try encodeContainer.encode(domainARN, forKey: .domainARN)
        }
        if let indexName = indexName {
            try encodeContainer.encode(indexName, forKey: .indexName)
        }
        if let indexRotationPeriod = indexRotationPeriod {
            try encodeContainer.encode(indexRotationPeriod.rawValue, forKey: .indexRotationPeriod)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3Configuration = s3Configuration {
            try encodeContainer.encode(s3Configuration, forKey: .s3Configuration)
        }
        if let typeName = typeName {
            try encodeContainer.encode(typeName, forKey: .typeName)
        }
        if let vpcConfiguration = vpcConfiguration {
            try encodeContainer.encode(vpcConfiguration, forKey: .vpcConfiguration)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let domainARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .domainARN)
        domainARN = domainARNDecoded
        let clusterEndpointDecoded = try containerValues.decodeIfPresent(String.self, forKey: .clusterEndpoint)
        clusterEndpoint = clusterEndpointDecoded
        let indexNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .indexName)
        indexName = indexNameDecoded
        let typeNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .typeName)
        typeName = typeNameDecoded
        let indexRotationPeriodDecoded = try containerValues.decodeIfPresent(ElasticsearchIndexRotationPeriod.self, forKey: .indexRotationPeriod)
        indexRotationPeriod = indexRotationPeriodDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(ElasticsearchBufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(ElasticsearchRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(ElasticsearchS3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3ConfigurationDecoded = try containerValues.decodeIfPresent(S3DestinationConfiguration.self, forKey: .s3Configuration)
        s3Configuration = s3ConfigurationDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
        let vpcConfigurationDecoded = try containerValues.decodeIfPresent(VpcConfiguration.self, forKey: .vpcConfiguration)
        vpcConfiguration = vpcConfigurationDecoded
    }
}

extension ElasticsearchDestinationConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ElasticsearchDestinationConfiguration(bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), clusterEndpoint: \(String(describing: clusterEndpoint)), domainARN: \(String(describing: domainARN)), indexName: \(String(describing: indexName)), indexRotationPeriod: \(String(describing: indexRotationPeriod)), processingConfiguration: \(String(describing: processingConfiguration)), retryOptions: \(String(describing: retryOptions)), roleARN: \(String(describing: roleARN)), s3BackupMode: \(String(describing: s3BackupMode)), s3Configuration: \(String(describing: s3Configuration)), typeName: \(String(describing: typeName)), vpcConfiguration: \(String(describing: vpcConfiguration)))"}
}

/// <p>Describes the configuration of a destination in Amazon ES.</p>
public struct ElasticsearchDestinationConfiguration: Equatable {
    /// <p>The buffering options. If no value is specified, the default values for
    ///             <code>ElasticsearchBufferingHints</code> are used.</p>
    public let bufferingHints: ElasticsearchBufferingHints?
    /// <p>The Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The endpoint to use when communicating with the cluster. Specify either this
    ///             <code>ClusterEndpoint</code> or the <code>DomainARN</code> field.</p>
    public let clusterEndpoint: String?
    /// <p>The ARN of the Amazon ES domain. The IAM role must have permissions
    ///             for<code>DescribeElasticsearchDomain</code>, <code>DescribeElasticsearchDomains</code>,
    ///          and <code>DescribeElasticsearchDomainConfig</code>after assuming the role specified in
    ///             <b>RoleARN</b>. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    ///
    ///          <p>Specify either <code>ClusterEndpoint</code> or <code>DomainARN</code>.</p>
    public let domainARN: String?
    /// <p>The Elasticsearch index name.</p>
    public let indexName: String?
    /// <p>The Elasticsearch index rotation period. Index rotation appends a timestamp to the
    ///             <code>IndexName</code> to facilitate the expiration of old data. For more information,
    ///          see <a href="https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation">Index Rotation for the
    ///             Amazon ES Destination</a>. The default value is<code>OneDay</code>.</p>
    public let indexRotationPeriod: ElasticsearchIndexRotationPeriod?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to
    ///          Amazon ES. The default value is 300 (5 minutes).</p>
    public let retryOptions: ElasticsearchRetryOptions?
    /// <p>The Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data Firehose
    ///          for calling the Amazon ES Configuration API and for indexing documents. For more
    ///          information, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3">Grant Kinesis Data
    ///             Firehose Access to an Amazon S3 Destination</a> and <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?
    /// <p>Defines how documents should be delivered to Amazon S3. When it is set to
    ///             <code>FailedDocumentsOnly</code>, Kinesis Data Firehose writes any documents that could
    ///          not be indexed to the configured Amazon S3 destination, with
    ///             <code>elasticsearch-failed/</code> appended to the key prefix. When set to
    ///             <code>AllDocuments</code>, Kinesis Data Firehose delivers all incoming records to Amazon
    ///          S3, and also writes failed documents with <code>elasticsearch-failed/</code> appended to
    ///          the prefix. For more information, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-s3-backup">Amazon S3 Backup for the
    ///             Amazon ES Destination</a>. Default value is
    ///          <code>FailedDocumentsOnly</code>.</p>
    ///          <p>You can't change this backup mode after you create the delivery stream. </p>
    public let s3BackupMode: ElasticsearchS3BackupMode?
    /// <p>The configuration for the backup Amazon S3 location.</p>
    public let s3Configuration: S3DestinationConfiguration?
    /// <p>The Elasticsearch type name. For Elasticsearch 6.x, there can be only one type per
    ///          index. If you try to specify a new type for an existing index that already has another
    ///          type, Kinesis Data Firehose returns an error during run time.</p>
    ///
    ///          <p>For Elasticsearch 7.x, don't specify a <code>TypeName</code>.</p>
    public let typeName: String?
    /// <p>The details of the VPC of the Amazon ES destination.</p>
    public let vpcConfiguration: VpcConfiguration?

    public init (
        bufferingHints: ElasticsearchBufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        clusterEndpoint: String? = nil,
        domainARN: String? = nil,
        indexName: String? = nil,
        indexRotationPeriod: ElasticsearchIndexRotationPeriod? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        retryOptions: ElasticsearchRetryOptions? = nil,
        roleARN: String? = nil,
        s3BackupMode: ElasticsearchS3BackupMode? = nil,
        s3Configuration: S3DestinationConfiguration? = nil,
        typeName: String? = nil,
        vpcConfiguration: VpcConfiguration? = nil
    )
    {
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.clusterEndpoint = clusterEndpoint
        self.domainARN = domainARN
        self.indexName = indexName
        self.indexRotationPeriod = indexRotationPeriod
        self.processingConfiguration = processingConfiguration
        self.retryOptions = retryOptions
        self.roleARN = roleARN
        self.s3BackupMode = s3BackupMode
        self.s3Configuration = s3Configuration
        self.typeName = typeName
        self.vpcConfiguration = vpcConfiguration
    }
}

extension ElasticsearchDestinationDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case clusterEndpoint = "ClusterEndpoint"
        case domainARN = "DomainARN"
        case indexName = "IndexName"
        case indexRotationPeriod = "IndexRotationPeriod"
        case processingConfiguration = "ProcessingConfiguration"
        case retryOptions = "RetryOptions"
        case roleARN = "RoleARN"
        case s3BackupMode = "S3BackupMode"
        case s3DestinationDescription = "S3DestinationDescription"
        case typeName = "TypeName"
        case vpcConfigurationDescription = "VpcConfigurationDescription"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let clusterEndpoint = clusterEndpoint {
            try encodeContainer.encode(clusterEndpoint, forKey: .clusterEndpoint)
        }
        if let domainARN = domainARN {
            try encodeContainer.encode(domainARN, forKey: .domainARN)
        }
        if let indexName = indexName {
            try encodeContainer.encode(indexName, forKey: .indexName)
        }
        if let indexRotationPeriod = indexRotationPeriod {
            try encodeContainer.encode(indexRotationPeriod.rawValue, forKey: .indexRotationPeriod)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3DestinationDescription = s3DestinationDescription {
            try encodeContainer.encode(s3DestinationDescription, forKey: .s3DestinationDescription)
        }
        if let typeName = typeName {
            try encodeContainer.encode(typeName, forKey: .typeName)
        }
        if let vpcConfigurationDescription = vpcConfigurationDescription {
            try encodeContainer.encode(vpcConfigurationDescription, forKey: .vpcConfigurationDescription)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let domainARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .domainARN)
        domainARN = domainARNDecoded
        let clusterEndpointDecoded = try containerValues.decodeIfPresent(String.self, forKey: .clusterEndpoint)
        clusterEndpoint = clusterEndpointDecoded
        let indexNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .indexName)
        indexName = indexNameDecoded
        let typeNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .typeName)
        typeName = typeNameDecoded
        let indexRotationPeriodDecoded = try containerValues.decodeIfPresent(ElasticsearchIndexRotationPeriod.self, forKey: .indexRotationPeriod)
        indexRotationPeriod = indexRotationPeriodDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(ElasticsearchBufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(ElasticsearchRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(ElasticsearchS3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3DestinationDescriptionDecoded = try containerValues.decodeIfPresent(S3DestinationDescription.self, forKey: .s3DestinationDescription)
        s3DestinationDescription = s3DestinationDescriptionDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
        let vpcConfigurationDescriptionDecoded = try containerValues.decodeIfPresent(VpcConfigurationDescription.self, forKey: .vpcConfigurationDescription)
        vpcConfigurationDescription = vpcConfigurationDescriptionDecoded
    }
}

extension ElasticsearchDestinationDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ElasticsearchDestinationDescription(bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), clusterEndpoint: \(String(describing: clusterEndpoint)), domainARN: \(String(describing: domainARN)), indexName: \(String(describing: indexName)), indexRotationPeriod: \(String(describing: indexRotationPeriod)), processingConfiguration: \(String(describing: processingConfiguration)), retryOptions: \(String(describing: retryOptions)), roleARN: \(String(describing: roleARN)), s3BackupMode: \(String(describing: s3BackupMode)), s3DestinationDescription: \(String(describing: s3DestinationDescription)), typeName: \(String(describing: typeName)), vpcConfigurationDescription: \(String(describing: vpcConfigurationDescription)))"}
}

/// <p>The destination description in Amazon ES.</p>
public struct ElasticsearchDestinationDescription: Equatable {
    /// <p>The buffering options.</p>
    public let bufferingHints: ElasticsearchBufferingHints?
    /// <p>The Amazon CloudWatch logging options.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The endpoint to use when communicating with the cluster. Kinesis Data Firehose uses
    ///          either this <code>ClusterEndpoint</code> or the <code>DomainARN</code> field to send data
    ///          to Amazon ES.</p>
    public let clusterEndpoint: String?
    /// <p>The ARN of the Amazon ES domain. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    ///
    ///          <p>Kinesis Data Firehose uses either <code>ClusterEndpoint</code> or <code>DomainARN</code>
    ///          to send data to Amazon ES.</p>
    public let domainARN: String?
    /// <p>The Elasticsearch index name.</p>
    public let indexName: String?
    /// <p>The Elasticsearch index rotation period</p>
    public let indexRotationPeriod: ElasticsearchIndexRotationPeriod?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The Amazon ES retry options.</p>
    public let retryOptions: ElasticsearchRetryOptions?
    /// <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?
    /// <p>The Amazon S3 backup mode.</p>
    public let s3BackupMode: ElasticsearchS3BackupMode?
    /// <p>The Amazon S3 destination.</p>
    public let s3DestinationDescription: S3DestinationDescription?
    /// <p>The Elasticsearch type name. This applies to Elasticsearch 6.x and lower versions.
    ///          For Elasticsearch 7.x, there's no value for <code>TypeName</code>.</p>
    public let typeName: String?
    /// <p>The details of the VPC of the Amazon ES destination.</p>
    public let vpcConfigurationDescription: VpcConfigurationDescription?

    public init (
        bufferingHints: ElasticsearchBufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        clusterEndpoint: String? = nil,
        domainARN: String? = nil,
        indexName: String? = nil,
        indexRotationPeriod: ElasticsearchIndexRotationPeriod? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        retryOptions: ElasticsearchRetryOptions? = nil,
        roleARN: String? = nil,
        s3BackupMode: ElasticsearchS3BackupMode? = nil,
        s3DestinationDescription: S3DestinationDescription? = nil,
        typeName: String? = nil,
        vpcConfigurationDescription: VpcConfigurationDescription? = nil
    )
    {
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.clusterEndpoint = clusterEndpoint
        self.domainARN = domainARN
        self.indexName = indexName
        self.indexRotationPeriod = indexRotationPeriod
        self.processingConfiguration = processingConfiguration
        self.retryOptions = retryOptions
        self.roleARN = roleARN
        self.s3BackupMode = s3BackupMode
        self.s3DestinationDescription = s3DestinationDescription
        self.typeName = typeName
        self.vpcConfigurationDescription = vpcConfigurationDescription
    }
}

extension ElasticsearchDestinationUpdate: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case clusterEndpoint = "ClusterEndpoint"
        case domainARN = "DomainARN"
        case indexName = "IndexName"
        case indexRotationPeriod = "IndexRotationPeriod"
        case processingConfiguration = "ProcessingConfiguration"
        case retryOptions = "RetryOptions"
        case roleARN = "RoleARN"
        case s3Update = "S3Update"
        case typeName = "TypeName"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let clusterEndpoint = clusterEndpoint {
            try encodeContainer.encode(clusterEndpoint, forKey: .clusterEndpoint)
        }
        if let domainARN = domainARN {
            try encodeContainer.encode(domainARN, forKey: .domainARN)
        }
        if let indexName = indexName {
            try encodeContainer.encode(indexName, forKey: .indexName)
        }
        if let indexRotationPeriod = indexRotationPeriod {
            try encodeContainer.encode(indexRotationPeriod.rawValue, forKey: .indexRotationPeriod)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3Update = s3Update {
            try encodeContainer.encode(s3Update, forKey: .s3Update)
        }
        if let typeName = typeName {
            try encodeContainer.encode(typeName, forKey: .typeName)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let domainARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .domainARN)
        domainARN = domainARNDecoded
        let clusterEndpointDecoded = try containerValues.decodeIfPresent(String.self, forKey: .clusterEndpoint)
        clusterEndpoint = clusterEndpointDecoded
        let indexNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .indexName)
        indexName = indexNameDecoded
        let typeNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .typeName)
        typeName = typeNameDecoded
        let indexRotationPeriodDecoded = try containerValues.decodeIfPresent(ElasticsearchIndexRotationPeriod.self, forKey: .indexRotationPeriod)
        indexRotationPeriod = indexRotationPeriodDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(ElasticsearchBufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(ElasticsearchRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3UpdateDecoded = try containerValues.decodeIfPresent(S3DestinationUpdate.self, forKey: .s3Update)
        s3Update = s3UpdateDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
    }
}

extension ElasticsearchDestinationUpdate: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ElasticsearchDestinationUpdate(bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), clusterEndpoint: \(String(describing: clusterEndpoint)), domainARN: \(String(describing: domainARN)), indexName: \(String(describing: indexName)), indexRotationPeriod: \(String(describing: indexRotationPeriod)), processingConfiguration: \(String(describing: processingConfiguration)), retryOptions: \(String(describing: retryOptions)), roleARN: \(String(describing: roleARN)), s3Update: \(String(describing: s3Update)), typeName: \(String(describing: typeName)))"}
}

/// <p>Describes an update for a destination in Amazon ES.</p>
public struct ElasticsearchDestinationUpdate: Equatable {
    /// <p>The buffering options. If no value is specified,
    ///             <code>ElasticsearchBufferingHints</code> object default values are used. </p>
    public let bufferingHints: ElasticsearchBufferingHints?
    /// <p>The CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The endpoint to use when communicating with the cluster. Specify either this
    ///             <code>ClusterEndpoint</code> or the <code>DomainARN</code> field.</p>
    public let clusterEndpoint: String?
    /// <p>The ARN of the Amazon ES domain. The IAM role must have permissions
    ///             for<code>DescribeElasticsearchDomain</code>, <code>DescribeElasticsearchDomains</code>,
    ///          and <code>DescribeElasticsearchDomainConfig</code>after assuming the IAM role specified in
    ///             <code>RoleARN</code>. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    ///
    ///          <p>Specify either <code>ClusterEndpoint</code> or <code>DomainARN</code>.</p>
    public let domainARN: String?
    /// <p>The Elasticsearch index name.</p>
    public let indexName: String?
    /// <p>The Elasticsearch index rotation period. Index rotation appends a timestamp to
    ///             <code>IndexName</code> to facilitate the expiration of old data. For more information,
    ///          see <a href="https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation">Index Rotation for the
    ///             Amazon ES Destination</a>. Default value is<code>OneDay</code>.</p>
    public let indexRotationPeriod: ElasticsearchIndexRotationPeriod?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to
    ///          Amazon ES. The default value is 300 (5 minutes).</p>
    public let retryOptions: ElasticsearchRetryOptions?
    /// <p>The Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data Firehose
    ///          for calling the Amazon ES Configuration API and for indexing documents. For more
    ///          information, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3">Grant Kinesis Data
    ///             Firehose Access to an Amazon S3 Destination</a> and <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?
    /// <p>The Amazon S3 destination.</p>
    public let s3Update: S3DestinationUpdate?
    /// <p>The Elasticsearch type name. For Elasticsearch 6.x, there can be only one type per
    ///          index. If you try to specify a new type for an existing index that already has another
    ///          type, Kinesis Data Firehose returns an error during runtime.</p>
    ///
    ///          <p>If you upgrade Elasticsearch from 6.x to 7.x and dont update your delivery stream,
    ///          Kinesis Data Firehose still delivers data to Elasticsearch with the old index name and type
    ///          name. If you want to update your delivery stream with a new index name, provide an empty
    ///          string for <code>TypeName</code>. </p>
    public let typeName: String?

    public init (
        bufferingHints: ElasticsearchBufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        clusterEndpoint: String? = nil,
        domainARN: String? = nil,
        indexName: String? = nil,
        indexRotationPeriod: ElasticsearchIndexRotationPeriod? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        retryOptions: ElasticsearchRetryOptions? = nil,
        roleARN: String? = nil,
        s3Update: S3DestinationUpdate? = nil,
        typeName: String? = nil
    )
    {
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.clusterEndpoint = clusterEndpoint
        self.domainARN = domainARN
        self.indexName = indexName
        self.indexRotationPeriod = indexRotationPeriod
        self.processingConfiguration = processingConfiguration
        self.retryOptions = retryOptions
        self.roleARN = roleARN
        self.s3Update = s3Update
        self.typeName = typeName
    }
}

public enum ElasticsearchIndexRotationPeriod {
    case norotation
    case oneday
    case onehour
    case onemonth
    case oneweek
    case sdkUnknown(String)
}

extension ElasticsearchIndexRotationPeriod : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [ElasticsearchIndexRotationPeriod] {
        return [
            .norotation,
            .oneday,
            .onehour,
            .onemonth,
            .oneweek,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .norotation: return "NoRotation"
        case .oneday: return "OneDay"
        case .onehour: return "OneHour"
        case .onemonth: return "OneMonth"
        case .oneweek: return "OneWeek"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = ElasticsearchIndexRotationPeriod(rawValue: rawValue) ?? ElasticsearchIndexRotationPeriod.sdkUnknown(rawValue)
    }
}

extension ElasticsearchRetryOptions: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case durationInSeconds = "DurationInSeconds"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let durationInSeconds = durationInSeconds {
            try encodeContainer.encode(durationInSeconds, forKey: .durationInSeconds)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let durationInSecondsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .durationInSeconds)
        durationInSeconds = durationInSecondsDecoded
    }
}

extension ElasticsearchRetryOptions: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ElasticsearchRetryOptions(durationInSeconds: \(String(describing: durationInSeconds)))"}
}

/// <p>Configures retry behavior in case Kinesis Data Firehose is unable to deliver
///          documents to Amazon ES.</p>
public struct ElasticsearchRetryOptions: Equatable {
    /// <p>After an initial failure to deliver to Amazon ES, the total amount of time during
    ///          which Kinesis Data Firehose retries delivery (including the first attempt). After this time
    ///          has elapsed, the failed documents are written to Amazon S3. Default value is 300 seconds (5
    ///          minutes). A value of 0 (zero) results in no retries.</p>
    public let durationInSeconds: Int?

    public init (
        durationInSeconds: Int? = nil
    )
    {
        self.durationInSeconds = durationInSeconds
    }
}

public enum ElasticsearchS3BackupMode {
    case alldocuments
    case faileddocumentsonly
    case sdkUnknown(String)
}

extension ElasticsearchS3BackupMode : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [ElasticsearchS3BackupMode] {
        return [
            .alldocuments,
            .faileddocumentsonly,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .alldocuments: return "AllDocuments"
        case .faileddocumentsonly: return "FailedDocumentsOnly"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = ElasticsearchS3BackupMode(rawValue: rawValue) ?? ElasticsearchS3BackupMode.sdkUnknown(rawValue)
    }
}

extension EncryptionConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case kMSEncryptionConfig = "KMSEncryptionConfig"
        case noEncryptionConfig = "NoEncryptionConfig"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let kMSEncryptionConfig = kMSEncryptionConfig {
            try encodeContainer.encode(kMSEncryptionConfig, forKey: .kMSEncryptionConfig)
        }
        if let noEncryptionConfig = noEncryptionConfig {
            try encodeContainer.encode(noEncryptionConfig.rawValue, forKey: .noEncryptionConfig)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let noEncryptionConfigDecoded = try containerValues.decodeIfPresent(NoEncryptionConfig.self, forKey: .noEncryptionConfig)
        noEncryptionConfig = noEncryptionConfigDecoded
        let kMSEncryptionConfigDecoded = try containerValues.decodeIfPresent(KMSEncryptionConfig.self, forKey: .kMSEncryptionConfig)
        kMSEncryptionConfig = kMSEncryptionConfigDecoded
    }
}

extension EncryptionConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "EncryptionConfiguration(kMSEncryptionConfig: \(String(describing: kMSEncryptionConfig)), noEncryptionConfig: \(String(describing: noEncryptionConfig)))"}
}

/// <p>Describes the encryption for a destination in Amazon S3.</p>
public struct EncryptionConfiguration: Equatable {
    /// <p>The encryption key.</p>
    public let kMSEncryptionConfig: KMSEncryptionConfig?
    /// <p>Specifically override existing encryption information to ensure that no encryption is
    ///          used.</p>
    public let noEncryptionConfig: NoEncryptionConfig?

    public init (
        kMSEncryptionConfig: KMSEncryptionConfig? = nil,
        noEncryptionConfig: NoEncryptionConfig? = nil
    )
    {
        self.kMSEncryptionConfig = kMSEncryptionConfig
        self.noEncryptionConfig = noEncryptionConfig
    }
}

extension ExtendedS3DestinationConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bucketARN = "BucketARN"
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case compressionFormat = "CompressionFormat"
        case dataFormatConversionConfiguration = "DataFormatConversionConfiguration"
        case encryptionConfiguration = "EncryptionConfiguration"
        case errorOutputPrefix = "ErrorOutputPrefix"
        case prefix = "Prefix"
        case processingConfiguration = "ProcessingConfiguration"
        case roleARN = "RoleARN"
        case s3BackupConfiguration = "S3BackupConfiguration"
        case s3BackupMode = "S3BackupMode"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bucketARN = bucketARN {
            try encodeContainer.encode(bucketARN, forKey: .bucketARN)
        }
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let compressionFormat = compressionFormat {
            try encodeContainer.encode(compressionFormat.rawValue, forKey: .compressionFormat)
        }
        if let dataFormatConversionConfiguration = dataFormatConversionConfiguration {
            try encodeContainer.encode(dataFormatConversionConfiguration, forKey: .dataFormatConversionConfiguration)
        }
        if let encryptionConfiguration = encryptionConfiguration {
            try encodeContainer.encode(encryptionConfiguration, forKey: .encryptionConfiguration)
        }
        if let errorOutputPrefix = errorOutputPrefix {
            try encodeContainer.encode(errorOutputPrefix, forKey: .errorOutputPrefix)
        }
        if let prefix = prefix {
            try encodeContainer.encode(prefix, forKey: .prefix)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3BackupConfiguration = s3BackupConfiguration {
            try encodeContainer.encode(s3BackupConfiguration, forKey: .s3BackupConfiguration)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let bucketARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .bucketARN)
        bucketARN = bucketARNDecoded
        let prefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .prefix)
        prefix = prefixDecoded
        let errorOutputPrefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .errorOutputPrefix)
        errorOutputPrefix = errorOutputPrefixDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(BufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let compressionFormatDecoded = try containerValues.decodeIfPresent(CompressionFormat.self, forKey: .compressionFormat)
        compressionFormat = compressionFormatDecoded
        let encryptionConfigurationDecoded = try containerValues.decodeIfPresent(EncryptionConfiguration.self, forKey: .encryptionConfiguration)
        encryptionConfiguration = encryptionConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(S3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3BackupConfigurationDecoded = try containerValues.decodeIfPresent(S3DestinationConfiguration.self, forKey: .s3BackupConfiguration)
        s3BackupConfiguration = s3BackupConfigurationDecoded
        let dataFormatConversionConfigurationDecoded = try containerValues.decodeIfPresent(DataFormatConversionConfiguration.self, forKey: .dataFormatConversionConfiguration)
        dataFormatConversionConfiguration = dataFormatConversionConfigurationDecoded
    }
}

extension ExtendedS3DestinationConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ExtendedS3DestinationConfiguration(bucketARN: \(String(describing: bucketARN)), bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), compressionFormat: \(String(describing: compressionFormat)), dataFormatConversionConfiguration: \(String(describing: dataFormatConversionConfiguration)), encryptionConfiguration: \(String(describing: encryptionConfiguration)), errorOutputPrefix: \(String(describing: errorOutputPrefix)), prefix: \(String(describing: prefix)), processingConfiguration: \(String(describing: processingConfiguration)), roleARN: \(String(describing: roleARN)), s3BackupConfiguration: \(String(describing: s3BackupConfiguration)), s3BackupMode: \(String(describing: s3BackupMode)))"}
}

/// <p>Describes the configuration of a destination in Amazon S3.</p>
public struct ExtendedS3DestinationConfiguration: Equatable {
    /// <p>The ARN of the S3 bucket. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let bucketARN: String?
    /// <p>The buffering option.</p>
    public let bufferingHints: BufferingHints?
    /// <p>The Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The compression format. If no value is specified, the default is
    ///          UNCOMPRESSED.</p>
    public let compressionFormat: CompressionFormat?
    /// <p>The serializer, deserializer, and schema for converting data from the JSON format to
    ///          the Parquet or ORC format before writing it to Amazon S3.</p>
    public let dataFormatConversionConfiguration: DataFormatConversionConfiguration?
    /// <p>The encryption configuration. If no value is specified, the default is no
    ///          encryption.</p>
    public let encryptionConfiguration: EncryptionConfiguration?
    /// <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
    ///          them to S3. This prefix appears immediately following the bucket name. For information
    ///          about how to specify this prefix, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let errorOutputPrefix: String?
    /// <p>The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered Amazon S3
    ///          files. You can also specify a custom prefix, as described in <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let prefix: String?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?
    /// <p>The configuration for backup in Amazon S3.</p>
    public let s3BackupConfiguration: S3DestinationConfiguration?
    /// <p>The Amazon S3 backup mode. After you create a delivery stream, you can update it to
    ///          enable Amazon S3 backup if it is disabled. If backup is enabled, you can't update the
    ///          delivery stream to disable it. </p>
    public let s3BackupMode: S3BackupMode?

    public init (
        bucketARN: String? = nil,
        bufferingHints: BufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        compressionFormat: CompressionFormat? = nil,
        dataFormatConversionConfiguration: DataFormatConversionConfiguration? = nil,
        encryptionConfiguration: EncryptionConfiguration? = nil,
        errorOutputPrefix: String? = nil,
        prefix: String? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        roleARN: String? = nil,
        s3BackupConfiguration: S3DestinationConfiguration? = nil,
        s3BackupMode: S3BackupMode? = nil
    )
    {
        self.bucketARN = bucketARN
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.compressionFormat = compressionFormat
        self.dataFormatConversionConfiguration = dataFormatConversionConfiguration
        self.encryptionConfiguration = encryptionConfiguration
        self.errorOutputPrefix = errorOutputPrefix
        self.prefix = prefix
        self.processingConfiguration = processingConfiguration
        self.roleARN = roleARN
        self.s3BackupConfiguration = s3BackupConfiguration
        self.s3BackupMode = s3BackupMode
    }
}

extension ExtendedS3DestinationDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bucketARN = "BucketARN"
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case compressionFormat = "CompressionFormat"
        case dataFormatConversionConfiguration = "DataFormatConversionConfiguration"
        case encryptionConfiguration = "EncryptionConfiguration"
        case errorOutputPrefix = "ErrorOutputPrefix"
        case prefix = "Prefix"
        case processingConfiguration = "ProcessingConfiguration"
        case roleARN = "RoleARN"
        case s3BackupDescription = "S3BackupDescription"
        case s3BackupMode = "S3BackupMode"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bucketARN = bucketARN {
            try encodeContainer.encode(bucketARN, forKey: .bucketARN)
        }
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let compressionFormat = compressionFormat {
            try encodeContainer.encode(compressionFormat.rawValue, forKey: .compressionFormat)
        }
        if let dataFormatConversionConfiguration = dataFormatConversionConfiguration {
            try encodeContainer.encode(dataFormatConversionConfiguration, forKey: .dataFormatConversionConfiguration)
        }
        if let encryptionConfiguration = encryptionConfiguration {
            try encodeContainer.encode(encryptionConfiguration, forKey: .encryptionConfiguration)
        }
        if let errorOutputPrefix = errorOutputPrefix {
            try encodeContainer.encode(errorOutputPrefix, forKey: .errorOutputPrefix)
        }
        if let prefix = prefix {
            try encodeContainer.encode(prefix, forKey: .prefix)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3BackupDescription = s3BackupDescription {
            try encodeContainer.encode(s3BackupDescription, forKey: .s3BackupDescription)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let bucketARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .bucketARN)
        bucketARN = bucketARNDecoded
        let prefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .prefix)
        prefix = prefixDecoded
        let errorOutputPrefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .errorOutputPrefix)
        errorOutputPrefix = errorOutputPrefixDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(BufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let compressionFormatDecoded = try containerValues.decodeIfPresent(CompressionFormat.self, forKey: .compressionFormat)
        compressionFormat = compressionFormatDecoded
        let encryptionConfigurationDecoded = try containerValues.decodeIfPresent(EncryptionConfiguration.self, forKey: .encryptionConfiguration)
        encryptionConfiguration = encryptionConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(S3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3BackupDescriptionDecoded = try containerValues.decodeIfPresent(S3DestinationDescription.self, forKey: .s3BackupDescription)
        s3BackupDescription = s3BackupDescriptionDecoded
        let dataFormatConversionConfigurationDecoded = try containerValues.decodeIfPresent(DataFormatConversionConfiguration.self, forKey: .dataFormatConversionConfiguration)
        dataFormatConversionConfiguration = dataFormatConversionConfigurationDecoded
    }
}

extension ExtendedS3DestinationDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ExtendedS3DestinationDescription(bucketARN: \(String(describing: bucketARN)), bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), compressionFormat: \(String(describing: compressionFormat)), dataFormatConversionConfiguration: \(String(describing: dataFormatConversionConfiguration)), encryptionConfiguration: \(String(describing: encryptionConfiguration)), errorOutputPrefix: \(String(describing: errorOutputPrefix)), prefix: \(String(describing: prefix)), processingConfiguration: \(String(describing: processingConfiguration)), roleARN: \(String(describing: roleARN)), s3BackupDescription: \(String(describing: s3BackupDescription)), s3BackupMode: \(String(describing: s3BackupMode)))"}
}

/// <p>Describes a destination in Amazon S3.</p>
public struct ExtendedS3DestinationDescription: Equatable {
    /// <p>The ARN of the S3 bucket. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let bucketARN: String?
    /// <p>The buffering option.</p>
    public let bufferingHints: BufferingHints?
    /// <p>The Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The compression format. If no value is specified, the default is
    ///             <code>UNCOMPRESSED</code>.</p>
    public let compressionFormat: CompressionFormat?
    /// <p>The serializer, deserializer, and schema for converting data from the JSON format to
    ///          the Parquet or ORC format before writing it to Amazon S3.</p>
    public let dataFormatConversionConfiguration: DataFormatConversionConfiguration?
    /// <p>The encryption configuration. If no value is specified, the default is no
    ///          encryption.</p>
    public let encryptionConfiguration: EncryptionConfiguration?
    /// <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
    ///          them to S3. This prefix appears immediately following the bucket name. For information
    ///          about how to specify this prefix, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let errorOutputPrefix: String?
    /// <p>The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered Amazon S3
    ///          files. You can also specify a custom prefix, as described in <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let prefix: String?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?
    /// <p>The configuration for backup in Amazon S3.</p>
    public let s3BackupDescription: S3DestinationDescription?
    /// <p>The Amazon S3 backup mode.</p>
    public let s3BackupMode: S3BackupMode?

    public init (
        bucketARN: String? = nil,
        bufferingHints: BufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        compressionFormat: CompressionFormat? = nil,
        dataFormatConversionConfiguration: DataFormatConversionConfiguration? = nil,
        encryptionConfiguration: EncryptionConfiguration? = nil,
        errorOutputPrefix: String? = nil,
        prefix: String? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        roleARN: String? = nil,
        s3BackupDescription: S3DestinationDescription? = nil,
        s3BackupMode: S3BackupMode? = nil
    )
    {
        self.bucketARN = bucketARN
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.compressionFormat = compressionFormat
        self.dataFormatConversionConfiguration = dataFormatConversionConfiguration
        self.encryptionConfiguration = encryptionConfiguration
        self.errorOutputPrefix = errorOutputPrefix
        self.prefix = prefix
        self.processingConfiguration = processingConfiguration
        self.roleARN = roleARN
        self.s3BackupDescription = s3BackupDescription
        self.s3BackupMode = s3BackupMode
    }
}

extension ExtendedS3DestinationUpdate: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bucketARN = "BucketARN"
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case compressionFormat = "CompressionFormat"
        case dataFormatConversionConfiguration = "DataFormatConversionConfiguration"
        case encryptionConfiguration = "EncryptionConfiguration"
        case errorOutputPrefix = "ErrorOutputPrefix"
        case prefix = "Prefix"
        case processingConfiguration = "ProcessingConfiguration"
        case roleARN = "RoleARN"
        case s3BackupMode = "S3BackupMode"
        case s3BackupUpdate = "S3BackupUpdate"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bucketARN = bucketARN {
            try encodeContainer.encode(bucketARN, forKey: .bucketARN)
        }
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let compressionFormat = compressionFormat {
            try encodeContainer.encode(compressionFormat.rawValue, forKey: .compressionFormat)
        }
        if let dataFormatConversionConfiguration = dataFormatConversionConfiguration {
            try encodeContainer.encode(dataFormatConversionConfiguration, forKey: .dataFormatConversionConfiguration)
        }
        if let encryptionConfiguration = encryptionConfiguration {
            try encodeContainer.encode(encryptionConfiguration, forKey: .encryptionConfiguration)
        }
        if let errorOutputPrefix = errorOutputPrefix {
            try encodeContainer.encode(errorOutputPrefix, forKey: .errorOutputPrefix)
        }
        if let prefix = prefix {
            try encodeContainer.encode(prefix, forKey: .prefix)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3BackupUpdate = s3BackupUpdate {
            try encodeContainer.encode(s3BackupUpdate, forKey: .s3BackupUpdate)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let bucketARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .bucketARN)
        bucketARN = bucketARNDecoded
        let prefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .prefix)
        prefix = prefixDecoded
        let errorOutputPrefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .errorOutputPrefix)
        errorOutputPrefix = errorOutputPrefixDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(BufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let compressionFormatDecoded = try containerValues.decodeIfPresent(CompressionFormat.self, forKey: .compressionFormat)
        compressionFormat = compressionFormatDecoded
        let encryptionConfigurationDecoded = try containerValues.decodeIfPresent(EncryptionConfiguration.self, forKey: .encryptionConfiguration)
        encryptionConfiguration = encryptionConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(S3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3BackupUpdateDecoded = try containerValues.decodeIfPresent(S3DestinationUpdate.self, forKey: .s3BackupUpdate)
        s3BackupUpdate = s3BackupUpdateDecoded
        let dataFormatConversionConfigurationDecoded = try containerValues.decodeIfPresent(DataFormatConversionConfiguration.self, forKey: .dataFormatConversionConfiguration)
        dataFormatConversionConfiguration = dataFormatConversionConfigurationDecoded
    }
}

extension ExtendedS3DestinationUpdate: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ExtendedS3DestinationUpdate(bucketARN: \(String(describing: bucketARN)), bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), compressionFormat: \(String(describing: compressionFormat)), dataFormatConversionConfiguration: \(String(describing: dataFormatConversionConfiguration)), encryptionConfiguration: \(String(describing: encryptionConfiguration)), errorOutputPrefix: \(String(describing: errorOutputPrefix)), prefix: \(String(describing: prefix)), processingConfiguration: \(String(describing: processingConfiguration)), roleARN: \(String(describing: roleARN)), s3BackupMode: \(String(describing: s3BackupMode)), s3BackupUpdate: \(String(describing: s3BackupUpdate)))"}
}

/// <p>Describes an update for a destination in Amazon S3.</p>
public struct ExtendedS3DestinationUpdate: Equatable {
    /// <p>The ARN of the S3 bucket. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let bucketARN: String?
    /// <p>The buffering option.</p>
    public let bufferingHints: BufferingHints?
    /// <p>The Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The compression format. If no value is specified, the default is
    ///             <code>UNCOMPRESSED</code>. </p>
    public let compressionFormat: CompressionFormat?
    /// <p>The serializer, deserializer, and schema for converting data from the JSON format to
    ///          the Parquet or ORC format before writing it to Amazon S3.</p>
    public let dataFormatConversionConfiguration: DataFormatConversionConfiguration?
    /// <p>The encryption configuration. If no value is specified, the default is no
    ///          encryption.</p>
    public let encryptionConfiguration: EncryptionConfiguration?
    /// <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
    ///          them to S3. This prefix appears immediately following the bucket name. For information
    ///          about how to specify this prefix, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let errorOutputPrefix: String?
    /// <p>The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered Amazon S3
    ///          files. You can also specify a custom prefix, as described in <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let prefix: String?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?
    /// <p>You can update a delivery stream to enable Amazon S3 backup if it is disabled. If
    ///          backup is enabled, you can't update the delivery stream to disable it. </p>
    public let s3BackupMode: S3BackupMode?
    /// <p>The Amazon S3 destination for backup.</p>
    public let s3BackupUpdate: S3DestinationUpdate?

    public init (
        bucketARN: String? = nil,
        bufferingHints: BufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        compressionFormat: CompressionFormat? = nil,
        dataFormatConversionConfiguration: DataFormatConversionConfiguration? = nil,
        encryptionConfiguration: EncryptionConfiguration? = nil,
        errorOutputPrefix: String? = nil,
        prefix: String? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        roleARN: String? = nil,
        s3BackupMode: S3BackupMode? = nil,
        s3BackupUpdate: S3DestinationUpdate? = nil
    )
    {
        self.bucketARN = bucketARN
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.compressionFormat = compressionFormat
        self.dataFormatConversionConfiguration = dataFormatConversionConfiguration
        self.encryptionConfiguration = encryptionConfiguration
        self.errorOutputPrefix = errorOutputPrefix
        self.prefix = prefix
        self.processingConfiguration = processingConfiguration
        self.roleARN = roleARN
        self.s3BackupMode = s3BackupMode
        self.s3BackupUpdate = s3BackupUpdate
    }
}

extension FailureDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case details = "Details"
        case type = "Type"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let details = details {
            try encodeContainer.encode(details, forKey: .details)
        }
        if let type = type {
            try encodeContainer.encode(type.rawValue, forKey: .type)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let typeDecoded = try containerValues.decodeIfPresent(DeliveryStreamFailureType.self, forKey: .type)
        type = typeDecoded
        let detailsDecoded = try containerValues.decodeIfPresent(String.self, forKey: .details)
        details = detailsDecoded
    }
}

extension FailureDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "FailureDescription(details: \(String(describing: details)), type: \(String(describing: type)))"}
}

/// <p>Provides details in case one of the following operations fails due to an error related
///          to KMS: <a>CreateDeliveryStream</a>, <a>DeleteDeliveryStream</a>,
///             <a>StartDeliveryStreamEncryption</a>, <a>StopDeliveryStreamEncryption</a>.</p>
public struct FailureDescription: Equatable {
    /// <p>A message providing details about the error that caused the failure.</p>
    public let details: String?
    /// <p>The type of error that caused the failure.</p>
    public let type: DeliveryStreamFailureType?

    public init (
        details: String? = nil,
        type: DeliveryStreamFailureType? = nil
    )
    {
        self.details = details
        self.type = type
    }
}

public enum HECEndpointType {
    case event
    case raw
    case sdkUnknown(String)
}

extension HECEndpointType : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [HECEndpointType] {
        return [
            .event,
            .raw,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .event: return "Event"
        case .raw: return "Raw"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = HECEndpointType(rawValue: rawValue) ?? HECEndpointType.sdkUnknown(rawValue)
    }
}

extension HiveJsonSerDe: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case timestampFormats = "TimestampFormats"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let timestampFormats = timestampFormats {
            var timestampFormatsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .timestampFormats)
            for listofnonemptystrings0 in timestampFormats {
                try timestampFormatsContainer.encode(listofnonemptystrings0)
            }
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let timestampFormatsContainer = try containerValues.decodeIfPresent([String?].self, forKey: .timestampFormats)
        var timestampFormatsDecoded0:[String]? = nil
        if let timestampFormatsContainer = timestampFormatsContainer {
            timestampFormatsDecoded0 = [String]()
            for string0 in timestampFormatsContainer {
                if let string0 = string0 {
                    timestampFormatsDecoded0?.append(string0)
                }
            }
        }
        timestampFormats = timestampFormatsDecoded0
    }
}

extension HiveJsonSerDe: CustomDebugStringConvertible {
    public var debugDescription: String {
        "HiveJsonSerDe(timestampFormats: \(String(describing: timestampFormats)))"}
}

/// <p>The native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for deserializing
///          data, which means converting it from the JSON format in preparation for serializing it to
///          the Parquet or ORC format. This is one of two deserializers you can choose, depending on
///          which one offers the functionality you need. The other option is the OpenX SerDe.</p>
public struct HiveJsonSerDe: Equatable {
    /// <p>Indicates how you want Kinesis Data Firehose to parse the date and timestamps that
    ///          may be present in your input data JSON. To specify these format strings, follow the pattern
    ///          syntax of JodaTime's DateTimeFormat format strings. For more information, see <a href="https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html">Class DateTimeFormat</a>. You can also use the special value <code>millis</code> to
    ///          parse timestamps in epoch milliseconds. If you don't specify a format, Kinesis Data
    ///          Firehose uses <code>java.sql.Timestamp::valueOf</code> by default.</p>
    public let timestampFormats: [String]?

    public init (
        timestampFormats: [String]? = nil
    )
    {
        self.timestampFormats = timestampFormats
    }
}

extension HttpEndpointBufferingHints: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case intervalInSeconds = "IntervalInSeconds"
        case sizeInMBs = "SizeInMBs"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let intervalInSeconds = intervalInSeconds {
            try encodeContainer.encode(intervalInSeconds, forKey: .intervalInSeconds)
        }
        if let sizeInMBs = sizeInMBs {
            try encodeContainer.encode(sizeInMBs, forKey: .sizeInMBs)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let sizeInMBsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .sizeInMBs)
        sizeInMBs = sizeInMBsDecoded
        let intervalInSecondsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .intervalInSeconds)
        intervalInSeconds = intervalInSecondsDecoded
    }
}

extension HttpEndpointBufferingHints: CustomDebugStringConvertible {
    public var debugDescription: String {
        "HttpEndpointBufferingHints(intervalInSeconds: \(String(describing: intervalInSeconds)), sizeInMBs: \(String(describing: sizeInMBs)))"}
}

/// <p>Describes the buffering options that can be applied before data is delivered to the HTTP
///          endpoint destination. Kinesis Data Firehose treats these options as hints, and it might
///          choose to use more optimal values. The <code>SizeInMBs</code> and
///             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for
///          one of them, you must also provide a value for the other. </p>
public struct HttpEndpointBufferingHints: Equatable {
    /// <p>Buffer incoming data for the specified period of time, in seconds, before delivering it
    ///          to the destination. The default value is 300 (5 minutes). </p>
    public let intervalInSeconds: Int?
    /// <p>Buffer incoming data to the specified size, in MBs, before delivering it to the
    ///          destination. The default value is 5. </p>
    ///          <p>We recommend setting this parameter to a value greater than the amount of data you
    ///          typically ingest into the delivery stream in 10 seconds. For example, if you typically
    ///          ingest data at 1 MB/sec, the value should be 10 MB or higher. </p>
    public let sizeInMBs: Int?

    public init (
        intervalInSeconds: Int? = nil,
        sizeInMBs: Int? = nil
    )
    {
        self.intervalInSeconds = intervalInSeconds
        self.sizeInMBs = sizeInMBs
    }
}

extension HttpEndpointCommonAttribute: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case attributeName = "AttributeName"
        case attributeValue = "AttributeValue"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let attributeName = attributeName {
            try encodeContainer.encode(attributeName, forKey: .attributeName)
        }
        if let attributeValue = attributeValue {
            try encodeContainer.encode(attributeValue, forKey: .attributeValue)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let attributeNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .attributeName)
        attributeName = attributeNameDecoded
        let attributeValueDecoded = try containerValues.decodeIfPresent(String.self, forKey: .attributeValue)
        attributeValue = attributeValueDecoded
    }
}

extension HttpEndpointCommonAttribute: CustomDebugStringConvertible {
    public var debugDescription: String {
        "HttpEndpointCommonAttribute(attributeName: \(String(describing: attributeName)), attributeValue: \(String(describing: attributeValue)))"}
}

/// <p>Describes the metadata that's delivered to the specified HTTP endpoint
///          destination.</p>
public struct HttpEndpointCommonAttribute: Equatable {
    /// <p>The name of the HTTP endpoint common attribute.</p>
    public let attributeName: String?
    /// <p>The value of the HTTP endpoint common attribute.</p>
    public let attributeValue: String?

    public init (
        attributeName: String? = nil,
        attributeValue: String? = nil
    )
    {
        self.attributeName = attributeName
        self.attributeValue = attributeValue
    }
}

extension HttpEndpointConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case accessKey = "AccessKey"
        case name = "Name"
        case url = "Url"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let accessKey = accessKey {
            try encodeContainer.encode(accessKey, forKey: .accessKey)
        }
        if let name = name {
            try encodeContainer.encode(name, forKey: .name)
        }
        if let url = url {
            try encodeContainer.encode(url, forKey: .url)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let urlDecoded = try containerValues.decodeIfPresent(String.self, forKey: .url)
        url = urlDecoded
        let nameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .name)
        name = nameDecoded
        let accessKeyDecoded = try containerValues.decodeIfPresent(String.self, forKey: .accessKey)
        accessKey = accessKeyDecoded
    }
}

extension HttpEndpointConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "HttpEndpointConfiguration(accessKey: \(String(describing: accessKey)), name: \(String(describing: name)), url: \(String(describing: url)))"}
}

/// <p>Describes the configuration of the HTTP endpoint to which Kinesis Firehose delivers
///          data.</p>
public struct HttpEndpointConfiguration: Equatable {
    /// <p>The access key required for Kinesis Firehose to authenticate with the HTTP endpoint
    ///          selected as the destination.</p>
    public let accessKey: String?
    /// <p>The name of the HTTP endpoint selected as the destination.</p>
    public let name: String?
    /// <p>The URL of the HTTP endpoint selected as the destination.</p>
    public let url: String?

    public init (
        accessKey: String? = nil,
        name: String? = nil,
        url: String? = nil
    )
    {
        self.accessKey = accessKey
        self.name = name
        self.url = url
    }
}

extension HttpEndpointDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case name = "Name"
        case url = "Url"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let name = name {
            try encodeContainer.encode(name, forKey: .name)
        }
        if let url = url {
            try encodeContainer.encode(url, forKey: .url)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let urlDecoded = try containerValues.decodeIfPresent(String.self, forKey: .url)
        url = urlDecoded
        let nameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .name)
        name = nameDecoded
    }
}

extension HttpEndpointDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "HttpEndpointDescription(name: \(String(describing: name)), url: \(String(describing: url)))"}
}

/// <p>Describes the HTTP endpoint selected as the destination. </p>
public struct HttpEndpointDescription: Equatable {
    /// <p>The name of the HTTP endpoint selected as the destination.</p>
    public let name: String?
    /// <p>The URL of the HTTP endpoint selected as the destination.</p>
    public let url: String?

    public init (
        name: String? = nil,
        url: String? = nil
    )
    {
        self.name = name
        self.url = url
    }
}

extension HttpEndpointDestinationConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case endpointConfiguration = "EndpointConfiguration"
        case processingConfiguration = "ProcessingConfiguration"
        case requestConfiguration = "RequestConfiguration"
        case retryOptions = "RetryOptions"
        case roleARN = "RoleARN"
        case s3BackupMode = "S3BackupMode"
        case s3Configuration = "S3Configuration"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let endpointConfiguration = endpointConfiguration {
            try encodeContainer.encode(endpointConfiguration, forKey: .endpointConfiguration)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let requestConfiguration = requestConfiguration {
            try encodeContainer.encode(requestConfiguration, forKey: .requestConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3Configuration = s3Configuration {
            try encodeContainer.encode(s3Configuration, forKey: .s3Configuration)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let endpointConfigurationDecoded = try containerValues.decodeIfPresent(HttpEndpointConfiguration.self, forKey: .endpointConfiguration)
        endpointConfiguration = endpointConfigurationDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(HttpEndpointBufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
        let requestConfigurationDecoded = try containerValues.decodeIfPresent(HttpEndpointRequestConfiguration.self, forKey: .requestConfiguration)
        requestConfiguration = requestConfigurationDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(HttpEndpointRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(HttpEndpointS3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3ConfigurationDecoded = try containerValues.decodeIfPresent(S3DestinationConfiguration.self, forKey: .s3Configuration)
        s3Configuration = s3ConfigurationDecoded
    }
}

extension HttpEndpointDestinationConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "HttpEndpointDestinationConfiguration(bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), endpointConfiguration: \(String(describing: endpointConfiguration)), processingConfiguration: \(String(describing: processingConfiguration)), requestConfiguration: \(String(describing: requestConfiguration)), retryOptions: \(String(describing: retryOptions)), roleARN: \(String(describing: roleARN)), s3BackupMode: \(String(describing: s3BackupMode)), s3Configuration: \(String(describing: s3Configuration)))"}
}

/// <p>Describes the configuration of the HTTP endpoint destination.</p>
public struct HttpEndpointDestinationConfiguration: Equatable {
    /// <p>The buffering options that can be used before data is delivered to the specified
    ///          destination. Kinesis Data Firehose treats these options as hints, and it might choose to
    ///          use more optimal values. The <code>SizeInMBs</code> and <code>IntervalInSeconds</code>
    ///          parameters are optional. However, if you specify a value for one of them, you must also
    ///          provide a value for the other. </p>
    public let bufferingHints: HttpEndpointBufferingHints?
    /// <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The configuration of the HTTP endpoint selected as the destination.</p>
    public let endpointConfiguration: HttpEndpointConfiguration?
    /// <p>Describes a data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The configuration of the requeste sent to the HTTP endpoint specified as the
    ///          destination.</p>
    public let requestConfiguration: HttpEndpointRequestConfiguration?
    /// <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to
    ///          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of
    ///          receipt from the specified HTTP endpoint destination.</p>
    public let retryOptions: HttpEndpointRetryOptions?
    /// <p>Kinesis Data Firehose uses this IAM role for all the permissions that the delivery
    ///          stream needs.</p>
    public let roleARN: String?
    /// <p>Describes the S3 bucket backup options for the data that Kinesis Data Firehose delivers
    ///          to the HTTP endpoint destination. You can back up all documents (<code>AllData</code>) or
    ///          only the documents that Kinesis Data Firehose could not deliver to the specified HTTP
    ///          endpoint destination (<code>FailedDataOnly</code>).</p>
    public let s3BackupMode: HttpEndpointS3BackupMode?
    /// <p>Describes the configuration of a destination in Amazon S3.</p>
    public let s3Configuration: S3DestinationConfiguration?

    public init (
        bufferingHints: HttpEndpointBufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        endpointConfiguration: HttpEndpointConfiguration? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        requestConfiguration: HttpEndpointRequestConfiguration? = nil,
        retryOptions: HttpEndpointRetryOptions? = nil,
        roleARN: String? = nil,
        s3BackupMode: HttpEndpointS3BackupMode? = nil,
        s3Configuration: S3DestinationConfiguration? = nil
    )
    {
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.endpointConfiguration = endpointConfiguration
        self.processingConfiguration = processingConfiguration
        self.requestConfiguration = requestConfiguration
        self.retryOptions = retryOptions
        self.roleARN = roleARN
        self.s3BackupMode = s3BackupMode
        self.s3Configuration = s3Configuration
    }
}

extension HttpEndpointDestinationDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case endpointConfiguration = "EndpointConfiguration"
        case processingConfiguration = "ProcessingConfiguration"
        case requestConfiguration = "RequestConfiguration"
        case retryOptions = "RetryOptions"
        case roleARN = "RoleARN"
        case s3BackupMode = "S3BackupMode"
        case s3DestinationDescription = "S3DestinationDescription"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let endpointConfiguration = endpointConfiguration {
            try encodeContainer.encode(endpointConfiguration, forKey: .endpointConfiguration)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let requestConfiguration = requestConfiguration {
            try encodeContainer.encode(requestConfiguration, forKey: .requestConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3DestinationDescription = s3DestinationDescription {
            try encodeContainer.encode(s3DestinationDescription, forKey: .s3DestinationDescription)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let endpointConfigurationDecoded = try containerValues.decodeIfPresent(HttpEndpointDescription.self, forKey: .endpointConfiguration)
        endpointConfiguration = endpointConfigurationDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(HttpEndpointBufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
        let requestConfigurationDecoded = try containerValues.decodeIfPresent(HttpEndpointRequestConfiguration.self, forKey: .requestConfiguration)
        requestConfiguration = requestConfigurationDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(HttpEndpointRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(HttpEndpointS3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3DestinationDescriptionDecoded = try containerValues.decodeIfPresent(S3DestinationDescription.self, forKey: .s3DestinationDescription)
        s3DestinationDescription = s3DestinationDescriptionDecoded
    }
}

extension HttpEndpointDestinationDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "HttpEndpointDestinationDescription(bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), endpointConfiguration: \(String(describing: endpointConfiguration)), processingConfiguration: \(String(describing: processingConfiguration)), requestConfiguration: \(String(describing: requestConfiguration)), retryOptions: \(String(describing: retryOptions)), roleARN: \(String(describing: roleARN)), s3BackupMode: \(String(describing: s3BackupMode)), s3DestinationDescription: \(String(describing: s3DestinationDescription)))"}
}

/// <p>Describes the HTTP endpoint destination.</p>
public struct HttpEndpointDestinationDescription: Equatable {
    /// <p>Describes buffering options that can be applied to the data before it is delivered to
    ///          the HTTPS endpoint destination. Kinesis Data Firehose teats these options as hints, and it
    ///          might choose to use more optimal values. The <code>SizeInMBs</code> and
    ///             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for
    ///          one of them, you must also provide a value for the other. </p>
    public let bufferingHints: HttpEndpointBufferingHints?
    /// <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The configuration of the specified HTTP endpoint destination.</p>
    public let endpointConfiguration: HttpEndpointDescription?
    /// <p>Describes a data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The configuration of request sent to the HTTP endpoint specified as the
    ///          destination.</p>
    public let requestConfiguration: HttpEndpointRequestConfiguration?
    /// <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to
    ///          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of
    ///          receipt from the specified HTTP endpoint destination.</p>
    public let retryOptions: HttpEndpointRetryOptions?
    /// <p>Kinesis Data Firehose uses this IAM role for all the permissions that the delivery
    ///          stream needs.</p>
    public let roleARN: String?
    /// <p>Describes the S3 bucket backup options for the data that Kinesis Firehose delivers to
    ///          the HTTP endpoint destination. You can back up all documents (<code>AllData</code>) or only
    ///          the documents that Kinesis Data Firehose could not deliver to the specified HTTP endpoint
    ///          destination (<code>FailedDataOnly</code>).</p>
    public let s3BackupMode: HttpEndpointS3BackupMode?
    /// <p>Describes a destination in Amazon S3.</p>
    public let s3DestinationDescription: S3DestinationDescription?

    public init (
        bufferingHints: HttpEndpointBufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        endpointConfiguration: HttpEndpointDescription? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        requestConfiguration: HttpEndpointRequestConfiguration? = nil,
        retryOptions: HttpEndpointRetryOptions? = nil,
        roleARN: String? = nil,
        s3BackupMode: HttpEndpointS3BackupMode? = nil,
        s3DestinationDescription: S3DestinationDescription? = nil
    )
    {
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.endpointConfiguration = endpointConfiguration
        self.processingConfiguration = processingConfiguration
        self.requestConfiguration = requestConfiguration
        self.retryOptions = retryOptions
        self.roleARN = roleARN
        self.s3BackupMode = s3BackupMode
        self.s3DestinationDescription = s3DestinationDescription
    }
}

extension HttpEndpointDestinationUpdate: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case endpointConfiguration = "EndpointConfiguration"
        case processingConfiguration = "ProcessingConfiguration"
        case requestConfiguration = "RequestConfiguration"
        case retryOptions = "RetryOptions"
        case roleARN = "RoleARN"
        case s3BackupMode = "S3BackupMode"
        case s3Update = "S3Update"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let endpointConfiguration = endpointConfiguration {
            try encodeContainer.encode(endpointConfiguration, forKey: .endpointConfiguration)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let requestConfiguration = requestConfiguration {
            try encodeContainer.encode(requestConfiguration, forKey: .requestConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3Update = s3Update {
            try encodeContainer.encode(s3Update, forKey: .s3Update)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let endpointConfigurationDecoded = try containerValues.decodeIfPresent(HttpEndpointConfiguration.self, forKey: .endpointConfiguration)
        endpointConfiguration = endpointConfigurationDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(HttpEndpointBufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
        let requestConfigurationDecoded = try containerValues.decodeIfPresent(HttpEndpointRequestConfiguration.self, forKey: .requestConfiguration)
        requestConfiguration = requestConfigurationDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(HttpEndpointRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(HttpEndpointS3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3UpdateDecoded = try containerValues.decodeIfPresent(S3DestinationUpdate.self, forKey: .s3Update)
        s3Update = s3UpdateDecoded
    }
}

extension HttpEndpointDestinationUpdate: CustomDebugStringConvertible {
    public var debugDescription: String {
        "HttpEndpointDestinationUpdate(bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), endpointConfiguration: \(String(describing: endpointConfiguration)), processingConfiguration: \(String(describing: processingConfiguration)), requestConfiguration: \(String(describing: requestConfiguration)), retryOptions: \(String(describing: retryOptions)), roleARN: \(String(describing: roleARN)), s3BackupMode: \(String(describing: s3BackupMode)), s3Update: \(String(describing: s3Update)))"}
}

/// <p>Updates the specified HTTP endpoint destination.</p>
public struct HttpEndpointDestinationUpdate: Equatable {
    /// <p>Describes buffering options that can be applied to the data before it is delivered to
    ///          the HTTPS endpoint destination. Kinesis Data Firehose teats these options as hints, and it
    ///          might choose to use more optimal values. The <code>SizeInMBs</code> and
    ///             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for
    ///          one of them, you must also provide a value for the other. </p>
    public let bufferingHints: HttpEndpointBufferingHints?
    /// <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>Describes the configuration of the HTTP endpoint destination.</p>
    public let endpointConfiguration: HttpEndpointConfiguration?
    /// <p>Describes a data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The configuration of the request sent to the HTTP endpoint specified as the
    ///          destination.</p>
    public let requestConfiguration: HttpEndpointRequestConfiguration?
    /// <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to
    ///          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of
    ///          receipt from the specified HTTP endpoint destination.</p>
    public let retryOptions: HttpEndpointRetryOptions?
    /// <p>Kinesis Data Firehose uses this IAM role for all the permissions that the delivery
    ///          stream needs.</p>
    public let roleARN: String?
    /// <p>Describes the S3 bucket backup options for the data that Kinesis Firehose delivers to
    ///          the HTTP endpoint destination. You can back up all documents (<code>AllData</code>) or only
    ///          the documents that Kinesis Data Firehose could not deliver to the specified HTTP endpoint
    ///          destination (<code>FailedDataOnly</code>).</p>
    public let s3BackupMode: HttpEndpointS3BackupMode?
    /// <p>Describes an update for a destination in Amazon S3.</p>
    public let s3Update: S3DestinationUpdate?

    public init (
        bufferingHints: HttpEndpointBufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        endpointConfiguration: HttpEndpointConfiguration? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        requestConfiguration: HttpEndpointRequestConfiguration? = nil,
        retryOptions: HttpEndpointRetryOptions? = nil,
        roleARN: String? = nil,
        s3BackupMode: HttpEndpointS3BackupMode? = nil,
        s3Update: S3DestinationUpdate? = nil
    )
    {
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.endpointConfiguration = endpointConfiguration
        self.processingConfiguration = processingConfiguration
        self.requestConfiguration = requestConfiguration
        self.retryOptions = retryOptions
        self.roleARN = roleARN
        self.s3BackupMode = s3BackupMode
        self.s3Update = s3Update
    }
}

extension HttpEndpointRequestConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case commonAttributes = "CommonAttributes"
        case contentEncoding = "ContentEncoding"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let commonAttributes = commonAttributes {
            var commonAttributesContainer = encodeContainer.nestedUnkeyedContainer(forKey: .commonAttributes)
            for httpendpointcommonattributeslist0 in commonAttributes {
                try commonAttributesContainer.encode(httpendpointcommonattributeslist0)
            }
        }
        if let contentEncoding = contentEncoding {
            try encodeContainer.encode(contentEncoding.rawValue, forKey: .contentEncoding)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let contentEncodingDecoded = try containerValues.decodeIfPresent(ContentEncoding.self, forKey: .contentEncoding)
        contentEncoding = contentEncodingDecoded
        let commonAttributesContainer = try containerValues.decodeIfPresent([HttpEndpointCommonAttribute?].self, forKey: .commonAttributes)
        var commonAttributesDecoded0:[HttpEndpointCommonAttribute]? = nil
        if let commonAttributesContainer = commonAttributesContainer {
            commonAttributesDecoded0 = [HttpEndpointCommonAttribute]()
            for structure0 in commonAttributesContainer {
                if let structure0 = structure0 {
                    commonAttributesDecoded0?.append(structure0)
                }
            }
        }
        commonAttributes = commonAttributesDecoded0
    }
}

extension HttpEndpointRequestConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "HttpEndpointRequestConfiguration(commonAttributes: \(String(describing: commonAttributes)), contentEncoding: \(String(describing: contentEncoding)))"}
}

/// <p>The configuration of the HTTP endpoint request.</p>
public struct HttpEndpointRequestConfiguration: Equatable {
    /// <p>Describes the metadata sent to the HTTP endpoint destination.</p>
    public let commonAttributes: [HttpEndpointCommonAttribute]?
    /// <p>Kinesis Data Firehose uses the content encoding to compress the body of a request before
    ///          sending the request to the destination. For more information, see <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding">Content-Encoding</a> in MDN Web Docs, the official Mozilla documentation.</p>
    public let contentEncoding: ContentEncoding?

    public init (
        commonAttributes: [HttpEndpointCommonAttribute]? = nil,
        contentEncoding: ContentEncoding? = nil
    )
    {
        self.commonAttributes = commonAttributes
        self.contentEncoding = contentEncoding
    }
}

extension HttpEndpointRetryOptions: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case durationInSeconds = "DurationInSeconds"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let durationInSeconds = durationInSeconds {
            try encodeContainer.encode(durationInSeconds, forKey: .durationInSeconds)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let durationInSecondsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .durationInSeconds)
        durationInSeconds = durationInSecondsDecoded
    }
}

extension HttpEndpointRetryOptions: CustomDebugStringConvertible {
    public var debugDescription: String {
        "HttpEndpointRetryOptions(durationInSeconds: \(String(describing: durationInSeconds)))"}
}

/// <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to
///          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of
///          receipt from the specified HTTP endpoint destination.</p>
public struct HttpEndpointRetryOptions: Equatable {
    /// <p>The total amount of time that Kinesis Data Firehose spends on retries. This duration
    ///          starts after the initial attempt to send data to the custom destination via HTTPS endpoint
    ///          fails. It doesn't include the periods during which Kinesis Data Firehose waits for
    ///          acknowledgment from the specified destination after each attempt. </p>
    public let durationInSeconds: Int?

    public init (
        durationInSeconds: Int? = nil
    )
    {
        self.durationInSeconds = durationInSeconds
    }
}

public enum HttpEndpointS3BackupMode {
    case alldata
    case faileddataonly
    case sdkUnknown(String)
}

extension HttpEndpointS3BackupMode : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [HttpEndpointS3BackupMode] {
        return [
            .alldata,
            .faileddataonly,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .alldata: return "AllData"
        case .faileddataonly: return "FailedDataOnly"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = HttpEndpointS3BackupMode(rawValue: rawValue) ?? HttpEndpointS3BackupMode.sdkUnknown(rawValue)
    }
}

extension InputFormatConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deserializer = "Deserializer"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deserializer = deserializer {
            try encodeContainer.encode(deserializer, forKey: .deserializer)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deserializerDecoded = try containerValues.decodeIfPresent(Deserializer.self, forKey: .deserializer)
        deserializer = deserializerDecoded
    }
}

extension InputFormatConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "InputFormatConfiguration(deserializer: \(String(describing: deserializer)))"}
}

/// <p>Specifies the deserializer you want to use to convert the format of the input data.
///          This parameter is required if <code>Enabled</code> is set to true.</p>
public struct InputFormatConfiguration: Equatable {
    /// <p>Specifies which deserializer to use. You can choose either the Apache Hive JSON SerDe
    ///          or the OpenX JSON SerDe. If both are non-null, the server rejects the request.</p>
    public let deserializer: Deserializer?

    public init (
        deserializer: Deserializer? = nil
    )
    {
        self.deserializer = deserializer
    }
}

extension InvalidArgumentException: CustomDebugStringConvertible {
    public var debugDescription: String {
        "InvalidArgumentException(message: \(String(describing: message)))"}
}

extension InvalidArgumentException: AWSHttpServiceError {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: InvalidArgumentExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>The specified input parameter has a value that is not valid.</p>
public struct InvalidArgumentException: ClientRuntime.ServiceError, Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: HttpStatusCode?
    public var _message: String?
    public var _requestID: String?
    public var _retryable: Bool = false
    public var _isThrottling: Bool = false
    public var _type: ErrorType = .client
    /// <p>A message that provides information about the error.</p>
    public var message: String?

    public init (
        message: String? = nil
    )
    {
        self.message = message
    }
}

struct InvalidArgumentExceptionBody: Equatable {
    public let message: String?
}

extension InvalidArgumentExceptionBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case message
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(String.self, forKey: .message)
        message = messageDecoded
    }
}

extension InvalidKMSResourceException: CustomDebugStringConvertible {
    public var debugDescription: String {
        "InvalidKMSResourceException(code: \(String(describing: code)), message: \(String(describing: message)))"}
}

extension InvalidKMSResourceException: AWSHttpServiceError {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: InvalidKMSResourceExceptionBody = try responseDecoder.decode(responseBody: data)
            self.code = output.code
            self.message = output.message
        } else {
            self.code = nil
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>Kinesis Data Firehose throws this exception when an attempt to put records or to start
///          or stop delivery stream encryption fails. This happens when the KMS service throws one of
///          the following exception types: <code>AccessDeniedException</code>,
///             <code>InvalidStateException</code>, <code>DisabledException</code>, or
///             <code>NotFoundException</code>.</p>
public struct InvalidKMSResourceException: ClientRuntime.ServiceError, Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: HttpStatusCode?
    public var _message: String?
    public var _requestID: String?
    public var _retryable: Bool = false
    public var _isThrottling: Bool = false
    public var _type: ErrorType = .client
    public var code: String?
    public var message: String?

    public init (
        code: String? = nil,
        message: String? = nil
    )
    {
        self.code = code
        self.message = message
    }
}

struct InvalidKMSResourceExceptionBody: Equatable {
    public let code: String?
    public let message: String?
}

extension InvalidKMSResourceExceptionBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case code
        case message
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let codeDecoded = try containerValues.decodeIfPresent(String.self, forKey: .code)
        code = codeDecoded
        let messageDecoded = try containerValues.decodeIfPresent(String.self, forKey: .message)
        message = messageDecoded
    }
}

extension KMSEncryptionConfig: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case aWSKMSKeyARN = "AWSKMSKeyARN"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let aWSKMSKeyARN = aWSKMSKeyARN {
            try encodeContainer.encode(aWSKMSKeyARN, forKey: .aWSKMSKeyARN)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let aWSKMSKeyARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .aWSKMSKeyARN)
        aWSKMSKeyARN = aWSKMSKeyARNDecoded
    }
}

extension KMSEncryptionConfig: CustomDebugStringConvertible {
    public var debugDescription: String {
        "KMSEncryptionConfig(aWSKMSKeyARN: \(String(describing: aWSKMSKeyARN)))"}
}

/// <p>Describes an encryption key for a destination in Amazon S3.</p>
public struct KMSEncryptionConfig: Equatable {
    /// <p>The Amazon Resource Name (ARN) of the encryption key. Must belong to the same AWS
    ///          Region as the destination Amazon S3 bucket. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let aWSKMSKeyARN: String?

    public init (
        aWSKMSKeyARN: String? = nil
    )
    {
        self.aWSKMSKeyARN = aWSKMSKeyARN
    }
}

public enum KeyType {
    case awsOwnedCmk
    case customerManagedCmk
    case sdkUnknown(String)
}

extension KeyType : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [KeyType] {
        return [
            .awsOwnedCmk,
            .customerManagedCmk,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .awsOwnedCmk: return "AWS_OWNED_CMK"
        case .customerManagedCmk: return "CUSTOMER_MANAGED_CMK"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = KeyType(rawValue: rawValue) ?? KeyType.sdkUnknown(rawValue)
    }
}

extension KinesisStreamSourceConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case kinesisStreamARN = "KinesisStreamARN"
        case roleARN = "RoleARN"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let kinesisStreamARN = kinesisStreamARN {
            try encodeContainer.encode(kinesisStreamARN, forKey: .kinesisStreamARN)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let kinesisStreamARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .kinesisStreamARN)
        kinesisStreamARN = kinesisStreamARNDecoded
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
    }
}

extension KinesisStreamSourceConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "KinesisStreamSourceConfiguration(kinesisStreamARN: \(String(describing: kinesisStreamARN)), roleARN: \(String(describing: roleARN)))"}
}

/// <p>The stream and role Amazon Resource Names (ARNs) for a Kinesis data stream used as
///          the source for a delivery stream.</p>
public struct KinesisStreamSourceConfiguration: Equatable {
    /// <p>The ARN of the source Kinesis data stream. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-kinesis-streams">Amazon Kinesis Data Streams ARN Format</a>.</p>
    public let kinesisStreamARN: String?
    /// <p>The ARN of the role that provides access to the source Kinesis data stream. For more
    ///          information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-iam">AWS Identity and Access Management (IAM) ARN Format</a>.</p>
    public let roleARN: String?

    public init (
        kinesisStreamARN: String? = nil,
        roleARN: String? = nil
    )
    {
        self.kinesisStreamARN = kinesisStreamARN
        self.roleARN = roleARN
    }
}

extension KinesisStreamSourceDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deliveryStartTimestamp = "DeliveryStartTimestamp"
        case kinesisStreamARN = "KinesisStreamARN"
        case roleARN = "RoleARN"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deliveryStartTimestamp = deliveryStartTimestamp {
            try encodeContainer.encode(deliveryStartTimestamp.timeIntervalSince1970, forKey: .deliveryStartTimestamp)
        }
        if let kinesisStreamARN = kinesisStreamARN {
            try encodeContainer.encode(kinesisStreamARN, forKey: .kinesisStreamARN)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let kinesisStreamARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .kinesisStreamARN)
        kinesisStreamARN = kinesisStreamARNDecoded
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let deliveryStartTimestampDecoded = try containerValues.decodeIfPresent(Date.self, forKey: .deliveryStartTimestamp)
        deliveryStartTimestamp = deliveryStartTimestampDecoded
    }
}

extension KinesisStreamSourceDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "KinesisStreamSourceDescription(deliveryStartTimestamp: \(String(describing: deliveryStartTimestamp)), kinesisStreamARN: \(String(describing: kinesisStreamARN)), roleARN: \(String(describing: roleARN)))"}
}

/// <p>Details about a Kinesis data stream used as the source for a Kinesis Data Firehose
///          delivery stream.</p>
public struct KinesisStreamSourceDescription: Equatable {
    /// <p>Kinesis Data Firehose starts retrieving records from the Kinesis data stream starting
    ///          with this timestamp.</p>
    public let deliveryStartTimestamp: Date?
    /// <p>The Amazon Resource Name (ARN) of the source Kinesis data stream. For more
    ///          information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-kinesis-streams">Amazon Kinesis Data Streams ARN Format</a>.</p>
    public let kinesisStreamARN: String?
    /// <p>The ARN of the role used by the source Kinesis data stream. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-iam">AWS Identity and Access Management (IAM) ARN Format</a>.</p>
    public let roleARN: String?

    public init (
        deliveryStartTimestamp: Date? = nil,
        kinesisStreamARN: String? = nil,
        roleARN: String? = nil
    )
    {
        self.deliveryStartTimestamp = deliveryStartTimestamp
        self.kinesisStreamARN = kinesisStreamARN
        self.roleARN = roleARN
    }
}

extension LimitExceededException: CustomDebugStringConvertible {
    public var debugDescription: String {
        "LimitExceededException(message: \(String(describing: message)))"}
}

extension LimitExceededException: AWSHttpServiceError {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: LimitExceededExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>You have already reached the limit for a requested resource.</p>
public struct LimitExceededException: ClientRuntime.ServiceError, Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: HttpStatusCode?
    public var _message: String?
    public var _requestID: String?
    public var _retryable: Bool = false
    public var _isThrottling: Bool = false
    public var _type: ErrorType = .client
    /// <p>A message that provides information about the error.</p>
    public var message: String?

    public init (
        message: String? = nil
    )
    {
        self.message = message
    }
}

struct LimitExceededExceptionBody: Equatable {
    public let message: String?
}

extension LimitExceededExceptionBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case message
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(String.self, forKey: .message)
        message = messageDecoded
    }
}

public struct ListDeliveryStreamsInputBodyMiddleware: Middleware {
    public let id: String = "ListDeliveryStreamsInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<ListDeliveryStreamsInput>,
                  next: H) -> Swift.Result<OperationOutput<ListDeliveryStreamsOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<ListDeliveryStreamsInput>
    public typealias MOutput = OperationOutput<ListDeliveryStreamsOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<ListDeliveryStreamsOutputError>
}

extension ListDeliveryStreamsInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ListDeliveryStreamsInput(deliveryStreamType: \(String(describing: deliveryStreamType)), exclusiveStartDeliveryStreamName: \(String(describing: exclusiveStartDeliveryStreamName)), limit: \(String(describing: limit)))"}
}

extension ListDeliveryStreamsInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamType = "DeliveryStreamType"
        case exclusiveStartDeliveryStreamName = "ExclusiveStartDeliveryStreamName"
        case limit = "Limit"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deliveryStreamType = deliveryStreamType {
            try encodeContainer.encode(deliveryStreamType.rawValue, forKey: .deliveryStreamType)
        }
        if let exclusiveStartDeliveryStreamName = exclusiveStartDeliveryStreamName {
            try encodeContainer.encode(exclusiveStartDeliveryStreamName, forKey: .exclusiveStartDeliveryStreamName)
        }
        if let limit = limit {
            try encodeContainer.encode(limit, forKey: .limit)
        }
    }
}

public struct ListDeliveryStreamsInputHeadersMiddleware: Middleware {
    public let id: String = "ListDeliveryStreamsInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<ListDeliveryStreamsInput>,
                  next: H) -> Swift.Result<OperationOutput<ListDeliveryStreamsOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<ListDeliveryStreamsInput>
    public typealias MOutput = OperationOutput<ListDeliveryStreamsOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<ListDeliveryStreamsOutputError>
}

public struct ListDeliveryStreamsInputQueryItemMiddleware: Middleware {
    public let id: String = "ListDeliveryStreamsInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<ListDeliveryStreamsInput>,
                  next: H) -> Swift.Result<OperationOutput<ListDeliveryStreamsOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<ListDeliveryStreamsInput>
    public typealias MOutput = OperationOutput<ListDeliveryStreamsOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<ListDeliveryStreamsOutputError>
}

public struct ListDeliveryStreamsInput: Equatable {
    /// <p>The delivery stream type. This can be one of the following values:</p>
    ///          <ul>
    ///             <li>
    ///                <p>
    ///                   <code>DirectPut</code>: Provider applications access the delivery stream
    ///                directly.</p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>KinesisStreamAsSource</code>: The delivery stream uses a Kinesis data
    ///                stream as a source.</p>
    ///             </li>
    ///          </ul>
    ///          <p>This parameter is optional. If this parameter is omitted, delivery streams of all
    ///          types are returned.</p>
    public let deliveryStreamType: DeliveryStreamType?
    /// <p>The list of delivery streams returned by this call to
    ///             <code>ListDeliveryStreams</code> will start with the delivery stream whose name comes
    ///          alphabetically immediately after the name you specify in
    ///             <code>ExclusiveStartDeliveryStreamName</code>.</p>
    public let exclusiveStartDeliveryStreamName: String?
    /// <p>The maximum number of delivery streams to list. The default value is 10.</p>
    public let limit: Int?

    public init (
        deliveryStreamType: DeliveryStreamType? = nil,
        exclusiveStartDeliveryStreamName: String? = nil,
        limit: Int? = nil
    )
    {
        self.deliveryStreamType = deliveryStreamType
        self.exclusiveStartDeliveryStreamName = exclusiveStartDeliveryStreamName
        self.limit = limit
    }
}

struct ListDeliveryStreamsInputBody: Equatable {
    public let limit: Int?
    public let deliveryStreamType: DeliveryStreamType?
    public let exclusiveStartDeliveryStreamName: String?
}

extension ListDeliveryStreamsInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamType = "DeliveryStreamType"
        case exclusiveStartDeliveryStreamName = "ExclusiveStartDeliveryStreamName"
        case limit = "Limit"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let limitDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .limit)
        limit = limitDecoded
        let deliveryStreamTypeDecoded = try containerValues.decodeIfPresent(DeliveryStreamType.self, forKey: .deliveryStreamType)
        deliveryStreamType = deliveryStreamTypeDecoded
        let exclusiveStartDeliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .exclusiveStartDeliveryStreamName)
        exclusiveStartDeliveryStreamName = exclusiveStartDeliveryStreamNameDecoded
    }
}

extension ListDeliveryStreamsOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension ListDeliveryStreamsOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum ListDeliveryStreamsOutputError: Swift.Error, Equatable {
    case unknown(UnknownAWSHttpServiceError)
}

extension ListDeliveryStreamsOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ListDeliveryStreamsOutputResponse(deliveryStreamNames: \(String(describing: deliveryStreamNames)), hasMoreDeliveryStreams: \(String(describing: hasMoreDeliveryStreams)))"}
}

extension ListDeliveryStreamsOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: ListDeliveryStreamsOutputResponseBody = try responseDecoder.decode(responseBody: data)
            self.deliveryStreamNames = output.deliveryStreamNames
            self.hasMoreDeliveryStreams = output.hasMoreDeliveryStreams
        } else {
            self.deliveryStreamNames = nil
            self.hasMoreDeliveryStreams = nil
        }
    }
}

public struct ListDeliveryStreamsOutputResponse: Equatable {
    /// <p>The names of the delivery streams.</p>
    public let deliveryStreamNames: [String]?
    /// <p>Indicates whether there are more delivery streams available to list.</p>
    public let hasMoreDeliveryStreams: Bool?

    public init (
        deliveryStreamNames: [String]? = nil,
        hasMoreDeliveryStreams: Bool? = nil
    )
    {
        self.deliveryStreamNames = deliveryStreamNames
        self.hasMoreDeliveryStreams = hasMoreDeliveryStreams
    }
}

struct ListDeliveryStreamsOutputResponseBody: Equatable {
    public let deliveryStreamNames: [String]?
    public let hasMoreDeliveryStreams: Bool?
}

extension ListDeliveryStreamsOutputResponseBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamNames = "DeliveryStreamNames"
        case hasMoreDeliveryStreams = "HasMoreDeliveryStreams"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNamesContainer = try containerValues.decodeIfPresent([String?].self, forKey: .deliveryStreamNames)
        var deliveryStreamNamesDecoded0:[String]? = nil
        if let deliveryStreamNamesContainer = deliveryStreamNamesContainer {
            deliveryStreamNamesDecoded0 = [String]()
            for string0 in deliveryStreamNamesContainer {
                if let string0 = string0 {
                    deliveryStreamNamesDecoded0?.append(string0)
                }
            }
        }
        deliveryStreamNames = deliveryStreamNamesDecoded0
        let hasMoreDeliveryStreamsDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .hasMoreDeliveryStreams)
        hasMoreDeliveryStreams = hasMoreDeliveryStreamsDecoded
    }
}

public struct ListTagsForDeliveryStreamInputBodyMiddleware: Middleware {
    public let id: String = "ListTagsForDeliveryStreamInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<ListTagsForDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<ListTagsForDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<ListTagsForDeliveryStreamInput>
    public typealias MOutput = OperationOutput<ListTagsForDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<ListTagsForDeliveryStreamOutputError>
}

extension ListTagsForDeliveryStreamInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ListTagsForDeliveryStreamInput(deliveryStreamName: \(String(describing: deliveryStreamName)), exclusiveStartTagKey: \(String(describing: exclusiveStartTagKey)), limit: \(String(describing: limit)))"}
}

extension ListTagsForDeliveryStreamInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case exclusiveStartTagKey = "ExclusiveStartTagKey"
        case limit = "Limit"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
        if let exclusiveStartTagKey = exclusiveStartTagKey {
            try encodeContainer.encode(exclusiveStartTagKey, forKey: .exclusiveStartTagKey)
        }
        if let limit = limit {
            try encodeContainer.encode(limit, forKey: .limit)
        }
    }
}

public struct ListTagsForDeliveryStreamInputHeadersMiddleware: Middleware {
    public let id: String = "ListTagsForDeliveryStreamInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<ListTagsForDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<ListTagsForDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<ListTagsForDeliveryStreamInput>
    public typealias MOutput = OperationOutput<ListTagsForDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<ListTagsForDeliveryStreamOutputError>
}

public struct ListTagsForDeliveryStreamInputQueryItemMiddleware: Middleware {
    public let id: String = "ListTagsForDeliveryStreamInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<ListTagsForDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<ListTagsForDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<ListTagsForDeliveryStreamInput>
    public typealias MOutput = OperationOutput<ListTagsForDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<ListTagsForDeliveryStreamOutputError>
}

public struct ListTagsForDeliveryStreamInput: Equatable {
    /// <p>The name of the delivery stream whose tags you want to list.</p>
    public let deliveryStreamName: String?
    /// <p>The key to use as the starting point for the list of tags. If you set this parameter,
    ///             <code>ListTagsForDeliveryStream</code> gets all tags that occur after
    ///             <code>ExclusiveStartTagKey</code>.</p>
    public let exclusiveStartTagKey: String?
    /// <p>The number of tags to return. If this number is less than the total number of tags
    ///          associated with the delivery stream, <code>HasMoreTags</code> is set to <code>true</code>
    ///          in the response. To list additional tags, set <code>ExclusiveStartTagKey</code> to the last
    ///          key in the response. </p>
    public let limit: Int?

    public init (
        deliveryStreamName: String? = nil,
        exclusiveStartTagKey: String? = nil,
        limit: Int? = nil
    )
    {
        self.deliveryStreamName = deliveryStreamName
        self.exclusiveStartTagKey = exclusiveStartTagKey
        self.limit = limit
    }
}

struct ListTagsForDeliveryStreamInputBody: Equatable {
    public let deliveryStreamName: String?
    public let exclusiveStartTagKey: String?
    public let limit: Int?
}

extension ListTagsForDeliveryStreamInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case exclusiveStartTagKey = "ExclusiveStartTagKey"
        case limit = "Limit"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
        let exclusiveStartTagKeyDecoded = try containerValues.decodeIfPresent(String.self, forKey: .exclusiveStartTagKey)
        exclusiveStartTagKey = exclusiveStartTagKeyDecoded
        let limitDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .limit)
        limit = limitDecoded
    }
}

extension ListTagsForDeliveryStreamOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension ListTagsForDeliveryStreamOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "LimitExceededException" : self = .limitExceededException(try LimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum ListTagsForDeliveryStreamOutputError: Swift.Error, Equatable {
    case invalidArgumentException(InvalidArgumentException)
    case limitExceededException(LimitExceededException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unknown(UnknownAWSHttpServiceError)
}

extension ListTagsForDeliveryStreamOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ListTagsForDeliveryStreamOutputResponse(hasMoreTags: \(String(describing: hasMoreTags)), tags: \(String(describing: tags)))"}
}

extension ListTagsForDeliveryStreamOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: ListTagsForDeliveryStreamOutputResponseBody = try responseDecoder.decode(responseBody: data)
            self.hasMoreTags = output.hasMoreTags
            self.tags = output.tags
        } else {
            self.hasMoreTags = nil
            self.tags = nil
        }
    }
}

public struct ListTagsForDeliveryStreamOutputResponse: Equatable {
    /// <p>If this is <code>true</code> in the response, more tags are available. To list the
    ///          remaining tags, set <code>ExclusiveStartTagKey</code> to the key of the last tag returned
    ///          and call <code>ListTagsForDeliveryStream</code> again.</p>
    public let hasMoreTags: Bool?
    /// <p>A list of tags associated with <code>DeliveryStreamName</code>, starting with the
    ///          first tag after <code>ExclusiveStartTagKey</code> and up to the specified
    ///             <code>Limit</code>.</p>
    public let tags: [Tag]?

    public init (
        hasMoreTags: Bool? = nil,
        tags: [Tag]? = nil
    )
    {
        self.hasMoreTags = hasMoreTags
        self.tags = tags
    }
}

struct ListTagsForDeliveryStreamOutputResponseBody: Equatable {
    public let tags: [Tag]?
    public let hasMoreTags: Bool?
}

extension ListTagsForDeliveryStreamOutputResponseBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case hasMoreTags = "HasMoreTags"
        case tags = "Tags"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let tagsContainer = try containerValues.decodeIfPresent([Tag?].self, forKey: .tags)
        var tagsDecoded0:[Tag]? = nil
        if let tagsContainer = tagsContainer {
            tagsDecoded0 = [Tag]()
            for structure0 in tagsContainer {
                if let structure0 = structure0 {
                    tagsDecoded0?.append(structure0)
                }
            }
        }
        tags = tagsDecoded0
        let hasMoreTagsDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .hasMoreTags)
        hasMoreTags = hasMoreTagsDecoded
    }
}

public enum NoEncryptionConfig {
    case noencryption
    case sdkUnknown(String)
}

extension NoEncryptionConfig : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [NoEncryptionConfig] {
        return [
            .noencryption,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .noencryption: return "NoEncryption"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = NoEncryptionConfig(rawValue: rawValue) ?? NoEncryptionConfig.sdkUnknown(rawValue)
    }
}

extension OpenXJsonSerDe: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case caseInsensitive = "CaseInsensitive"
        case columnToJsonKeyMappings = "ColumnToJsonKeyMappings"
        case convertDotsInJsonKeysToUnderscores = "ConvertDotsInJsonKeysToUnderscores"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let caseInsensitive = caseInsensitive {
            try encodeContainer.encode(caseInsensitive, forKey: .caseInsensitive)
        }
        if let columnToJsonKeyMappings = columnToJsonKeyMappings {
            var columnToJsonKeyMappingsContainer = encodeContainer.nestedContainer(keyedBy: Key.self, forKey: .columnToJsonKeyMappings)
            for (dictKey0, columntojsonkeymappings0) in columnToJsonKeyMappings {
                try columnToJsonKeyMappingsContainer.encode(columntojsonkeymappings0, forKey: Key(stringValue: dictKey0))
            }
        }
        if let convertDotsInJsonKeysToUnderscores = convertDotsInJsonKeysToUnderscores {
            try encodeContainer.encode(convertDotsInJsonKeysToUnderscores, forKey: .convertDotsInJsonKeysToUnderscores)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let convertDotsInJsonKeysToUnderscoresDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .convertDotsInJsonKeysToUnderscores)
        convertDotsInJsonKeysToUnderscores = convertDotsInJsonKeysToUnderscoresDecoded
        let caseInsensitiveDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .caseInsensitive)
        caseInsensitive = caseInsensitiveDecoded
        let columnToJsonKeyMappingsContainer = try containerValues.decodeIfPresent([String: String?].self, forKey: .columnToJsonKeyMappings)
        var columnToJsonKeyMappingsDecoded0: [String:String]? = nil
        if let columnToJsonKeyMappingsContainer = columnToJsonKeyMappingsContainer {
            columnToJsonKeyMappingsDecoded0 = [String:String]()
            for (key0, nonemptystring0) in columnToJsonKeyMappingsContainer {
                if let nonemptystring0 = nonemptystring0 {
                    columnToJsonKeyMappingsDecoded0?[key0] = nonemptystring0
                }
            }
        }
        columnToJsonKeyMappings = columnToJsonKeyMappingsDecoded0
    }
}

extension OpenXJsonSerDe: CustomDebugStringConvertible {
    public var debugDescription: String {
        "OpenXJsonSerDe(caseInsensitive: \(String(describing: caseInsensitive)), columnToJsonKeyMappings: \(String(describing: columnToJsonKeyMappings)), convertDotsInJsonKeysToUnderscores: \(String(describing: convertDotsInJsonKeysToUnderscores)))"}
}

/// <p>The OpenX SerDe. Used by Kinesis Data Firehose for deserializing data, which means
///          converting it from the JSON format in preparation for serializing it to the Parquet or ORC
///          format. This is one of two deserializers you can choose, depending on which one offers the
///          functionality you need. The other option is the native Hive / HCatalog JsonSerDe.</p>
public struct OpenXJsonSerDe: Equatable {
    /// <p>When set to <code>true</code>, which is the default, Kinesis Data Firehose converts
    ///          JSON keys to lowercase before deserializing them.</p>
    public let caseInsensitive: Bool?
    /// <p>Maps column names to JSON keys that aren't identical to the column names. This is
    ///          useful when the JSON contains keys that are Hive keywords. For example,
    ///             <code>timestamp</code> is a Hive keyword. If you have a JSON key named
    ///             <code>timestamp</code>, set this parameter to <code>{"ts": "timestamp"}</code> to map
    ///          this key to a column named <code>ts</code>.</p>
    public let columnToJsonKeyMappings: [String:String]?
    /// <p>When set to <code>true</code>, specifies that the names of the keys include dots and
    ///          that you want Kinesis Data Firehose to replace them with underscores. This is useful
    ///          because Apache Hive does not allow dots in column names. For example, if the JSON contains
    ///          a key whose name is "a.b", you can define the column name to be "a_b" when using this
    ///          option.</p>
    ///          <p>The default is <code>false</code>.</p>
    public let convertDotsInJsonKeysToUnderscores: Bool?

    public init (
        caseInsensitive: Bool? = nil,
        columnToJsonKeyMappings: [String:String]? = nil,
        convertDotsInJsonKeysToUnderscores: Bool? = nil
    )
    {
        self.caseInsensitive = caseInsensitive
        self.columnToJsonKeyMappings = columnToJsonKeyMappings
        self.convertDotsInJsonKeysToUnderscores = convertDotsInJsonKeysToUnderscores
    }
}

public enum OrcCompression {
    case `none`
    case snappy
    case zlib
    case sdkUnknown(String)
}

extension OrcCompression : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [OrcCompression] {
        return [
            .none,
            .snappy,
            .zlib,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .none: return "NONE"
        case .snappy: return "SNAPPY"
        case .zlib: return "ZLIB"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = OrcCompression(rawValue: rawValue) ?? OrcCompression.sdkUnknown(rawValue)
    }
}

public enum OrcFormatVersion {
    case v011
    case v012
    case sdkUnknown(String)
}

extension OrcFormatVersion : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [OrcFormatVersion] {
        return [
            .v011,
            .v012,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .v011: return "V0_11"
        case .v012: return "V0_12"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = OrcFormatVersion(rawValue: rawValue) ?? OrcFormatVersion.sdkUnknown(rawValue)
    }
}

extension OrcSerDe: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case blockSizeBytes = "BlockSizeBytes"
        case bloomFilterColumns = "BloomFilterColumns"
        case bloomFilterFalsePositiveProbability = "BloomFilterFalsePositiveProbability"
        case compression = "Compression"
        case dictionaryKeyThreshold = "DictionaryKeyThreshold"
        case enablePadding = "EnablePadding"
        case formatVersion = "FormatVersion"
        case paddingTolerance = "PaddingTolerance"
        case rowIndexStride = "RowIndexStride"
        case stripeSizeBytes = "StripeSizeBytes"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let blockSizeBytes = blockSizeBytes {
            try encodeContainer.encode(blockSizeBytes, forKey: .blockSizeBytes)
        }
        if let bloomFilterColumns = bloomFilterColumns {
            var bloomFilterColumnsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .bloomFilterColumns)
            for listofnonemptystringswithoutwhitespace0 in bloomFilterColumns {
                try bloomFilterColumnsContainer.encode(listofnonemptystringswithoutwhitespace0)
            }
        }
        if let bloomFilterFalsePositiveProbability = bloomFilterFalsePositiveProbability {
            try encodeContainer.encode(bloomFilterFalsePositiveProbability, forKey: .bloomFilterFalsePositiveProbability)
        }
        if let compression = compression {
            try encodeContainer.encode(compression.rawValue, forKey: .compression)
        }
        if let dictionaryKeyThreshold = dictionaryKeyThreshold {
            try encodeContainer.encode(dictionaryKeyThreshold, forKey: .dictionaryKeyThreshold)
        }
        if let enablePadding = enablePadding {
            try encodeContainer.encode(enablePadding, forKey: .enablePadding)
        }
        if let formatVersion = formatVersion {
            try encodeContainer.encode(formatVersion.rawValue, forKey: .formatVersion)
        }
        if let paddingTolerance = paddingTolerance {
            try encodeContainer.encode(paddingTolerance, forKey: .paddingTolerance)
        }
        if let rowIndexStride = rowIndexStride {
            try encodeContainer.encode(rowIndexStride, forKey: .rowIndexStride)
        }
        if let stripeSizeBytes = stripeSizeBytes {
            try encodeContainer.encode(stripeSizeBytes, forKey: .stripeSizeBytes)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let stripeSizeBytesDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .stripeSizeBytes)
        stripeSizeBytes = stripeSizeBytesDecoded
        let blockSizeBytesDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .blockSizeBytes)
        blockSizeBytes = blockSizeBytesDecoded
        let rowIndexStrideDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .rowIndexStride)
        rowIndexStride = rowIndexStrideDecoded
        let enablePaddingDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .enablePadding)
        enablePadding = enablePaddingDecoded
        let paddingToleranceDecoded = try containerValues.decodeIfPresent(Double.self, forKey: .paddingTolerance)
        paddingTolerance = paddingToleranceDecoded
        let compressionDecoded = try containerValues.decodeIfPresent(OrcCompression.self, forKey: .compression)
        compression = compressionDecoded
        let bloomFilterColumnsContainer = try containerValues.decodeIfPresent([String?].self, forKey: .bloomFilterColumns)
        var bloomFilterColumnsDecoded0:[String]? = nil
        if let bloomFilterColumnsContainer = bloomFilterColumnsContainer {
            bloomFilterColumnsDecoded0 = [String]()
            for string0 in bloomFilterColumnsContainer {
                if let string0 = string0 {
                    bloomFilterColumnsDecoded0?.append(string0)
                }
            }
        }
        bloomFilterColumns = bloomFilterColumnsDecoded0
        let bloomFilterFalsePositiveProbabilityDecoded = try containerValues.decodeIfPresent(Double.self, forKey: .bloomFilterFalsePositiveProbability)
        bloomFilterFalsePositiveProbability = bloomFilterFalsePositiveProbabilityDecoded
        let dictionaryKeyThresholdDecoded = try containerValues.decodeIfPresent(Double.self, forKey: .dictionaryKeyThreshold)
        dictionaryKeyThreshold = dictionaryKeyThresholdDecoded
        let formatVersionDecoded = try containerValues.decodeIfPresent(OrcFormatVersion.self, forKey: .formatVersion)
        formatVersion = formatVersionDecoded
    }
}

extension OrcSerDe: CustomDebugStringConvertible {
    public var debugDescription: String {
        "OrcSerDe(blockSizeBytes: \(String(describing: blockSizeBytes)), bloomFilterColumns: \(String(describing: bloomFilterColumns)), bloomFilterFalsePositiveProbability: \(String(describing: bloomFilterFalsePositiveProbability)), compression: \(String(describing: compression)), dictionaryKeyThreshold: \(String(describing: dictionaryKeyThreshold)), enablePadding: \(String(describing: enablePadding)), formatVersion: \(String(describing: formatVersion)), paddingTolerance: \(String(describing: paddingTolerance)), rowIndexStride: \(String(describing: rowIndexStride)), stripeSizeBytes: \(String(describing: stripeSizeBytes)))"}
}

/// <p>A serializer to use for converting data to the ORC format before storing it in Amazon
///          S3. For more information, see <a href="https://orc.apache.org/docs/">Apache
///          ORC</a>.</p>
public struct OrcSerDe: Equatable {
    /// <p>The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to
    ///          copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the
    ///          minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.</p>
    public let blockSizeBytes: Int?
    /// <p>The column names for which you want Kinesis Data Firehose to create bloom filters. The
    ///          default is <code>null</code>.</p>
    public let bloomFilterColumns: [String]?
    /// <p>The Bloom filter false positive probability (FPP). The lower the FPP, the bigger the
    ///          Bloom filter. The default value is 0.05, the minimum is 0, and the maximum is 1.</p>
    public let bloomFilterFalsePositiveProbability: Double?
    /// <p>The compression code to use over data blocks. The default is <code>SNAPPY</code>.</p>
    public let compression: OrcCompression?
    /// <p>Represents the fraction of the total number of non-null rows. To turn off dictionary
    ///          encoding, set this fraction to a number that is less than the number of distinct keys in a
    ///          dictionary. To always use dictionary encoding, set this threshold to 1.</p>
    public let dictionaryKeyThreshold: Double?
    /// <p>Set this to <code>true</code> to indicate that you want stripes to be padded to the HDFS
    ///          block boundaries. This is useful if you intend to copy the data from Amazon S3 to HDFS
    ///          before querying. The default is <code>false</code>.</p>
    public let enablePadding: Bool?
    /// <p>The version of the file to write. The possible values are <code>V0_11</code> and
    ///             <code>V0_12</code>. The default is <code>V0_12</code>.</p>
    public let formatVersion: OrcFormatVersion?
    /// <p>A number between 0 and 1 that defines the tolerance for block padding as a decimal
    ///          fraction of stripe size. The default value is 0.05, which means 5 percent of stripe
    ///          size.</p>
    ///          <p>For the default values of 64 MiB ORC stripes and 256 MiB HDFS blocks, the default block
    ///          padding tolerance of 5 percent reserves a maximum of 3.2 MiB for padding within the 256 MiB
    ///          block. In such a case, if the available size within the block is more than 3.2 MiB, a new,
    ///          smaller stripe is inserted to fit within that space. This ensures that no stripe crosses
    ///          block boundaries and causes remote reads within a node-local task.</p>
    ///          <p>Kinesis Data Firehose ignores this parameter when <a>OrcSerDe$EnablePadding</a> is <code>false</code>.</p>
    public let paddingTolerance: Double?
    /// <p>The number of rows between index entries. The default is 10,000 and the minimum is
    ///          1,000.</p>
    public let rowIndexStride: Int?
    /// <p>The number of bytes in each stripe. The default is 64 MiB and the minimum is 8
    ///          MiB.</p>
    public let stripeSizeBytes: Int?

    public init (
        blockSizeBytes: Int? = nil,
        bloomFilterColumns: [String]? = nil,
        bloomFilterFalsePositiveProbability: Double? = nil,
        compression: OrcCompression? = nil,
        dictionaryKeyThreshold: Double? = nil,
        enablePadding: Bool? = nil,
        formatVersion: OrcFormatVersion? = nil,
        paddingTolerance: Double? = nil,
        rowIndexStride: Int? = nil,
        stripeSizeBytes: Int? = nil
    )
    {
        self.blockSizeBytes = blockSizeBytes
        self.bloomFilterColumns = bloomFilterColumns
        self.bloomFilterFalsePositiveProbability = bloomFilterFalsePositiveProbability
        self.compression = compression
        self.dictionaryKeyThreshold = dictionaryKeyThreshold
        self.enablePadding = enablePadding
        self.formatVersion = formatVersion
        self.paddingTolerance = paddingTolerance
        self.rowIndexStride = rowIndexStride
        self.stripeSizeBytes = stripeSizeBytes
    }
}

extension OutputFormatConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case serializer = "Serializer"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let serializer = serializer {
            try encodeContainer.encode(serializer, forKey: .serializer)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let serializerDecoded = try containerValues.decodeIfPresent(Serializer.self, forKey: .serializer)
        serializer = serializerDecoded
    }
}

extension OutputFormatConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "OutputFormatConfiguration(serializer: \(String(describing: serializer)))"}
}

/// <p>Specifies the serializer that you want Kinesis Data Firehose to use to convert the
///          format of your data before it writes it to Amazon S3. This parameter is required if
///             <code>Enabled</code> is set to true.</p>
public struct OutputFormatConfiguration: Equatable {
    /// <p>Specifies which serializer to use. You can choose either the ORC SerDe or the Parquet
    ///          SerDe. If both are non-null, the server rejects the request.</p>
    public let serializer: Serializer?

    public init (
        serializer: Serializer? = nil
    )
    {
        self.serializer = serializer
    }
}

public enum ParquetCompression {
    case gzip
    case snappy
    case uncompressed
    case sdkUnknown(String)
}

extension ParquetCompression : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [ParquetCompression] {
        return [
            .gzip,
            .snappy,
            .uncompressed,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .gzip: return "GZIP"
        case .snappy: return "SNAPPY"
        case .uncompressed: return "UNCOMPRESSED"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = ParquetCompression(rawValue: rawValue) ?? ParquetCompression.sdkUnknown(rawValue)
    }
}

extension ParquetSerDe: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case blockSizeBytes = "BlockSizeBytes"
        case compression = "Compression"
        case enableDictionaryCompression = "EnableDictionaryCompression"
        case maxPaddingBytes = "MaxPaddingBytes"
        case pageSizeBytes = "PageSizeBytes"
        case writerVersion = "WriterVersion"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let blockSizeBytes = blockSizeBytes {
            try encodeContainer.encode(blockSizeBytes, forKey: .blockSizeBytes)
        }
        if let compression = compression {
            try encodeContainer.encode(compression.rawValue, forKey: .compression)
        }
        if let enableDictionaryCompression = enableDictionaryCompression {
            try encodeContainer.encode(enableDictionaryCompression, forKey: .enableDictionaryCompression)
        }
        if let maxPaddingBytes = maxPaddingBytes {
            try encodeContainer.encode(maxPaddingBytes, forKey: .maxPaddingBytes)
        }
        if let pageSizeBytes = pageSizeBytes {
            try encodeContainer.encode(pageSizeBytes, forKey: .pageSizeBytes)
        }
        if let writerVersion = writerVersion {
            try encodeContainer.encode(writerVersion.rawValue, forKey: .writerVersion)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let blockSizeBytesDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .blockSizeBytes)
        blockSizeBytes = blockSizeBytesDecoded
        let pageSizeBytesDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .pageSizeBytes)
        pageSizeBytes = pageSizeBytesDecoded
        let compressionDecoded = try containerValues.decodeIfPresent(ParquetCompression.self, forKey: .compression)
        compression = compressionDecoded
        let enableDictionaryCompressionDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .enableDictionaryCompression)
        enableDictionaryCompression = enableDictionaryCompressionDecoded
        let maxPaddingBytesDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .maxPaddingBytes)
        maxPaddingBytes = maxPaddingBytesDecoded
        let writerVersionDecoded = try containerValues.decodeIfPresent(ParquetWriterVersion.self, forKey: .writerVersion)
        writerVersion = writerVersionDecoded
    }
}

extension ParquetSerDe: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ParquetSerDe(blockSizeBytes: \(String(describing: blockSizeBytes)), compression: \(String(describing: compression)), enableDictionaryCompression: \(String(describing: enableDictionaryCompression)), maxPaddingBytes: \(String(describing: maxPaddingBytes)), pageSizeBytes: \(String(describing: pageSizeBytes)), writerVersion: \(String(describing: writerVersion)))"}
}

/// <p>A serializer to use for converting data to the Parquet format before storing it in
///          Amazon S3. For more information, see <a href="https://parquet.apache.org/documentation/latest/">Apache Parquet</a>.</p>
public struct ParquetSerDe: Equatable {
    /// <p>The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to
    ///          copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the
    ///          minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.</p>
    public let blockSizeBytes: Int?
    /// <p>The compression code to use over data blocks. The possible values are
    ///             <code>UNCOMPRESSED</code>, <code>SNAPPY</code>, and <code>GZIP</code>, with the default
    ///          being <code>SNAPPY</code>. Use <code>SNAPPY</code> for higher decompression speed. Use
    ///             <code>GZIP</code> if the compression ratio is more important than speed.</p>
    public let compression: ParquetCompression?
    /// <p>Indicates whether to enable dictionary compression.</p>
    public let enableDictionaryCompression: Bool?
    /// <p>The maximum amount of padding to apply. This is useful if you intend to copy the data
    ///          from Amazon S3 to HDFS before querying. The default is 0.</p>
    public let maxPaddingBytes: Int?
    /// <p>The Parquet page size. Column chunks are divided into pages. A page is conceptually an
    ///          indivisible unit (in terms of compression and encoding). The minimum value is 64 KiB and
    ///          the default is 1 MiB.</p>
    public let pageSizeBytes: Int?
    /// <p>Indicates the version of row format to output. The possible values are <code>V1</code>
    ///          and <code>V2</code>. The default is <code>V1</code>.</p>
    public let writerVersion: ParquetWriterVersion?

    public init (
        blockSizeBytes: Int? = nil,
        compression: ParquetCompression? = nil,
        enableDictionaryCompression: Bool? = nil,
        maxPaddingBytes: Int? = nil,
        pageSizeBytes: Int? = nil,
        writerVersion: ParquetWriterVersion? = nil
    )
    {
        self.blockSizeBytes = blockSizeBytes
        self.compression = compression
        self.enableDictionaryCompression = enableDictionaryCompression
        self.maxPaddingBytes = maxPaddingBytes
        self.pageSizeBytes = pageSizeBytes
        self.writerVersion = writerVersion
    }
}

public enum ParquetWriterVersion {
    case v1
    case v2
    case sdkUnknown(String)
}

extension ParquetWriterVersion : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [ParquetWriterVersion] {
        return [
            .v1,
            .v2,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .v1: return "V1"
        case .v2: return "V2"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = ParquetWriterVersion(rawValue: rawValue) ?? ParquetWriterVersion.sdkUnknown(rawValue)
    }
}

extension ProcessingConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case enabled = "Enabled"
        case processors = "Processors"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let enabled = enabled {
            try encodeContainer.encode(enabled, forKey: .enabled)
        }
        if let processors = processors {
            var processorsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .processors)
            for processorlist0 in processors {
                try processorsContainer.encode(processorlist0)
            }
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let enabledDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .enabled)
        enabled = enabledDecoded
        let processorsContainer = try containerValues.decodeIfPresent([Processor?].self, forKey: .processors)
        var processorsDecoded0:[Processor]? = nil
        if let processorsContainer = processorsContainer {
            processorsDecoded0 = [Processor]()
            for structure0 in processorsContainer {
                if let structure0 = structure0 {
                    processorsDecoded0?.append(structure0)
                }
            }
        }
        processors = processorsDecoded0
    }
}

extension ProcessingConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ProcessingConfiguration(enabled: \(String(describing: enabled)), processors: \(String(describing: processors)))"}
}

/// <p>Describes a data processing configuration.</p>
public struct ProcessingConfiguration: Equatable {
    /// <p>Enables or disables data processing.</p>
    public let enabled: Bool?
    /// <p>The data processors.</p>
    public let processors: [Processor]?

    public init (
        enabled: Bool? = nil,
        processors: [Processor]? = nil
    )
    {
        self.enabled = enabled
        self.processors = processors
    }
}

extension Processor: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case parameters = "Parameters"
        case type = "Type"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let parameters = parameters {
            var parametersContainer = encodeContainer.nestedUnkeyedContainer(forKey: .parameters)
            for processorparameterlist0 in parameters {
                try parametersContainer.encode(processorparameterlist0)
            }
        }
        if let type = type {
            try encodeContainer.encode(type.rawValue, forKey: .type)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let typeDecoded = try containerValues.decodeIfPresent(ProcessorType.self, forKey: .type)
        type = typeDecoded
        let parametersContainer = try containerValues.decodeIfPresent([ProcessorParameter?].self, forKey: .parameters)
        var parametersDecoded0:[ProcessorParameter]? = nil
        if let parametersContainer = parametersContainer {
            parametersDecoded0 = [ProcessorParameter]()
            for structure0 in parametersContainer {
                if let structure0 = structure0 {
                    parametersDecoded0?.append(structure0)
                }
            }
        }
        parameters = parametersDecoded0
    }
}

extension Processor: CustomDebugStringConvertible {
    public var debugDescription: String {
        "Processor(parameters: \(String(describing: parameters)), type: \(String(describing: type)))"}
}

/// <p>Describes a data processor.</p>
public struct Processor: Equatable {
    /// <p>The processor parameters.</p>
    public let parameters: [ProcessorParameter]?
    /// <p>The type of processor.</p>
    public let type: ProcessorType?

    public init (
        parameters: [ProcessorParameter]? = nil,
        type: ProcessorType? = nil
    )
    {
        self.parameters = parameters
        self.type = type
    }
}

extension ProcessorParameter: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case parameterName = "ParameterName"
        case parameterValue = "ParameterValue"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let parameterName = parameterName {
            try encodeContainer.encode(parameterName.rawValue, forKey: .parameterName)
        }
        if let parameterValue = parameterValue {
            try encodeContainer.encode(parameterValue, forKey: .parameterValue)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let parameterNameDecoded = try containerValues.decodeIfPresent(ProcessorParameterName.self, forKey: .parameterName)
        parameterName = parameterNameDecoded
        let parameterValueDecoded = try containerValues.decodeIfPresent(String.self, forKey: .parameterValue)
        parameterValue = parameterValueDecoded
    }
}

extension ProcessorParameter: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ProcessorParameter(parameterName: \(String(describing: parameterName)), parameterValue: \(String(describing: parameterValue)))"}
}

/// <p>Describes the processor parameter.</p>
public struct ProcessorParameter: Equatable {
    /// <p>The name of the parameter.</p>
    public let parameterName: ProcessorParameterName?
    /// <p>The parameter value.</p>
    public let parameterValue: String?

    public init (
        parameterName: ProcessorParameterName? = nil,
        parameterValue: String? = nil
    )
    {
        self.parameterName = parameterName
        self.parameterValue = parameterValue
    }
}

public enum ProcessorParameterName {
    case bufferIntervalInSeconds
    case bufferSizeInMb
    case lambdaArn
    case lambdaNumberOfRetries
    case roleArn
    case sdkUnknown(String)
}

extension ProcessorParameterName : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [ProcessorParameterName] {
        return [
            .bufferIntervalInSeconds,
            .bufferSizeInMb,
            .lambdaArn,
            .lambdaNumberOfRetries,
            .roleArn,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .bufferIntervalInSeconds: return "BufferIntervalInSeconds"
        case .bufferSizeInMb: return "BufferSizeInMBs"
        case .lambdaArn: return "LambdaArn"
        case .lambdaNumberOfRetries: return "NumberOfRetries"
        case .roleArn: return "RoleArn"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = ProcessorParameterName(rawValue: rawValue) ?? ProcessorParameterName.sdkUnknown(rawValue)
    }
}

public enum ProcessorType {
    case lambda
    case sdkUnknown(String)
}

extension ProcessorType : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [ProcessorType] {
        return [
            .lambda,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .lambda: return "Lambda"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = ProcessorType(rawValue: rawValue) ?? ProcessorType.sdkUnknown(rawValue)
    }
}

public struct PutRecordBatchInputBodyMiddleware: Middleware {
    public let id: String = "PutRecordBatchInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<PutRecordBatchInput>,
                  next: H) -> Swift.Result<OperationOutput<PutRecordBatchOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<PutRecordBatchInput>
    public typealias MOutput = OperationOutput<PutRecordBatchOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<PutRecordBatchOutputError>
}

extension PutRecordBatchInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "PutRecordBatchInput(deliveryStreamName: \(String(describing: deliveryStreamName)), records: \(String(describing: records)))"}
}

extension PutRecordBatchInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case records = "Records"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
        if let records = records {
            var recordsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .records)
            for putrecordbatchrequestentrylist0 in records {
                try recordsContainer.encode(putrecordbatchrequestentrylist0)
            }
        }
    }
}

public struct PutRecordBatchInputHeadersMiddleware: Middleware {
    public let id: String = "PutRecordBatchInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<PutRecordBatchInput>,
                  next: H) -> Swift.Result<OperationOutput<PutRecordBatchOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<PutRecordBatchInput>
    public typealias MOutput = OperationOutput<PutRecordBatchOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<PutRecordBatchOutputError>
}

public struct PutRecordBatchInputQueryItemMiddleware: Middleware {
    public let id: String = "PutRecordBatchInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<PutRecordBatchInput>,
                  next: H) -> Swift.Result<OperationOutput<PutRecordBatchOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<PutRecordBatchInput>
    public typealias MOutput = OperationOutput<PutRecordBatchOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<PutRecordBatchOutputError>
}

public struct PutRecordBatchInput: Equatable {
    /// <p>The name of the delivery stream.</p>
    public let deliveryStreamName: String?
    /// <p>One or more records.</p>
    public let records: [Record]?

    public init (
        deliveryStreamName: String? = nil,
        records: [Record]? = nil
    )
    {
        self.deliveryStreamName = deliveryStreamName
        self.records = records
    }
}

struct PutRecordBatchInputBody: Equatable {
    public let deliveryStreamName: String?
    public let records: [Record]?
}

extension PutRecordBatchInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case records = "Records"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
        let recordsContainer = try containerValues.decodeIfPresent([Record?].self, forKey: .records)
        var recordsDecoded0:[Record]? = nil
        if let recordsContainer = recordsContainer {
            recordsDecoded0 = [Record]()
            for structure0 in recordsContainer {
                if let structure0 = structure0 {
                    recordsDecoded0?.append(structure0)
                }
            }
        }
        records = recordsDecoded0
    }
}

extension PutRecordBatchOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension PutRecordBatchOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidKMSResourceException" : self = .invalidKMSResourceException(try InvalidKMSResourceException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ServiceUnavailableException" : self = .serviceUnavailableException(try ServiceUnavailableException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum PutRecordBatchOutputError: Swift.Error, Equatable {
    case invalidArgumentException(InvalidArgumentException)
    case invalidKMSResourceException(InvalidKMSResourceException)
    case resourceNotFoundException(ResourceNotFoundException)
    case serviceUnavailableException(ServiceUnavailableException)
    case unknown(UnknownAWSHttpServiceError)
}

extension PutRecordBatchOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "PutRecordBatchOutputResponse(encrypted: \(String(describing: encrypted)), failedPutCount: \(String(describing: failedPutCount)), requestResponses: \(String(describing: requestResponses)))"}
}

extension PutRecordBatchOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: PutRecordBatchOutputResponseBody = try responseDecoder.decode(responseBody: data)
            self.encrypted = output.encrypted
            self.failedPutCount = output.failedPutCount
            self.requestResponses = output.requestResponses
        } else {
            self.encrypted = nil
            self.failedPutCount = nil
            self.requestResponses = nil
        }
    }
}

public struct PutRecordBatchOutputResponse: Equatable {
    /// <p>Indicates whether server-side encryption (SSE) was enabled during this operation.</p>
    public let encrypted: Bool?
    /// <p>The number of records that might have failed processing. This number might be greater
    ///          than 0 even if the <a>PutRecordBatch</a> call succeeds. Check
    ///             <code>FailedPutCount</code> to determine whether there are records that you need to
    ///          resend.</p>
    public let failedPutCount: Int?
    /// <p>The results array. For each record, the index of the response element is the same as
    ///          the index used in the request array.</p>
    public let requestResponses: [PutRecordBatchResponseEntry]?

    public init (
        encrypted: Bool? = nil,
        failedPutCount: Int? = nil,
        requestResponses: [PutRecordBatchResponseEntry]? = nil
    )
    {
        self.encrypted = encrypted
        self.failedPutCount = failedPutCount
        self.requestResponses = requestResponses
    }
}

struct PutRecordBatchOutputResponseBody: Equatable {
    public let failedPutCount: Int?
    public let encrypted: Bool?
    public let requestResponses: [PutRecordBatchResponseEntry]?
}

extension PutRecordBatchOutputResponseBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case encrypted = "Encrypted"
        case failedPutCount = "FailedPutCount"
        case requestResponses = "RequestResponses"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let failedPutCountDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .failedPutCount)
        failedPutCount = failedPutCountDecoded
        let encryptedDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .encrypted)
        encrypted = encryptedDecoded
        let requestResponsesContainer = try containerValues.decodeIfPresent([PutRecordBatchResponseEntry?].self, forKey: .requestResponses)
        var requestResponsesDecoded0:[PutRecordBatchResponseEntry]? = nil
        if let requestResponsesContainer = requestResponsesContainer {
            requestResponsesDecoded0 = [PutRecordBatchResponseEntry]()
            for structure0 in requestResponsesContainer {
                if let structure0 = structure0 {
                    requestResponsesDecoded0?.append(structure0)
                }
            }
        }
        requestResponses = requestResponsesDecoded0
    }
}

extension PutRecordBatchResponseEntry: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case errorCode = "ErrorCode"
        case errorMessage = "ErrorMessage"
        case recordId = "RecordId"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let errorCode = errorCode {
            try encodeContainer.encode(errorCode, forKey: .errorCode)
        }
        if let errorMessage = errorMessage {
            try encodeContainer.encode(errorMessage, forKey: .errorMessage)
        }
        if let recordId = recordId {
            try encodeContainer.encode(recordId, forKey: .recordId)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let recordIdDecoded = try containerValues.decodeIfPresent(String.self, forKey: .recordId)
        recordId = recordIdDecoded
        let errorCodeDecoded = try containerValues.decodeIfPresent(String.self, forKey: .errorCode)
        errorCode = errorCodeDecoded
        let errorMessageDecoded = try containerValues.decodeIfPresent(String.self, forKey: .errorMessage)
        errorMessage = errorMessageDecoded
    }
}

extension PutRecordBatchResponseEntry: CustomDebugStringConvertible {
    public var debugDescription: String {
        "PutRecordBatchResponseEntry(errorCode: \(String(describing: errorCode)), errorMessage: \(String(describing: errorMessage)), recordId: \(String(describing: recordId)))"}
}

/// <p>Contains the result for an individual record from a <a>PutRecordBatch</a>
///          request. If the record is successfully added to your delivery stream, it receives a record
///          ID. If the record fails to be added to your delivery stream, the result includes an error
///          code and an error message.</p>
public struct PutRecordBatchResponseEntry: Equatable {
    /// <p>The error code for an individual record result.</p>
    public let errorCode: String?
    /// <p>The error message for an individual record result.</p>
    public let errorMessage: String?
    /// <p>The ID of the record.</p>
    public let recordId: String?

    public init (
        errorCode: String? = nil,
        errorMessage: String? = nil,
        recordId: String? = nil
    )
    {
        self.errorCode = errorCode
        self.errorMessage = errorMessage
        self.recordId = recordId
    }
}

public struct PutRecordInputBodyMiddleware: Middleware {
    public let id: String = "PutRecordInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<PutRecordInput>,
                  next: H) -> Swift.Result<OperationOutput<PutRecordOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<PutRecordInput>
    public typealias MOutput = OperationOutput<PutRecordOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<PutRecordOutputError>
}

extension PutRecordInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "PutRecordInput(deliveryStreamName: \(String(describing: deliveryStreamName)), record: \(String(describing: record)))"}
}

extension PutRecordInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case record = "Record"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
        if let record = record {
            try encodeContainer.encode(record, forKey: .record)
        }
    }
}

public struct PutRecordInputHeadersMiddleware: Middleware {
    public let id: String = "PutRecordInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<PutRecordInput>,
                  next: H) -> Swift.Result<OperationOutput<PutRecordOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<PutRecordInput>
    public typealias MOutput = OperationOutput<PutRecordOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<PutRecordOutputError>
}

public struct PutRecordInputQueryItemMiddleware: Middleware {
    public let id: String = "PutRecordInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<PutRecordInput>,
                  next: H) -> Swift.Result<OperationOutput<PutRecordOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<PutRecordInput>
    public typealias MOutput = OperationOutput<PutRecordOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<PutRecordOutputError>
}

public struct PutRecordInput: Equatable {
    /// <p>The name of the delivery stream.</p>
    public let deliveryStreamName: String?
    /// <p>The record.</p>
    public let record: Record?

    public init (
        deliveryStreamName: String? = nil,
        record: Record? = nil
    )
    {
        self.deliveryStreamName = deliveryStreamName
        self.record = record
    }
}

struct PutRecordInputBody: Equatable {
    public let deliveryStreamName: String?
    public let record: Record?
}

extension PutRecordInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case record = "Record"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
        let recordDecoded = try containerValues.decodeIfPresent(Record.self, forKey: .record)
        record = recordDecoded
    }
}

extension PutRecordOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension PutRecordOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidKMSResourceException" : self = .invalidKMSResourceException(try InvalidKMSResourceException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ServiceUnavailableException" : self = .serviceUnavailableException(try ServiceUnavailableException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum PutRecordOutputError: Swift.Error, Equatable {
    case invalidArgumentException(InvalidArgumentException)
    case invalidKMSResourceException(InvalidKMSResourceException)
    case resourceNotFoundException(ResourceNotFoundException)
    case serviceUnavailableException(ServiceUnavailableException)
    case unknown(UnknownAWSHttpServiceError)
}

extension PutRecordOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "PutRecordOutputResponse(encrypted: \(String(describing: encrypted)), recordId: \(String(describing: recordId)))"}
}

extension PutRecordOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: PutRecordOutputResponseBody = try responseDecoder.decode(responseBody: data)
            self.encrypted = output.encrypted
            self.recordId = output.recordId
        } else {
            self.encrypted = nil
            self.recordId = nil
        }
    }
}

public struct PutRecordOutputResponse: Equatable {
    /// <p>Indicates whether server-side encryption (SSE) was enabled during this operation.</p>
    public let encrypted: Bool?
    /// <p>The ID of the record.</p>
    public let recordId: String?

    public init (
        encrypted: Bool? = nil,
        recordId: String? = nil
    )
    {
        self.encrypted = encrypted
        self.recordId = recordId
    }
}

struct PutRecordOutputResponseBody: Equatable {
    public let recordId: String?
    public let encrypted: Bool?
}

extension PutRecordOutputResponseBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case encrypted = "Encrypted"
        case recordId = "RecordId"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let recordIdDecoded = try containerValues.decodeIfPresent(String.self, forKey: .recordId)
        recordId = recordIdDecoded
        let encryptedDecoded = try containerValues.decodeIfPresent(Bool.self, forKey: .encrypted)
        encrypted = encryptedDecoded
    }
}

extension Record: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case data = "Data"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let data = data {
            try encodeContainer.encode(data.base64EncodedString(), forKey: .data)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let dataDecoded = try containerValues.decodeIfPresent(Data.self, forKey: .data)
        data = dataDecoded
    }
}

extension Record: CustomDebugStringConvertible {
    public var debugDescription: String {
        "Record(data: \(String(describing: data)))"}
}

/// <p>The unit of data in a delivery stream.</p>
public struct Record: Equatable {
    /// <p>The data blob, which is base64-encoded when the blob is serialized. The maximum size
    ///          of the data blob, before base64-encoding, is 1,000 KiB.</p>
    public let data: Data?

    public init (
        data: Data? = nil
    )
    {
        self.data = data
    }
}

extension RedshiftDestinationConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case clusterJDBCURL = "ClusterJDBCURL"
        case copyCommand = "CopyCommand"
        case password = "Password"
        case processingConfiguration = "ProcessingConfiguration"
        case retryOptions = "RetryOptions"
        case roleARN = "RoleARN"
        case s3BackupConfiguration = "S3BackupConfiguration"
        case s3BackupMode = "S3BackupMode"
        case s3Configuration = "S3Configuration"
        case username = "Username"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let clusterJDBCURL = clusterJDBCURL {
            try encodeContainer.encode(clusterJDBCURL, forKey: .clusterJDBCURL)
        }
        if let copyCommand = copyCommand {
            try encodeContainer.encode(copyCommand, forKey: .copyCommand)
        }
        if let password = password {
            try encodeContainer.encode(password, forKey: .password)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3BackupConfiguration = s3BackupConfiguration {
            try encodeContainer.encode(s3BackupConfiguration, forKey: .s3BackupConfiguration)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3Configuration = s3Configuration {
            try encodeContainer.encode(s3Configuration, forKey: .s3Configuration)
        }
        if let username = username {
            try encodeContainer.encode(username, forKey: .username)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let clusterJDBCURLDecoded = try containerValues.decodeIfPresent(String.self, forKey: .clusterJDBCURL)
        clusterJDBCURL = clusterJDBCURLDecoded
        let copyCommandDecoded = try containerValues.decodeIfPresent(CopyCommand.self, forKey: .copyCommand)
        copyCommand = copyCommandDecoded
        let usernameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .username)
        username = usernameDecoded
        let passwordDecoded = try containerValues.decodeIfPresent(String.self, forKey: .password)
        password = passwordDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(RedshiftRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3ConfigurationDecoded = try containerValues.decodeIfPresent(S3DestinationConfiguration.self, forKey: .s3Configuration)
        s3Configuration = s3ConfigurationDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(RedshiftS3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3BackupConfigurationDecoded = try containerValues.decodeIfPresent(S3DestinationConfiguration.self, forKey: .s3BackupConfiguration)
        s3BackupConfiguration = s3BackupConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
    }
}

extension RedshiftDestinationConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "RedshiftDestinationConfiguration(cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), clusterJDBCURL: \(String(describing: clusterJDBCURL)), copyCommand: \(String(describing: copyCommand)), password: \(String(describing: password)), processingConfiguration: \(String(describing: processingConfiguration)), retryOptions: \(String(describing: retryOptions)), roleARN: \(String(describing: roleARN)), s3BackupConfiguration: \(String(describing: s3BackupConfiguration)), s3BackupMode: \(String(describing: s3BackupMode)), s3Configuration: \(String(describing: s3Configuration)), username: \(String(describing: username)))"}
}

/// <p>Describes the configuration of a destination in Amazon Redshift.</p>
public struct RedshiftDestinationConfiguration: Equatable {
    /// <p>The CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The database connection string.</p>
    public let clusterJDBCURL: String?
    /// <p>The <code>COPY</code> command.</p>
    public let copyCommand: CopyCommand?
    /// <p>The user password.</p>
    public let password: String?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to
    ///          Amazon Redshift. Default value is 3600 (60 minutes).</p>
    public let retryOptions: RedshiftRetryOptions?
    /// <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?
    /// <p>The configuration for backup in Amazon S3.</p>
    public let s3BackupConfiguration: S3DestinationConfiguration?
    /// <p>The Amazon S3 backup mode. After you create a delivery stream, you can update it to
    ///          enable Amazon S3 backup if it is disabled. If backup is enabled, you can't update the
    ///          delivery stream to disable it. </p>
    public let s3BackupMode: RedshiftS3BackupMode?
    /// <p>The configuration for the intermediate Amazon S3 location from which Amazon Redshift
    ///          obtains data. Restrictions are described in the topic for <a>CreateDeliveryStream</a>.</p>
    ///          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified
    ///          in <code>RedshiftDestinationConfiguration.S3Configuration</code> because the Amazon
    ///          Redshift <code>COPY</code> operation that reads from the S3 bucket doesn't support these
    ///          compression formats.</p>
    public let s3Configuration: S3DestinationConfiguration?
    /// <p>The name of the user.</p>
    public let username: String?

    public init (
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        clusterJDBCURL: String? = nil,
        copyCommand: CopyCommand? = nil,
        password: String? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        retryOptions: RedshiftRetryOptions? = nil,
        roleARN: String? = nil,
        s3BackupConfiguration: S3DestinationConfiguration? = nil,
        s3BackupMode: RedshiftS3BackupMode? = nil,
        s3Configuration: S3DestinationConfiguration? = nil,
        username: String? = nil
    )
    {
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.clusterJDBCURL = clusterJDBCURL
        self.copyCommand = copyCommand
        self.password = password
        self.processingConfiguration = processingConfiguration
        self.retryOptions = retryOptions
        self.roleARN = roleARN
        self.s3BackupConfiguration = s3BackupConfiguration
        self.s3BackupMode = s3BackupMode
        self.s3Configuration = s3Configuration
        self.username = username
    }
}

extension RedshiftDestinationDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case clusterJDBCURL = "ClusterJDBCURL"
        case copyCommand = "CopyCommand"
        case processingConfiguration = "ProcessingConfiguration"
        case retryOptions = "RetryOptions"
        case roleARN = "RoleARN"
        case s3BackupDescription = "S3BackupDescription"
        case s3BackupMode = "S3BackupMode"
        case s3DestinationDescription = "S3DestinationDescription"
        case username = "Username"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let clusterJDBCURL = clusterJDBCURL {
            try encodeContainer.encode(clusterJDBCURL, forKey: .clusterJDBCURL)
        }
        if let copyCommand = copyCommand {
            try encodeContainer.encode(copyCommand, forKey: .copyCommand)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3BackupDescription = s3BackupDescription {
            try encodeContainer.encode(s3BackupDescription, forKey: .s3BackupDescription)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3DestinationDescription = s3DestinationDescription {
            try encodeContainer.encode(s3DestinationDescription, forKey: .s3DestinationDescription)
        }
        if let username = username {
            try encodeContainer.encode(username, forKey: .username)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let clusterJDBCURLDecoded = try containerValues.decodeIfPresent(String.self, forKey: .clusterJDBCURL)
        clusterJDBCURL = clusterJDBCURLDecoded
        let copyCommandDecoded = try containerValues.decodeIfPresent(CopyCommand.self, forKey: .copyCommand)
        copyCommand = copyCommandDecoded
        let usernameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .username)
        username = usernameDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(RedshiftRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3DestinationDescriptionDecoded = try containerValues.decodeIfPresent(S3DestinationDescription.self, forKey: .s3DestinationDescription)
        s3DestinationDescription = s3DestinationDescriptionDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(RedshiftS3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3BackupDescriptionDecoded = try containerValues.decodeIfPresent(S3DestinationDescription.self, forKey: .s3BackupDescription)
        s3BackupDescription = s3BackupDescriptionDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
    }
}

extension RedshiftDestinationDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "RedshiftDestinationDescription(cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), clusterJDBCURL: \(String(describing: clusterJDBCURL)), copyCommand: \(String(describing: copyCommand)), processingConfiguration: \(String(describing: processingConfiguration)), retryOptions: \(String(describing: retryOptions)), roleARN: \(String(describing: roleARN)), s3BackupDescription: \(String(describing: s3BackupDescription)), s3BackupMode: \(String(describing: s3BackupMode)), s3DestinationDescription: \(String(describing: s3DestinationDescription)), username: \(String(describing: username)))"}
}

/// <p>Describes a destination in Amazon Redshift.</p>
public struct RedshiftDestinationDescription: Equatable {
    /// <p>The Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The database connection string.</p>
    public let clusterJDBCURL: String?
    /// <p>The <code>COPY</code> command.</p>
    public let copyCommand: CopyCommand?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to
    ///          Amazon Redshift. Default value is 3600 (60 minutes).</p>
    public let retryOptions: RedshiftRetryOptions?
    /// <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?
    /// <p>The configuration for backup in Amazon S3.</p>
    public let s3BackupDescription: S3DestinationDescription?
    /// <p>The Amazon S3 backup mode.</p>
    public let s3BackupMode: RedshiftS3BackupMode?
    /// <p>The Amazon S3 destination.</p>
    public let s3DestinationDescription: S3DestinationDescription?
    /// <p>The name of the user.</p>
    public let username: String?

    public init (
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        clusterJDBCURL: String? = nil,
        copyCommand: CopyCommand? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        retryOptions: RedshiftRetryOptions? = nil,
        roleARN: String? = nil,
        s3BackupDescription: S3DestinationDescription? = nil,
        s3BackupMode: RedshiftS3BackupMode? = nil,
        s3DestinationDescription: S3DestinationDescription? = nil,
        username: String? = nil
    )
    {
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.clusterJDBCURL = clusterJDBCURL
        self.copyCommand = copyCommand
        self.processingConfiguration = processingConfiguration
        self.retryOptions = retryOptions
        self.roleARN = roleARN
        self.s3BackupDescription = s3BackupDescription
        self.s3BackupMode = s3BackupMode
        self.s3DestinationDescription = s3DestinationDescription
        self.username = username
    }
}

extension RedshiftDestinationUpdate: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case clusterJDBCURL = "ClusterJDBCURL"
        case copyCommand = "CopyCommand"
        case password = "Password"
        case processingConfiguration = "ProcessingConfiguration"
        case retryOptions = "RetryOptions"
        case roleARN = "RoleARN"
        case s3BackupMode = "S3BackupMode"
        case s3BackupUpdate = "S3BackupUpdate"
        case s3Update = "S3Update"
        case username = "Username"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let clusterJDBCURL = clusterJDBCURL {
            try encodeContainer.encode(clusterJDBCURL, forKey: .clusterJDBCURL)
        }
        if let copyCommand = copyCommand {
            try encodeContainer.encode(copyCommand, forKey: .copyCommand)
        }
        if let password = password {
            try encodeContainer.encode(password, forKey: .password)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3BackupUpdate = s3BackupUpdate {
            try encodeContainer.encode(s3BackupUpdate, forKey: .s3BackupUpdate)
        }
        if let s3Update = s3Update {
            try encodeContainer.encode(s3Update, forKey: .s3Update)
        }
        if let username = username {
            try encodeContainer.encode(username, forKey: .username)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let clusterJDBCURLDecoded = try containerValues.decodeIfPresent(String.self, forKey: .clusterJDBCURL)
        clusterJDBCURL = clusterJDBCURLDecoded
        let copyCommandDecoded = try containerValues.decodeIfPresent(CopyCommand.self, forKey: .copyCommand)
        copyCommand = copyCommandDecoded
        let usernameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .username)
        username = usernameDecoded
        let passwordDecoded = try containerValues.decodeIfPresent(String.self, forKey: .password)
        password = passwordDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(RedshiftRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3UpdateDecoded = try containerValues.decodeIfPresent(S3DestinationUpdate.self, forKey: .s3Update)
        s3Update = s3UpdateDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(RedshiftS3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3BackupUpdateDecoded = try containerValues.decodeIfPresent(S3DestinationUpdate.self, forKey: .s3BackupUpdate)
        s3BackupUpdate = s3BackupUpdateDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
    }
}

extension RedshiftDestinationUpdate: CustomDebugStringConvertible {
    public var debugDescription: String {
        "RedshiftDestinationUpdate(cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), clusterJDBCURL: \(String(describing: clusterJDBCURL)), copyCommand: \(String(describing: copyCommand)), password: \(String(describing: password)), processingConfiguration: \(String(describing: processingConfiguration)), retryOptions: \(String(describing: retryOptions)), roleARN: \(String(describing: roleARN)), s3BackupMode: \(String(describing: s3BackupMode)), s3BackupUpdate: \(String(describing: s3BackupUpdate)), s3Update: \(String(describing: s3Update)), username: \(String(describing: username)))"}
}

/// <p>Describes an update for a destination in Amazon Redshift.</p>
public struct RedshiftDestinationUpdate: Equatable {
    /// <p>The Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The database connection string.</p>
    public let clusterJDBCURL: String?
    /// <p>The <code>COPY</code> command.</p>
    public let copyCommand: CopyCommand?
    /// <p>The user password.</p>
    public let password: String?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to
    ///          Amazon Redshift. Default value is 3600 (60 minutes).</p>
    public let retryOptions: RedshiftRetryOptions?
    /// <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?
    /// <p>You can update a delivery stream to enable Amazon S3 backup if it is disabled. If
    ///          backup is enabled, you can't update the delivery stream to disable it. </p>
    public let s3BackupMode: RedshiftS3BackupMode?
    /// <p>The Amazon S3 destination for backup.</p>
    public let s3BackupUpdate: S3DestinationUpdate?
    /// <p>The Amazon S3 destination.</p>
    ///          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified
    ///          in <code>RedshiftDestinationUpdate.S3Update</code> because the Amazon Redshift
    ///             <code>COPY</code> operation that reads from the S3 bucket doesn't support these
    ///          compression formats.</p>
    public let s3Update: S3DestinationUpdate?
    /// <p>The name of the user.</p>
    public let username: String?

    public init (
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        clusterJDBCURL: String? = nil,
        copyCommand: CopyCommand? = nil,
        password: String? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        retryOptions: RedshiftRetryOptions? = nil,
        roleARN: String? = nil,
        s3BackupMode: RedshiftS3BackupMode? = nil,
        s3BackupUpdate: S3DestinationUpdate? = nil,
        s3Update: S3DestinationUpdate? = nil,
        username: String? = nil
    )
    {
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.clusterJDBCURL = clusterJDBCURL
        self.copyCommand = copyCommand
        self.password = password
        self.processingConfiguration = processingConfiguration
        self.retryOptions = retryOptions
        self.roleARN = roleARN
        self.s3BackupMode = s3BackupMode
        self.s3BackupUpdate = s3BackupUpdate
        self.s3Update = s3Update
        self.username = username
    }
}

extension RedshiftRetryOptions: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case durationInSeconds = "DurationInSeconds"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let durationInSeconds = durationInSeconds {
            try encodeContainer.encode(durationInSeconds, forKey: .durationInSeconds)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let durationInSecondsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .durationInSeconds)
        durationInSeconds = durationInSecondsDecoded
    }
}

extension RedshiftRetryOptions: CustomDebugStringConvertible {
    public var debugDescription: String {
        "RedshiftRetryOptions(durationInSeconds: \(String(describing: durationInSeconds)))"}
}

/// <p>Configures retry behavior in case Kinesis Data Firehose is unable to deliver
///          documents to Amazon Redshift.</p>
public struct RedshiftRetryOptions: Equatable {
    /// <p>The length of time during which Kinesis Data Firehose retries delivery after a
    ///          failure, starting from the initial request and including the first attempt. The default
    ///          value is 3600 seconds (60 minutes). Kinesis Data Firehose does not retry if the value of
    ///             <code>DurationInSeconds</code> is 0 (zero) or if the first delivery attempt takes longer
    ///          than the current value.</p>
    public let durationInSeconds: Int?

    public init (
        durationInSeconds: Int? = nil
    )
    {
        self.durationInSeconds = durationInSeconds
    }
}

public enum RedshiftS3BackupMode {
    case disabled
    case enabled
    case sdkUnknown(String)
}

extension RedshiftS3BackupMode : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [RedshiftS3BackupMode] {
        return [
            .disabled,
            .enabled,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .disabled: return "Disabled"
        case .enabled: return "Enabled"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = RedshiftS3BackupMode(rawValue: rawValue) ?? RedshiftS3BackupMode.sdkUnknown(rawValue)
    }
}

extension ResourceInUseException: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ResourceInUseException(message: \(String(describing: message)))"}
}

extension ResourceInUseException: AWSHttpServiceError {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: ResourceInUseExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>The resource is already in use and not available for this operation.</p>
public struct ResourceInUseException: ClientRuntime.ServiceError, Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: HttpStatusCode?
    public var _message: String?
    public var _requestID: String?
    public var _retryable: Bool = false
    public var _isThrottling: Bool = false
    public var _type: ErrorType = .client
    /// <p>A message that provides information about the error.</p>
    public var message: String?

    public init (
        message: String? = nil
    )
    {
        self.message = message
    }
}

struct ResourceInUseExceptionBody: Equatable {
    public let message: String?
}

extension ResourceInUseExceptionBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case message
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(String.self, forKey: .message)
        message = messageDecoded
    }
}

extension ResourceNotFoundException: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ResourceNotFoundException(message: \(String(describing: message)))"}
}

extension ResourceNotFoundException: AWSHttpServiceError {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: ResourceNotFoundExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>The specified resource could not be found.</p>
public struct ResourceNotFoundException: ClientRuntime.ServiceError, Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: HttpStatusCode?
    public var _message: String?
    public var _requestID: String?
    public var _retryable: Bool = false
    public var _isThrottling: Bool = false
    public var _type: ErrorType = .client
    /// <p>A message that provides information about the error.</p>
    public var message: String?

    public init (
        message: String? = nil
    )
    {
        self.message = message
    }
}

struct ResourceNotFoundExceptionBody: Equatable {
    public let message: String?
}

extension ResourceNotFoundExceptionBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case message
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(String.self, forKey: .message)
        message = messageDecoded
    }
}

public enum S3BackupMode {
    case disabled
    case enabled
    case sdkUnknown(String)
}

extension S3BackupMode : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [S3BackupMode] {
        return [
            .disabled,
            .enabled,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .disabled: return "Disabled"
        case .enabled: return "Enabled"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = S3BackupMode(rawValue: rawValue) ?? S3BackupMode.sdkUnknown(rawValue)
    }
}

extension S3DestinationConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bucketARN = "BucketARN"
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case compressionFormat = "CompressionFormat"
        case encryptionConfiguration = "EncryptionConfiguration"
        case errorOutputPrefix = "ErrorOutputPrefix"
        case prefix = "Prefix"
        case roleARN = "RoleARN"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bucketARN = bucketARN {
            try encodeContainer.encode(bucketARN, forKey: .bucketARN)
        }
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let compressionFormat = compressionFormat {
            try encodeContainer.encode(compressionFormat.rawValue, forKey: .compressionFormat)
        }
        if let encryptionConfiguration = encryptionConfiguration {
            try encodeContainer.encode(encryptionConfiguration, forKey: .encryptionConfiguration)
        }
        if let errorOutputPrefix = errorOutputPrefix {
            try encodeContainer.encode(errorOutputPrefix, forKey: .errorOutputPrefix)
        }
        if let prefix = prefix {
            try encodeContainer.encode(prefix, forKey: .prefix)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let bucketARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .bucketARN)
        bucketARN = bucketARNDecoded
        let prefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .prefix)
        prefix = prefixDecoded
        let errorOutputPrefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .errorOutputPrefix)
        errorOutputPrefix = errorOutputPrefixDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(BufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let compressionFormatDecoded = try containerValues.decodeIfPresent(CompressionFormat.self, forKey: .compressionFormat)
        compressionFormat = compressionFormatDecoded
        let encryptionConfigurationDecoded = try containerValues.decodeIfPresent(EncryptionConfiguration.self, forKey: .encryptionConfiguration)
        encryptionConfiguration = encryptionConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
    }
}

extension S3DestinationConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "S3DestinationConfiguration(bucketARN: \(String(describing: bucketARN)), bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), compressionFormat: \(String(describing: compressionFormat)), encryptionConfiguration: \(String(describing: encryptionConfiguration)), errorOutputPrefix: \(String(describing: errorOutputPrefix)), prefix: \(String(describing: prefix)), roleARN: \(String(describing: roleARN)))"}
}

/// <p>Describes the configuration of a destination in Amazon S3.</p>
public struct S3DestinationConfiguration: Equatable {
    /// <p>The ARN of the S3 bucket. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let bucketARN: String?
    /// <p>The buffering option. If no value is specified, <code>BufferingHints</code> object
    ///          default values are used.</p>
    public let bufferingHints: BufferingHints?
    /// <p>The CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The compression format. If no value is specified, the default is
    ///             <code>UNCOMPRESSED</code>.</p>
    ///          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified
    ///          for Amazon Redshift destinations because they are not supported by the Amazon Redshift
    ///             <code>COPY</code> operation that reads from the S3 bucket.</p>
    public let compressionFormat: CompressionFormat?
    /// <p>The encryption configuration. If no value is specified, the default is no
    ///          encryption.</p>
    public let encryptionConfiguration: EncryptionConfiguration?
    /// <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
    ///          them to S3. This prefix appears immediately following the bucket name. For information
    ///          about how to specify this prefix, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let errorOutputPrefix: String?
    /// <p>The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered Amazon S3
    ///          files. You can also specify a custom prefix, as described in <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let prefix: String?
    /// <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?

    public init (
        bucketARN: String? = nil,
        bufferingHints: BufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        compressionFormat: CompressionFormat? = nil,
        encryptionConfiguration: EncryptionConfiguration? = nil,
        errorOutputPrefix: String? = nil,
        prefix: String? = nil,
        roleARN: String? = nil
    )
    {
        self.bucketARN = bucketARN
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.compressionFormat = compressionFormat
        self.encryptionConfiguration = encryptionConfiguration
        self.errorOutputPrefix = errorOutputPrefix
        self.prefix = prefix
        self.roleARN = roleARN
    }
}

extension S3DestinationDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bucketARN = "BucketARN"
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case compressionFormat = "CompressionFormat"
        case encryptionConfiguration = "EncryptionConfiguration"
        case errorOutputPrefix = "ErrorOutputPrefix"
        case prefix = "Prefix"
        case roleARN = "RoleARN"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bucketARN = bucketARN {
            try encodeContainer.encode(bucketARN, forKey: .bucketARN)
        }
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let compressionFormat = compressionFormat {
            try encodeContainer.encode(compressionFormat.rawValue, forKey: .compressionFormat)
        }
        if let encryptionConfiguration = encryptionConfiguration {
            try encodeContainer.encode(encryptionConfiguration, forKey: .encryptionConfiguration)
        }
        if let errorOutputPrefix = errorOutputPrefix {
            try encodeContainer.encode(errorOutputPrefix, forKey: .errorOutputPrefix)
        }
        if let prefix = prefix {
            try encodeContainer.encode(prefix, forKey: .prefix)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let bucketARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .bucketARN)
        bucketARN = bucketARNDecoded
        let prefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .prefix)
        prefix = prefixDecoded
        let errorOutputPrefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .errorOutputPrefix)
        errorOutputPrefix = errorOutputPrefixDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(BufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let compressionFormatDecoded = try containerValues.decodeIfPresent(CompressionFormat.self, forKey: .compressionFormat)
        compressionFormat = compressionFormatDecoded
        let encryptionConfigurationDecoded = try containerValues.decodeIfPresent(EncryptionConfiguration.self, forKey: .encryptionConfiguration)
        encryptionConfiguration = encryptionConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
    }
}

extension S3DestinationDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "S3DestinationDescription(bucketARN: \(String(describing: bucketARN)), bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), compressionFormat: \(String(describing: compressionFormat)), encryptionConfiguration: \(String(describing: encryptionConfiguration)), errorOutputPrefix: \(String(describing: errorOutputPrefix)), prefix: \(String(describing: prefix)), roleARN: \(String(describing: roleARN)))"}
}

/// <p>Describes a destination in Amazon S3.</p>
public struct S3DestinationDescription: Equatable {
    /// <p>The ARN of the S3 bucket. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let bucketARN: String?
    /// <p>The buffering option. If no value is specified, <code>BufferingHints</code> object
    ///          default values are used.</p>
    public let bufferingHints: BufferingHints?
    /// <p>The Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The compression format. If no value is specified, the default is
    ///             <code>UNCOMPRESSED</code>.</p>
    public let compressionFormat: CompressionFormat?
    /// <p>The encryption configuration. If no value is specified, the default is no
    ///          encryption.</p>
    public let encryptionConfiguration: EncryptionConfiguration?
    /// <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
    ///          them to S3. This prefix appears immediately following the bucket name. For information
    ///          about how to specify this prefix, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let errorOutputPrefix: String?
    /// <p>The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered Amazon S3
    ///          files. You can also specify a custom prefix, as described in <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let prefix: String?
    /// <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?

    public init (
        bucketARN: String? = nil,
        bufferingHints: BufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        compressionFormat: CompressionFormat? = nil,
        encryptionConfiguration: EncryptionConfiguration? = nil,
        errorOutputPrefix: String? = nil,
        prefix: String? = nil,
        roleARN: String? = nil
    )
    {
        self.bucketARN = bucketARN
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.compressionFormat = compressionFormat
        self.encryptionConfiguration = encryptionConfiguration
        self.errorOutputPrefix = errorOutputPrefix
        self.prefix = prefix
        self.roleARN = roleARN
    }
}

extension S3DestinationUpdate: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case bucketARN = "BucketARN"
        case bufferingHints = "BufferingHints"
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case compressionFormat = "CompressionFormat"
        case encryptionConfiguration = "EncryptionConfiguration"
        case errorOutputPrefix = "ErrorOutputPrefix"
        case prefix = "Prefix"
        case roleARN = "RoleARN"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let bucketARN = bucketARN {
            try encodeContainer.encode(bucketARN, forKey: .bucketARN)
        }
        if let bufferingHints = bufferingHints {
            try encodeContainer.encode(bufferingHints, forKey: .bufferingHints)
        }
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let compressionFormat = compressionFormat {
            try encodeContainer.encode(compressionFormat.rawValue, forKey: .compressionFormat)
        }
        if let encryptionConfiguration = encryptionConfiguration {
            try encodeContainer.encode(encryptionConfiguration, forKey: .encryptionConfiguration)
        }
        if let errorOutputPrefix = errorOutputPrefix {
            try encodeContainer.encode(errorOutputPrefix, forKey: .errorOutputPrefix)
        }
        if let prefix = prefix {
            try encodeContainer.encode(prefix, forKey: .prefix)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let bucketARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .bucketARN)
        bucketARN = bucketARNDecoded
        let prefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .prefix)
        prefix = prefixDecoded
        let errorOutputPrefixDecoded = try containerValues.decodeIfPresent(String.self, forKey: .errorOutputPrefix)
        errorOutputPrefix = errorOutputPrefixDecoded
        let bufferingHintsDecoded = try containerValues.decodeIfPresent(BufferingHints.self, forKey: .bufferingHints)
        bufferingHints = bufferingHintsDecoded
        let compressionFormatDecoded = try containerValues.decodeIfPresent(CompressionFormat.self, forKey: .compressionFormat)
        compressionFormat = compressionFormatDecoded
        let encryptionConfigurationDecoded = try containerValues.decodeIfPresent(EncryptionConfiguration.self, forKey: .encryptionConfiguration)
        encryptionConfiguration = encryptionConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
    }
}

extension S3DestinationUpdate: CustomDebugStringConvertible {
    public var debugDescription: String {
        "S3DestinationUpdate(bucketARN: \(String(describing: bucketARN)), bufferingHints: \(String(describing: bufferingHints)), cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), compressionFormat: \(String(describing: compressionFormat)), encryptionConfiguration: \(String(describing: encryptionConfiguration)), errorOutputPrefix: \(String(describing: errorOutputPrefix)), prefix: \(String(describing: prefix)), roleARN: \(String(describing: roleARN)))"}
}

/// <p>Describes an update for a destination in Amazon S3.</p>
public struct S3DestinationUpdate: Equatable {
    /// <p>The ARN of the S3 bucket. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon
    ///             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let bucketARN: String?
    /// <p>The buffering option. If no value is specified, <code>BufferingHints</code> object
    ///          default values are used.</p>
    public let bufferingHints: BufferingHints?
    /// <p>The CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The compression format. If no value is specified, the default is
    ///             <code>UNCOMPRESSED</code>.</p>
    ///          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified
    ///          for Amazon Redshift destinations because they are not supported by the Amazon Redshift
    ///             <code>COPY</code> operation that reads from the S3 bucket.</p>
    public let compressionFormat: CompressionFormat?
    /// <p>The encryption configuration. If no value is specified, the default is no
    ///          encryption.</p>
    public let encryptionConfiguration: EncryptionConfiguration?
    /// <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing
    ///          them to S3. This prefix appears immediately following the bucket name. For information
    ///          about how to specify this prefix, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let errorOutputPrefix: String?
    /// <p>The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered Amazon S3
    ///          files. You can also specify a custom prefix, as described in <a href="https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html">Custom Prefixes
    ///             for Amazon S3 Objects</a>.</p>
    public let prefix: String?
    /// <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
    ///             <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>
    public let roleARN: String?

    public init (
        bucketARN: String? = nil,
        bufferingHints: BufferingHints? = nil,
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        compressionFormat: CompressionFormat? = nil,
        encryptionConfiguration: EncryptionConfiguration? = nil,
        errorOutputPrefix: String? = nil,
        prefix: String? = nil,
        roleARN: String? = nil
    )
    {
        self.bucketARN = bucketARN
        self.bufferingHints = bufferingHints
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.compressionFormat = compressionFormat
        self.encryptionConfiguration = encryptionConfiguration
        self.errorOutputPrefix = errorOutputPrefix
        self.prefix = prefix
        self.roleARN = roleARN
    }
}

extension SchemaConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case catalogId = "CatalogId"
        case databaseName = "DatabaseName"
        case region = "Region"
        case roleARN = "RoleARN"
        case tableName = "TableName"
        case versionId = "VersionId"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let catalogId = catalogId {
            try encodeContainer.encode(catalogId, forKey: .catalogId)
        }
        if let databaseName = databaseName {
            try encodeContainer.encode(databaseName, forKey: .databaseName)
        }
        if let region = region {
            try encodeContainer.encode(region, forKey: .region)
        }
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let tableName = tableName {
            try encodeContainer.encode(tableName, forKey: .tableName)
        }
        if let versionId = versionId {
            try encodeContainer.encode(versionId, forKey: .versionId)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let catalogIdDecoded = try containerValues.decodeIfPresent(String.self, forKey: .catalogId)
        catalogId = catalogIdDecoded
        let databaseNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .databaseName)
        databaseName = databaseNameDecoded
        let tableNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .tableName)
        tableName = tableNameDecoded
        let regionDecoded = try containerValues.decodeIfPresent(String.self, forKey: .region)
        region = regionDecoded
        let versionIdDecoded = try containerValues.decodeIfPresent(String.self, forKey: .versionId)
        versionId = versionIdDecoded
    }
}

extension SchemaConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "SchemaConfiguration(catalogId: \(String(describing: catalogId)), databaseName: \(String(describing: databaseName)), region: \(String(describing: region)), roleARN: \(String(describing: roleARN)), tableName: \(String(describing: tableName)), versionId: \(String(describing: versionId)))"}
}

/// <p>Specifies the schema to which you want Kinesis Data Firehose to configure your data
///          before it writes it to Amazon S3. This parameter is required if <code>Enabled</code> is set
///          to true.</p>
public struct SchemaConfiguration: Equatable {
    /// <p>The ID of the AWS Glue Data Catalog. If you don't supply this, the AWS account ID is
    ///          used by default.</p>
    public let catalogId: String?
    /// <p>Specifies the name of the AWS Glue database that contains the schema for the output
    ///          data.</p>
    public let databaseName: String?
    /// <p>If you don't specify an AWS Region, the default is the current Region.</p>
    public let region: String?
    /// <p>The role that Kinesis Data Firehose can use to access AWS Glue. This role must be in
    ///          the same account you use for Kinesis Data Firehose. Cross-account roles aren't
    ///          allowed.</p>
    public let roleARN: String?
    /// <p>Specifies the AWS Glue table that contains the column information that constitutes your
    ///          data schema.</p>
    public let tableName: String?
    /// <p>Specifies the table version for the output data schema. If you don't specify this
    ///          version ID, or if you set it to <code>LATEST</code>, Kinesis Data Firehose uses the most
    ///          recent version. This means that any updates to the table are automatically picked
    ///          up.</p>
    public let versionId: String?

    public init (
        catalogId: String? = nil,
        databaseName: String? = nil,
        region: String? = nil,
        roleARN: String? = nil,
        tableName: String? = nil,
        versionId: String? = nil
    )
    {
        self.catalogId = catalogId
        self.databaseName = databaseName
        self.region = region
        self.roleARN = roleARN
        self.tableName = tableName
        self.versionId = versionId
    }
}

extension Serializer: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case orcSerDe = "OrcSerDe"
        case parquetSerDe = "ParquetSerDe"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let orcSerDe = orcSerDe {
            try encodeContainer.encode(orcSerDe, forKey: .orcSerDe)
        }
        if let parquetSerDe = parquetSerDe {
            try encodeContainer.encode(parquetSerDe, forKey: .parquetSerDe)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let parquetSerDeDecoded = try containerValues.decodeIfPresent(ParquetSerDe.self, forKey: .parquetSerDe)
        parquetSerDe = parquetSerDeDecoded
        let orcSerDeDecoded = try containerValues.decodeIfPresent(OrcSerDe.self, forKey: .orcSerDe)
        orcSerDe = orcSerDeDecoded
    }
}

extension Serializer: CustomDebugStringConvertible {
    public var debugDescription: String {
        "Serializer(orcSerDe: \(String(describing: orcSerDe)), parquetSerDe: \(String(describing: parquetSerDe)))"}
}

/// <p>The serializer that you want Kinesis Data Firehose to use to convert data to the target
///          format before writing it to Amazon S3. Kinesis Data Firehose supports two types of
///          serializers: the <a href="https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/orc/OrcSerde.html">ORC SerDe</a> and the <a href="https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.html">Parquet SerDe</a>.</p>
public struct Serializer: Equatable {
    /// <p>A serializer to use for converting data to the ORC format before storing it in Amazon
    ///          S3. For more information, see <a href="https://orc.apache.org/docs/">Apache
    ///          ORC</a>.</p>
    public let orcSerDe: OrcSerDe?
    /// <p>A serializer to use for converting data to the Parquet format before storing it in
    ///          Amazon S3. For more information, see <a href="https://parquet.apache.org/documentation/latest/">Apache Parquet</a>.</p>
    public let parquetSerDe: ParquetSerDe?

    public init (
        orcSerDe: OrcSerDe? = nil,
        parquetSerDe: ParquetSerDe? = nil
    )
    {
        self.orcSerDe = orcSerDe
        self.parquetSerDe = parquetSerDe
    }
}

extension ServiceUnavailableException: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ServiceUnavailableException(message: \(String(describing: message)))"}
}

extension ServiceUnavailableException: AWSHttpServiceError {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        if case .stream(let reader) = httpResponse.body,
            let responseDecoder = decoder {
            let data = reader.toBytes().toData()
            let output: ServiceUnavailableExceptionBody = try responseDecoder.decode(responseBody: data)
            self.message = output.message
        } else {
            self.message = nil
        }
        self._headers = httpResponse.headers
        self._statusCode = httpResponse.statusCode
        self._requestID = requestID
        self._message = message
    }
}

/// <p>The service is unavailable. Back off and retry the operation. If you continue to see
///          the exception, throughput limits for the delivery stream may have been exceeded. For more
///          information about limits and how to request an increase, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/limits.html">Amazon Kinesis Data Firehose
///          Limits</a>.</p>
public struct ServiceUnavailableException: ClientRuntime.ServiceError, Equatable {
    public var _headers: ClientRuntime.Headers?
    public var _statusCode: HttpStatusCode?
    public var _message: String?
    public var _requestID: String?
    public var _retryable: Bool = false
    public var _isThrottling: Bool = false
    public var _type: ErrorType = .server
    /// <p>A message that provides information about the error.</p>
    public var message: String?

    public init (
        message: String? = nil
    )
    {
        self.message = message
    }
}

struct ServiceUnavailableExceptionBody: Equatable {
    public let message: String?
}

extension ServiceUnavailableExceptionBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case message
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let messageDecoded = try containerValues.decodeIfPresent(String.self, forKey: .message)
        message = messageDecoded
    }
}

extension SourceDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case kinesisStreamSourceDescription = "KinesisStreamSourceDescription"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let kinesisStreamSourceDescription = kinesisStreamSourceDescription {
            try encodeContainer.encode(kinesisStreamSourceDescription, forKey: .kinesisStreamSourceDescription)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let kinesisStreamSourceDescriptionDecoded = try containerValues.decodeIfPresent(KinesisStreamSourceDescription.self, forKey: .kinesisStreamSourceDescription)
        kinesisStreamSourceDescription = kinesisStreamSourceDescriptionDecoded
    }
}

extension SourceDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "SourceDescription(kinesisStreamSourceDescription: \(String(describing: kinesisStreamSourceDescription)))"}
}

/// <p>Details about a Kinesis data stream used as the source for a Kinesis Data Firehose
///          delivery stream.</p>
public struct SourceDescription: Equatable {
    /// <p>The <a>KinesisStreamSourceDescription</a> value for the source Kinesis
    ///          data stream.</p>
    public let kinesisStreamSourceDescription: KinesisStreamSourceDescription?

    public init (
        kinesisStreamSourceDescription: KinesisStreamSourceDescription? = nil
    )
    {
        self.kinesisStreamSourceDescription = kinesisStreamSourceDescription
    }
}

extension SplunkDestinationConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case hECAcknowledgmentTimeoutInSeconds = "HECAcknowledgmentTimeoutInSeconds"
        case hECEndpoint = "HECEndpoint"
        case hECEndpointType = "HECEndpointType"
        case hECToken = "HECToken"
        case processingConfiguration = "ProcessingConfiguration"
        case retryOptions = "RetryOptions"
        case s3BackupMode = "S3BackupMode"
        case s3Configuration = "S3Configuration"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let hECAcknowledgmentTimeoutInSeconds = hECAcknowledgmentTimeoutInSeconds {
            try encodeContainer.encode(hECAcknowledgmentTimeoutInSeconds, forKey: .hECAcknowledgmentTimeoutInSeconds)
        }
        if let hECEndpoint = hECEndpoint {
            try encodeContainer.encode(hECEndpoint, forKey: .hECEndpoint)
        }
        if let hECEndpointType = hECEndpointType {
            try encodeContainer.encode(hECEndpointType.rawValue, forKey: .hECEndpointType)
        }
        if let hECToken = hECToken {
            try encodeContainer.encode(hECToken, forKey: .hECToken)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3Configuration = s3Configuration {
            try encodeContainer.encode(s3Configuration, forKey: .s3Configuration)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let hECEndpointDecoded = try containerValues.decodeIfPresent(String.self, forKey: .hECEndpoint)
        hECEndpoint = hECEndpointDecoded
        let hECEndpointTypeDecoded = try containerValues.decodeIfPresent(HECEndpointType.self, forKey: .hECEndpointType)
        hECEndpointType = hECEndpointTypeDecoded
        let hECTokenDecoded = try containerValues.decodeIfPresent(String.self, forKey: .hECToken)
        hECToken = hECTokenDecoded
        let hECAcknowledgmentTimeoutInSecondsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .hECAcknowledgmentTimeoutInSeconds)
        hECAcknowledgmentTimeoutInSeconds = hECAcknowledgmentTimeoutInSecondsDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(SplunkRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(SplunkS3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3ConfigurationDecoded = try containerValues.decodeIfPresent(S3DestinationConfiguration.self, forKey: .s3Configuration)
        s3Configuration = s3ConfigurationDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
    }
}

extension SplunkDestinationConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "SplunkDestinationConfiguration(cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), hECAcknowledgmentTimeoutInSeconds: \(String(describing: hECAcknowledgmentTimeoutInSeconds)), hECEndpoint: \(String(describing: hECEndpoint)), hECEndpointType: \(String(describing: hECEndpointType)), hECToken: \(String(describing: hECToken)), processingConfiguration: \(String(describing: processingConfiguration)), retryOptions: \(String(describing: retryOptions)), s3BackupMode: \(String(describing: s3BackupMode)), s3Configuration: \(String(describing: s3Configuration)))"}
}

/// <p>Describes the configuration of a destination in Splunk.</p>
public struct SplunkDestinationConfiguration: Equatable {
    /// <p>The Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The amount of time that Kinesis Data Firehose waits to receive an acknowledgment from
    ///          Splunk after it sends it data. At the end of the timeout period, Kinesis Data Firehose
    ///          either tries to send the data again or considers it an error, based on your retry
    ///          settings.</p>
    public let hECAcknowledgmentTimeoutInSeconds: Int?
    /// <p>The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your
    ///          data.</p>
    public let hECEndpoint: String?
    /// <p>This type can be either "Raw" or "Event."</p>
    public let hECEndpointType: HECEndpointType?
    /// <p>This is a GUID that you obtain from your Splunk cluster when you create a new HEC
    ///          endpoint.</p>
    public let hECToken: String?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk,
    ///          or if it doesn't receive an acknowledgment of receipt from Splunk.</p>
    public let retryOptions: SplunkRetryOptions?
    /// <p>Defines how documents should be delivered to Amazon S3. When set to
    ///             <code>FailedEventsOnly</code>, Kinesis Data Firehose writes any data that could not be
    ///          indexed to the configured Amazon S3 destination. When set to <code>AllEvents</code>,
    ///          Kinesis Data Firehose delivers all incoming records to Amazon S3, and also writes failed
    ///          documents to Amazon S3. The default value is <code>FailedEventsOnly</code>.</p>
    ///          <p>You can update this backup mode from <code>FailedEventsOnly</code> to
    ///             <code>AllEvents</code>. You can't update it from <code>AllEvents</code> to
    ///             <code>FailedEventsOnly</code>.</p>
    public let s3BackupMode: SplunkS3BackupMode?
    /// <p>The configuration for the backup Amazon S3 location.</p>
    public let s3Configuration: S3DestinationConfiguration?

    public init (
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        hECAcknowledgmentTimeoutInSeconds: Int? = nil,
        hECEndpoint: String? = nil,
        hECEndpointType: HECEndpointType? = nil,
        hECToken: String? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        retryOptions: SplunkRetryOptions? = nil,
        s3BackupMode: SplunkS3BackupMode? = nil,
        s3Configuration: S3DestinationConfiguration? = nil
    )
    {
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.hECAcknowledgmentTimeoutInSeconds = hECAcknowledgmentTimeoutInSeconds
        self.hECEndpoint = hECEndpoint
        self.hECEndpointType = hECEndpointType
        self.hECToken = hECToken
        self.processingConfiguration = processingConfiguration
        self.retryOptions = retryOptions
        self.s3BackupMode = s3BackupMode
        self.s3Configuration = s3Configuration
    }
}

extension SplunkDestinationDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case hECAcknowledgmentTimeoutInSeconds = "HECAcknowledgmentTimeoutInSeconds"
        case hECEndpoint = "HECEndpoint"
        case hECEndpointType = "HECEndpointType"
        case hECToken = "HECToken"
        case processingConfiguration = "ProcessingConfiguration"
        case retryOptions = "RetryOptions"
        case s3BackupMode = "S3BackupMode"
        case s3DestinationDescription = "S3DestinationDescription"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let hECAcknowledgmentTimeoutInSeconds = hECAcknowledgmentTimeoutInSeconds {
            try encodeContainer.encode(hECAcknowledgmentTimeoutInSeconds, forKey: .hECAcknowledgmentTimeoutInSeconds)
        }
        if let hECEndpoint = hECEndpoint {
            try encodeContainer.encode(hECEndpoint, forKey: .hECEndpoint)
        }
        if let hECEndpointType = hECEndpointType {
            try encodeContainer.encode(hECEndpointType.rawValue, forKey: .hECEndpointType)
        }
        if let hECToken = hECToken {
            try encodeContainer.encode(hECToken, forKey: .hECToken)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3DestinationDescription = s3DestinationDescription {
            try encodeContainer.encode(s3DestinationDescription, forKey: .s3DestinationDescription)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let hECEndpointDecoded = try containerValues.decodeIfPresent(String.self, forKey: .hECEndpoint)
        hECEndpoint = hECEndpointDecoded
        let hECEndpointTypeDecoded = try containerValues.decodeIfPresent(HECEndpointType.self, forKey: .hECEndpointType)
        hECEndpointType = hECEndpointTypeDecoded
        let hECTokenDecoded = try containerValues.decodeIfPresent(String.self, forKey: .hECToken)
        hECToken = hECTokenDecoded
        let hECAcknowledgmentTimeoutInSecondsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .hECAcknowledgmentTimeoutInSeconds)
        hECAcknowledgmentTimeoutInSeconds = hECAcknowledgmentTimeoutInSecondsDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(SplunkRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(SplunkS3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3DestinationDescriptionDecoded = try containerValues.decodeIfPresent(S3DestinationDescription.self, forKey: .s3DestinationDescription)
        s3DestinationDescription = s3DestinationDescriptionDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
    }
}

extension SplunkDestinationDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "SplunkDestinationDescription(cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), hECAcknowledgmentTimeoutInSeconds: \(String(describing: hECAcknowledgmentTimeoutInSeconds)), hECEndpoint: \(String(describing: hECEndpoint)), hECEndpointType: \(String(describing: hECEndpointType)), hECToken: \(String(describing: hECToken)), processingConfiguration: \(String(describing: processingConfiguration)), retryOptions: \(String(describing: retryOptions)), s3BackupMode: \(String(describing: s3BackupMode)), s3DestinationDescription: \(String(describing: s3DestinationDescription)))"}
}

/// <p>Describes a destination in Splunk.</p>
public struct SplunkDestinationDescription: Equatable {
    /// <p>The Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The amount of time that Kinesis Data Firehose waits to receive an acknowledgment from
    ///          Splunk after it sends it data. At the end of the timeout period, Kinesis Data Firehose
    ///          either tries to send the data again or considers it an error, based on your retry
    ///          settings.</p>
    public let hECAcknowledgmentTimeoutInSeconds: Int?
    /// <p>The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your
    ///          data.</p>
    public let hECEndpoint: String?
    /// <p>This type can be either "Raw" or "Event."</p>
    public let hECEndpointType: HECEndpointType?
    /// <p>A GUID you obtain from your Splunk cluster when you create a new HEC
    ///          endpoint.</p>
    public let hECToken: String?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk
    ///          or if it doesn't receive an acknowledgment of receipt from Splunk.</p>
    public let retryOptions: SplunkRetryOptions?
    /// <p>Defines how documents should be delivered to Amazon S3. When set to
    ///             <code>FailedDocumentsOnly</code>, Kinesis Data Firehose writes any data that could not
    ///          be indexed to the configured Amazon S3 destination. When set to <code>AllDocuments</code>,
    ///          Kinesis Data Firehose delivers all incoming records to Amazon S3, and also writes failed
    ///          documents to Amazon S3. Default value is <code>FailedDocumentsOnly</code>. </p>
    public let s3BackupMode: SplunkS3BackupMode?
    /// <p>The Amazon S3 destination.></p>
    public let s3DestinationDescription: S3DestinationDescription?

    public init (
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        hECAcknowledgmentTimeoutInSeconds: Int? = nil,
        hECEndpoint: String? = nil,
        hECEndpointType: HECEndpointType? = nil,
        hECToken: String? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        retryOptions: SplunkRetryOptions? = nil,
        s3BackupMode: SplunkS3BackupMode? = nil,
        s3DestinationDescription: S3DestinationDescription? = nil
    )
    {
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.hECAcknowledgmentTimeoutInSeconds = hECAcknowledgmentTimeoutInSeconds
        self.hECEndpoint = hECEndpoint
        self.hECEndpointType = hECEndpointType
        self.hECToken = hECToken
        self.processingConfiguration = processingConfiguration
        self.retryOptions = retryOptions
        self.s3BackupMode = s3BackupMode
        self.s3DestinationDescription = s3DestinationDescription
    }
}

extension SplunkDestinationUpdate: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case cloudWatchLoggingOptions = "CloudWatchLoggingOptions"
        case hECAcknowledgmentTimeoutInSeconds = "HECAcknowledgmentTimeoutInSeconds"
        case hECEndpoint = "HECEndpoint"
        case hECEndpointType = "HECEndpointType"
        case hECToken = "HECToken"
        case processingConfiguration = "ProcessingConfiguration"
        case retryOptions = "RetryOptions"
        case s3BackupMode = "S3BackupMode"
        case s3Update = "S3Update"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let cloudWatchLoggingOptions = cloudWatchLoggingOptions {
            try encodeContainer.encode(cloudWatchLoggingOptions, forKey: .cloudWatchLoggingOptions)
        }
        if let hECAcknowledgmentTimeoutInSeconds = hECAcknowledgmentTimeoutInSeconds {
            try encodeContainer.encode(hECAcknowledgmentTimeoutInSeconds, forKey: .hECAcknowledgmentTimeoutInSeconds)
        }
        if let hECEndpoint = hECEndpoint {
            try encodeContainer.encode(hECEndpoint, forKey: .hECEndpoint)
        }
        if let hECEndpointType = hECEndpointType {
            try encodeContainer.encode(hECEndpointType.rawValue, forKey: .hECEndpointType)
        }
        if let hECToken = hECToken {
            try encodeContainer.encode(hECToken, forKey: .hECToken)
        }
        if let processingConfiguration = processingConfiguration {
            try encodeContainer.encode(processingConfiguration, forKey: .processingConfiguration)
        }
        if let retryOptions = retryOptions {
            try encodeContainer.encode(retryOptions, forKey: .retryOptions)
        }
        if let s3BackupMode = s3BackupMode {
            try encodeContainer.encode(s3BackupMode.rawValue, forKey: .s3BackupMode)
        }
        if let s3Update = s3Update {
            try encodeContainer.encode(s3Update, forKey: .s3Update)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let hECEndpointDecoded = try containerValues.decodeIfPresent(String.self, forKey: .hECEndpoint)
        hECEndpoint = hECEndpointDecoded
        let hECEndpointTypeDecoded = try containerValues.decodeIfPresent(HECEndpointType.self, forKey: .hECEndpointType)
        hECEndpointType = hECEndpointTypeDecoded
        let hECTokenDecoded = try containerValues.decodeIfPresent(String.self, forKey: .hECToken)
        hECToken = hECTokenDecoded
        let hECAcknowledgmentTimeoutInSecondsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .hECAcknowledgmentTimeoutInSeconds)
        hECAcknowledgmentTimeoutInSeconds = hECAcknowledgmentTimeoutInSecondsDecoded
        let retryOptionsDecoded = try containerValues.decodeIfPresent(SplunkRetryOptions.self, forKey: .retryOptions)
        retryOptions = retryOptionsDecoded
        let s3BackupModeDecoded = try containerValues.decodeIfPresent(SplunkS3BackupMode.self, forKey: .s3BackupMode)
        s3BackupMode = s3BackupModeDecoded
        let s3UpdateDecoded = try containerValues.decodeIfPresent(S3DestinationUpdate.self, forKey: .s3Update)
        s3Update = s3UpdateDecoded
        let processingConfigurationDecoded = try containerValues.decodeIfPresent(ProcessingConfiguration.self, forKey: .processingConfiguration)
        processingConfiguration = processingConfigurationDecoded
        let cloudWatchLoggingOptionsDecoded = try containerValues.decodeIfPresent(CloudWatchLoggingOptions.self, forKey: .cloudWatchLoggingOptions)
        cloudWatchLoggingOptions = cloudWatchLoggingOptionsDecoded
    }
}

extension SplunkDestinationUpdate: CustomDebugStringConvertible {
    public var debugDescription: String {
        "SplunkDestinationUpdate(cloudWatchLoggingOptions: \(String(describing: cloudWatchLoggingOptions)), hECAcknowledgmentTimeoutInSeconds: \(String(describing: hECAcknowledgmentTimeoutInSeconds)), hECEndpoint: \(String(describing: hECEndpoint)), hECEndpointType: \(String(describing: hECEndpointType)), hECToken: \(String(describing: hECToken)), processingConfiguration: \(String(describing: processingConfiguration)), retryOptions: \(String(describing: retryOptions)), s3BackupMode: \(String(describing: s3BackupMode)), s3Update: \(String(describing: s3Update)))"}
}

/// <p>Describes an update for a destination in Splunk.</p>
public struct SplunkDestinationUpdate: Equatable {
    /// <p>The Amazon CloudWatch logging options for your delivery stream.</p>
    public let cloudWatchLoggingOptions: CloudWatchLoggingOptions?
    /// <p>The amount of time that Kinesis Data Firehose waits to receive an acknowledgment from
    ///          Splunk after it sends data. At the end of the timeout period, Kinesis Data Firehose either
    ///          tries to send the data again or considers it an error, based on your retry
    ///          settings.</p>
    public let hECAcknowledgmentTimeoutInSeconds: Int?
    /// <p>The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your
    ///          data.</p>
    public let hECEndpoint: String?
    /// <p>This type can be either "Raw" or "Event."</p>
    public let hECEndpointType: HECEndpointType?
    /// <p>A GUID that you obtain from your Splunk cluster when you create a new HEC
    ///          endpoint.</p>
    public let hECToken: String?
    /// <p>The data processing configuration.</p>
    public let processingConfiguration: ProcessingConfiguration?
    /// <p>The retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk
    ///          or if it doesn't receive an acknowledgment of receipt from Splunk.</p>
    public let retryOptions: SplunkRetryOptions?
    /// <p>Specifies how you want Kinesis Data Firehose to back up documents to Amazon S3. When
    ///          set to <code>FailedDocumentsOnly</code>, Kinesis Data Firehose writes any data that could
    ///          not be indexed to the configured Amazon S3 destination. When set to <code>AllEvents</code>,
    ///          Kinesis Data Firehose delivers all incoming records to Amazon S3, and also writes failed
    ///          documents to Amazon S3. The default value is <code>FailedEventsOnly</code>.</p>
    ///          <p>You can update this backup mode from <code>FailedEventsOnly</code> to
    ///             <code>AllEvents</code>. You can't update it from <code>AllEvents</code> to
    ///             <code>FailedEventsOnly</code>.</p>
    public let s3BackupMode: SplunkS3BackupMode?
    /// <p>Your update to the configuration of the backup Amazon S3 location.</p>
    public let s3Update: S3DestinationUpdate?

    public init (
        cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil,
        hECAcknowledgmentTimeoutInSeconds: Int? = nil,
        hECEndpoint: String? = nil,
        hECEndpointType: HECEndpointType? = nil,
        hECToken: String? = nil,
        processingConfiguration: ProcessingConfiguration? = nil,
        retryOptions: SplunkRetryOptions? = nil,
        s3BackupMode: SplunkS3BackupMode? = nil,
        s3Update: S3DestinationUpdate? = nil
    )
    {
        self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
        self.hECAcknowledgmentTimeoutInSeconds = hECAcknowledgmentTimeoutInSeconds
        self.hECEndpoint = hECEndpoint
        self.hECEndpointType = hECEndpointType
        self.hECToken = hECToken
        self.processingConfiguration = processingConfiguration
        self.retryOptions = retryOptions
        self.s3BackupMode = s3BackupMode
        self.s3Update = s3Update
    }
}

extension SplunkRetryOptions: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case durationInSeconds = "DurationInSeconds"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let durationInSeconds = durationInSeconds {
            try encodeContainer.encode(durationInSeconds, forKey: .durationInSeconds)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let durationInSecondsDecoded = try containerValues.decodeIfPresent(Int.self, forKey: .durationInSeconds)
        durationInSeconds = durationInSecondsDecoded
    }
}

extension SplunkRetryOptions: CustomDebugStringConvertible {
    public var debugDescription: String {
        "SplunkRetryOptions(durationInSeconds: \(String(describing: durationInSeconds)))"}
}

/// <p>Configures retry behavior in case Kinesis Data Firehose is unable to deliver
///          documents to Splunk, or if it doesn't receive an acknowledgment from Splunk.</p>
public struct SplunkRetryOptions: Equatable {
    /// <p>The total amount of time that Kinesis Data Firehose spends on retries. This duration
    ///          starts after the initial attempt to send data to Splunk fails. It doesn't include the
    ///          periods during which Kinesis Data Firehose waits for acknowledgment from Splunk after each
    ///          attempt.</p>
    public let durationInSeconds: Int?

    public init (
        durationInSeconds: Int? = nil
    )
    {
        self.durationInSeconds = durationInSeconds
    }
}

public enum SplunkS3BackupMode {
    case allevents
    case failedeventsonly
    case sdkUnknown(String)
}

extension SplunkS3BackupMode : Equatable, RawRepresentable, Codable, CaseIterable, Hashable {
    public static var allCases: [SplunkS3BackupMode] {
        return [
            .allevents,
            .failedeventsonly,
            .sdkUnknown("")
        ]
    }
    public init?(rawValue: String) {
        let value = Self.allCases.first(where: { $0.rawValue == rawValue })
        self = value ?? Self.sdkUnknown(rawValue)
    }
    public var rawValue: String {
        switch self {
        case .allevents: return "AllEvents"
        case .failedeventsonly: return "FailedEventsOnly"
        case let .sdkUnknown(s): return s
        }
    }
    public init(from decoder: Decoder) throws {
        let container = try decoder.singleValueContainer()
        let rawValue = try container.decode(RawValue.self)
        self = SplunkS3BackupMode(rawValue: rawValue) ?? SplunkS3BackupMode.sdkUnknown(rawValue)
    }
}

public struct StartDeliveryStreamEncryptionInputBodyMiddleware: Middleware {
    public let id: String = "StartDeliveryStreamEncryptionInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<StartDeliveryStreamEncryptionInput>,
                  next: H) -> Swift.Result<OperationOutput<StartDeliveryStreamEncryptionOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<StartDeliveryStreamEncryptionInput>
    public typealias MOutput = OperationOutput<StartDeliveryStreamEncryptionOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<StartDeliveryStreamEncryptionOutputError>
}

extension StartDeliveryStreamEncryptionInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "StartDeliveryStreamEncryptionInput(deliveryStreamEncryptionConfigurationInput: \(String(describing: deliveryStreamEncryptionConfigurationInput)), deliveryStreamName: \(String(describing: deliveryStreamName)))"}
}

extension StartDeliveryStreamEncryptionInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamEncryptionConfigurationInput = "DeliveryStreamEncryptionConfigurationInput"
        case deliveryStreamName = "DeliveryStreamName"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deliveryStreamEncryptionConfigurationInput = deliveryStreamEncryptionConfigurationInput {
            try encodeContainer.encode(deliveryStreamEncryptionConfigurationInput, forKey: .deliveryStreamEncryptionConfigurationInput)
        }
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
    }
}

public struct StartDeliveryStreamEncryptionInputHeadersMiddleware: Middleware {
    public let id: String = "StartDeliveryStreamEncryptionInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<StartDeliveryStreamEncryptionInput>,
                  next: H) -> Swift.Result<OperationOutput<StartDeliveryStreamEncryptionOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<StartDeliveryStreamEncryptionInput>
    public typealias MOutput = OperationOutput<StartDeliveryStreamEncryptionOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<StartDeliveryStreamEncryptionOutputError>
}

public struct StartDeliveryStreamEncryptionInputQueryItemMiddleware: Middleware {
    public let id: String = "StartDeliveryStreamEncryptionInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<StartDeliveryStreamEncryptionInput>,
                  next: H) -> Swift.Result<OperationOutput<StartDeliveryStreamEncryptionOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<StartDeliveryStreamEncryptionInput>
    public typealias MOutput = OperationOutput<StartDeliveryStreamEncryptionOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<StartDeliveryStreamEncryptionOutputError>
}

public struct StartDeliveryStreamEncryptionInput: Equatable {
    /// <p>Used to specify the type and Amazon Resource Name (ARN) of the KMS key needed for
    ///          Server-Side Encryption (SSE).</p>
    public let deliveryStreamEncryptionConfigurationInput: DeliveryStreamEncryptionConfigurationInput?
    /// <p>The name of the delivery stream for which you want to enable server-side encryption
    ///          (SSE).</p>
    public let deliveryStreamName: String?

    public init (
        deliveryStreamEncryptionConfigurationInput: DeliveryStreamEncryptionConfigurationInput? = nil,
        deliveryStreamName: String? = nil
    )
    {
        self.deliveryStreamEncryptionConfigurationInput = deliveryStreamEncryptionConfigurationInput
        self.deliveryStreamName = deliveryStreamName
    }
}

struct StartDeliveryStreamEncryptionInputBody: Equatable {
    public let deliveryStreamName: String?
    public let deliveryStreamEncryptionConfigurationInput: DeliveryStreamEncryptionConfigurationInput?
}

extension StartDeliveryStreamEncryptionInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamEncryptionConfigurationInput = "DeliveryStreamEncryptionConfigurationInput"
        case deliveryStreamName = "DeliveryStreamName"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
        let deliveryStreamEncryptionConfigurationInputDecoded = try containerValues.decodeIfPresent(DeliveryStreamEncryptionConfigurationInput.self, forKey: .deliveryStreamEncryptionConfigurationInput)
        deliveryStreamEncryptionConfigurationInput = deliveryStreamEncryptionConfigurationInputDecoded
    }
}

extension StartDeliveryStreamEncryptionOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension StartDeliveryStreamEncryptionOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidKMSResourceException" : self = .invalidKMSResourceException(try InvalidKMSResourceException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "LimitExceededException" : self = .limitExceededException(try LimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceInUseException" : self = .resourceInUseException(try ResourceInUseException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum StartDeliveryStreamEncryptionOutputError: Swift.Error, Equatable {
    case invalidArgumentException(InvalidArgumentException)
    case invalidKMSResourceException(InvalidKMSResourceException)
    case limitExceededException(LimitExceededException)
    case resourceInUseException(ResourceInUseException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unknown(UnknownAWSHttpServiceError)
}

extension StartDeliveryStreamEncryptionOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "StartDeliveryStreamEncryptionOutputResponse()"}
}

extension StartDeliveryStreamEncryptionOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
    }
}

public struct StartDeliveryStreamEncryptionOutputResponse: Equatable {

    public init() {}
}

struct StartDeliveryStreamEncryptionOutputResponseBody: Equatable {
}

extension StartDeliveryStreamEncryptionOutputResponseBody: Decodable {

    public init (from decoder: Decoder) throws {
    }
}

public struct StopDeliveryStreamEncryptionInputBodyMiddleware: Middleware {
    public let id: String = "StopDeliveryStreamEncryptionInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<StopDeliveryStreamEncryptionInput>,
                  next: H) -> Swift.Result<OperationOutput<StopDeliveryStreamEncryptionOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<StopDeliveryStreamEncryptionInput>
    public typealias MOutput = OperationOutput<StopDeliveryStreamEncryptionOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<StopDeliveryStreamEncryptionOutputError>
}

extension StopDeliveryStreamEncryptionInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "StopDeliveryStreamEncryptionInput(deliveryStreamName: \(String(describing: deliveryStreamName)))"}
}

extension StopDeliveryStreamEncryptionInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
    }
}

public struct StopDeliveryStreamEncryptionInputHeadersMiddleware: Middleware {
    public let id: String = "StopDeliveryStreamEncryptionInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<StopDeliveryStreamEncryptionInput>,
                  next: H) -> Swift.Result<OperationOutput<StopDeliveryStreamEncryptionOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<StopDeliveryStreamEncryptionInput>
    public typealias MOutput = OperationOutput<StopDeliveryStreamEncryptionOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<StopDeliveryStreamEncryptionOutputError>
}

public struct StopDeliveryStreamEncryptionInputQueryItemMiddleware: Middleware {
    public let id: String = "StopDeliveryStreamEncryptionInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<StopDeliveryStreamEncryptionInput>,
                  next: H) -> Swift.Result<OperationOutput<StopDeliveryStreamEncryptionOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<StopDeliveryStreamEncryptionInput>
    public typealias MOutput = OperationOutput<StopDeliveryStreamEncryptionOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<StopDeliveryStreamEncryptionOutputError>
}

public struct StopDeliveryStreamEncryptionInput: Equatable {
    /// <p>The name of the delivery stream for which you want to disable server-side encryption
    ///          (SSE).</p>
    public let deliveryStreamName: String?

    public init (
        deliveryStreamName: String? = nil
    )
    {
        self.deliveryStreamName = deliveryStreamName
    }
}

struct StopDeliveryStreamEncryptionInputBody: Equatable {
    public let deliveryStreamName: String?
}

extension StopDeliveryStreamEncryptionInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
    }
}

extension StopDeliveryStreamEncryptionOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension StopDeliveryStreamEncryptionOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "LimitExceededException" : self = .limitExceededException(try LimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceInUseException" : self = .resourceInUseException(try ResourceInUseException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum StopDeliveryStreamEncryptionOutputError: Swift.Error, Equatable {
    case invalidArgumentException(InvalidArgumentException)
    case limitExceededException(LimitExceededException)
    case resourceInUseException(ResourceInUseException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unknown(UnknownAWSHttpServiceError)
}

extension StopDeliveryStreamEncryptionOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "StopDeliveryStreamEncryptionOutputResponse()"}
}

extension StopDeliveryStreamEncryptionOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
    }
}

public struct StopDeliveryStreamEncryptionOutputResponse: Equatable {

    public init() {}
}

struct StopDeliveryStreamEncryptionOutputResponseBody: Equatable {
}

extension StopDeliveryStreamEncryptionOutputResponseBody: Decodable {

    public init (from decoder: Decoder) throws {
    }
}

extension Tag: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case key = "Key"
        case value = "Value"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let key = key {
            try encodeContainer.encode(key, forKey: .key)
        }
        if let value = value {
            try encodeContainer.encode(value, forKey: .value)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let keyDecoded = try containerValues.decodeIfPresent(String.self, forKey: .key)
        key = keyDecoded
        let valueDecoded = try containerValues.decodeIfPresent(String.self, forKey: .value)
        value = valueDecoded
    }
}

extension Tag: CustomDebugStringConvertible {
    public var debugDescription: String {
        "Tag(key: \(String(describing: key)), value: \(String(describing: value)))"}
}

/// <p>Metadata that you can assign to a delivery stream, consisting of a key-value
///          pair.</p>
public struct Tag: Equatable {
    /// <p>A unique identifier for the tag. Maximum length: 128 characters. Valid characters:
    ///          Unicode letters, digits, white space, _ . / = + - % @</p>
    public let key: String?
    /// <p>An optional string, which you can use to describe or define the tag. Maximum length:
    ///          256 characters. Valid characters: Unicode letters, digits, white space, _ . / = + - %
    ///          @</p>
    public let value: String?

    public init (
        key: String? = nil,
        value: String? = nil
    )
    {
        self.key = key
        self.value = value
    }
}

public struct TagDeliveryStreamInputBodyMiddleware: Middleware {
    public let id: String = "TagDeliveryStreamInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<TagDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<TagDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<TagDeliveryStreamInput>
    public typealias MOutput = OperationOutput<TagDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<TagDeliveryStreamOutputError>
}

extension TagDeliveryStreamInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "TagDeliveryStreamInput(deliveryStreamName: \(String(describing: deliveryStreamName)), tags: \(String(describing: tags)))"}
}

extension TagDeliveryStreamInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case tags = "Tags"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
        if let tags = tags {
            var tagsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .tags)
            for tagdeliverystreaminputtaglist0 in tags {
                try tagsContainer.encode(tagdeliverystreaminputtaglist0)
            }
        }
    }
}

public struct TagDeliveryStreamInputHeadersMiddleware: Middleware {
    public let id: String = "TagDeliveryStreamInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<TagDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<TagDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<TagDeliveryStreamInput>
    public typealias MOutput = OperationOutput<TagDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<TagDeliveryStreamOutputError>
}

public struct TagDeliveryStreamInputQueryItemMiddleware: Middleware {
    public let id: String = "TagDeliveryStreamInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<TagDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<TagDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<TagDeliveryStreamInput>
    public typealias MOutput = OperationOutput<TagDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<TagDeliveryStreamOutputError>
}

public struct TagDeliveryStreamInput: Equatable {
    /// <p>The name of the delivery stream to which you want to add the tags.</p>
    public let deliveryStreamName: String?
    /// <p>A set of key-value pairs to use to create the tags.</p>
    public let tags: [Tag]?

    public init (
        deliveryStreamName: String? = nil,
        tags: [Tag]? = nil
    )
    {
        self.deliveryStreamName = deliveryStreamName
        self.tags = tags
    }
}

struct TagDeliveryStreamInputBody: Equatable {
    public let deliveryStreamName: String?
    public let tags: [Tag]?
}

extension TagDeliveryStreamInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case tags = "Tags"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
        let tagsContainer = try containerValues.decodeIfPresent([Tag?].self, forKey: .tags)
        var tagsDecoded0:[Tag]? = nil
        if let tagsContainer = tagsContainer {
            tagsDecoded0 = [Tag]()
            for structure0 in tagsContainer {
                if let structure0 = structure0 {
                    tagsDecoded0?.append(structure0)
                }
            }
        }
        tags = tagsDecoded0
    }
}

extension TagDeliveryStreamOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension TagDeliveryStreamOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "LimitExceededException" : self = .limitExceededException(try LimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceInUseException" : self = .resourceInUseException(try ResourceInUseException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum TagDeliveryStreamOutputError: Swift.Error, Equatable {
    case invalidArgumentException(InvalidArgumentException)
    case limitExceededException(LimitExceededException)
    case resourceInUseException(ResourceInUseException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unknown(UnknownAWSHttpServiceError)
}

extension TagDeliveryStreamOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "TagDeliveryStreamOutputResponse()"}
}

extension TagDeliveryStreamOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
    }
}

public struct TagDeliveryStreamOutputResponse: Equatable {

    public init() {}
}

struct TagDeliveryStreamOutputResponseBody: Equatable {
}

extension TagDeliveryStreamOutputResponseBody: Decodable {

    public init (from decoder: Decoder) throws {
    }
}

public struct UntagDeliveryStreamInputBodyMiddleware: Middleware {
    public let id: String = "UntagDeliveryStreamInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<UntagDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<UntagDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<UntagDeliveryStreamInput>
    public typealias MOutput = OperationOutput<UntagDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<UntagDeliveryStreamOutputError>
}

extension UntagDeliveryStreamInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "UntagDeliveryStreamInput(deliveryStreamName: \(String(describing: deliveryStreamName)), tagKeys: \(String(describing: tagKeys)))"}
}

extension UntagDeliveryStreamInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case tagKeys = "TagKeys"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
        if let tagKeys = tagKeys {
            var tagKeysContainer = encodeContainer.nestedUnkeyedContainer(forKey: .tagKeys)
            for tagkeylist0 in tagKeys {
                try tagKeysContainer.encode(tagkeylist0)
            }
        }
    }
}

public struct UntagDeliveryStreamInputHeadersMiddleware: Middleware {
    public let id: String = "UntagDeliveryStreamInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<UntagDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<UntagDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<UntagDeliveryStreamInput>
    public typealias MOutput = OperationOutput<UntagDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<UntagDeliveryStreamOutputError>
}

public struct UntagDeliveryStreamInputQueryItemMiddleware: Middleware {
    public let id: String = "UntagDeliveryStreamInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<UntagDeliveryStreamInput>,
                  next: H) -> Swift.Result<OperationOutput<UntagDeliveryStreamOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<UntagDeliveryStreamInput>
    public typealias MOutput = OperationOutput<UntagDeliveryStreamOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<UntagDeliveryStreamOutputError>
}

public struct UntagDeliveryStreamInput: Equatable {
    /// <p>The name of the delivery stream.</p>
    public let deliveryStreamName: String?
    /// <p>A list of tag keys. Each corresponding tag is removed from the delivery
    ///          stream.</p>
    public let tagKeys: [String]?

    public init (
        deliveryStreamName: String? = nil,
        tagKeys: [String]? = nil
    )
    {
        self.deliveryStreamName = deliveryStreamName
        self.tagKeys = tagKeys
    }
}

struct UntagDeliveryStreamInputBody: Equatable {
    public let deliveryStreamName: String?
    public let tagKeys: [String]?
}

extension UntagDeliveryStreamInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case deliveryStreamName = "DeliveryStreamName"
        case tagKeys = "TagKeys"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
        let tagKeysContainer = try containerValues.decodeIfPresent([String?].self, forKey: .tagKeys)
        var tagKeysDecoded0:[String]? = nil
        if let tagKeysContainer = tagKeysContainer {
            tagKeysDecoded0 = [String]()
            for string0 in tagKeysContainer {
                if let string0 = string0 {
                    tagKeysDecoded0?.append(string0)
                }
            }
        }
        tagKeys = tagKeysDecoded0
    }
}

extension UntagDeliveryStreamOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension UntagDeliveryStreamOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "LimitExceededException" : self = .limitExceededException(try LimitExceededException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceInUseException" : self = .resourceInUseException(try ResourceInUseException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum UntagDeliveryStreamOutputError: Swift.Error, Equatable {
    case invalidArgumentException(InvalidArgumentException)
    case limitExceededException(LimitExceededException)
    case resourceInUseException(ResourceInUseException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unknown(UnknownAWSHttpServiceError)
}

extension UntagDeliveryStreamOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "UntagDeliveryStreamOutputResponse()"}
}

extension UntagDeliveryStreamOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
    }
}

public struct UntagDeliveryStreamOutputResponse: Equatable {

    public init() {}
}

struct UntagDeliveryStreamOutputResponseBody: Equatable {
}

extension UntagDeliveryStreamOutputResponseBody: Decodable {

    public init (from decoder: Decoder) throws {
    }
}

public struct UpdateDestinationInputBodyMiddleware: Middleware {
    public let id: String = "UpdateDestinationInputBodyMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<UpdateDestinationInput>,
                  next: H) -> Swift.Result<OperationOutput<UpdateDestinationOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        do {
            if try !input.operationInput.allPropertiesAreNull() {
                let encoder = context.getEncoder()
                let data = try encoder.encode(input.operationInput)
                let body = HttpBody.data(data)
                input.builder.withBody(body)
            }
        } catch let err {
            return .failure(.client(ClientError.serializationFailed(err.localizedDescription)))
        }
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<UpdateDestinationInput>
    public typealias MOutput = OperationOutput<UpdateDestinationOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<UpdateDestinationOutputError>
}

extension UpdateDestinationInput: CustomDebugStringConvertible {
    public var debugDescription: String {
        "UpdateDestinationInput(currentDeliveryStreamVersionId: \(String(describing: currentDeliveryStreamVersionId)), deliveryStreamName: \(String(describing: deliveryStreamName)), destinationId: \(String(describing: destinationId)), elasticsearchDestinationUpdate: \(String(describing: elasticsearchDestinationUpdate)), extendedS3DestinationUpdate: \(String(describing: extendedS3DestinationUpdate)), httpEndpointDestinationUpdate: \(String(describing: httpEndpointDestinationUpdate)), redshiftDestinationUpdate: \(String(describing: redshiftDestinationUpdate)), s3DestinationUpdate: \(String(describing: s3DestinationUpdate)), splunkDestinationUpdate: \(String(describing: splunkDestinationUpdate)))"}
}

extension UpdateDestinationInput: Encodable, Reflection {
    enum CodingKeys: String, CodingKey {
        case currentDeliveryStreamVersionId = "CurrentDeliveryStreamVersionId"
        case deliveryStreamName = "DeliveryStreamName"
        case destinationId = "DestinationId"
        case elasticsearchDestinationUpdate = "ElasticsearchDestinationUpdate"
        case extendedS3DestinationUpdate = "ExtendedS3DestinationUpdate"
        case httpEndpointDestinationUpdate = "HttpEndpointDestinationUpdate"
        case redshiftDestinationUpdate = "RedshiftDestinationUpdate"
        case s3DestinationUpdate = "S3DestinationUpdate"
        case splunkDestinationUpdate = "SplunkDestinationUpdate"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let currentDeliveryStreamVersionId = currentDeliveryStreamVersionId {
            try encodeContainer.encode(currentDeliveryStreamVersionId, forKey: .currentDeliveryStreamVersionId)
        }
        if let deliveryStreamName = deliveryStreamName {
            try encodeContainer.encode(deliveryStreamName, forKey: .deliveryStreamName)
        }
        if let destinationId = destinationId {
            try encodeContainer.encode(destinationId, forKey: .destinationId)
        }
        if let elasticsearchDestinationUpdate = elasticsearchDestinationUpdate {
            try encodeContainer.encode(elasticsearchDestinationUpdate, forKey: .elasticsearchDestinationUpdate)
        }
        if let extendedS3DestinationUpdate = extendedS3DestinationUpdate {
            try encodeContainer.encode(extendedS3DestinationUpdate, forKey: .extendedS3DestinationUpdate)
        }
        if let httpEndpointDestinationUpdate = httpEndpointDestinationUpdate {
            try encodeContainer.encode(httpEndpointDestinationUpdate, forKey: .httpEndpointDestinationUpdate)
        }
        if let redshiftDestinationUpdate = redshiftDestinationUpdate {
            try encodeContainer.encode(redshiftDestinationUpdate, forKey: .redshiftDestinationUpdate)
        }
        if let s3DestinationUpdate = s3DestinationUpdate {
            try encodeContainer.encode(s3DestinationUpdate, forKey: .s3DestinationUpdate)
        }
        if let splunkDestinationUpdate = splunkDestinationUpdate {
            try encodeContainer.encode(splunkDestinationUpdate, forKey: .splunkDestinationUpdate)
        }
    }
}

public struct UpdateDestinationInputHeadersMiddleware: Middleware {
    public let id: String = "UpdateDestinationInputHeadersMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<UpdateDestinationInput>,
                  next: H) -> Swift.Result<OperationOutput<UpdateDestinationOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<UpdateDestinationInput>
    public typealias MOutput = OperationOutput<UpdateDestinationOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<UpdateDestinationOutputError>
}

public struct UpdateDestinationInputQueryItemMiddleware: Middleware {
    public let id: String = "UpdateDestinationInputQueryItemMiddleware"

    public init() {}

    public func handle<H>(context: Context,
                  input: SerializeStepInput<UpdateDestinationInput>,
                  next: H) -> Swift.Result<OperationOutput<UpdateDestinationOutputResponse>, MError>
    where H: Handler,
    Self.MInput == H.Input,
    Self.MOutput == H.Output,
    Self.Context == H.Context,
    Self.MError == H.MiddlewareError
    {
        return next.handle(context: context, input: input)
    }

    public typealias MInput = SerializeStepInput<UpdateDestinationInput>
    public typealias MOutput = OperationOutput<UpdateDestinationOutputResponse>
    public typealias Context = ClientRuntime.HttpContext
    public typealias MError = SdkError<UpdateDestinationOutputError>
}

public struct UpdateDestinationInput: Equatable {
    /// <p>Obtain this value from the <code>VersionId</code> result of <a>DeliveryStreamDescription</a>. This value is required, and helps the service
    ///          perform conditional operations. For example, if there is an interleaving update and this
    ///          value is null, then the update destination fails. After the update is successful, the
    ///             <code>VersionId</code> value is updated. The service then performs a merge of the old
    ///          configuration with the new configuration.</p>
    public let currentDeliveryStreamVersionId: String?
    /// <p>The name of the delivery stream.</p>
    public let deliveryStreamName: String?
    /// <p>The ID of the destination.</p>
    public let destinationId: String?
    /// <p>Describes an update for a destination in Amazon ES.</p>
    public let elasticsearchDestinationUpdate: ElasticsearchDestinationUpdate?
    /// <p>Describes an update for a destination in Amazon S3.</p>
    public let extendedS3DestinationUpdate: ExtendedS3DestinationUpdate?
    /// <p>Describes an update to the specified HTTP endpoint destination.</p>
    public let httpEndpointDestinationUpdate: HttpEndpointDestinationUpdate?
    /// <p>Describes an update for a destination in Amazon Redshift.</p>
    public let redshiftDestinationUpdate: RedshiftDestinationUpdate?
    /// <p>[Deprecated] Describes an update for a destination in Amazon S3.</p>
    @available(*, deprecated)
    public let s3DestinationUpdate: S3DestinationUpdate?
    /// <p>Describes an update for a destination in Splunk.</p>
    public let splunkDestinationUpdate: SplunkDestinationUpdate?

    public init (
        currentDeliveryStreamVersionId: String? = nil,
        deliveryStreamName: String? = nil,
        destinationId: String? = nil,
        elasticsearchDestinationUpdate: ElasticsearchDestinationUpdate? = nil,
        extendedS3DestinationUpdate: ExtendedS3DestinationUpdate? = nil,
        httpEndpointDestinationUpdate: HttpEndpointDestinationUpdate? = nil,
        redshiftDestinationUpdate: RedshiftDestinationUpdate? = nil,
        s3DestinationUpdate: S3DestinationUpdate? = nil,
        splunkDestinationUpdate: SplunkDestinationUpdate? = nil
    )
    {
        self.currentDeliveryStreamVersionId = currentDeliveryStreamVersionId
        self.deliveryStreamName = deliveryStreamName
        self.destinationId = destinationId
        self.elasticsearchDestinationUpdate = elasticsearchDestinationUpdate
        self.extendedS3DestinationUpdate = extendedS3DestinationUpdate
        self.httpEndpointDestinationUpdate = httpEndpointDestinationUpdate
        self.redshiftDestinationUpdate = redshiftDestinationUpdate
        self.s3DestinationUpdate = s3DestinationUpdate
        self.splunkDestinationUpdate = splunkDestinationUpdate
    }
}

struct UpdateDestinationInputBody: Equatable {
    public let deliveryStreamName: String?
    public let currentDeliveryStreamVersionId: String?
    public let destinationId: String?
    public let s3DestinationUpdate: S3DestinationUpdate?
    public let extendedS3DestinationUpdate: ExtendedS3DestinationUpdate?
    public let redshiftDestinationUpdate: RedshiftDestinationUpdate?
    public let elasticsearchDestinationUpdate: ElasticsearchDestinationUpdate?
    public let splunkDestinationUpdate: SplunkDestinationUpdate?
    public let httpEndpointDestinationUpdate: HttpEndpointDestinationUpdate?
}

extension UpdateDestinationInputBody: Decodable {
    enum CodingKeys: String, CodingKey {
        case currentDeliveryStreamVersionId = "CurrentDeliveryStreamVersionId"
        case deliveryStreamName = "DeliveryStreamName"
        case destinationId = "DestinationId"
        case elasticsearchDestinationUpdate = "ElasticsearchDestinationUpdate"
        case extendedS3DestinationUpdate = "ExtendedS3DestinationUpdate"
        case httpEndpointDestinationUpdate = "HttpEndpointDestinationUpdate"
        case redshiftDestinationUpdate = "RedshiftDestinationUpdate"
        case s3DestinationUpdate = "S3DestinationUpdate"
        case splunkDestinationUpdate = "SplunkDestinationUpdate"
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let deliveryStreamNameDecoded = try containerValues.decodeIfPresent(String.self, forKey: .deliveryStreamName)
        deliveryStreamName = deliveryStreamNameDecoded
        let currentDeliveryStreamVersionIdDecoded = try containerValues.decodeIfPresent(String.self, forKey: .currentDeliveryStreamVersionId)
        currentDeliveryStreamVersionId = currentDeliveryStreamVersionIdDecoded
        let destinationIdDecoded = try containerValues.decodeIfPresent(String.self, forKey: .destinationId)
        destinationId = destinationIdDecoded
        let s3DestinationUpdateDecoded = try containerValues.decodeIfPresent(S3DestinationUpdate.self, forKey: .s3DestinationUpdate)
        s3DestinationUpdate = s3DestinationUpdateDecoded
        let extendedS3DestinationUpdateDecoded = try containerValues.decodeIfPresent(ExtendedS3DestinationUpdate.self, forKey: .extendedS3DestinationUpdate)
        extendedS3DestinationUpdate = extendedS3DestinationUpdateDecoded
        let redshiftDestinationUpdateDecoded = try containerValues.decodeIfPresent(RedshiftDestinationUpdate.self, forKey: .redshiftDestinationUpdate)
        redshiftDestinationUpdate = redshiftDestinationUpdateDecoded
        let elasticsearchDestinationUpdateDecoded = try containerValues.decodeIfPresent(ElasticsearchDestinationUpdate.self, forKey: .elasticsearchDestinationUpdate)
        elasticsearchDestinationUpdate = elasticsearchDestinationUpdateDecoded
        let splunkDestinationUpdateDecoded = try containerValues.decodeIfPresent(SplunkDestinationUpdate.self, forKey: .splunkDestinationUpdate)
        splunkDestinationUpdate = splunkDestinationUpdateDecoded
        let httpEndpointDestinationUpdateDecoded = try containerValues.decodeIfPresent(HttpEndpointDestinationUpdate.self, forKey: .httpEndpointDestinationUpdate)
        httpEndpointDestinationUpdate = httpEndpointDestinationUpdateDecoded
    }
}

extension UpdateDestinationOutputError: HttpResponseBinding {
    public init(httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
        let errorDetails = try RestJSONError(httpResponse: httpResponse)
        let requestID = httpResponse.headers.value(for: X_AMZN_REQUEST_ID_HEADER)
        try self.init(errorType: errorDetails.errorType, httpResponse: httpResponse, decoder: decoder, message: errorDetails.errorMessage, requestID: requestID)
    }
}

extension UpdateDestinationOutputError {
    public init(errorType: String?, httpResponse: HttpResponse, decoder: ResponseDecoder? = nil, message: String? = nil, requestID: String? = nil) throws {
        switch errorType {
        case "ConcurrentModificationException" : self = .concurrentModificationException(try ConcurrentModificationException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "InvalidArgumentException" : self = .invalidArgumentException(try InvalidArgumentException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceInUseException" : self = .resourceInUseException(try ResourceInUseException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        case "ResourceNotFoundException" : self = .resourceNotFoundException(try ResourceNotFoundException(httpResponse: httpResponse, decoder: decoder, message: message, requestID: requestID))
        default : self = .unknown(UnknownAWSHttpServiceError(httpResponse: httpResponse, message: message, requestID: requestID))
        }
    }
}

public enum UpdateDestinationOutputError: Swift.Error, Equatable {
    case concurrentModificationException(ConcurrentModificationException)
    case invalidArgumentException(InvalidArgumentException)
    case resourceInUseException(ResourceInUseException)
    case resourceNotFoundException(ResourceNotFoundException)
    case unknown(UnknownAWSHttpServiceError)
}

extension UpdateDestinationOutputResponse: CustomDebugStringConvertible {
    public var debugDescription: String {
        "UpdateDestinationOutputResponse()"}
}

extension UpdateDestinationOutputResponse: HttpResponseBinding {
    public init (httpResponse: HttpResponse, decoder: ResponseDecoder? = nil) throws {
    }
}

public struct UpdateDestinationOutputResponse: Equatable {

    public init() {}
}

struct UpdateDestinationOutputResponseBody: Equatable {
}

extension UpdateDestinationOutputResponseBody: Decodable {

    public init (from decoder: Decoder) throws {
    }
}

extension VpcConfiguration: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case roleARN = "RoleARN"
        case securityGroupIds = "SecurityGroupIds"
        case subnetIds = "SubnetIds"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let securityGroupIds = securityGroupIds {
            var securityGroupIdsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .securityGroupIds)
            for securitygroupidlist0 in securityGroupIds {
                try securityGroupIdsContainer.encode(securitygroupidlist0)
            }
        }
        if let subnetIds = subnetIds {
            var subnetIdsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .subnetIds)
            for subnetidlist0 in subnetIds {
                try subnetIdsContainer.encode(subnetidlist0)
            }
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let subnetIdsContainer = try containerValues.decodeIfPresent([String?].self, forKey: .subnetIds)
        var subnetIdsDecoded0:[String]? = nil
        if let subnetIdsContainer = subnetIdsContainer {
            subnetIdsDecoded0 = [String]()
            for string0 in subnetIdsContainer {
                if let string0 = string0 {
                    subnetIdsDecoded0?.append(string0)
                }
            }
        }
        subnetIds = subnetIdsDecoded0
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let securityGroupIdsContainer = try containerValues.decodeIfPresent([String?].self, forKey: .securityGroupIds)
        var securityGroupIdsDecoded0:[String]? = nil
        if let securityGroupIdsContainer = securityGroupIdsContainer {
            securityGroupIdsDecoded0 = [String]()
            for string0 in securityGroupIdsContainer {
                if let string0 = string0 {
                    securityGroupIdsDecoded0?.append(string0)
                }
            }
        }
        securityGroupIds = securityGroupIdsDecoded0
    }
}

extension VpcConfiguration: CustomDebugStringConvertible {
    public var debugDescription: String {
        "VpcConfiguration(roleARN: \(String(describing: roleARN)), securityGroupIds: \(String(describing: securityGroupIds)), subnetIds: \(String(describing: subnetIds)))"}
}

/// <p>The details of the VPC of the Amazon ES destination.</p>
public struct VpcConfiguration: Equatable {
    /// <p>The ARN of the IAM role that you want the delivery stream to use to create endpoints in
    ///          the destination VPC. You can use your existing Kinesis Data Firehose delivery role or you
    ///          can specify a new role. In either case, make sure that the role trusts the Kinesis Data
    ///          Firehose service principal and that it grants the following permissions:</p>
    ///          <ul>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DescribeVpcs</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DescribeVpcAttribute</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DescribeSubnets</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DescribeSecurityGroups</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DescribeNetworkInterfaces</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:CreateNetworkInterface</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:CreateNetworkInterfacePermission</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DeleteNetworkInterface</code>
    ///                </p>
    ///             </li>
    ///          </ul>
    ///          <p>If you revoke these permissions after you create the delivery stream, Kinesis Data
    ///          Firehose can't scale out by creating more ENIs when necessary. You might therefore see a
    ///          degradation in performance.</p>
    public let roleARN: String?
    /// <p>The IDs of the security groups that you want Kinesis Data Firehose to use when it
    ///          creates ENIs in the VPC of the Amazon ES destination. You can use the same security group
    ///          that the Amazon ES domain uses or different ones. If you specify different security groups
    ///          here, ensure that they allow outbound HTTPS traffic to the Amazon ES domain's security
    ///          group. Also ensure that the Amazon ES domain's security group allows HTTPS traffic from the
    ///          security groups specified here. If you use the same security group for both your delivery
    ///          stream and the Amazon ES domain, make sure the security group inbound rule allows HTTPS
    ///          traffic. For more information about security group rules, see <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules">Security group rules</a> in the Amazon VPC documentation.</p>
    public let securityGroupIds: [String]?
    /// <p>The IDs of the subnets that you want Kinesis Data Firehose to use to create ENIs in the
    ///          VPC of the Amazon ES destination. Make sure that the routing tables and inbound and
    ///          outbound rules allow traffic to flow from the subnets whose IDs are specified here to the
    ///          subnets that have the destination Amazon ES endpoints. Kinesis Data Firehose creates at
    ///          least one ENI in each of the subnets that are specified here. Do not delete or modify these
    ///          ENIs.</p>
    ///          <p>The number of ENIs that Kinesis Data Firehose creates in the subnets specified here
    ///          scales up and down automatically based on throughput. To enable Kinesis Data Firehose to
    ///          scale up the number of ENIs to match throughput, ensure that you have sufficient quota. To
    ///          help you calculate the quota you need, assume that Kinesis Data Firehose can create up to
    ///          three ENIs for this delivery stream for each of the subnets specified here. For more
    ///          information about ENI quota, see <a href="https://docs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html#vpc-limits-enis">Network Interfaces </a> in the Amazon VPC Quotas topic.</p>
    public let subnetIds: [String]?

    public init (
        roleARN: String? = nil,
        securityGroupIds: [String]? = nil,
        subnetIds: [String]? = nil
    )
    {
        self.roleARN = roleARN
        self.securityGroupIds = securityGroupIds
        self.subnetIds = subnetIds
    }
}

extension VpcConfigurationDescription: Codable, Reflection {
    enum CodingKeys: String, CodingKey {
        case roleARN = "RoleARN"
        case securityGroupIds = "SecurityGroupIds"
        case subnetIds = "SubnetIds"
        case vpcId = "VpcId"
    }

    public func encode(to encoder: Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let roleARN = roleARN {
            try encodeContainer.encode(roleARN, forKey: .roleARN)
        }
        if let securityGroupIds = securityGroupIds {
            var securityGroupIdsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .securityGroupIds)
            for securitygroupidlist0 in securityGroupIds {
                try securityGroupIdsContainer.encode(securitygroupidlist0)
            }
        }
        if let subnetIds = subnetIds {
            var subnetIdsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .subnetIds)
            for subnetidlist0 in subnetIds {
                try subnetIdsContainer.encode(subnetidlist0)
            }
        }
        if let vpcId = vpcId {
            try encodeContainer.encode(vpcId, forKey: .vpcId)
        }
    }

    public init (from decoder: Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let subnetIdsContainer = try containerValues.decodeIfPresent([String?].self, forKey: .subnetIds)
        var subnetIdsDecoded0:[String]? = nil
        if let subnetIdsContainer = subnetIdsContainer {
            subnetIdsDecoded0 = [String]()
            for string0 in subnetIdsContainer {
                if let string0 = string0 {
                    subnetIdsDecoded0?.append(string0)
                }
            }
        }
        subnetIds = subnetIdsDecoded0
        let roleARNDecoded = try containerValues.decodeIfPresent(String.self, forKey: .roleARN)
        roleARN = roleARNDecoded
        let securityGroupIdsContainer = try containerValues.decodeIfPresent([String?].self, forKey: .securityGroupIds)
        var securityGroupIdsDecoded0:[String]? = nil
        if let securityGroupIdsContainer = securityGroupIdsContainer {
            securityGroupIdsDecoded0 = [String]()
            for string0 in securityGroupIdsContainer {
                if let string0 = string0 {
                    securityGroupIdsDecoded0?.append(string0)
                }
            }
        }
        securityGroupIds = securityGroupIdsDecoded0
        let vpcIdDecoded = try containerValues.decodeIfPresent(String.self, forKey: .vpcId)
        vpcId = vpcIdDecoded
    }
}

extension VpcConfigurationDescription: CustomDebugStringConvertible {
    public var debugDescription: String {
        "VpcConfigurationDescription(roleARN: \(String(describing: roleARN)), securityGroupIds: \(String(describing: securityGroupIds)), subnetIds: \(String(describing: subnetIds)), vpcId: \(String(describing: vpcId)))"}
}

/// <p>The details of the VPC of the Amazon ES destination.</p>
public struct VpcConfigurationDescription: Equatable {
    /// <p>The ARN of the IAM role that the delivery stream uses to create endpoints in the
    ///          destination VPC. You can use your existing Kinesis Data Firehose delivery role or you can
    ///          specify a new role. In either case, make sure that the role trusts the Kinesis Data
    ///          Firehose service principal and that it grants the following permissions:</p>
    ///          <ul>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DescribeVpcs</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DescribeVpcAttribute</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DescribeSubnets</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DescribeSecurityGroups</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DescribeNetworkInterfaces</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:CreateNetworkInterface</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:CreateNetworkInterfacePermission</code>
    ///                </p>
    ///             </li>
    ///             <li>
    ///                <p>
    ///                   <code>ec2:DeleteNetworkInterface</code>
    ///                </p>
    ///             </li>
    ///          </ul>
    ///          <p>If you revoke these permissions after you create the delivery stream, Kinesis Data
    ///          Firehose can't scale out by creating more ENIs when necessary. You might therefore see a
    ///          degradation in performance.</p>
    public let roleARN: String?
    /// <p>The IDs of the security groups that Kinesis Data Firehose uses when it creates ENIs in
    ///          the VPC of the Amazon ES destination. You can use the same security group that the Amazon
    ///          ES domain uses or different ones. If you specify different security groups, ensure that
    ///          they allow outbound HTTPS traffic to the Amazon ES domain's security group. Also ensure
    ///          that the Amazon ES domain's security group allows HTTPS traffic from the security groups
    ///          specified here. If you use the same security group for both your delivery stream and the
    ///          Amazon ES domain, make sure the security group inbound rule allows HTTPS traffic. For more
    ///          information about security group rules, see <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules">Security group rules</a> in the Amazon VPC documentation.</p>
    public let securityGroupIds: [String]?
    /// <p>The IDs of the subnets that Kinesis Data Firehose uses to create ENIs in the VPC of the
    ///          Amazon ES destination. Make sure that the routing tables and inbound and outbound rules
    ///          allow traffic to flow from the subnets whose IDs are specified here to the subnets that
    ///          have the destination Amazon ES endpoints. Kinesis Data Firehose creates at least one ENI in
    ///          each of the subnets that are specified here. Do not delete or modify these ENIs.</p>
    ///          <p>The number of ENIs that Kinesis Data Firehose creates in the subnets specified here
    ///          scales up and down automatically based on throughput. To enable Kinesis Data Firehose to
    ///          scale up the number of ENIs to match throughput, ensure that you have sufficient quota. To
    ///          help you calculate the quota you need, assume that Kinesis Data Firehose can create up to
    ///          three ENIs for this delivery stream for each of the subnets specified here. For more
    ///          information about ENI quota, see <a href="https://docs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html#vpc-limits-enis">Network Interfaces </a> in the Amazon VPC Quotas topic.</p>
    public let subnetIds: [String]?
    /// <p>The ID of the Amazon ES destination's VPC.</p>
    public let vpcId: String?

    public init (
        roleARN: String? = nil,
        securityGroupIds: [String]? = nil,
        subnetIds: [String]? = nil,
        vpcId: String? = nil
    )
    {
        self.roleARN = roleARN
        self.securityGroupIds = securityGroupIds
        self.subnetIds = subnetIds
        self.vpcId = vpcId
    }
}
