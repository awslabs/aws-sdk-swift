// Code generated by smithy-swift-codegen. DO NOT EDIT!



/// <p>Provides information about the resource settings for a job that imports endpoint definitions from one or more files. The files can be stored in an Amazon Simple Storage Service (Amazon S3) bucket or uploaded directly from a computer by using the Amazon Pinpoint console.</p>
public struct ImportJobResource: Equatable {
    /// <p>Specifies whether the import job creates a segment that contains the endpoints, when the endpoint definitions are imported.</p>
    public let defineSegment: Bool
    /// <p>(Deprecated) Your AWS account ID, which you assigned to an external ID key in an IAM trust policy. Amazon Pinpoint previously used this value to assume an IAM role when importing endpoint definitions, but we removed this requirement. We don't recommend use of external IDs for IAM roles that are assumed by Amazon Pinpoint.</p>
    public let externalId: String?
    /// <p>The format of the files that contain the endpoint definitions to import. Valid values are: CSV, for comma-separated values format; and, JSON, for newline-delimited JSON format.</p> <p>If the files are stored in an Amazon S3 location and that location contains multiple files that use different formats, Amazon Pinpoint imports data only from the files that use the specified format.</p>
    public let format: Format?
    /// <p>Specifies whether the import job registers the endpoints with Amazon Pinpoint, when the endpoint definitions are imported.</p>
    public let registerEndpoints: Bool
    /// <p>The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that authorizes Amazon Pinpoint to access the Amazon S3 location to import endpoint definitions from.</p>
    public let roleArn: String?
    /// <p>The URL of the Amazon Simple Storage Service (Amazon S3) bucket that contains the endpoint definitions to import. This location can be a folder or a single file. If the location is a folder, Amazon Pinpoint imports endpoint definitions from the files in this location, including any subfolders that the folder contains.</p> <p>The URL should be in the following format: s3://<replaceable>bucket-name</replaceable>/<replaceable>folder-name</replaceable>/<replaceable>file-name</replaceable>. The location can end with the key for an individual object or a prefix that qualifies multiple objects.</p>
    public let s3Url: String?
    /// <p>The identifier for the segment that the import job updates or adds endpoint definitions to, if the import job updates an existing segment.</p>
    public let segmentId: String?
    /// <p>The custom name for the segment that's created by the import job, if the value of the DefineSegment property is true.</p>
    public let segmentName: String?

    public init (
        defineSegment: Bool = false,
        externalId: String? = nil,
        format: Format? = nil,
        registerEndpoints: Bool = false,
        roleArn: String? = nil,
        s3Url: String? = nil,
        segmentId: String? = nil,
        segmentName: String? = nil
    )
    {
        self.defineSegment = defineSegment
        self.externalId = externalId
        self.format = format
        self.registerEndpoints = registerEndpoints
        self.roleArn = roleArn
        self.s3Url = s3Url
        self.segmentId = segmentId
        self.segmentName = segmentName
    }
}

extension ImportJobResource: CustomDebugStringConvertible {
    public var debugDescription: String {
        "ImportJobResource(defineSegment: \(String(describing: defineSegment)), externalId: \(String(describing: externalId)), format: \(String(describing: format)), registerEndpoints: \(String(describing: registerEndpoints)), roleArn: \(String(describing: roleArn)), s3Url: \(String(describing: s3Url)), segmentId: \(String(describing: segmentId)), segmentName: \(String(describing: segmentName)))"}
}
