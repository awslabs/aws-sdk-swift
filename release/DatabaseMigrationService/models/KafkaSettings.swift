// Code generated by smithy-swift-codegen. DO NOT EDIT!



/// <p>Provides information that describes an Apache Kafka endpoint. This
///          information includes the output format of records applied to the endpoint and details of
///          transaction and control table data information.</p>
public struct KafkaSettings: Equatable {
    /// <p>A comma-separated list of one or more broker locations in your Kafka cluster that host your Kafka instance. Specify each broker location
    ///          in the form <code>
    ///                <i>broker-hostname-or-ip</i>:<i>port</i>
    ///             </code>. For example, <code>"ec2-12-345-678-901.compute-1.amazonaws.com:2345"</code>.
    ///          For more information and examples of specifying a list of broker locations,
    ///          see <a href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Kafka.html">Using Apache Kafka as a target for AWS Database Migration Service</a>
    ///          in the <i>AWS Data Migration Service User Guide</i>.
    ///       </p>
    public let broker: String?
    /// <p>Shows detailed control information for table definition, column definition, and table
    ///          and column changes in the Kafka message output. The default is <code>false</code>.</p>
    public let includeControlDetails: Bool?
    /// <p>Include NULL and empty columns for records migrated to the endpoint. The default is <code>false</code>.</p>
    public let includeNullAndEmpty: Bool?
    /// <p>Shows the partition value within the Kafka message output, unless the partition type is
    ///             <code>schema-table-type</code>. The default is <code>false</code>.</p>
    public let includePartitionValue: Bool?
    /// <p>Includes any data definition language (DDL) operations that change the table in the
    ///          control data, such as <code>rename-table</code>, <code>drop-table</code>,
    ///             <code>add-column</code>, <code>drop-column</code>, and <code>rename-column</code>. The
    ///          default is <code>false</code>.</p>
    public let includeTableAlterOperations: Bool?
    /// <p>Provides detailed transaction information from the source database. This information
    ///          includes a commit timestamp, a log position, and values for <code>transaction_id</code>,
    ///          previous <code>transaction_id</code>, and <code>transaction_record_id</code> (the record
    ///          offset within a transaction). The default is <code>false</code>.</p>
    public let includeTransactionDetails: Bool?
    /// <p>The output format for the records created on the endpoint. The message format is
    ///             <code>JSON</code> (default) or <code>JSON_UNFORMATTED</code> (a single line with no
    ///          tab).</p>
    public let messageFormat: MessageFormatValue?
    /// <p>The maximum size in bytes for records created on the endpoint The default is 1,000,000.</p>
    public let messageMaxBytes: Int?
    /// <p>Prefixes schema and table names to partition values, when the partition type is
    ///             <code>primary-key-type</code>. Doing this increases data distribution among Kafka
    ///          partitions. For example, suppose that a SysBench schema has thousands of tables and each
    ///          table has only limited range for a primary key. In this case, the same primary key is sent
    ///          from thousands of tables to the same partition, which causes throttling. The default is
    ///             <code>false</code>.</p>
    public let partitionIncludeSchemaTable: Bool?
    /// <p>The secure password you created when you first set up your MSK cluster to validate a client identity and
    ///          make an encrypted connection between server and client using SASL-SSL authentication.</p>
    public let saslPassword: String?
    /// <p> The secure username you created when you first set up your MSK cluster to validate a client identity and
    ///          make an encrypted connection between server and client using SASL-SSL authentication.</p>
    public let saslUsername: String?
    /// <p>Set secure connection to a Kafka target endpoint using Transport Layer Security (TLS). Options include
    ///          <code>ssl-encryption</code>, <code>ssl-authentication</code>, and <code>sasl-ssl</code>.
    ///          <code>sasl-ssl</code> requires <code>SaslUsername</code> and <code>SaslPassword</code>.</p>
    public let securityProtocol: KafkaSecurityProtocol?
    /// <p> The Amazon Resource Name (ARN) for the private Certification Authority (CA) cert that AWS DMS uses
    ///          to securely connect to your Kafka target endpoint.</p>
    public let sslCaCertificateArn: String?
    /// <p>The Amazon Resource Name (ARN) of the client certificate used to securely connect to a Kafka target endpoint.</p>
    public let sslClientCertificateArn: String?
    /// <p>The Amazon Resource Name (ARN) for the client private key used to securely connect to a Kafka target endpoint.</p>
    public let sslClientKeyArn: String?
    /// <p> The password for the client private key used to securely connect to a Kafka target endpoint.</p>
    public let sslClientKeyPassword: String?
    /// <p>The topic to which you migrate the data. If you don't specify a topic, AWS DMS
    ///          specifies <code>"kafka-default-topic"</code> as the migration topic.</p>
    public let topic: String?

    public init (
        broker: String? = nil,
        includeControlDetails: Bool? = nil,
        includeNullAndEmpty: Bool? = nil,
        includePartitionValue: Bool? = nil,
        includeTableAlterOperations: Bool? = nil,
        includeTransactionDetails: Bool? = nil,
        messageFormat: MessageFormatValue? = nil,
        messageMaxBytes: Int? = nil,
        partitionIncludeSchemaTable: Bool? = nil,
        saslPassword: String? = nil,
        saslUsername: String? = nil,
        securityProtocol: KafkaSecurityProtocol? = nil,
        sslCaCertificateArn: String? = nil,
        sslClientCertificateArn: String? = nil,
        sslClientKeyArn: String? = nil,
        sslClientKeyPassword: String? = nil,
        topic: String? = nil
    )
    {
        self.broker = broker
        self.includeControlDetails = includeControlDetails
        self.includeNullAndEmpty = includeNullAndEmpty
        self.includePartitionValue = includePartitionValue
        self.includeTableAlterOperations = includeTableAlterOperations
        self.includeTransactionDetails = includeTransactionDetails
        self.messageFormat = messageFormat
        self.messageMaxBytes = messageMaxBytes
        self.partitionIncludeSchemaTable = partitionIncludeSchemaTable
        self.saslPassword = saslPassword
        self.saslUsername = saslUsername
        self.securityProtocol = securityProtocol
        self.sslCaCertificateArn = sslCaCertificateArn
        self.sslClientCertificateArn = sslClientCertificateArn
        self.sslClientKeyArn = sslClientKeyArn
        self.sslClientKeyPassword = sslClientKeyPassword
        self.topic = topic
    }
}
