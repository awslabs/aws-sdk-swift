//
// Copyright Amazon.com Inc. or its affiliates.
// All Rights Reserved.
//
// SPDX-License-Identifier: Apache-2.0
//

// Code generated by smithy-swift-codegen. DO NOT EDIT!

@_spi(SmithyReadWrite) import ClientRuntime
import Foundation
import class SmithyHTTPAPI.HTTPResponse
@_spi(SmithyReadWrite) import class SmithyJSON.Reader
@_spi(SmithyReadWrite) import class SmithyJSON.Writer
import enum ClientRuntime.ErrorFault
import enum Smithy.ClientError
import enum SmithyReadWrite.ReaderError
@_spi(SmithyReadWrite) import enum SmithyReadWrite.ReadingClosures
@_spi(SmithyReadWrite) import enum SmithyReadWrite.WritingClosures
@_spi(SmithyTimestamps) import enum SmithyTimestamps.TimestampFormat
import protocol AWSClientRuntime.AWSServiceError
import protocol ClientRuntime.HTTPError
import protocol ClientRuntime.ModeledError
@_spi(SmithyReadWrite) import protocol SmithyReadWrite.SmithyReader
@_spi(SmithyReadWrite) import protocol SmithyReadWrite.SmithyWriter
@_spi(SmithyReadWrite) import struct AWSClientRuntime.RestJSONError
@_spi(UnknownAWSHTTPServiceError) import struct AWSClientRuntime.UnknownAWSHTTPServiceError
import struct Smithy.URIQueryItem
@_spi(SmithyReadWrite) import struct SmithyReadWrite.ReadingClosureBox
@_spi(SmithyReadWrite) import struct SmithyReadWrite.WritingClosureBox

extension PipesClientTypes {

    public enum AssignPublicIp: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case disabled
        case enabled
        case sdkUnknown(Swift.String)

        public static var allCases: [AssignPublicIp] {
            return [
                .disabled,
                .enabled
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .disabled: return "DISABLED"
            case .enabled: return "ENABLED"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// This structure specifies the VPC subnets and security groups for the task, and whether a public IP address is to be used. This structure is relevant only for ECS tasks that use the awsvpc network mode.
    public struct AwsVpcConfiguration: Swift.Sendable {
        /// Specifies whether the task's elastic network interface receives a public IP address. You can specify ENABLED only when LaunchType in EcsParameters is set to FARGATE.
        public var assignPublicIp: PipesClientTypes.AssignPublicIp?
        /// Specifies the security groups associated with the task. These security groups must all be in the same VPC. You can specify as many as five security groups. If you do not specify a security group, the default security group for the VPC is used.
        public var securityGroups: [Swift.String]?
        /// Specifies the subnets associated with the task. These subnets must all be in the same VPC. You can specify as many as 16 subnets.
        /// This member is required.
        public var subnets: [Swift.String]?

        public init(
            assignPublicIp: PipesClientTypes.AssignPublicIp? = nil,
            securityGroups: [Swift.String]? = nil,
            subnets: [Swift.String]? = nil
        )
        {
            self.assignPublicIp = assignPublicIp
            self.securityGroups = securityGroups
            self.subnets = subnets
        }
    }
}

extension PipesClientTypes.AwsVpcConfiguration: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "AwsVpcConfiguration(assignPublicIp: \(Swift.String(describing: assignPublicIp)), securityGroups: \"CONTENT_REDACTED\", subnets: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The array properties for the submitted job, such as the size of the array. The array size can be between 2 and 10,000. If you specify array properties for a job, it becomes an array job. This parameter is used only if the target is an Batch job.
    public struct BatchArrayProperties: Swift.Sendable {
        /// The size of the array, if this is an array batch job.
        public var size: Swift.Int?

        public init(
            size: Swift.Int? = nil
        )
        {
            self.size = size
        }
    }
}

extension PipesClientTypes {

    /// The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. Environment variables cannot start with "Batch". This naming convention is reserved for variables that Batch sets.
    public struct BatchEnvironmentVariable: Swift.Sendable {
        /// The name of the key-value pair. For environment variables, this is the name of the environment variable.
        public var name: Swift.String?
        /// The value of the key-value pair. For environment variables, this is the value of the environment variable.
        public var value: Swift.String?

        public init(
            name: Swift.String? = nil,
            value: Swift.String? = nil
        )
        {
            self.name = name
            self.value = value
        }
    }
}

extension PipesClientTypes {

    public enum BatchResourceRequirementType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case gpu
        case memory
        case vcpu
        case sdkUnknown(Swift.String)

        public static var allCases: [BatchResourceRequirementType] {
            return [
                .gpu,
                .memory,
                .vcpu
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .gpu: return "GPU"
            case .memory: return "MEMORY"
            case .vcpu: return "VCPU"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// The type and amount of a resource to assign to a container. The supported resources include GPU, MEMORY, and VCPU.
    public struct BatchResourceRequirement: Swift.Sendable {
        /// The type of resource to assign to a container. The supported resources include GPU, MEMORY, and VCPU.
        /// This member is required.
        public var type: PipesClientTypes.BatchResourceRequirementType?
        /// The quantity of the specified resource to reserve for the container. The values vary based on the type specified. type="GPU" The number of physical GPUs to reserve for the container. Make sure that the number of GPUs reserved for all containers in a job doesn't exceed the number of available GPUs on the compute resource that the job is launched on. GPUs aren't available for jobs that are running on Fargate resources. type="MEMORY" The memory hard limit (in MiB) present to the container. This parameter is supported for jobs that are running on EC2 resources. If your container attempts to exceed the memory specified, the container is terminated. This parameter maps to Memory in the [ Create a container](https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.docker.com/engine/api/v1.23/) and the --memory option to [docker run](https://docs.docker.com/engine/reference/run/). You must specify at least 4 MiB of memory for a job. This is required but can be specified in several places for multi-node parallel (MNP) jobs. It must be specified for each node at least once. This parameter maps to Memory in the [ Create a container](https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.docker.com/engine/api/v1.23/) and the --memory option to [docker run](https://docs.docker.com/engine/reference/run/). If you're trying to maximize your resource utilization by providing your jobs as much memory as possible for a particular instance type, see [Memory management](https://docs.aws.amazon.com/batch/latest/userguide/memory-management.html) in the Batch User Guide. For jobs that are running on Fargate resources, then value is the hard limit (in MiB), and must match one of the supported values and the VCPU values must be one of the values supported for that memory value. value = 512 VCPU = 0.25 value = 1024 VCPU = 0.25 or 0.5 value = 2048 VCPU = 0.25, 0.5, or 1 value = 3072 VCPU = 0.5, or 1 value = 4096 VCPU = 0.5, 1, or 2 value = 5120, 6144, or 7168 VCPU = 1 or 2 value = 8192 VCPU = 1, 2, 4, or 8 value = 9216, 10240, 11264, 12288, 13312, 14336, or 15360 VCPU = 2 or 4 value = 16384 VCPU = 2, 4, or 8 value = 17408, 18432, 19456, 21504, 22528, 23552, 25600, 26624, 27648, 29696, or 30720 VCPU = 4 value = 20480, 24576, or 28672 VCPU = 4 or 8 value = 36864, 45056, 53248, or 61440 VCPU = 8 value = 32768, 40960, 49152, or 57344 VCPU = 8 or 16 value = 65536, 73728, 81920, 90112, 98304, 106496, 114688, or 122880 VCPU = 16 type="VCPU" The number of vCPUs reserved for the container. This parameter maps to CpuShares in the [ Create a container](https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.docker.com/engine/api/v1.23/) and the --cpu-shares option to [docker run](https://docs.docker.com/engine/reference/run/). Each vCPU is equivalent to 1,024 CPU shares. For EC2 resources, you must specify at least one vCPU. This is required but can be specified in several places; it must be specified for each node at least once. The default for the Fargate On-Demand vCPU resource count quota is 6 vCPUs. For more information about Fargate quotas, see [Fargate quotas](https://docs.aws.amazon.com/general/latest/gr/ecs-service.html#service-quotas-fargate) in the Amazon Web Services General Reference. For jobs that are running on Fargate resources, then value must match one of the supported values and the MEMORY values must be one of the values supported for that VCPU value. The supported values are 0.25, 0.5, 1, 2, 4, 8, and 16 value = 0.25 MEMORY = 512, 1024, or 2048 value = 0.5 MEMORY = 1024, 2048, 3072, or 4096 value = 1 MEMORY = 2048, 3072, 4096, 5120, 6144, 7168, or 8192 value = 2 MEMORY = 4096, 5120, 6144, 7168, 8192, 9216, 10240, 11264, 12288, 13312, 14336, 15360, or 16384 value = 4 MEMORY = 8192, 9216, 10240, 11264, 12288, 13312, 14336, 15360, 16384, 17408, 18432, 19456, 20480, 21504, 22528, 23552, 24576, 25600, 26624, 27648, 28672, 29696, or 30720 value = 8 MEMORY = 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056, 49152, 53248, 57344, or 61440 value = 16 MEMORY = 32768, 40960, 49152, 57344, 65536, 73728, 81920, 90112, 98304, 106496, 114688, or 122880
        /// This member is required.
        public var value: Swift.String?

        public init(
            type: PipesClientTypes.BatchResourceRequirementType? = nil,
            value: Swift.String? = nil
        )
        {
            self.type = type
            self.value = value
        }
    }
}

extension PipesClientTypes {

    /// The overrides that are sent to a container.
    public struct BatchContainerOverrides: Swift.Sendable {
        /// The command to send to the container that overrides the default command from the Docker image or the task definition.
        public var command: [Swift.String]?
        /// The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. Environment variables cannot start with "Batch". This naming convention is reserved for variables that Batch sets.
        public var environment: [PipesClientTypes.BatchEnvironmentVariable]?
        /// The instance type to use for a multi-node parallel job. This parameter isn't applicable to single-node container jobs or jobs that run on Fargate resources, and shouldn't be provided.
        public var instanceType: Swift.String?
        /// The type and amount of resources to assign to a container. This overrides the settings in the job definition. The supported resources include GPU, MEMORY, and VCPU.
        public var resourceRequirements: [PipesClientTypes.BatchResourceRequirement]?

        public init(
            command: [Swift.String]? = nil,
            environment: [PipesClientTypes.BatchEnvironmentVariable]? = nil,
            instanceType: Swift.String? = nil,
            resourceRequirements: [PipesClientTypes.BatchResourceRequirement]? = nil
        )
        {
            self.command = command
            self.environment = environment
            self.instanceType = instanceType
            self.resourceRequirements = resourceRequirements
        }
    }
}

extension PipesClientTypes {

    public enum BatchJobDependencyType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case nToN
        case sequential
        case sdkUnknown(Swift.String)

        public static var allCases: [BatchJobDependencyType] {
            return [
                .nToN,
                .sequential
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .nToN: return "N_TO_N"
            case .sequential: return "SEQUENTIAL"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// An object that represents an Batch job dependency.
    public struct BatchJobDependency: Swift.Sendable {
        /// The job ID of the Batch job that's associated with this dependency.
        public var jobId: Swift.String?
        /// The type of the job dependency.
        public var type: PipesClientTypes.BatchJobDependencyType?

        public init(
            jobId: Swift.String? = nil,
            type: PipesClientTypes.BatchJobDependencyType? = nil
        )
        {
            self.jobId = jobId
            self.type = type
        }
    }
}

extension PipesClientTypes {

    /// The retry strategy that's associated with a job. For more information, see [ Automated job retries](https://docs.aws.amazon.com/batch/latest/userguide/job_retries.html) in the Batch User Guide.
    public struct BatchRetryStrategy: Swift.Sendable {
        /// The number of times to move a job to the RUNNABLE status. If the value of attempts is greater than one, the job is retried on failure the same number of attempts as the value.
        public var attempts: Swift.Int?

        public init(
            attempts: Swift.Int? = nil
        )
        {
            self.attempts = attempts
        }
    }
}

extension PipesClientTypes {

    /// The details of a capacity provider strategy. To learn more, see [CapacityProviderStrategyItem](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CapacityProviderStrategyItem.html) in the Amazon ECS API Reference.
    public struct CapacityProviderStrategyItem: Swift.Sendable {
        /// The base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.
        public var base: Swift.Int
        /// The short name of the capacity provider.
        /// This member is required.
        public var capacityProvider: Swift.String?
        /// The weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.
        public var weight: Swift.Int

        public init(
            base: Swift.Int = 0,
            capacityProvider: Swift.String? = nil,
            weight: Swift.Int = 0
        )
        {
            self.base = base
            self.capacityProvider = capacityProvider
            self.weight = weight
        }
    }
}

extension PipesClientTypes.CapacityProviderStrategyItem: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "CapacityProviderStrategyItem(base: \(Swift.String(describing: base)), weight: \(Swift.String(describing: weight)), capacityProvider: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The Amazon CloudWatch Logs logging configuration settings for the pipe.
    public struct CloudwatchLogsLogDestination: Swift.Sendable {
        /// The Amazon Web Services Resource Name (ARN) for the CloudWatch log group to which EventBridge sends the log records.
        public var logGroupArn: Swift.String?

        public init(
            logGroupArn: Swift.String? = nil
        )
        {
            self.logGroupArn = logGroupArn
        }
    }
}

extension PipesClientTypes {

    /// The Amazon CloudWatch Logs logging configuration settings for the pipe.
    public struct CloudwatchLogsLogDestinationParameters: Swift.Sendable {
        /// The Amazon Web Services Resource Name (ARN) for the CloudWatch log group to which EventBridge sends the log records.
        /// This member is required.
        public var logGroupArn: Swift.String?

        public init(
            logGroupArn: Swift.String? = nil
        )
        {
            self.logGroupArn = logGroupArn
        }
    }
}

/// An action you attempted resulted in an exception.
public struct ConflictException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error {

    public struct Properties {
        /// This member is required.
        public internal(set) var message: Swift.String? = nil
        /// The ID of the resource that caused the exception.
        /// This member is required.
        public internal(set) var resourceId: Swift.String? = nil
        /// The type of resource that caused the exception.
        /// This member is required.
        public internal(set) var resourceType: Swift.String? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "ConflictException" }
    public static var fault: ClientRuntime.ErrorFault { .client }
    public static var isRetryable: Swift.Bool { false }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil,
        resourceId: Swift.String? = nil,
        resourceType: Swift.String? = nil
    )
    {
        self.properties.message = message
        self.properties.resourceId = resourceId
        self.properties.resourceType = resourceType
    }
}

/// This exception occurs due to unexpected causes.
public struct InternalException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error {

    public struct Properties {
        /// This member is required.
        public internal(set) var message: Swift.String? = nil
        /// The number of seconds to wait before retrying the action that caused the exception.
        public internal(set) var retryAfterSeconds: Swift.Int? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "InternalException" }
    public static var fault: ClientRuntime.ErrorFault { .server }
    public static var isRetryable: Swift.Bool { false }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil,
        retryAfterSeconds: Swift.Int? = nil
    )
    {
        self.properties.message = message
        self.properties.retryAfterSeconds = retryAfterSeconds
    }
}

/// An entity that you specified does not exist.
public struct NotFoundException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error {

    public struct Properties {
        public internal(set) var message: Swift.String? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "NotFoundException" }
    public static var fault: ClientRuntime.ErrorFault { .client }
    public static var isRetryable: Swift.Bool { false }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil
    )
    {
        self.properties.message = message
    }
}

/// A quota has been exceeded.
public struct ServiceQuotaExceededException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error {

    public struct Properties {
        /// This member is required.
        public internal(set) var message: Swift.String? = nil
        /// The identifier of the quota that caused the exception.
        /// This member is required.
        public internal(set) var quotaCode: Swift.String? = nil
        /// The ID of the resource that caused the exception.
        /// This member is required.
        public internal(set) var resourceId: Swift.String? = nil
        /// The type of resource that caused the exception.
        /// This member is required.
        public internal(set) var resourceType: Swift.String? = nil
        /// The identifier of the service that caused the exception.
        /// This member is required.
        public internal(set) var serviceCode: Swift.String? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "ServiceQuotaExceededException" }
    public static var fault: ClientRuntime.ErrorFault { .client }
    public static var isRetryable: Swift.Bool { false }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil,
        quotaCode: Swift.String? = nil,
        resourceId: Swift.String? = nil,
        resourceType: Swift.String? = nil,
        serviceCode: Swift.String? = nil
    )
    {
        self.properties.message = message
        self.properties.quotaCode = quotaCode
        self.properties.resourceId = resourceId
        self.properties.resourceType = resourceType
        self.properties.serviceCode = serviceCode
    }
}

/// An action was throttled.
public struct ThrottlingException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error {

    public struct Properties {
        /// This member is required.
        public internal(set) var message: Swift.String? = nil
        /// The identifier of the quota that caused the exception.
        public internal(set) var quotaCode: Swift.String? = nil
        /// The number of seconds to wait before retrying the action that caused the exception.
        public internal(set) var retryAfterSeconds: Swift.Int? = nil
        /// The identifier of the service that caused the exception.
        public internal(set) var serviceCode: Swift.String? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "ThrottlingException" }
    public static var fault: ClientRuntime.ErrorFault { .client }
    public static var isRetryable: Swift.Bool { false }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil,
        quotaCode: Swift.String? = nil,
        retryAfterSeconds: Swift.Int? = nil,
        serviceCode: Swift.String? = nil
    )
    {
        self.properties.message = message
        self.properties.quotaCode = quotaCode
        self.properties.retryAfterSeconds = retryAfterSeconds
        self.properties.serviceCode = serviceCode
    }
}

extension PipesClientTypes {

    /// Indicates that an error has occurred while performing a validate operation.
    public struct ValidationExceptionField: Swift.Sendable {
        /// The message of the exception.
        /// This member is required.
        public var message: Swift.String?
        /// The name of the exception.
        /// This member is required.
        public var name: Swift.String?

        public init(
            message: Swift.String? = nil,
            name: Swift.String? = nil
        )
        {
            self.message = message
            self.name = name
        }
    }
}

/// Indicates that an error has occurred while performing a validate operation.
public struct ValidationException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error {

    public struct Properties {
        /// The list of fields for which validation failed and the corresponding failure messages.
        public internal(set) var fieldList: [PipesClientTypes.ValidationExceptionField]? = nil
        public internal(set) var message: Swift.String? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "ValidationException" }
    public static var fault: ClientRuntime.ErrorFault { .client }
    public static var isRetryable: Swift.Bool { false }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        fieldList: [PipesClientTypes.ValidationExceptionField]? = nil,
        message: Swift.String? = nil
    )
    {
        self.properties.fieldList = fieldList
        self.properties.message = message
    }
}

extension PipesClientTypes {

    public enum RequestedPipeState: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case running
        case stopped
        case sdkUnknown(Swift.String)

        public static var allCases: [RequestedPipeState] {
            return [
                .running,
                .stopped
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .running: return "RUNNING"
            case .stopped: return "STOPPED"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// These are custom parameter to be used when the target is an API Gateway REST APIs or EventBridge ApiDestinations. In the latter case, these are merged with any InvocationParameters specified on the Connection, with any values from the Connection taking precedence.
    public struct PipeEnrichmentHttpParameters: Swift.Sendable {
        /// The headers that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        public var headerParameters: [Swift.String: Swift.String]?
        /// The path parameter values to be used to populate API Gateway REST API or EventBridge ApiDestination path wildcards ("*").
        public var pathParameterValues: [Swift.String]?
        /// The query string keys/values that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        public var queryStringParameters: [Swift.String: Swift.String]?

        public init(
            headerParameters: [Swift.String: Swift.String]? = nil,
            pathParameterValues: [Swift.String]? = nil,
            queryStringParameters: [Swift.String: Swift.String]? = nil
        )
        {
            self.headerParameters = headerParameters
            self.pathParameterValues = pathParameterValues
            self.queryStringParameters = queryStringParameters
        }
    }
}

extension PipesClientTypes.PipeEnrichmentHttpParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeEnrichmentHttpParameters(headerParameters: [keys: \(Swift.String(describing: headerParameters?.keys)), values: \"CONTENT_REDACTED\"], pathParameterValues: \"CONTENT_REDACTED\", queryStringParameters: [keys: \(Swift.String(describing: queryStringParameters?.keys)), values: \"CONTENT_REDACTED\"])"}
}

extension PipesClientTypes {

    /// The parameters required to set up enrichment on your pipe.
    public struct PipeEnrichmentParameters: Swift.Sendable {
        /// Contains the HTTP parameters to use when the target is a API Gateway REST endpoint or EventBridge ApiDestination. If you specify an API Gateway REST API or EventBridge ApiDestination as a target, you can use this parameter to specify headers, path parameters, and query string keys/values as part of your target invoking request. If you're using ApiDestinations, the corresponding Connection can also have these values configured. In case of any conflicting keys, values from the Connection take precedence.
        public var httpParameters: PipesClientTypes.PipeEnrichmentHttpParameters?
        /// Valid JSON text passed to the enrichment. In this case, nothing from the event itself is passed to the enrichment. For more information, see [The JavaScript Object Notation (JSON) Data Interchange Format](http://www.rfc-editor.org/rfc/rfc7159.txt). To remove an input template, specify an empty string.
        public var inputTemplate: Swift.String?

        public init(
            httpParameters: PipesClientTypes.PipeEnrichmentHttpParameters? = nil,
            inputTemplate: Swift.String? = nil
        )
        {
            self.httpParameters = httpParameters
            self.inputTemplate = inputTemplate
        }
    }
}

extension PipesClientTypes.PipeEnrichmentParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeEnrichmentParameters(httpParameters: \(Swift.String(describing: httpParameters)), inputTemplate: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The Amazon Data Firehose logging configuration settings for the pipe.
    public struct FirehoseLogDestinationParameters: Swift.Sendable {
        /// Specifies the Amazon Resource Name (ARN) of the Firehose delivery stream to which EventBridge delivers the pipe log records.
        /// This member is required.
        public var deliveryStreamArn: Swift.String?

        public init(
            deliveryStreamArn: Swift.String? = nil
        )
        {
            self.deliveryStreamArn = deliveryStreamArn
        }
    }
}

extension PipesClientTypes {

    public enum IncludeExecutionDataOption: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case all
        case sdkUnknown(Swift.String)

        public static var allCases: [IncludeExecutionDataOption] {
            return [
                .all
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .all: return "ALL"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    public enum LogLevel: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case error
        case info
        case off
        case trace
        case sdkUnknown(Swift.String)

        public static var allCases: [LogLevel] {
            return [
                .error,
                .info,
                .off,
                .trace
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .error: return "ERROR"
            case .info: return "INFO"
            case .off: return "OFF"
            case .trace: return "TRACE"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    public enum S3OutputFormat: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case json
        case plain
        case w3c
        case sdkUnknown(Swift.String)

        public static var allCases: [S3OutputFormat] {
            return [
                .json,
                .plain,
                .w3c
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .json: return "json"
            case .plain: return "plain"
            case .w3c: return "w3c"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// The Amazon S3 logging configuration settings for the pipe.
    public struct S3LogDestinationParameters: Swift.Sendable {
        /// Specifies the name of the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.
        /// This member is required.
        public var bucketName: Swift.String?
        /// Specifies the Amazon Web Services account that owns the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.
        /// This member is required.
        public var bucketOwner: Swift.String?
        /// How EventBridge should format the log records. EventBridge currently only supports json formatting.
        public var outputFormat: PipesClientTypes.S3OutputFormat?
        /// Specifies any prefix text with which to begin Amazon S3 log object names. You can use prefixes to organize the data that you store in Amazon S3 buckets. A prefix is a string of characters at the beginning of the object key name. A prefix can be any length, subject to the maximum length of the object key name (1,024 bytes). For more information, see [Organizing objects using prefixes](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-prefixes.html) in the Amazon Simple Storage Service User Guide.
        public var `prefix`: Swift.String?

        public init(
            bucketName: Swift.String? = nil,
            bucketOwner: Swift.String? = nil,
            outputFormat: PipesClientTypes.S3OutputFormat? = nil,
            `prefix`: Swift.String? = nil
        )
        {
            self.bucketName = bucketName
            self.bucketOwner = bucketOwner
            self.outputFormat = outputFormat
            self.`prefix` = `prefix`
        }
    }
}

extension PipesClientTypes {

    /// Specifies the logging configuration settings for the pipe. When you call UpdatePipe, EventBridge updates the fields in the PipeLogConfigurationParameters object atomically as one and overrides existing values. This is by design. If you don't specify an optional field in any of the Amazon Web Services service parameters objects (CloudwatchLogsLogDestinationParameters, FirehoseLogDestinationParameters, or S3LogDestinationParameters), EventBridge sets that field to its system-default value during the update. For example, suppose when you created the pipe you specified a Firehose stream log destination. You then update the pipe to add an Amazon S3 log destination. In addition to specifying the S3LogDestinationParameters for the new log destination, you must also specify the fields in the FirehoseLogDestinationParameters object in order to retain the Firehose stream log destination. For more information on generating pipe log records, see [Log EventBridge Pipes] in the Amazon EventBridge User Guide.
    public struct PipeLogConfigurationParameters: Swift.Sendable {
        /// The Amazon CloudWatch Logs logging configuration settings for the pipe.
        public var cloudwatchLogsLogDestination: PipesClientTypes.CloudwatchLogsLogDestinationParameters?
        /// The Amazon Data Firehose logging configuration settings for the pipe.
        public var firehoseLogDestination: PipesClientTypes.FirehoseLogDestinationParameters?
        /// Specify ALL to include the execution data (specifically, the payload, awsRequest, and awsResponse fields) in the log messages for this pipe. This applies to all log destinations for the pipe. For more information, see [Including execution data in logs](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-logs.html#eb-pipes-logs-execution-data) in the Amazon EventBridge User Guide. By default, execution data is not included.
        public var includeExecutionData: [PipesClientTypes.IncludeExecutionDataOption]?
        /// The level of logging detail to include. This applies to all log destinations for the pipe. For more information, see [Specifying EventBridge Pipes log level](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-logs.html#eb-pipes-logs-level) in the Amazon EventBridge User Guide.
        /// This member is required.
        public var level: PipesClientTypes.LogLevel?
        /// The Amazon S3 logging configuration settings for the pipe.
        public var s3LogDestination: PipesClientTypes.S3LogDestinationParameters?

        public init(
            cloudwatchLogsLogDestination: PipesClientTypes.CloudwatchLogsLogDestinationParameters? = nil,
            firehoseLogDestination: PipesClientTypes.FirehoseLogDestinationParameters? = nil,
            includeExecutionData: [PipesClientTypes.IncludeExecutionDataOption]? = nil,
            level: PipesClientTypes.LogLevel? = nil,
            s3LogDestination: PipesClientTypes.S3LogDestinationParameters? = nil
        )
        {
            self.cloudwatchLogsLogDestination = cloudwatchLogsLogDestination
            self.firehoseLogDestination = firehoseLogDestination
            self.includeExecutionData = includeExecutionData
            self.level = level
            self.s3LogDestination = s3LogDestination
        }
    }
}

extension PipesClientTypes {

    /// The Secrets Manager secret that stores your broker credentials.
    public enum MQBrokerAccessCredentials: Swift.Sendable {
        /// The ARN of the Secrets Manager secret.
        case basicauth(Swift.String)
        case sdkUnknown(Swift.String)
    }
}

extension PipesClientTypes {

    /// The parameters for using an Active MQ broker as a source.
    public struct PipeSourceActiveMQBrokerParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// The credentials needed to access the resource.
        /// This member is required.
        public var credentials: PipesClientTypes.MQBrokerAccessCredentials?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?
        /// The name of the destination queue to consume.
        /// This member is required.
        public var queueName: Swift.String?

        public init(
            batchSize: Swift.Int? = nil,
            credentials: PipesClientTypes.MQBrokerAccessCredentials? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil,
            queueName: Swift.String? = nil
        )
        {
            self.batchSize = batchSize
            self.credentials = credentials
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
            self.queueName = queueName
        }
    }
}

extension PipesClientTypes.PipeSourceActiveMQBrokerParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeSourceActiveMQBrokerParameters(batchSize: \(Swift.String(describing: batchSize)), credentials: \(Swift.String(describing: credentials)), maximumBatchingWindowInSeconds: \(Swift.String(describing: maximumBatchingWindowInSeconds)), queueName: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// A DeadLetterConfig object that contains information about a dead-letter queue configuration.
    public struct DeadLetterConfig: Swift.Sendable {
        /// The ARN of the specified target for the dead-letter queue. For Amazon Kinesis stream and Amazon DynamoDB stream sources, specify either an Amazon SNS topic or Amazon SQS queue ARN.
        public var arn: Swift.String?

        public init(
            arn: Swift.String? = nil
        )
        {
            self.arn = arn
        }
    }
}

extension PipesClientTypes {

    public enum OnPartialBatchItemFailureStreams: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case automaticBisect
        case sdkUnknown(Swift.String)

        public static var allCases: [OnPartialBatchItemFailureStreams] {
            return [
                .automaticBisect
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .automaticBisect: return "AUTOMATIC_BISECT"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    public enum DynamoDBStreamStartPosition: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case latest
        case trimHorizon
        case sdkUnknown(Swift.String)

        public static var allCases: [DynamoDBStreamStartPosition] {
            return [
                .latest,
                .trimHorizon
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .latest: return "LATEST"
            case .trimHorizon: return "TRIM_HORIZON"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using a DynamoDB stream as a source.
    public struct PipeSourceDynamoDBStreamParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// Define the target queue to send dead-letter queue events to.
        public var deadLetterConfig: PipesClientTypes.DeadLetterConfig?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?
        /// Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.
        public var maximumRecordAgeInSeconds: Swift.Int?
        /// Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.
        public var maximumRetryAttempts: Swift.Int?
        /// Define how to handle item process failures. AUTOMATIC_BISECT halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.
        public var onPartialBatchItemFailure: PipesClientTypes.OnPartialBatchItemFailureStreams?
        /// The number of batches to process concurrently from each shard. The default value is 1.
        public var parallelizationFactor: Swift.Int?
        /// The position in a stream from which to start reading.
        /// This member is required.
        public var startingPosition: PipesClientTypes.DynamoDBStreamStartPosition?

        public init(
            batchSize: Swift.Int? = nil,
            deadLetterConfig: PipesClientTypes.DeadLetterConfig? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil,
            maximumRecordAgeInSeconds: Swift.Int? = nil,
            maximumRetryAttempts: Swift.Int? = nil,
            onPartialBatchItemFailure: PipesClientTypes.OnPartialBatchItemFailureStreams? = nil,
            parallelizationFactor: Swift.Int? = nil,
            startingPosition: PipesClientTypes.DynamoDBStreamStartPosition? = nil
        )
        {
            self.batchSize = batchSize
            self.deadLetterConfig = deadLetterConfig
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
            self.maximumRecordAgeInSeconds = maximumRecordAgeInSeconds
            self.maximumRetryAttempts = maximumRetryAttempts
            self.onPartialBatchItemFailure = onPartialBatchItemFailure
            self.parallelizationFactor = parallelizationFactor
            self.startingPosition = startingPosition
        }
    }
}

extension PipesClientTypes {

    /// Filter events using an event pattern. For more information, see [Events and Event Patterns](https://docs.aws.amazon.com/eventbridge/latest/userguide/eventbridge-and-event-patterns.html) in the Amazon EventBridge User Guide.
    public struct Filter: Swift.Sendable {
        /// The event pattern.
        public var pattern: Swift.String?

        public init(
            pattern: Swift.String? = nil
        )
        {
            self.pattern = pattern
        }
    }
}

extension PipesClientTypes.Filter: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "Filter(pattern: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The collection of event patterns used to filter events. To remove a filter, specify a FilterCriteria object with an empty array of Filter objects. For more information, see [Events and Event Patterns](https://docs.aws.amazon.com/eventbridge/latest/userguide/eventbridge-and-event-patterns.html) in the Amazon EventBridge User Guide.
    public struct FilterCriteria: Swift.Sendable {
        /// The event patterns.
        public var filters: [PipesClientTypes.Filter]?

        public init(
            filters: [PipesClientTypes.Filter]? = nil
        )
        {
            self.filters = filters
        }
    }
}

extension PipesClientTypes {

    public enum KinesisStreamStartPosition: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case atTimestamp
        case latest
        case trimHorizon
        case sdkUnknown(Swift.String)

        public static var allCases: [KinesisStreamStartPosition] {
            return [
                .atTimestamp,
                .latest,
                .trimHorizon
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .atTimestamp: return "AT_TIMESTAMP"
            case .latest: return "LATEST"
            case .trimHorizon: return "TRIM_HORIZON"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using a Kinesis stream as a source.
    public struct PipeSourceKinesisStreamParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// Define the target queue to send dead-letter queue events to.
        public var deadLetterConfig: PipesClientTypes.DeadLetterConfig?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?
        /// Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.
        public var maximumRecordAgeInSeconds: Swift.Int?
        /// Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.
        public var maximumRetryAttempts: Swift.Int?
        /// Define how to handle item process failures. AUTOMATIC_BISECT halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.
        public var onPartialBatchItemFailure: PipesClientTypes.OnPartialBatchItemFailureStreams?
        /// The number of batches to process concurrently from each shard. The default value is 1.
        public var parallelizationFactor: Swift.Int?
        /// The position in a stream from which to start reading.
        /// This member is required.
        public var startingPosition: PipesClientTypes.KinesisStreamStartPosition?
        /// With StartingPosition set to AT_TIMESTAMP, the time from which to start reading, in Unix time seconds.
        public var startingPositionTimestamp: Foundation.Date?

        public init(
            batchSize: Swift.Int? = nil,
            deadLetterConfig: PipesClientTypes.DeadLetterConfig? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil,
            maximumRecordAgeInSeconds: Swift.Int? = nil,
            maximumRetryAttempts: Swift.Int? = nil,
            onPartialBatchItemFailure: PipesClientTypes.OnPartialBatchItemFailureStreams? = nil,
            parallelizationFactor: Swift.Int? = nil,
            startingPosition: PipesClientTypes.KinesisStreamStartPosition? = nil,
            startingPositionTimestamp: Foundation.Date? = nil
        )
        {
            self.batchSize = batchSize
            self.deadLetterConfig = deadLetterConfig
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
            self.maximumRecordAgeInSeconds = maximumRecordAgeInSeconds
            self.maximumRetryAttempts = maximumRetryAttempts
            self.onPartialBatchItemFailure = onPartialBatchItemFailure
            self.parallelizationFactor = parallelizationFactor
            self.startingPosition = startingPosition
            self.startingPositionTimestamp = startingPositionTimestamp
        }
    }
}

extension PipesClientTypes {

    /// The Secrets Manager secret that stores your stream credentials.
    public enum MSKAccessCredentials: Swift.Sendable {
        /// The ARN of the Secrets Manager secret.
        case saslscram512auth(Swift.String)
        /// The ARN of the Secrets Manager secret.
        case clientcertificatetlsauth(Swift.String)
        case sdkUnknown(Swift.String)
    }
}

extension PipesClientTypes {

    public enum MSKStartPosition: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case latest
        case trimHorizon
        case sdkUnknown(Swift.String)

        public static var allCases: [MSKStartPosition] {
            return [
                .latest,
                .trimHorizon
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .latest: return "LATEST"
            case .trimHorizon: return "TRIM_HORIZON"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using an MSK stream as a source.
    public struct PipeSourceManagedStreamingKafkaParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// The name of the destination queue to consume.
        public var consumerGroupID: Swift.String?
        /// The credentials needed to access the resource.
        public var credentials: PipesClientTypes.MSKAccessCredentials?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?
        /// The position in a stream from which to start reading.
        public var startingPosition: PipesClientTypes.MSKStartPosition?
        /// The name of the topic that the pipe will read from.
        /// This member is required.
        public var topicName: Swift.String?

        public init(
            batchSize: Swift.Int? = nil,
            consumerGroupID: Swift.String? = nil,
            credentials: PipesClientTypes.MSKAccessCredentials? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil,
            startingPosition: PipesClientTypes.MSKStartPosition? = nil,
            topicName: Swift.String? = nil
        )
        {
            self.batchSize = batchSize
            self.consumerGroupID = consumerGroupID
            self.credentials = credentials
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
            self.startingPosition = startingPosition
            self.topicName = topicName
        }
    }
}

extension PipesClientTypes.PipeSourceManagedStreamingKafkaParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeSourceManagedStreamingKafkaParameters(batchSize: \(Swift.String(describing: batchSize)), credentials: \(Swift.String(describing: credentials)), maximumBatchingWindowInSeconds: \(Swift.String(describing: maximumBatchingWindowInSeconds)), startingPosition: \(Swift.String(describing: startingPosition)), consumerGroupID: \"CONTENT_REDACTED\", topicName: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The parameters for using a Rabbit MQ broker as a source.
    public struct PipeSourceRabbitMQBrokerParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// The credentials needed to access the resource.
        /// This member is required.
        public var credentials: PipesClientTypes.MQBrokerAccessCredentials?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?
        /// The name of the destination queue to consume.
        /// This member is required.
        public var queueName: Swift.String?
        /// The name of the virtual host associated with the source broker.
        public var virtualHost: Swift.String?

        public init(
            batchSize: Swift.Int? = nil,
            credentials: PipesClientTypes.MQBrokerAccessCredentials? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil,
            queueName: Swift.String? = nil,
            virtualHost: Swift.String? = nil
        )
        {
            self.batchSize = batchSize
            self.credentials = credentials
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
            self.queueName = queueName
            self.virtualHost = virtualHost
        }
    }
}

extension PipesClientTypes.PipeSourceRabbitMQBrokerParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeSourceRabbitMQBrokerParameters(batchSize: \(Swift.String(describing: batchSize)), credentials: \(Swift.String(describing: credentials)), maximumBatchingWindowInSeconds: \(Swift.String(describing: maximumBatchingWindowInSeconds)), queueName: \"CONTENT_REDACTED\", virtualHost: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The Secrets Manager secret that stores your stream credentials.
    public enum SelfManagedKafkaAccessConfigurationCredentials: Swift.Sendable {
        /// The ARN of the Secrets Manager secret.
        case basicauth(Swift.String)
        /// The ARN of the Secrets Manager secret.
        case saslscram512auth(Swift.String)
        /// The ARN of the Secrets Manager secret.
        case saslscram256auth(Swift.String)
        /// The ARN of the Secrets Manager secret.
        case clientcertificatetlsauth(Swift.String)
        case sdkUnknown(Swift.String)
    }
}

extension PipesClientTypes {

    public enum SelfManagedKafkaStartPosition: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case latest
        case trimHorizon
        case sdkUnknown(Swift.String)

        public static var allCases: [SelfManagedKafkaStartPosition] {
            return [
                .latest,
                .trimHorizon
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .latest: return "LATEST"
            case .trimHorizon: return "TRIM_HORIZON"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// This structure specifies the VPC subnets and security groups for the stream, and whether a public IP address is to be used.
    public struct SelfManagedKafkaAccessConfigurationVpc: Swift.Sendable {
        /// Specifies the security groups associated with the stream. These security groups must all be in the same VPC. You can specify as many as five security groups.
        public var securityGroup: [Swift.String]?
        /// Specifies the subnets associated with the stream. These subnets must all be in the same VPC. You can specify as many as 16 subnets.
        public var subnets: [Swift.String]?

        public init(
            securityGroup: [Swift.String]? = nil,
            subnets: [Swift.String]? = nil
        )
        {
            self.securityGroup = securityGroup
            self.subnets = subnets
        }
    }
}

extension PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "SelfManagedKafkaAccessConfigurationVpc(securityGroup: \"CONTENT_REDACTED\", subnets: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The parameters for using a self-managed Apache Kafka stream as a source. A self managed cluster refers to any Apache Kafka cluster not hosted by Amazon Web Services. This includes both clusters you manage yourself, as well as those hosted by a third-party provider, such as [Confluent Cloud](https://www.confluent.io/), [CloudKarafka](https://www.cloudkarafka.com/), or [Redpanda](https://redpanda.com/). For more information, see [Apache Kafka streams as a source](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-kafka.html) in the Amazon EventBridge User Guide.
    public struct PipeSourceSelfManagedKafkaParameters: Swift.Sendable {
        /// An array of server URLs.
        public var additionalBootstrapServers: [Swift.String]?
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// The name of the destination queue to consume.
        public var consumerGroupID: Swift.String?
        /// The credentials needed to access the resource.
        public var credentials: PipesClientTypes.SelfManagedKafkaAccessConfigurationCredentials?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?
        /// The ARN of the Secrets Manager secret used for certification.
        public var serverRootCaCertificate: Swift.String?
        /// The position in a stream from which to start reading.
        public var startingPosition: PipesClientTypes.SelfManagedKafkaStartPosition?
        /// The name of the topic that the pipe will read from.
        /// This member is required.
        public var topicName: Swift.String?
        /// This structure specifies the VPC subnets and security groups for the stream, and whether a public IP address is to be used.
        public var vpc: PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc?

        public init(
            additionalBootstrapServers: [Swift.String]? = nil,
            batchSize: Swift.Int? = nil,
            consumerGroupID: Swift.String? = nil,
            credentials: PipesClientTypes.SelfManagedKafkaAccessConfigurationCredentials? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil,
            serverRootCaCertificate: Swift.String? = nil,
            startingPosition: PipesClientTypes.SelfManagedKafkaStartPosition? = nil,
            topicName: Swift.String? = nil,
            vpc: PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc? = nil
        )
        {
            self.additionalBootstrapServers = additionalBootstrapServers
            self.batchSize = batchSize
            self.consumerGroupID = consumerGroupID
            self.credentials = credentials
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
            self.serverRootCaCertificate = serverRootCaCertificate
            self.startingPosition = startingPosition
            self.topicName = topicName
            self.vpc = vpc
        }
    }
}

extension PipesClientTypes.PipeSourceSelfManagedKafkaParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeSourceSelfManagedKafkaParameters(batchSize: \(Swift.String(describing: batchSize)), credentials: \(Swift.String(describing: credentials)), maximumBatchingWindowInSeconds: \(Swift.String(describing: maximumBatchingWindowInSeconds)), serverRootCaCertificate: \(Swift.String(describing: serverRootCaCertificate)), startingPosition: \(Swift.String(describing: startingPosition)), vpc: \(Swift.String(describing: vpc)), additionalBootstrapServers: \"CONTENT_REDACTED\", consumerGroupID: \"CONTENT_REDACTED\", topicName: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The parameters for using a Amazon SQS stream as a source.
    public struct PipeSourceSqsQueueParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?

        public init(
            batchSize: Swift.Int? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil
        )
        {
            self.batchSize = batchSize
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
        }
    }
}

extension PipesClientTypes {

    /// The parameters required to set up a source for your pipe.
    public struct PipeSourceParameters: Swift.Sendable {
        /// The parameters for using an Active MQ broker as a source.
        public var activeMQBrokerParameters: PipesClientTypes.PipeSourceActiveMQBrokerParameters?
        /// The parameters for using a DynamoDB stream as a source.
        public var dynamoDBStreamParameters: PipesClientTypes.PipeSourceDynamoDBStreamParameters?
        /// The collection of event patterns used to filter events. To remove a filter, specify a FilterCriteria object with an empty array of Filter objects. For more information, see [Events and Event Patterns](https://docs.aws.amazon.com/eventbridge/latest/userguide/eventbridge-and-event-patterns.html) in the Amazon EventBridge User Guide.
        public var filterCriteria: PipesClientTypes.FilterCriteria?
        /// The parameters for using a Kinesis stream as a source.
        public var kinesisStreamParameters: PipesClientTypes.PipeSourceKinesisStreamParameters?
        /// The parameters for using an MSK stream as a source.
        public var managedStreamingKafkaParameters: PipesClientTypes.PipeSourceManagedStreamingKafkaParameters?
        /// The parameters for using a Rabbit MQ broker as a source.
        public var rabbitMQBrokerParameters: PipesClientTypes.PipeSourceRabbitMQBrokerParameters?
        /// The parameters for using a self-managed Apache Kafka stream as a source. A self managed cluster refers to any Apache Kafka cluster not hosted by Amazon Web Services. This includes both clusters you manage yourself, as well as those hosted by a third-party provider, such as [Confluent Cloud](https://www.confluent.io/), [CloudKarafka](https://www.cloudkarafka.com/), or [Redpanda](https://redpanda.com/). For more information, see [Apache Kafka streams as a source](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-kafka.html) in the Amazon EventBridge User Guide.
        public var selfManagedKafkaParameters: PipesClientTypes.PipeSourceSelfManagedKafkaParameters?
        /// The parameters for using a Amazon SQS stream as a source.
        public var sqsQueueParameters: PipesClientTypes.PipeSourceSqsQueueParameters?

        public init(
            activeMQBrokerParameters: PipesClientTypes.PipeSourceActiveMQBrokerParameters? = nil,
            dynamoDBStreamParameters: PipesClientTypes.PipeSourceDynamoDBStreamParameters? = nil,
            filterCriteria: PipesClientTypes.FilterCriteria? = nil,
            kinesisStreamParameters: PipesClientTypes.PipeSourceKinesisStreamParameters? = nil,
            managedStreamingKafkaParameters: PipesClientTypes.PipeSourceManagedStreamingKafkaParameters? = nil,
            rabbitMQBrokerParameters: PipesClientTypes.PipeSourceRabbitMQBrokerParameters? = nil,
            selfManagedKafkaParameters: PipesClientTypes.PipeSourceSelfManagedKafkaParameters? = nil,
            sqsQueueParameters: PipesClientTypes.PipeSourceSqsQueueParameters? = nil
        )
        {
            self.activeMQBrokerParameters = activeMQBrokerParameters
            self.dynamoDBStreamParameters = dynamoDBStreamParameters
            self.filterCriteria = filterCriteria
            self.kinesisStreamParameters = kinesisStreamParameters
            self.managedStreamingKafkaParameters = managedStreamingKafkaParameters
            self.rabbitMQBrokerParameters = rabbitMQBrokerParameters
            self.selfManagedKafkaParameters = selfManagedKafkaParameters
            self.sqsQueueParameters = sqsQueueParameters
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using an Batch job as a target.
    public struct PipeTargetBatchJobParameters: Swift.Sendable {
        /// The array properties for the submitted job, such as the size of the array. The array size can be between 2 and 10,000. If you specify array properties for a job, it becomes an array job. This parameter is used only if the target is an Batch job.
        public var arrayProperties: PipesClientTypes.BatchArrayProperties?
        /// The overrides that are sent to a container.
        public var containerOverrides: PipesClientTypes.BatchContainerOverrides?
        /// A list of dependencies for the job. A job can depend upon a maximum of 20 jobs. You can specify a SEQUENTIAL type dependency without specifying a job ID for array jobs so that each child array job completes sequentially, starting at index 0. You can also specify an N_TO_N type dependency with a job ID for array jobs. In that case, each index child of this job must wait for the corresponding index child of each dependency to complete before it can begin.
        public var dependsOn: [PipesClientTypes.BatchJobDependency]?
        /// The job definition used by this job. This value can be one of name, name:revision, or the Amazon Resource Name (ARN) for the job definition. If name is specified without a revision then the latest active revision is used.
        /// This member is required.
        public var jobDefinition: Swift.String?
        /// The name of the job. It can be up to 128 letters long. The first character must be alphanumeric, can contain uppercase and lowercase letters, numbers, hyphens (-), and underscores (_).
        /// This member is required.
        public var jobName: Swift.String?
        /// Additional parameters passed to the job that replace parameter substitution placeholders that are set in the job definition. Parameters are specified as a key and value pair mapping. Parameters included here override any corresponding parameter defaults from the job definition.
        public var parameters: [Swift.String: Swift.String]?
        /// The retry strategy to use for failed jobs. When a retry strategy is specified here, it overrides the retry strategy defined in the job definition.
        public var retryStrategy: PipesClientTypes.BatchRetryStrategy?

        public init(
            arrayProperties: PipesClientTypes.BatchArrayProperties? = nil,
            containerOverrides: PipesClientTypes.BatchContainerOverrides? = nil,
            dependsOn: [PipesClientTypes.BatchJobDependency]? = nil,
            jobDefinition: Swift.String? = nil,
            jobName: Swift.String? = nil,
            parameters: [Swift.String: Swift.String]? = nil,
            retryStrategy: PipesClientTypes.BatchRetryStrategy? = nil
        )
        {
            self.arrayProperties = arrayProperties
            self.containerOverrides = containerOverrides
            self.dependsOn = dependsOn
            self.jobDefinition = jobDefinition
            self.jobName = jobName
            self.parameters = parameters
            self.retryStrategy = retryStrategy
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using an CloudWatch Logs log stream as a target.
    public struct PipeTargetCloudWatchLogsParameters: Swift.Sendable {
        /// The name of the log stream.
        public var logStreamName: Swift.String?
        /// The time the event occurred, expressed as the number of milliseconds after Jan 1, 1970 00:00:00 UTC.
        public var timestamp: Swift.String?

        public init(
            logStreamName: Swift.String? = nil,
            timestamp: Swift.String? = nil
        )
        {
            self.logStreamName = logStreamName
            self.timestamp = timestamp
        }
    }
}

extension PipesClientTypes {

    public enum LaunchType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case ec2
        case external
        case fargate
        case sdkUnknown(Swift.String)

        public static var allCases: [LaunchType] {
            return [
                .ec2,
                .external,
                .fargate
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .ec2: return "EC2"
            case .external: return "EXTERNAL"
            case .fargate: return "FARGATE"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// This structure specifies the network configuration for an Amazon ECS task.
    public struct NetworkConfiguration: Swift.Sendable {
        /// Use this structure to specify the VPC subnets and security groups for the task, and whether a public IP address is to be used. This structure is relevant only for ECS tasks that use the awsvpc network mode.
        public var awsvpcConfiguration: PipesClientTypes.AwsVpcConfiguration?

        public init(
            awsvpcConfiguration: PipesClientTypes.AwsVpcConfiguration? = nil
        )
        {
            self.awsvpcConfiguration = awsvpcConfiguration
        }
    }
}

extension PipesClientTypes {

    /// The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.
    public struct EcsEnvironmentVariable: Swift.Sendable {
        /// The name of the key-value pair. For environment variables, this is the name of the environment variable.
        public var name: Swift.String?
        /// The value of the key-value pair. For environment variables, this is the value of the environment variable.
        public var value: Swift.String?

        public init(
            name: Swift.String? = nil,
            value: Swift.String? = nil
        )
        {
            self.name = name
            self.value = value
        }
    }
}

extension PipesClientTypes {

    public enum EcsEnvironmentFileType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case s3
        case sdkUnknown(Swift.String)

        public static var allCases: [EcsEnvironmentFileType] {
            return [
                .s3
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .s3: return "s3"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// A list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information about the environment variable file syntax, see [Declare default environment variables in file](https://docs.docker.com/compose/env-file/). If there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they're processed from the top down. We recommend that you use unique variable names. For more information, see [Specifying environment variables](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/taskdef-envfiles.html) in the Amazon Elastic Container Service Developer Guide. This parameter is only supported for tasks hosted on Fargate using the following platform versions:
    ///
    /// * Linux platform version 1.4.0 or later.
    ///
    /// * Windows platform version 1.0.0 or later.
    public struct EcsEnvironmentFile: Swift.Sendable {
        /// The file type to use. The only supported value is s3.
        /// This member is required.
        public var type: PipesClientTypes.EcsEnvironmentFileType?
        /// The Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.
        /// This member is required.
        public var value: Swift.String?

        public init(
            type: PipesClientTypes.EcsEnvironmentFileType? = nil,
            value: Swift.String? = nil
        )
        {
            self.type = type
            self.value = value
        }
    }
}

extension PipesClientTypes {

    public enum EcsResourceRequirementType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case gpu
        case inferenceaccelerator
        case sdkUnknown(Swift.String)

        public static var allCases: [EcsResourceRequirementType] {
            return [
                .gpu,
                .inferenceaccelerator
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .gpu: return "GPU"
            case .inferenceaccelerator: return "InferenceAccelerator"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// The type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see [Working with GPUs on Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-gpu.html) or [Working with Amazon Elastic Inference on Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-inference.html) in the Amazon Elastic Container Service Developer Guide
    public struct EcsResourceRequirement: Swift.Sendable {
        /// The type of resource to assign to a container. The supported values are GPU or InferenceAccelerator.
        /// This member is required.
        public var type: PipesClientTypes.EcsResourceRequirementType?
        /// The value for the specified resource type. If the GPU type is used, the value is the number of physical GPUs the Amazon ECS container agent reserves for the container. The number of GPUs that's reserved for all containers in a task can't exceed the number of available GPUs on the container instance that the task is launched on. If the InferenceAccelerator type is used, the value matches the deviceName for an InferenceAccelerator specified in a task definition.
        /// This member is required.
        public var value: Swift.String?

        public init(
            type: PipesClientTypes.EcsResourceRequirementType? = nil,
            value: Swift.String? = nil
        )
        {
            self.type = type
            self.value = value
        }
    }
}

extension PipesClientTypes {

    /// The overrides that are sent to a container. An empty container override can be passed in. An example of an empty container override is {"containerOverrides": [ ] }. If a non-empty container override is specified, the name parameter must be included.
    public struct EcsContainerOverride: Swift.Sendable {
        /// The command to send to the container that overrides the default command from the Docker image or the task definition. You must also specify a container name.
        public var command: [Swift.String]?
        /// The number of cpu units reserved for the container, instead of the default value from the task definition. You must also specify a container name.
        public var cpu: Swift.Int?
        /// The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.
        public var environment: [PipesClientTypes.EcsEnvironmentVariable]?
        /// A list of files containing the environment variables to pass to a container, instead of the value from the container definition.
        public var environmentFiles: [PipesClientTypes.EcsEnvironmentFile]?
        /// The hard limit (in MiB) of memory to present to the container, instead of the default value from the task definition. If your container attempts to exceed the memory specified here, the container is killed. You must also specify a container name.
        public var memory: Swift.Int?
        /// The soft limit (in MiB) of memory to reserve for the container, instead of the default value from the task definition. You must also specify a container name.
        public var memoryReservation: Swift.Int?
        /// The name of the container that receives the override. This parameter is required if any override is specified.
        public var name: Swift.String?
        /// The type and amount of a resource to assign to a container, instead of the default value from the task definition. The only supported resource is a GPU.
        public var resourceRequirements: [PipesClientTypes.EcsResourceRequirement]?

        public init(
            command: [Swift.String]? = nil,
            cpu: Swift.Int? = nil,
            environment: [PipesClientTypes.EcsEnvironmentVariable]? = nil,
            environmentFiles: [PipesClientTypes.EcsEnvironmentFile]? = nil,
            memory: Swift.Int? = nil,
            memoryReservation: Swift.Int? = nil,
            name: Swift.String? = nil,
            resourceRequirements: [PipesClientTypes.EcsResourceRequirement]? = nil
        )
        {
            self.command = command
            self.cpu = cpu
            self.environment = environment
            self.environmentFiles = environmentFiles
            self.memory = memory
            self.memoryReservation = memoryReservation
            self.name = name
            self.resourceRequirements = resourceRequirements
        }
    }
}

extension PipesClientTypes {

    /// The amount of ephemeral storage to allocate for the task. This parameter is used to expand the total amount of ephemeral storage available, beyond the default amount, for tasks hosted on Fargate. For more information, see [Fargate task storage](https://docs.aws.amazon.com/AmazonECS/latest/userguide/using_data_volumes.html) in the Amazon ECS User Guide for Fargate. This parameter is only supported for tasks hosted on Fargate using Linux platform version 1.4.0 or later. This parameter is not supported for Windows containers on Fargate.
    public struct EcsEphemeralStorage: Swift.Sendable {
        /// The total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.
        /// This member is required.
        public var sizeInGiB: Swift.Int?

        public init(
            sizeInGiB: Swift.Int? = nil
        )
        {
            self.sizeInGiB = sizeInGiB
        }
    }
}

extension PipesClientTypes {

    /// Details on an Elastic Inference accelerator task override. This parameter is used to override the Elastic Inference accelerator specified in the task definition. For more information, see [Working with Amazon Elastic Inference on Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/userguide/ecs-inference.html) in the Amazon Elastic Container Service Developer Guide.
    public struct EcsInferenceAcceleratorOverride: Swift.Sendable {
        /// The Elastic Inference accelerator device name to override for the task. This parameter must match a deviceName specified in the task definition.
        public var deviceName: Swift.String?
        /// The Elastic Inference accelerator type to use.
        public var deviceType: Swift.String?

        public init(
            deviceName: Swift.String? = nil,
            deviceType: Swift.String? = nil
        )
        {
            self.deviceName = deviceName
            self.deviceType = deviceType
        }
    }
}

extension PipesClientTypes {

    /// The overrides that are associated with a task.
    public struct EcsTaskOverride: Swift.Sendable {
        /// One or more container overrides that are sent to a task.
        public var containerOverrides: [PipesClientTypes.EcsContainerOverride]?
        /// The cpu override for the task.
        public var cpu: Swift.String?
        /// The ephemeral storage setting override for the task. This parameter is only supported for tasks hosted on Fargate that use the following platform versions:
        ///
        /// * Linux platform version 1.4.0 or later.
        ///
        /// * Windows platform version 1.0.0 or later.
        public var ephemeralStorage: PipesClientTypes.EcsEphemeralStorage?
        /// The Amazon Resource Name (ARN) of the task execution IAM role override for the task. For more information, see [Amazon ECS task execution IAM role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html) in the Amazon Elastic Container Service Developer Guide.
        public var executionRoleArn: Swift.String?
        /// The Elastic Inference accelerator override for the task.
        public var inferenceAcceleratorOverrides: [PipesClientTypes.EcsInferenceAcceleratorOverride]?
        /// The memory override for the task.
        public var memory: Swift.String?
        /// The Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see [IAM Role for Tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html) in the Amazon Elastic Container Service Developer Guide.
        public var taskRoleArn: Swift.String?

        public init(
            containerOverrides: [PipesClientTypes.EcsContainerOverride]? = nil,
            cpu: Swift.String? = nil,
            ephemeralStorage: PipesClientTypes.EcsEphemeralStorage? = nil,
            executionRoleArn: Swift.String? = nil,
            inferenceAcceleratorOverrides: [PipesClientTypes.EcsInferenceAcceleratorOverride]? = nil,
            memory: Swift.String? = nil,
            taskRoleArn: Swift.String? = nil
        )
        {
            self.containerOverrides = containerOverrides
            self.cpu = cpu
            self.ephemeralStorage = ephemeralStorage
            self.executionRoleArn = executionRoleArn
            self.inferenceAcceleratorOverrides = inferenceAcceleratorOverrides
            self.memory = memory
            self.taskRoleArn = taskRoleArn
        }
    }
}

extension PipesClientTypes {

    public enum PlacementConstraintType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case distinctInstance
        case memberOf
        case sdkUnknown(Swift.String)

        public static var allCases: [PlacementConstraintType] {
            return [
                .distinctInstance,
                .memberOf
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .distinctInstance: return "distinctInstance"
            case .memberOf: return "memberOf"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// An object representing a constraint on task placement. To learn more, see [Task Placement Constraints](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement-constraints.html) in the Amazon Elastic Container Service Developer Guide.
    public struct PlacementConstraint: Swift.Sendable {
        /// A cluster query language expression to apply to the constraint. You cannot specify an expression if the constraint type is distinctInstance. To learn more, see [Cluster Query Language](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html) in the Amazon Elastic Container Service Developer Guide.
        public var expression: Swift.String?
        /// The type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.
        public var type: PipesClientTypes.PlacementConstraintType?

        public init(
            expression: Swift.String? = nil,
            type: PipesClientTypes.PlacementConstraintType? = nil
        )
        {
            self.expression = expression
            self.type = type
        }
    }
}

extension PipesClientTypes.PlacementConstraint: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PlacementConstraint(type: \(Swift.String(describing: type)), expression: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    public enum PlacementStrategyType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case binpack
        case random
        case spread
        case sdkUnknown(Swift.String)

        public static var allCases: [PlacementStrategyType] {
            return [
                .binpack,
                .random,
                .spread
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .binpack: return "binpack"
            case .random: return "random"
            case .spread: return "spread"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// The task placement strategy for a task or service. To learn more, see [Task Placement Strategies](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement-strategies.html) in the Amazon Elastic Container Service Service Developer Guide.
    public struct PlacementStrategy: Swift.Sendable {
        /// The field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host, which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone. For the binpack placement strategy, valid values are cpu and memory. For the random placement strategy, this field is not used.
        public var field: Swift.String?
        /// The type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).
        public var type: PipesClientTypes.PlacementStrategyType?

        public init(
            field: Swift.String? = nil,
            type: PipesClientTypes.PlacementStrategyType? = nil
        )
        {
            self.field = field
            self.type = type
        }
    }
}

extension PipesClientTypes.PlacementStrategy: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PlacementStrategy(type: \(Swift.String(describing: type)), field: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    public enum PropagateTags: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case taskDefinition
        case sdkUnknown(Swift.String)

        public static var allCases: [PropagateTags] {
            return [
                .taskDefinition
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .taskDefinition: return "TASK_DEFINITION"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// A key-value pair associated with an Amazon Web Services resource. In EventBridge, rules and event buses support tagging.
    public struct Tag: Swift.Sendable {
        /// A string you can use to assign a value. The combination of tag keys and values can help you organize and categorize your resources.
        /// This member is required.
        public var key: Swift.String?
        /// The value for the specified tag key.
        /// This member is required.
        public var value: Swift.String?

        public init(
            key: Swift.String? = nil,
            value: Swift.String? = nil
        )
        {
            self.key = key
            self.value = value
        }
    }
}

extension PipesClientTypes.Tag: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "Tag(key: \(Swift.String(describing: key)), value: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The parameters for using an Amazon ECS task as a target.
    public struct PipeTargetEcsTaskParameters: Swift.Sendable {
        /// The capacity provider strategy to use for the task. If a capacityProviderStrategy is specified, the launchType parameter must be omitted. If no capacityProviderStrategy or launchType is specified, the defaultCapacityProviderStrategy for the cluster is used.
        public var capacityProviderStrategy: [PipesClientTypes.CapacityProviderStrategyItem]?
        /// Specifies whether to enable Amazon ECS managed tags for the task. For more information, see [Tagging Your Amazon ECS Resources](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html) in the Amazon Elastic Container Service Developer Guide.
        public var enableECSManagedTags: Swift.Bool
        /// Whether or not to enable the execute command functionality for the containers in this task. If true, this enables execute command functionality on all containers in the task.
        public var enableExecuteCommand: Swift.Bool
        /// Specifies an Amazon ECS task group for the task. The maximum length is 255 characters.
        public var group: Swift.String?
        /// Specifies the launch type on which your task is running. The launch type that you specify here must match one of the launch type (compatibilities) of the target task. The FARGATE value is supported only in the Regions where Fargate with Amazon ECS is supported. For more information, see [Fargate on Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/AWS-Fargate.html) in the Amazon Elastic Container Service Developer Guide.
        public var launchType: PipesClientTypes.LaunchType?
        /// Use this structure if the Amazon ECS task uses the awsvpc network mode. This structure specifies the VPC subnets and security groups associated with the task, and whether a public IP address is to be used. This structure is required if LaunchType is FARGATE because the awsvpc mode is required for Fargate tasks. If you specify NetworkConfiguration when the target ECS task does not use the awsvpc network mode, the task fails.
        public var networkConfiguration: PipesClientTypes.NetworkConfiguration?
        /// The overrides that are associated with a task.
        public var overrides: PipesClientTypes.EcsTaskOverride?
        /// An array of placement constraint objects to use for the task. You can specify up to 10 constraints per task (including constraints in the task definition and those specified at runtime).
        public var placementConstraints: [PipesClientTypes.PlacementConstraint]?
        /// The placement strategy objects to use for the task. You can specify a maximum of five strategy rules per task.
        public var placementStrategy: [PipesClientTypes.PlacementStrategy]?
        /// Specifies the platform version for the task. Specify only the numeric portion of the platform version, such as 1.1.0. This structure is used only if LaunchType is FARGATE. For more information about valid platform versions, see [Fargate Platform Versions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html) in the Amazon Elastic Container Service Developer Guide.
        public var platformVersion: Swift.String?
        /// Specifies whether to propagate the tags from the task definition to the task. If no value is specified, the tags are not propagated. Tags can only be propagated to the task during task creation. To add tags to a task after task creation, use the TagResource API action.
        public var propagateTags: PipesClientTypes.PropagateTags?
        /// The reference ID to use for the task.
        public var referenceId: Swift.String?
        /// The metadata that you apply to the task to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. To learn more, see [RunTask](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_RunTask.html#ECS-RunTask-request-tags) in the Amazon ECS API Reference.
        public var tags: [PipesClientTypes.Tag]?
        /// The number of tasks to create based on TaskDefinition. The default is 1.
        public var taskCount: Swift.Int?
        /// The ARN of the task definition to use if the event target is an Amazon ECS task.
        /// This member is required.
        public var taskDefinitionArn: Swift.String?

        public init(
            capacityProviderStrategy: [PipesClientTypes.CapacityProviderStrategyItem]? = nil,
            enableECSManagedTags: Swift.Bool = false,
            enableExecuteCommand: Swift.Bool = false,
            group: Swift.String? = nil,
            launchType: PipesClientTypes.LaunchType? = nil,
            networkConfiguration: PipesClientTypes.NetworkConfiguration? = nil,
            overrides: PipesClientTypes.EcsTaskOverride? = nil,
            placementConstraints: [PipesClientTypes.PlacementConstraint]? = nil,
            placementStrategy: [PipesClientTypes.PlacementStrategy]? = nil,
            platformVersion: Swift.String? = nil,
            propagateTags: PipesClientTypes.PropagateTags? = nil,
            referenceId: Swift.String? = nil,
            tags: [PipesClientTypes.Tag]? = nil,
            taskCount: Swift.Int? = nil,
            taskDefinitionArn: Swift.String? = nil
        )
        {
            self.capacityProviderStrategy = capacityProviderStrategy
            self.enableECSManagedTags = enableECSManagedTags
            self.enableExecuteCommand = enableExecuteCommand
            self.group = group
            self.launchType = launchType
            self.networkConfiguration = networkConfiguration
            self.overrides = overrides
            self.placementConstraints = placementConstraints
            self.placementStrategy = placementStrategy
            self.platformVersion = platformVersion
            self.propagateTags = propagateTags
            self.referenceId = referenceId
            self.tags = tags
            self.taskCount = taskCount
            self.taskDefinitionArn = taskDefinitionArn
        }
    }
}

extension PipesClientTypes.PipeTargetEcsTaskParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeTargetEcsTaskParameters(capacityProviderStrategy: \(Swift.String(describing: capacityProviderStrategy)), enableECSManagedTags: \(Swift.String(describing: enableECSManagedTags)), enableExecuteCommand: \(Swift.String(describing: enableExecuteCommand)), group: \(Swift.String(describing: group)), launchType: \(Swift.String(describing: launchType)), networkConfiguration: \(Swift.String(describing: networkConfiguration)), overrides: \(Swift.String(describing: overrides)), placementConstraints: \(Swift.String(describing: placementConstraints)), placementStrategy: \(Swift.String(describing: placementStrategy)), platformVersion: \(Swift.String(describing: platformVersion)), propagateTags: \(Swift.String(describing: propagateTags)), tags: \(Swift.String(describing: tags)), taskCount: \(Swift.String(describing: taskCount)), taskDefinitionArn: \(Swift.String(describing: taskDefinitionArn)), referenceId: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The parameters for using an EventBridge event bus as a target.
    public struct PipeTargetEventBridgeEventBusParameters: Swift.Sendable {
        /// A free-form string, with a maximum of 128 characters, used to decide what fields to expect in the event detail.
        public var detailType: Swift.String?
        /// The URL subdomain of the endpoint. For example, if the URL for Endpoint is https://abcde.veo.endpoints.event.amazonaws.com, then the EndpointId is abcde.veo.
        public var endpointId: Swift.String?
        /// Amazon Web Services resources, identified by Amazon Resource Name (ARN), which the event primarily concerns. Any number, including zero, may be present.
        public var resources: [Swift.String]?
        /// The source of the event.
        public var source: Swift.String?
        /// The time stamp of the event, per [RFC3339](https://www.rfc-editor.org/rfc/rfc3339.txt). If no time stamp is provided, the time stamp of the [PutEvents](https://docs.aws.amazon.com/eventbridge/latest/APIReference/API_PutEvents.html) call is used.
        public var time: Swift.String?

        public init(
            detailType: Swift.String? = nil,
            endpointId: Swift.String? = nil,
            resources: [Swift.String]? = nil,
            source: Swift.String? = nil,
            time: Swift.String? = nil
        )
        {
            self.detailType = detailType
            self.endpointId = endpointId
            self.resources = resources
            self.source = source
            self.time = time
        }
    }
}

extension PipesClientTypes.PipeTargetEventBridgeEventBusParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeTargetEventBridgeEventBusParameters(resources: \(Swift.String(describing: resources)), time: \(Swift.String(describing: time)), detailType: \"CONTENT_REDACTED\", endpointId: \"CONTENT_REDACTED\", source: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// These are custom parameter to be used when the target is an API Gateway REST APIs or EventBridge ApiDestinations.
    public struct PipeTargetHttpParameters: Swift.Sendable {
        /// The headers that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        public var headerParameters: [Swift.String: Swift.String]?
        /// The path parameter values to be used to populate API Gateway REST API or EventBridge ApiDestination path wildcards ("*").
        public var pathParameterValues: [Swift.String]?
        /// The query string keys/values that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        public var queryStringParameters: [Swift.String: Swift.String]?

        public init(
            headerParameters: [Swift.String: Swift.String]? = nil,
            pathParameterValues: [Swift.String]? = nil,
            queryStringParameters: [Swift.String: Swift.String]? = nil
        )
        {
            self.headerParameters = headerParameters
            self.pathParameterValues = pathParameterValues
            self.queryStringParameters = queryStringParameters
        }
    }
}

extension PipesClientTypes.PipeTargetHttpParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeTargetHttpParameters(headerParameters: [keys: \(Swift.String(describing: headerParameters?.keys)), values: \"CONTENT_REDACTED\"], pathParameterValues: \"CONTENT_REDACTED\", queryStringParameters: [keys: \(Swift.String(describing: queryStringParameters?.keys)), values: \"CONTENT_REDACTED\"])"}
}

extension PipesClientTypes {

    /// The parameters for using a Kinesis stream as a target.
    public struct PipeTargetKinesisStreamParameters: Swift.Sendable {
        /// Determines which shard in the stream the data record is assigned to. Partition keys are Unicode strings with a maximum length limit of 256 characters for each key. Amazon Kinesis Data Streams uses the partition key as input to a hash function that maps the partition key and associated data to a specific shard. Specifically, an MD5 hash function is used to map partition keys to 128-bit integer values and to map associated data records to shards. As a result of this hashing mechanism, all data records with the same partition key map to the same shard within the stream.
        /// This member is required.
        public var partitionKey: Swift.String?

        public init(
            partitionKey: Swift.String? = nil
        )
        {
            self.partitionKey = partitionKey
        }
    }
}

extension PipesClientTypes.PipeTargetKinesisStreamParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeTargetKinesisStreamParameters(partitionKey: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    public enum PipeTargetInvocationType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case fireAndForget
        case requestResponse
        case sdkUnknown(Swift.String)

        public static var allCases: [PipeTargetInvocationType] {
            return [
                .fireAndForget,
                .requestResponse
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .fireAndForget: return "FIRE_AND_FORGET"
            case .requestResponse: return "REQUEST_RESPONSE"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using a Lambda function as a target.
    public struct PipeTargetLambdaFunctionParameters: Swift.Sendable {
        /// Specify whether to invoke the function synchronously or asynchronously.
        ///
        /// * REQUEST_RESPONSE (default) - Invoke synchronously. This corresponds to the RequestResponse option in the InvocationType parameter for the Lambda [Invoke](https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_RequestSyntax) API.
        ///
        /// * FIRE_AND_FORGET - Invoke asynchronously. This corresponds to the Event option in the InvocationType parameter for the Lambda [Invoke](https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_RequestSyntax) API.
        ///
        ///
        /// For more information, see [Invocation types](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html#pipes-invocation) in the Amazon EventBridge User Guide.
        public var invocationType: PipesClientTypes.PipeTargetInvocationType?

        public init(
            invocationType: PipesClientTypes.PipeTargetInvocationType? = nil
        )
        {
            self.invocationType = invocationType
        }
    }
}

extension PipesClientTypes {

    /// These are custom parameters to be used when the target is a Amazon Redshift cluster to invoke the Amazon Redshift Data API BatchExecuteStatement.
    public struct PipeTargetRedshiftDataParameters: Swift.Sendable {
        /// The name of the database. Required when authenticating using temporary credentials.
        /// This member is required.
        public var database: Swift.String?
        /// The database user name. Required when authenticating using temporary credentials.
        public var dbUser: Swift.String?
        /// The name or ARN of the secret that enables access to the database. Required when authenticating using Secrets Manager.
        public var secretManagerArn: Swift.String?
        /// The SQL statement text to run.
        /// This member is required.
        public var sqls: [Swift.String]?
        /// The name of the SQL statement. You can name the SQL statement when you create it to identify the query.
        public var statementName: Swift.String?
        /// Indicates whether to send an event back to EventBridge after the SQL statement runs.
        public var withEvent: Swift.Bool

        public init(
            database: Swift.String? = nil,
            dbUser: Swift.String? = nil,
            secretManagerArn: Swift.String? = nil,
            sqls: [Swift.String]? = nil,
            statementName: Swift.String? = nil,
            withEvent: Swift.Bool = false
        )
        {
            self.database = database
            self.dbUser = dbUser
            self.secretManagerArn = secretManagerArn
            self.sqls = sqls
            self.statementName = statementName
            self.withEvent = withEvent
        }
    }
}

extension PipesClientTypes.PipeTargetRedshiftDataParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeTargetRedshiftDataParameters(secretManagerArn: \(Swift.String(describing: secretManagerArn)), withEvent: \(Swift.String(describing: withEvent)), database: \"CONTENT_REDACTED\", dbUser: \"CONTENT_REDACTED\", sqls: \"CONTENT_REDACTED\", statementName: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// Name/Value pair of a parameter to start execution of a SageMaker Model Building Pipeline.
    public struct SageMakerPipelineParameter: Swift.Sendable {
        /// Name of parameter to start execution of a SageMaker Model Building Pipeline.
        /// This member is required.
        public var name: Swift.String?
        /// Value of parameter to start execution of a SageMaker Model Building Pipeline.
        /// This member is required.
        public var value: Swift.String?

        public init(
            name: Swift.String? = nil,
            value: Swift.String? = nil
        )
        {
            self.name = name
            self.value = value
        }
    }
}

extension PipesClientTypes.SageMakerPipelineParameter: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "SageMakerPipelineParameter(name: \"CONTENT_REDACTED\", value: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The parameters for using a SageMaker pipeline as a target.
    public struct PipeTargetSageMakerPipelineParameters: Swift.Sendable {
        /// List of Parameter names and values for SageMaker Model Building Pipeline execution.
        public var pipelineParameterList: [PipesClientTypes.SageMakerPipelineParameter]?

        public init(
            pipelineParameterList: [PipesClientTypes.SageMakerPipelineParameter]? = nil
        )
        {
            self.pipelineParameterList = pipelineParameterList
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using a Amazon SQS stream as a target.
    public struct PipeTargetSqsQueueParameters: Swift.Sendable {
        /// This parameter applies only to FIFO (first-in-first-out) queues. The token used for deduplication of sent messages.
        public var messageDeduplicationId: Swift.String?
        /// The FIFO message group ID to use as the target.
        public var messageGroupId: Swift.String?

        public init(
            messageDeduplicationId: Swift.String? = nil,
            messageGroupId: Swift.String? = nil
        )
        {
            self.messageDeduplicationId = messageDeduplicationId
            self.messageGroupId = messageGroupId
        }
    }
}

extension PipesClientTypes.PipeTargetSqsQueueParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeTargetSqsQueueParameters(messageDeduplicationId: \"CONTENT_REDACTED\", messageGroupId: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// The parameters for using a Step Functions state machine as a target.
    public struct PipeTargetStateMachineParameters: Swift.Sendable {
        /// Specify whether to invoke the Step Functions state machine synchronously or asynchronously.
        ///
        /// * REQUEST_RESPONSE (default) - Invoke synchronously. For more information, see [StartSyncExecution](https://docs.aws.amazon.com/step-functions/latest/apireference/API_StartSyncExecution.html) in the Step Functions API Reference. REQUEST_RESPONSE is not supported for STANDARD state machine workflows.
        ///
        /// * FIRE_AND_FORGET - Invoke asynchronously. For more information, see [StartExecution](https://docs.aws.amazon.com/step-functions/latest/apireference/API_StartExecution.html) in the Step Functions API Reference.
        ///
        ///
        /// For more information, see [Invocation types](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html#pipes-invocation) in the Amazon EventBridge User Guide.
        public var invocationType: PipesClientTypes.PipeTargetInvocationType?

        public init(
            invocationType: PipesClientTypes.PipeTargetInvocationType? = nil
        )
        {
            self.invocationType = invocationType
        }
    }
}

extension PipesClientTypes {

    public enum DimensionValueType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case varchar
        case sdkUnknown(Swift.String)

        public static var allCases: [DimensionValueType] {
            return [
                .varchar
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .varchar: return "VARCHAR"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// Maps source data to a dimension in the target Timestream for LiveAnalytics table. For more information, see [Amazon Timestream for LiveAnalytics concepts](https://docs.aws.amazon.com/timestream/latest/developerguide/concepts.html)
    public struct DimensionMapping: Swift.Sendable {
        /// The metadata attributes of the time series. For example, the name and Availability Zone of an Amazon EC2 instance or the name of the manufacturer of a wind turbine are dimensions.
        /// This member is required.
        public var dimensionName: Swift.String?
        /// Dynamic path to the dimension value in the source event.
        /// This member is required.
        public var dimensionValue: Swift.String?
        /// The data type of the dimension for the time-series data.
        /// This member is required.
        public var dimensionValueType: PipesClientTypes.DimensionValueType?

        public init(
            dimensionName: Swift.String? = nil,
            dimensionValue: Swift.String? = nil,
            dimensionValueType: PipesClientTypes.DimensionValueType? = nil
        )
        {
            self.dimensionName = dimensionName
            self.dimensionValue = dimensionValue
            self.dimensionValueType = dimensionValueType
        }
    }
}

extension PipesClientTypes {

    public enum EpochTimeUnit: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case microseconds
        case milliseconds
        case nanoseconds
        case seconds
        case sdkUnknown(Swift.String)

        public static var allCases: [EpochTimeUnit] {
            return [
                .microseconds,
                .milliseconds,
                .nanoseconds,
                .seconds
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .microseconds: return "MICROSECONDS"
            case .milliseconds: return "MILLISECONDS"
            case .nanoseconds: return "NANOSECONDS"
            case .seconds: return "SECONDS"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    public enum MeasureValueType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case bigint
        case boolean
        case double
        case timestamp
        case varchar
        case sdkUnknown(Swift.String)

        public static var allCases: [MeasureValueType] {
            return [
                .bigint,
                .boolean,
                .double,
                .timestamp,
                .varchar
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .bigint: return "BIGINT"
            case .boolean: return "BOOLEAN"
            case .double: return "DOUBLE"
            case .timestamp: return "TIMESTAMP"
            case .varchar: return "VARCHAR"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// A mapping of a source event data field to a measure in a Timestream for LiveAnalytics record.
    public struct MultiMeasureAttributeMapping: Swift.Sendable {
        /// Dynamic path to the measurement attribute in the source event.
        /// This member is required.
        public var measureValue: Swift.String?
        /// Data type of the measurement attribute in the source event.
        /// This member is required.
        public var measureValueType: PipesClientTypes.MeasureValueType?
        /// Target measure name to be used.
        /// This member is required.
        public var multiMeasureAttributeName: Swift.String?

        public init(
            measureValue: Swift.String? = nil,
            measureValueType: PipesClientTypes.MeasureValueType? = nil,
            multiMeasureAttributeName: Swift.String? = nil
        )
        {
            self.measureValue = measureValue
            self.measureValueType = measureValueType
            self.multiMeasureAttributeName = multiMeasureAttributeName
        }
    }
}

extension PipesClientTypes {

    /// Maps multiple measures from the source event to the same Timestream for LiveAnalytics record. For more information, see [Amazon Timestream for LiveAnalytics concepts](https://docs.aws.amazon.com/timestream/latest/developerguide/concepts.html)
    public struct MultiMeasureMapping: Swift.Sendable {
        /// Mappings that represent multiple source event fields mapped to measures in the same Timestream for LiveAnalytics record.
        /// This member is required.
        public var multiMeasureAttributeMappings: [PipesClientTypes.MultiMeasureAttributeMapping]?
        /// The name of the multiple measurements per record (multi-measure).
        /// This member is required.
        public var multiMeasureName: Swift.String?

        public init(
            multiMeasureAttributeMappings: [PipesClientTypes.MultiMeasureAttributeMapping]? = nil,
            multiMeasureName: Swift.String? = nil
        )
        {
            self.multiMeasureAttributeMappings = multiMeasureAttributeMappings
            self.multiMeasureName = multiMeasureName
        }
    }
}

extension PipesClientTypes {

    /// Maps a single source data field to a single record in the specified Timestream for LiveAnalytics table. For more information, see [Amazon Timestream for LiveAnalytics concepts](https://docs.aws.amazon.com/timestream/latest/developerguide/concepts.html)
    public struct SingleMeasureMapping: Swift.Sendable {
        /// Target measure name for the measurement attribute in the Timestream table.
        /// This member is required.
        public var measureName: Swift.String?
        /// Dynamic path of the source field to map to the measure in the record.
        /// This member is required.
        public var measureValue: Swift.String?
        /// Data type of the source field.
        /// This member is required.
        public var measureValueType: PipesClientTypes.MeasureValueType?

        public init(
            measureName: Swift.String? = nil,
            measureValue: Swift.String? = nil,
            measureValueType: PipesClientTypes.MeasureValueType? = nil
        )
        {
            self.measureName = measureName
            self.measureValue = measureValue
            self.measureValueType = measureValueType
        }
    }
}

extension PipesClientTypes {

    public enum TimeFieldType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case epoch
        case timestampFormat
        case sdkUnknown(Swift.String)

        public static var allCases: [TimeFieldType] {
            return [
                .epoch,
                .timestampFormat
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .epoch: return "EPOCH"
            case .timestampFormat: return "TIMESTAMP_FORMAT"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using a Timestream for LiveAnalytics table as a target.
    public struct PipeTargetTimestreamParameters: Swift.Sendable {
        /// Map source data to dimensions in the target Timestream for LiveAnalytics table. For more information, see [Amazon Timestream for LiveAnalytics concepts](https://docs.aws.amazon.com/timestream/latest/developerguide/concepts.html)
        /// This member is required.
        public var dimensionMappings: [PipesClientTypes.DimensionMapping]?
        /// The granularity of the time units used. Default is MILLISECONDS. Required if TimeFieldType is specified as EPOCH.
        public var epochTimeUnit: PipesClientTypes.EpochTimeUnit?
        /// Maps multiple measures from the source event to the same record in the specified Timestream for LiveAnalytics table.
        public var multiMeasureMappings: [PipesClientTypes.MultiMeasureMapping]?
        /// Mappings of single source data fields to individual records in the specified Timestream for LiveAnalytics table.
        public var singleMeasureMappings: [PipesClientTypes.SingleMeasureMapping]?
        /// The type of time value used. The default is EPOCH.
        public var timeFieldType: PipesClientTypes.TimeFieldType?
        /// Dynamic path to the source data field that represents the time value for your data.
        /// This member is required.
        public var timeValue: Swift.String?
        /// How to format the timestamps. For example, yyyy-MM-dd'T'HH:mm:ss'Z'. Required if TimeFieldType is specified as TIMESTAMP_FORMAT.
        public var timestampFormat: Swift.String?
        /// 64 bit version value or source data field that represents the version value for your data. Write requests with a higher version number will update the existing measure values of the record and version. In cases where the measure value is the same, the version will still be updated. Default value is 1. Timestream for LiveAnalytics does not support updating partial measure values in a record. Write requests for duplicate data with a higher version number will update the existing measure value and version. In cases where the measure value is the same, Version will still be updated. Default value is 1. Version must be 1 or greater, or you will receive a ValidationException error.
        /// This member is required.
        public var versionValue: Swift.String?

        public init(
            dimensionMappings: [PipesClientTypes.DimensionMapping]? = nil,
            epochTimeUnit: PipesClientTypes.EpochTimeUnit? = nil,
            multiMeasureMappings: [PipesClientTypes.MultiMeasureMapping]? = nil,
            singleMeasureMappings: [PipesClientTypes.SingleMeasureMapping]? = nil,
            timeFieldType: PipesClientTypes.TimeFieldType? = nil,
            timeValue: Swift.String? = nil,
            timestampFormat: Swift.String? = nil,
            versionValue: Swift.String? = nil
        )
        {
            self.dimensionMappings = dimensionMappings
            self.epochTimeUnit = epochTimeUnit
            self.multiMeasureMappings = multiMeasureMappings
            self.singleMeasureMappings = singleMeasureMappings
            self.timeFieldType = timeFieldType
            self.timeValue = timeValue
            self.timestampFormat = timestampFormat
            self.versionValue = versionValue
        }
    }
}

extension PipesClientTypes {

    /// The parameters required to set up a target for your pipe. For more information about pipe target parameters, including how to use dynamic path parameters, see [Target parameters](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-event-target.html) in the Amazon EventBridge User Guide.
    public struct PipeTargetParameters: Swift.Sendable {
        /// The parameters for using an Batch job as a target.
        public var batchJobParameters: PipesClientTypes.PipeTargetBatchJobParameters?
        /// The parameters for using an CloudWatch Logs log stream as a target.
        public var cloudWatchLogsParameters: PipesClientTypes.PipeTargetCloudWatchLogsParameters?
        /// The parameters for using an Amazon ECS task as a target.
        public var ecsTaskParameters: PipesClientTypes.PipeTargetEcsTaskParameters?
        /// The parameters for using an EventBridge event bus as a target.
        public var eventBridgeEventBusParameters: PipesClientTypes.PipeTargetEventBridgeEventBusParameters?
        /// These are custom parameter to be used when the target is an API Gateway REST APIs or EventBridge ApiDestinations.
        public var httpParameters: PipesClientTypes.PipeTargetHttpParameters?
        /// Valid JSON text passed to the target. In this case, nothing from the event itself is passed to the target. For more information, see [The JavaScript Object Notation (JSON) Data Interchange Format](http://www.rfc-editor.org/rfc/rfc7159.txt). To remove an input template, specify an empty string.
        public var inputTemplate: Swift.String?
        /// The parameters for using a Kinesis stream as a target.
        public var kinesisStreamParameters: PipesClientTypes.PipeTargetKinesisStreamParameters?
        /// The parameters for using a Lambda function as a target.
        public var lambdaFunctionParameters: PipesClientTypes.PipeTargetLambdaFunctionParameters?
        /// These are custom parameters to be used when the target is a Amazon Redshift cluster to invoke the Amazon Redshift Data API BatchExecuteStatement.
        public var redshiftDataParameters: PipesClientTypes.PipeTargetRedshiftDataParameters?
        /// The parameters for using a SageMaker pipeline as a target.
        public var sageMakerPipelineParameters: PipesClientTypes.PipeTargetSageMakerPipelineParameters?
        /// The parameters for using a Amazon SQS stream as a target.
        public var sqsQueueParameters: PipesClientTypes.PipeTargetSqsQueueParameters?
        /// The parameters for using a Step Functions state machine as a target.
        public var stepFunctionStateMachineParameters: PipesClientTypes.PipeTargetStateMachineParameters?
        /// The parameters for using a Timestream for LiveAnalytics table as a target.
        public var timestreamParameters: PipesClientTypes.PipeTargetTimestreamParameters?

        public init(
            batchJobParameters: PipesClientTypes.PipeTargetBatchJobParameters? = nil,
            cloudWatchLogsParameters: PipesClientTypes.PipeTargetCloudWatchLogsParameters? = nil,
            ecsTaskParameters: PipesClientTypes.PipeTargetEcsTaskParameters? = nil,
            eventBridgeEventBusParameters: PipesClientTypes.PipeTargetEventBridgeEventBusParameters? = nil,
            httpParameters: PipesClientTypes.PipeTargetHttpParameters? = nil,
            inputTemplate: Swift.String? = nil,
            kinesisStreamParameters: PipesClientTypes.PipeTargetKinesisStreamParameters? = nil,
            lambdaFunctionParameters: PipesClientTypes.PipeTargetLambdaFunctionParameters? = nil,
            redshiftDataParameters: PipesClientTypes.PipeTargetRedshiftDataParameters? = nil,
            sageMakerPipelineParameters: PipesClientTypes.PipeTargetSageMakerPipelineParameters? = nil,
            sqsQueueParameters: PipesClientTypes.PipeTargetSqsQueueParameters? = nil,
            stepFunctionStateMachineParameters: PipesClientTypes.PipeTargetStateMachineParameters? = nil,
            timestreamParameters: PipesClientTypes.PipeTargetTimestreamParameters? = nil
        )
        {
            self.batchJobParameters = batchJobParameters
            self.cloudWatchLogsParameters = cloudWatchLogsParameters
            self.ecsTaskParameters = ecsTaskParameters
            self.eventBridgeEventBusParameters = eventBridgeEventBusParameters
            self.httpParameters = httpParameters
            self.inputTemplate = inputTemplate
            self.kinesisStreamParameters = kinesisStreamParameters
            self.lambdaFunctionParameters = lambdaFunctionParameters
            self.redshiftDataParameters = redshiftDataParameters
            self.sageMakerPipelineParameters = sageMakerPipelineParameters
            self.sqsQueueParameters = sqsQueueParameters
            self.stepFunctionStateMachineParameters = stepFunctionStateMachineParameters
            self.timestreamParameters = timestreamParameters
        }
    }
}

extension PipesClientTypes.PipeTargetParameters: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "PipeTargetParameters(batchJobParameters: \(Swift.String(describing: batchJobParameters)), cloudWatchLogsParameters: \(Swift.String(describing: cloudWatchLogsParameters)), ecsTaskParameters: \(Swift.String(describing: ecsTaskParameters)), eventBridgeEventBusParameters: \(Swift.String(describing: eventBridgeEventBusParameters)), httpParameters: \(Swift.String(describing: httpParameters)), kinesisStreamParameters: \(Swift.String(describing: kinesisStreamParameters)), lambdaFunctionParameters: \(Swift.String(describing: lambdaFunctionParameters)), redshiftDataParameters: \(Swift.String(describing: redshiftDataParameters)), sageMakerPipelineParameters: \(Swift.String(describing: sageMakerPipelineParameters)), sqsQueueParameters: \(Swift.String(describing: sqsQueueParameters)), stepFunctionStateMachineParameters: \(Swift.String(describing: stepFunctionStateMachineParameters)), timestreamParameters: \(Swift.String(describing: timestreamParameters)), inputTemplate: \"CONTENT_REDACTED\")"}
}

public struct CreatePipeInput: Swift.Sendable {
    /// A description of the pipe.
    public var description: Swift.String?
    /// The state the pipe should be in.
    public var desiredState: PipesClientTypes.RequestedPipeState?
    /// The ARN of the enrichment resource.
    public var enrichment: Swift.String?
    /// The parameters required to set up enrichment on your pipe.
    public var enrichmentParameters: PipesClientTypes.PipeEnrichmentParameters?
    /// The identifier of the KMS customer managed key for EventBridge to use, if you choose to use a customer managed key to encrypt pipe data. The identifier can be the key Amazon Resource Name (ARN), KeyId, key alias, or key alias ARN. If you do not specify a customer managed key identifier, EventBridge uses an Amazon Web Services owned key to encrypt pipe data. For more information, see [Managing keys](https://docs.aws.amazon.com/kms/latest/developerguide/getting-started.html) in the Key Management Service Developer Guide.
    public var kmsKeyIdentifier: Swift.String?
    /// The logging configuration settings for the pipe.
    public var logConfiguration: PipesClientTypes.PipeLogConfigurationParameters?
    /// The name of the pipe.
    /// This member is required.
    public var name: Swift.String?
    /// The ARN of the role that allows the pipe to send data to the target.
    /// This member is required.
    public var roleArn: Swift.String?
    /// The ARN of the source resource.
    /// This member is required.
    public var source: Swift.String?
    /// The parameters required to set up a source for your pipe.
    public var sourceParameters: PipesClientTypes.PipeSourceParameters?
    /// The list of key-value pairs to associate with the pipe.
    public var tags: [Swift.String: Swift.String]?
    /// The ARN of the target resource.
    /// This member is required.
    public var target: Swift.String?
    /// The parameters required to set up a target for your pipe. For more information about pipe target parameters, including how to use dynamic path parameters, see [Target parameters](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-event-target.html) in the Amazon EventBridge User Guide.
    public var targetParameters: PipesClientTypes.PipeTargetParameters?

    public init(
        description: Swift.String? = nil,
        desiredState: PipesClientTypes.RequestedPipeState? = nil,
        enrichment: Swift.String? = nil,
        enrichmentParameters: PipesClientTypes.PipeEnrichmentParameters? = nil,
        kmsKeyIdentifier: Swift.String? = nil,
        logConfiguration: PipesClientTypes.PipeLogConfigurationParameters? = nil,
        name: Swift.String? = nil,
        roleArn: Swift.String? = nil,
        source: Swift.String? = nil,
        sourceParameters: PipesClientTypes.PipeSourceParameters? = nil,
        tags: [Swift.String: Swift.String]? = nil,
        target: Swift.String? = nil,
        targetParameters: PipesClientTypes.PipeTargetParameters? = nil
    )
    {
        self.description = description
        self.desiredState = desiredState
        self.enrichment = enrichment
        self.enrichmentParameters = enrichmentParameters
        self.kmsKeyIdentifier = kmsKeyIdentifier
        self.logConfiguration = logConfiguration
        self.name = name
        self.roleArn = roleArn
        self.source = source
        self.sourceParameters = sourceParameters
        self.tags = tags
        self.target = target
        self.targetParameters = targetParameters
    }
}

extension CreatePipeInput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "CreatePipeInput(desiredState: \(Swift.String(describing: desiredState)), enrichment: \(Swift.String(describing: enrichment)), enrichmentParameters: \(Swift.String(describing: enrichmentParameters)), kmsKeyIdentifier: \(Swift.String(describing: kmsKeyIdentifier)), logConfiguration: \(Swift.String(describing: logConfiguration)), name: \(Swift.String(describing: name)), roleArn: \(Swift.String(describing: roleArn)), source: \(Swift.String(describing: source)), sourceParameters: \(Swift.String(describing: sourceParameters)), target: \(Swift.String(describing: target)), targetParameters: \(Swift.String(describing: targetParameters)), description: \"CONTENT_REDACTED\", tags: [keys: \(Swift.String(describing: tags?.keys)), values: \"CONTENT_REDACTED\"])"}
}

extension PipesClientTypes {

    public enum PipeState: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case createFailed
        case createRollbackFailed
        case creating
        case deleteFailed
        case deleteRollbackFailed
        case deleting
        case running
        case starting
        case startFailed
        case stopped
        case stopping
        case stopFailed
        case updateFailed
        case updateRollbackFailed
        case updating
        case sdkUnknown(Swift.String)

        public static var allCases: [PipeState] {
            return [
                .createFailed,
                .createRollbackFailed,
                .creating,
                .deleteFailed,
                .deleteRollbackFailed,
                .deleting,
                .running,
                .starting,
                .startFailed,
                .stopped,
                .stopping,
                .stopFailed,
                .updateFailed,
                .updateRollbackFailed,
                .updating
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .createFailed: return "CREATE_FAILED"
            case .createRollbackFailed: return "CREATE_ROLLBACK_FAILED"
            case .creating: return "CREATING"
            case .deleteFailed: return "DELETE_FAILED"
            case .deleteRollbackFailed: return "DELETE_ROLLBACK_FAILED"
            case .deleting: return "DELETING"
            case .running: return "RUNNING"
            case .starting: return "STARTING"
            case .startFailed: return "START_FAILED"
            case .stopped: return "STOPPED"
            case .stopping: return "STOPPING"
            case .stopFailed: return "STOP_FAILED"
            case .updateFailed: return "UPDATE_FAILED"
            case .updateRollbackFailed: return "UPDATE_ROLLBACK_FAILED"
            case .updating: return "UPDATING"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

public struct CreatePipeOutput: Swift.Sendable {
    /// The ARN of the pipe.
    public var arn: Swift.String?
    /// The time the pipe was created.
    public var creationTime: Foundation.Date?
    /// The state the pipe is in.
    public var currentState: PipesClientTypes.PipeState?
    /// The state the pipe should be in.
    public var desiredState: PipesClientTypes.RequestedPipeState?
    /// When the pipe was last updated, in [ISO-8601 format](https://www.w3.org/TR/NOTE-datetime) (YYYY-MM-DDThh:mm:ss.sTZD).
    public var lastModifiedTime: Foundation.Date?
    /// The name of the pipe.
    public var name: Swift.String?

    public init(
        arn: Swift.String? = nil,
        creationTime: Foundation.Date? = nil,
        currentState: PipesClientTypes.PipeState? = nil,
        desiredState: PipesClientTypes.RequestedPipeState? = nil,
        lastModifiedTime: Foundation.Date? = nil,
        name: Swift.String? = nil
    )
    {
        self.arn = arn
        self.creationTime = creationTime
        self.currentState = currentState
        self.desiredState = desiredState
        self.lastModifiedTime = lastModifiedTime
        self.name = name
    }
}

public struct DeletePipeInput: Swift.Sendable {
    /// The name of the pipe.
    /// This member is required.
    public var name: Swift.String?

    public init(
        name: Swift.String? = nil
    )
    {
        self.name = name
    }
}

extension PipesClientTypes {

    public enum RequestedPipeStateDescribeResponse: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case deleted
        case running
        case stopped
        case sdkUnknown(Swift.String)

        public static var allCases: [RequestedPipeStateDescribeResponse] {
            return [
                .deleted,
                .running,
                .stopped
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .deleted: return "DELETED"
            case .running: return "RUNNING"
            case .stopped: return "STOPPED"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

public struct DeletePipeOutput: Swift.Sendable {
    /// The ARN of the pipe.
    public var arn: Swift.String?
    /// The time the pipe was created.
    public var creationTime: Foundation.Date?
    /// The state the pipe is in.
    public var currentState: PipesClientTypes.PipeState?
    /// The state the pipe should be in.
    public var desiredState: PipesClientTypes.RequestedPipeStateDescribeResponse?
    /// When the pipe was last updated, in [ISO-8601 format](https://www.w3.org/TR/NOTE-datetime) (YYYY-MM-DDThh:mm:ss.sTZD).
    public var lastModifiedTime: Foundation.Date?
    /// The name of the pipe.
    public var name: Swift.String?

    public init(
        arn: Swift.String? = nil,
        creationTime: Foundation.Date? = nil,
        currentState: PipesClientTypes.PipeState? = nil,
        desiredState: PipesClientTypes.RequestedPipeStateDescribeResponse? = nil,
        lastModifiedTime: Foundation.Date? = nil,
        name: Swift.String? = nil
    )
    {
        self.arn = arn
        self.creationTime = creationTime
        self.currentState = currentState
        self.desiredState = desiredState
        self.lastModifiedTime = lastModifiedTime
        self.name = name
    }
}

public struct DescribePipeInput: Swift.Sendable {
    /// The name of the pipe.
    /// This member is required.
    public var name: Swift.String?

    public init(
        name: Swift.String? = nil
    )
    {
        self.name = name
    }
}

extension PipesClientTypes {

    /// The Amazon Data Firehose logging configuration settings for the pipe.
    public struct FirehoseLogDestination: Swift.Sendable {
        /// The Amazon Resource Name (ARN) of the Firehose delivery stream to which EventBridge delivers the pipe log records.
        public var deliveryStreamArn: Swift.String?

        public init(
            deliveryStreamArn: Swift.String? = nil
        )
        {
            self.deliveryStreamArn = deliveryStreamArn
        }
    }
}

extension PipesClientTypes {

    /// The Amazon S3 logging configuration settings for the pipe.
    public struct S3LogDestination: Swift.Sendable {
        /// The name of the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.
        public var bucketName: Swift.String?
        /// The Amazon Web Services account that owns the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.
        public var bucketOwner: Swift.String?
        /// The format EventBridge uses for the log records. EventBridge currently only supports json formatting.
        public var outputFormat: PipesClientTypes.S3OutputFormat?
        /// The prefix text with which to begin Amazon S3 log object names. For more information, see [Organizing objects using prefixes](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-prefixes.html) in the Amazon Simple Storage Service User Guide.
        public var `prefix`: Swift.String?

        public init(
            bucketName: Swift.String? = nil,
            bucketOwner: Swift.String? = nil,
            outputFormat: PipesClientTypes.S3OutputFormat? = nil,
            `prefix`: Swift.String? = nil
        )
        {
            self.bucketName = bucketName
            self.bucketOwner = bucketOwner
            self.outputFormat = outputFormat
            self.`prefix` = `prefix`
        }
    }
}

extension PipesClientTypes {

    /// The logging configuration settings for the pipe.
    public struct PipeLogConfiguration: Swift.Sendable {
        /// The Amazon CloudWatch Logs logging configuration settings for the pipe.
        public var cloudwatchLogsLogDestination: PipesClientTypes.CloudwatchLogsLogDestination?
        /// The Amazon Data Firehose logging configuration settings for the pipe.
        public var firehoseLogDestination: PipesClientTypes.FirehoseLogDestination?
        /// Whether the execution data (specifically, the payload, awsRequest, and awsResponse fields) is included in the log messages for this pipe. This applies to all log destinations for the pipe. For more information, see [Including execution data in logs](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-logs.html#eb-pipes-logs-execution-data) in the Amazon EventBridge User Guide.
        public var includeExecutionData: [PipesClientTypes.IncludeExecutionDataOption]?
        /// The level of logging detail to include. This applies to all log destinations for the pipe.
        public var level: PipesClientTypes.LogLevel?
        /// The Amazon S3 logging configuration settings for the pipe.
        public var s3LogDestination: PipesClientTypes.S3LogDestination?

        public init(
            cloudwatchLogsLogDestination: PipesClientTypes.CloudwatchLogsLogDestination? = nil,
            firehoseLogDestination: PipesClientTypes.FirehoseLogDestination? = nil,
            includeExecutionData: [PipesClientTypes.IncludeExecutionDataOption]? = nil,
            level: PipesClientTypes.LogLevel? = nil,
            s3LogDestination: PipesClientTypes.S3LogDestination? = nil
        )
        {
            self.cloudwatchLogsLogDestination = cloudwatchLogsLogDestination
            self.firehoseLogDestination = firehoseLogDestination
            self.includeExecutionData = includeExecutionData
            self.level = level
            self.s3LogDestination = s3LogDestination
        }
    }
}

public struct DescribePipeOutput: Swift.Sendable {
    /// The ARN of the pipe.
    public var arn: Swift.String?
    /// The time the pipe was created.
    public var creationTime: Foundation.Date?
    /// The state the pipe is in.
    public var currentState: PipesClientTypes.PipeState?
    /// A description of the pipe.
    public var description: Swift.String?
    /// The state the pipe should be in.
    public var desiredState: PipesClientTypes.RequestedPipeStateDescribeResponse?
    /// The ARN of the enrichment resource.
    public var enrichment: Swift.String?
    /// The parameters required to set up enrichment on your pipe.
    public var enrichmentParameters: PipesClientTypes.PipeEnrichmentParameters?
    /// The identifier of the KMS customer managed key for EventBridge to use to encrypt pipe data, if one has been specified. For more information, see [Data encryption in EventBridge](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-encryption.html) in the Amazon EventBridge User Guide.
    public var kmsKeyIdentifier: Swift.String?
    /// When the pipe was last updated, in [ISO-8601 format](https://www.w3.org/TR/NOTE-datetime) (YYYY-MM-DDThh:mm:ss.sTZD).
    public var lastModifiedTime: Foundation.Date?
    /// The logging configuration settings for the pipe.
    public var logConfiguration: PipesClientTypes.PipeLogConfiguration?
    /// The name of the pipe.
    public var name: Swift.String?
    /// The ARN of the role that allows the pipe to send data to the target.
    public var roleArn: Swift.String?
    /// The ARN of the source resource.
    public var source: Swift.String?
    /// The parameters required to set up a source for your pipe.
    public var sourceParameters: PipesClientTypes.PipeSourceParameters?
    /// The reason the pipe is in its current state.
    public var stateReason: Swift.String?
    /// The list of key-value pairs to associate with the pipe.
    public var tags: [Swift.String: Swift.String]?
    /// The ARN of the target resource.
    public var target: Swift.String?
    /// The parameters required to set up a target for your pipe. For more information about pipe target parameters, including how to use dynamic path parameters, see [Target parameters](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-event-target.html) in the Amazon EventBridge User Guide.
    public var targetParameters: PipesClientTypes.PipeTargetParameters?

    public init(
        arn: Swift.String? = nil,
        creationTime: Foundation.Date? = nil,
        currentState: PipesClientTypes.PipeState? = nil,
        description: Swift.String? = nil,
        desiredState: PipesClientTypes.RequestedPipeStateDescribeResponse? = nil,
        enrichment: Swift.String? = nil,
        enrichmentParameters: PipesClientTypes.PipeEnrichmentParameters? = nil,
        kmsKeyIdentifier: Swift.String? = nil,
        lastModifiedTime: Foundation.Date? = nil,
        logConfiguration: PipesClientTypes.PipeLogConfiguration? = nil,
        name: Swift.String? = nil,
        roleArn: Swift.String? = nil,
        source: Swift.String? = nil,
        sourceParameters: PipesClientTypes.PipeSourceParameters? = nil,
        stateReason: Swift.String? = nil,
        tags: [Swift.String: Swift.String]? = nil,
        target: Swift.String? = nil,
        targetParameters: PipesClientTypes.PipeTargetParameters? = nil
    )
    {
        self.arn = arn
        self.creationTime = creationTime
        self.currentState = currentState
        self.description = description
        self.desiredState = desiredState
        self.enrichment = enrichment
        self.enrichmentParameters = enrichmentParameters
        self.kmsKeyIdentifier = kmsKeyIdentifier
        self.lastModifiedTime = lastModifiedTime
        self.logConfiguration = logConfiguration
        self.name = name
        self.roleArn = roleArn
        self.source = source
        self.sourceParameters = sourceParameters
        self.stateReason = stateReason
        self.tags = tags
        self.target = target
        self.targetParameters = targetParameters
    }
}

extension DescribePipeOutput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "DescribePipeOutput(arn: \(Swift.String(describing: arn)), creationTime: \(Swift.String(describing: creationTime)), currentState: \(Swift.String(describing: currentState)), desiredState: \(Swift.String(describing: desiredState)), enrichment: \(Swift.String(describing: enrichment)), enrichmentParameters: \(Swift.String(describing: enrichmentParameters)), kmsKeyIdentifier: \(Swift.String(describing: kmsKeyIdentifier)), lastModifiedTime: \(Swift.String(describing: lastModifiedTime)), logConfiguration: \(Swift.String(describing: logConfiguration)), name: \(Swift.String(describing: name)), roleArn: \(Swift.String(describing: roleArn)), source: \(Swift.String(describing: source)), sourceParameters: \(Swift.String(describing: sourceParameters)), stateReason: \(Swift.String(describing: stateReason)), target: \(Swift.String(describing: target)), targetParameters: \(Swift.String(describing: targetParameters)), description: \"CONTENT_REDACTED\", tags: [keys: \(Swift.String(describing: tags?.keys)), values: \"CONTENT_REDACTED\"])"}
}

public struct ListPipesInput: Swift.Sendable {
    /// The state the pipe is in.
    public var currentState: PipesClientTypes.PipeState?
    /// The state the pipe should be in.
    public var desiredState: PipesClientTypes.RequestedPipeState?
    /// The maximum number of pipes to include in the response.
    public var limit: Swift.Int?
    /// A value that will return a subset of the pipes associated with this account. For example, "NamePrefix": "ABC" will return all endpoints with "ABC" in the name.
    public var namePrefix: Swift.String?
    /// If nextToken is returned, there are more results available. The value of nextToken is a unique pagination token for each page. Make the call again using the returned token to retrieve the next page. Keep all other arguments unchanged. Each pagination token expires after 24 hours. Using an expired pagination token will return an HTTP 400 InvalidToken error.
    public var nextToken: Swift.String?
    /// The prefix matching the pipe source.
    public var sourcePrefix: Swift.String?
    /// The prefix matching the pipe target.
    public var targetPrefix: Swift.String?

    public init(
        currentState: PipesClientTypes.PipeState? = nil,
        desiredState: PipesClientTypes.RequestedPipeState? = nil,
        limit: Swift.Int? = nil,
        namePrefix: Swift.String? = nil,
        nextToken: Swift.String? = nil,
        sourcePrefix: Swift.String? = nil,
        targetPrefix: Swift.String? = nil
    )
    {
        self.currentState = currentState
        self.desiredState = desiredState
        self.limit = limit
        self.namePrefix = namePrefix
        self.nextToken = nextToken
        self.sourcePrefix = sourcePrefix
        self.targetPrefix = targetPrefix
    }
}

extension ListPipesInput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "ListPipesInput(currentState: \(Swift.String(describing: currentState)), desiredState: \(Swift.String(describing: desiredState)), limit: \(Swift.String(describing: limit)), namePrefix: \(Swift.String(describing: namePrefix)), sourcePrefix: \(Swift.String(describing: sourcePrefix)), targetPrefix: \(Swift.String(describing: targetPrefix)), nextToken: \"CONTENT_REDACTED\")"}
}

extension PipesClientTypes {

    /// An object that represents a pipe. Amazon EventBridgePipes connect event sources to targets and reduces the need for specialized knowledge and integration code.
    public struct Pipe: Swift.Sendable {
        /// The ARN of the pipe.
        public var arn: Swift.String?
        /// The time the pipe was created.
        public var creationTime: Foundation.Date?
        /// The state the pipe is in.
        public var currentState: PipesClientTypes.PipeState?
        /// The state the pipe should be in.
        public var desiredState: PipesClientTypes.RequestedPipeState?
        /// The ARN of the enrichment resource.
        public var enrichment: Swift.String?
        /// When the pipe was last updated, in [ISO-8601 format](https://www.w3.org/TR/NOTE-datetime) (YYYY-MM-DDThh:mm:ss.sTZD).
        public var lastModifiedTime: Foundation.Date?
        /// The name of the pipe.
        public var name: Swift.String?
        /// The ARN of the source resource.
        public var source: Swift.String?
        /// The reason the pipe is in its current state.
        public var stateReason: Swift.String?
        /// The ARN of the target resource.
        public var target: Swift.String?

        public init(
            arn: Swift.String? = nil,
            creationTime: Foundation.Date? = nil,
            currentState: PipesClientTypes.PipeState? = nil,
            desiredState: PipesClientTypes.RequestedPipeState? = nil,
            enrichment: Swift.String? = nil,
            lastModifiedTime: Foundation.Date? = nil,
            name: Swift.String? = nil,
            source: Swift.String? = nil,
            stateReason: Swift.String? = nil,
            target: Swift.String? = nil
        )
        {
            self.arn = arn
            self.creationTime = creationTime
            self.currentState = currentState
            self.desiredState = desiredState
            self.enrichment = enrichment
            self.lastModifiedTime = lastModifiedTime
            self.name = name
            self.source = source
            self.stateReason = stateReason
            self.target = target
        }
    }
}

public struct ListPipesOutput: Swift.Sendable {
    /// If nextToken is returned, there are more results available. The value of nextToken is a unique pagination token for each page. Make the call again using the returned token to retrieve the next page. Keep all other arguments unchanged. Each pagination token expires after 24 hours. Using an expired pagination token will return an HTTP 400 InvalidToken error.
    public var nextToken: Swift.String?
    /// The pipes returned by the call.
    public var pipes: [PipesClientTypes.Pipe]?

    public init(
        nextToken: Swift.String? = nil,
        pipes: [PipesClientTypes.Pipe]? = nil
    )
    {
        self.nextToken = nextToken
        self.pipes = pipes
    }
}

extension ListPipesOutput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "ListPipesOutput(pipes: \(Swift.String(describing: pipes)), nextToken: \"CONTENT_REDACTED\")"}
}

public struct ListTagsForResourceInput: Swift.Sendable {
    /// The ARN of the pipe for which you want to view tags.
    /// This member is required.
    public var resourceArn: Swift.String?

    public init(
        resourceArn: Swift.String? = nil
    )
    {
        self.resourceArn = resourceArn
    }
}

public struct ListTagsForResourceOutput: Swift.Sendable {
    /// The list of key-value pairs to associate with the pipe.
    public var tags: [Swift.String: Swift.String]?

    public init(
        tags: [Swift.String: Swift.String]? = nil
    )
    {
        self.tags = tags
    }
}

extension ListTagsForResourceOutput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "ListTagsForResourceOutput(tags: [keys: \(Swift.String(describing: tags?.keys)), values: \"CONTENT_REDACTED\"])"}
}

public struct StartPipeInput: Swift.Sendable {
    /// The name of the pipe.
    /// This member is required.
    public var name: Swift.String?

    public init(
        name: Swift.String? = nil
    )
    {
        self.name = name
    }
}

public struct StartPipeOutput: Swift.Sendable {
    /// The ARN of the pipe.
    public var arn: Swift.String?
    /// The time the pipe was created.
    public var creationTime: Foundation.Date?
    /// The state the pipe is in.
    public var currentState: PipesClientTypes.PipeState?
    /// The state the pipe should be in.
    public var desiredState: PipesClientTypes.RequestedPipeState?
    /// When the pipe was last updated, in [ISO-8601 format](https://www.w3.org/TR/NOTE-datetime) (YYYY-MM-DDThh:mm:ss.sTZD).
    public var lastModifiedTime: Foundation.Date?
    /// The name of the pipe.
    public var name: Swift.String?

    public init(
        arn: Swift.String? = nil,
        creationTime: Foundation.Date? = nil,
        currentState: PipesClientTypes.PipeState? = nil,
        desiredState: PipesClientTypes.RequestedPipeState? = nil,
        lastModifiedTime: Foundation.Date? = nil,
        name: Swift.String? = nil
    )
    {
        self.arn = arn
        self.creationTime = creationTime
        self.currentState = currentState
        self.desiredState = desiredState
        self.lastModifiedTime = lastModifiedTime
        self.name = name
    }
}

public struct StopPipeInput: Swift.Sendable {
    /// The name of the pipe.
    /// This member is required.
    public var name: Swift.String?

    public init(
        name: Swift.String? = nil
    )
    {
        self.name = name
    }
}

public struct StopPipeOutput: Swift.Sendable {
    /// The ARN of the pipe.
    public var arn: Swift.String?
    /// The time the pipe was created.
    public var creationTime: Foundation.Date?
    /// The state the pipe is in.
    public var currentState: PipesClientTypes.PipeState?
    /// The state the pipe should be in.
    public var desiredState: PipesClientTypes.RequestedPipeState?
    /// When the pipe was last updated, in [ISO-8601 format](https://www.w3.org/TR/NOTE-datetime) (YYYY-MM-DDThh:mm:ss.sTZD).
    public var lastModifiedTime: Foundation.Date?
    /// The name of the pipe.
    public var name: Swift.String?

    public init(
        arn: Swift.String? = nil,
        creationTime: Foundation.Date? = nil,
        currentState: PipesClientTypes.PipeState? = nil,
        desiredState: PipesClientTypes.RequestedPipeState? = nil,
        lastModifiedTime: Foundation.Date? = nil,
        name: Swift.String? = nil
    )
    {
        self.arn = arn
        self.creationTime = creationTime
        self.currentState = currentState
        self.desiredState = desiredState
        self.lastModifiedTime = lastModifiedTime
        self.name = name
    }
}

extension PipesClientTypes {

    /// The parameters for using an Active MQ broker as a source.
    public struct UpdatePipeSourceActiveMQBrokerParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// The credentials needed to access the resource.
        /// This member is required.
        public var credentials: PipesClientTypes.MQBrokerAccessCredentials?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?

        public init(
            batchSize: Swift.Int? = nil,
            credentials: PipesClientTypes.MQBrokerAccessCredentials? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil
        )
        {
            self.batchSize = batchSize
            self.credentials = credentials
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using a DynamoDB stream as a source.
    public struct UpdatePipeSourceDynamoDBStreamParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// Define the target queue to send dead-letter queue events to.
        public var deadLetterConfig: PipesClientTypes.DeadLetterConfig?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?
        /// Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.
        public var maximumRecordAgeInSeconds: Swift.Int?
        /// Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.
        public var maximumRetryAttempts: Swift.Int?
        /// Define how to handle item process failures. AUTOMATIC_BISECT halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.
        public var onPartialBatchItemFailure: PipesClientTypes.OnPartialBatchItemFailureStreams?
        /// The number of batches to process concurrently from each shard. The default value is 1.
        public var parallelizationFactor: Swift.Int?

        public init(
            batchSize: Swift.Int? = nil,
            deadLetterConfig: PipesClientTypes.DeadLetterConfig? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil,
            maximumRecordAgeInSeconds: Swift.Int? = nil,
            maximumRetryAttempts: Swift.Int? = nil,
            onPartialBatchItemFailure: PipesClientTypes.OnPartialBatchItemFailureStreams? = nil,
            parallelizationFactor: Swift.Int? = nil
        )
        {
            self.batchSize = batchSize
            self.deadLetterConfig = deadLetterConfig
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
            self.maximumRecordAgeInSeconds = maximumRecordAgeInSeconds
            self.maximumRetryAttempts = maximumRetryAttempts
            self.onPartialBatchItemFailure = onPartialBatchItemFailure
            self.parallelizationFactor = parallelizationFactor
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using a Kinesis stream as a source.
    public struct UpdatePipeSourceKinesisStreamParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// Define the target queue to send dead-letter queue events to.
        public var deadLetterConfig: PipesClientTypes.DeadLetterConfig?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?
        /// Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.
        public var maximumRecordAgeInSeconds: Swift.Int?
        /// Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.
        public var maximumRetryAttempts: Swift.Int?
        /// Define how to handle item process failures. AUTOMATIC_BISECT halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.
        public var onPartialBatchItemFailure: PipesClientTypes.OnPartialBatchItemFailureStreams?
        /// The number of batches to process concurrently from each shard. The default value is 1.
        public var parallelizationFactor: Swift.Int?

        public init(
            batchSize: Swift.Int? = nil,
            deadLetterConfig: PipesClientTypes.DeadLetterConfig? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil,
            maximumRecordAgeInSeconds: Swift.Int? = nil,
            maximumRetryAttempts: Swift.Int? = nil,
            onPartialBatchItemFailure: PipesClientTypes.OnPartialBatchItemFailureStreams? = nil,
            parallelizationFactor: Swift.Int? = nil
        )
        {
            self.batchSize = batchSize
            self.deadLetterConfig = deadLetterConfig
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
            self.maximumRecordAgeInSeconds = maximumRecordAgeInSeconds
            self.maximumRetryAttempts = maximumRetryAttempts
            self.onPartialBatchItemFailure = onPartialBatchItemFailure
            self.parallelizationFactor = parallelizationFactor
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using an MSK stream as a source.
    public struct UpdatePipeSourceManagedStreamingKafkaParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// The credentials needed to access the resource.
        public var credentials: PipesClientTypes.MSKAccessCredentials?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?

        public init(
            batchSize: Swift.Int? = nil,
            credentials: PipesClientTypes.MSKAccessCredentials? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil
        )
        {
            self.batchSize = batchSize
            self.credentials = credentials
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using a Rabbit MQ broker as a source.
    public struct UpdatePipeSourceRabbitMQBrokerParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// The credentials needed to access the resource.
        /// This member is required.
        public var credentials: PipesClientTypes.MQBrokerAccessCredentials?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?

        public init(
            batchSize: Swift.Int? = nil,
            credentials: PipesClientTypes.MQBrokerAccessCredentials? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil
        )
        {
            self.batchSize = batchSize
            self.credentials = credentials
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using a self-managed Apache Kafka stream as a source. A self managed cluster refers to any Apache Kafka cluster not hosted by Amazon Web Services. This includes both clusters you manage yourself, as well as those hosted by a third-party provider, such as [Confluent Cloud](https://www.confluent.io/), [CloudKarafka](https://www.cloudkarafka.com/), or [Redpanda](https://redpanda.com/). For more information, see [Apache Kafka streams as a source](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-kafka.html) in the Amazon EventBridge User Guide.
    public struct UpdatePipeSourceSelfManagedKafkaParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// The credentials needed to access the resource.
        public var credentials: PipesClientTypes.SelfManagedKafkaAccessConfigurationCredentials?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?
        /// The ARN of the Secrets Manager secret used for certification.
        public var serverRootCaCertificate: Swift.String?
        /// This structure specifies the VPC subnets and security groups for the stream, and whether a public IP address is to be used.
        public var vpc: PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc?

        public init(
            batchSize: Swift.Int? = nil,
            credentials: PipesClientTypes.SelfManagedKafkaAccessConfigurationCredentials? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil,
            serverRootCaCertificate: Swift.String? = nil,
            vpc: PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc? = nil
        )
        {
            self.batchSize = batchSize
            self.credentials = credentials
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
            self.serverRootCaCertificate = serverRootCaCertificate
            self.vpc = vpc
        }
    }
}

extension PipesClientTypes {

    /// The parameters for using a Amazon SQS stream as a source.
    public struct UpdatePipeSourceSqsQueueParameters: Swift.Sendable {
        /// The maximum number of records to include in each batch.
        public var batchSize: Swift.Int?
        /// The maximum length of a time to wait for events.
        public var maximumBatchingWindowInSeconds: Swift.Int?

        public init(
            batchSize: Swift.Int? = nil,
            maximumBatchingWindowInSeconds: Swift.Int? = nil
        )
        {
            self.batchSize = batchSize
            self.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds
        }
    }
}

extension PipesClientTypes {

    /// The parameters required to set up a source for your pipe.
    public struct UpdatePipeSourceParameters: Swift.Sendable {
        /// The parameters for using an Active MQ broker as a source.
        public var activeMQBrokerParameters: PipesClientTypes.UpdatePipeSourceActiveMQBrokerParameters?
        /// The parameters for using a DynamoDB stream as a source.
        public var dynamoDBStreamParameters: PipesClientTypes.UpdatePipeSourceDynamoDBStreamParameters?
        /// The collection of event patterns used to filter events. To remove a filter, specify a FilterCriteria object with an empty array of Filter objects. For more information, see [Events and Event Patterns](https://docs.aws.amazon.com/eventbridge/latest/userguide/eventbridge-and-event-patterns.html) in the Amazon EventBridge User Guide.
        public var filterCriteria: PipesClientTypes.FilterCriteria?
        /// The parameters for using a Kinesis stream as a source.
        public var kinesisStreamParameters: PipesClientTypes.UpdatePipeSourceKinesisStreamParameters?
        /// The parameters for using an MSK stream as a source.
        public var managedStreamingKafkaParameters: PipesClientTypes.UpdatePipeSourceManagedStreamingKafkaParameters?
        /// The parameters for using a Rabbit MQ broker as a source.
        public var rabbitMQBrokerParameters: PipesClientTypes.UpdatePipeSourceRabbitMQBrokerParameters?
        /// The parameters for using a self-managed Apache Kafka stream as a source. A self managed cluster refers to any Apache Kafka cluster not hosted by Amazon Web Services. This includes both clusters you manage yourself, as well as those hosted by a third-party provider, such as [Confluent Cloud](https://www.confluent.io/), [CloudKarafka](https://www.cloudkarafka.com/), or [Redpanda](https://redpanda.com/). For more information, see [Apache Kafka streams as a source](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-kafka.html) in the Amazon EventBridge User Guide.
        public var selfManagedKafkaParameters: PipesClientTypes.UpdatePipeSourceSelfManagedKafkaParameters?
        /// The parameters for using a Amazon SQS stream as a source.
        public var sqsQueueParameters: PipesClientTypes.UpdatePipeSourceSqsQueueParameters?

        public init(
            activeMQBrokerParameters: PipesClientTypes.UpdatePipeSourceActiveMQBrokerParameters? = nil,
            dynamoDBStreamParameters: PipesClientTypes.UpdatePipeSourceDynamoDBStreamParameters? = nil,
            filterCriteria: PipesClientTypes.FilterCriteria? = nil,
            kinesisStreamParameters: PipesClientTypes.UpdatePipeSourceKinesisStreamParameters? = nil,
            managedStreamingKafkaParameters: PipesClientTypes.UpdatePipeSourceManagedStreamingKafkaParameters? = nil,
            rabbitMQBrokerParameters: PipesClientTypes.UpdatePipeSourceRabbitMQBrokerParameters? = nil,
            selfManagedKafkaParameters: PipesClientTypes.UpdatePipeSourceSelfManagedKafkaParameters? = nil,
            sqsQueueParameters: PipesClientTypes.UpdatePipeSourceSqsQueueParameters? = nil
        )
        {
            self.activeMQBrokerParameters = activeMQBrokerParameters
            self.dynamoDBStreamParameters = dynamoDBStreamParameters
            self.filterCriteria = filterCriteria
            self.kinesisStreamParameters = kinesisStreamParameters
            self.managedStreamingKafkaParameters = managedStreamingKafkaParameters
            self.rabbitMQBrokerParameters = rabbitMQBrokerParameters
            self.selfManagedKafkaParameters = selfManagedKafkaParameters
            self.sqsQueueParameters = sqsQueueParameters
        }
    }
}

public struct UpdatePipeInput: Swift.Sendable {
    /// A description of the pipe.
    public var description: Swift.String?
    /// The state the pipe should be in.
    public var desiredState: PipesClientTypes.RequestedPipeState?
    /// The ARN of the enrichment resource.
    public var enrichment: Swift.String?
    /// The parameters required to set up enrichment on your pipe.
    public var enrichmentParameters: PipesClientTypes.PipeEnrichmentParameters?
    /// The identifier of the KMS customer managed key for EventBridge to use, if you choose to use a customer managed key to encrypt pipe data. The identifier can be the key Amazon Resource Name (ARN), KeyId, key alias, or key alias ARN. To update a pipe that is using the default Amazon Web Services owned key to use a customer managed key instead, or update a pipe that is using a customer managed key to use a different customer managed key, specify a customer managed key identifier. To update a pipe that is using a customer managed key to use the default Amazon Web Services owned key, specify an empty string. For more information, see [Managing keys](https://docs.aws.amazon.com/kms/latest/developerguide/getting-started.html) in the Key Management Service Developer Guide.
    public var kmsKeyIdentifier: Swift.String?
    /// The logging configuration settings for the pipe.
    public var logConfiguration: PipesClientTypes.PipeLogConfigurationParameters?
    /// The name of the pipe.
    /// This member is required.
    public var name: Swift.String?
    /// The ARN of the role that allows the pipe to send data to the target.
    /// This member is required.
    public var roleArn: Swift.String?
    /// The parameters required to set up a source for your pipe.
    public var sourceParameters: PipesClientTypes.UpdatePipeSourceParameters?
    /// The ARN of the target resource.
    public var target: Swift.String?
    /// The parameters required to set up a target for your pipe. For more information about pipe target parameters, including how to use dynamic path parameters, see [Target parameters](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-event-target.html) in the Amazon EventBridge User Guide.
    public var targetParameters: PipesClientTypes.PipeTargetParameters?

    public init(
        description: Swift.String? = nil,
        desiredState: PipesClientTypes.RequestedPipeState? = nil,
        enrichment: Swift.String? = nil,
        enrichmentParameters: PipesClientTypes.PipeEnrichmentParameters? = nil,
        kmsKeyIdentifier: Swift.String? = nil,
        logConfiguration: PipesClientTypes.PipeLogConfigurationParameters? = nil,
        name: Swift.String? = nil,
        roleArn: Swift.String? = nil,
        sourceParameters: PipesClientTypes.UpdatePipeSourceParameters? = nil,
        target: Swift.String? = nil,
        targetParameters: PipesClientTypes.PipeTargetParameters? = nil
    )
    {
        self.description = description
        self.desiredState = desiredState
        self.enrichment = enrichment
        self.enrichmentParameters = enrichmentParameters
        self.kmsKeyIdentifier = kmsKeyIdentifier
        self.logConfiguration = logConfiguration
        self.name = name
        self.roleArn = roleArn
        self.sourceParameters = sourceParameters
        self.target = target
        self.targetParameters = targetParameters
    }
}

extension UpdatePipeInput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "UpdatePipeInput(desiredState: \(Swift.String(describing: desiredState)), enrichment: \(Swift.String(describing: enrichment)), enrichmentParameters: \(Swift.String(describing: enrichmentParameters)), kmsKeyIdentifier: \(Swift.String(describing: kmsKeyIdentifier)), logConfiguration: \(Swift.String(describing: logConfiguration)), name: \(Swift.String(describing: name)), roleArn: \(Swift.String(describing: roleArn)), sourceParameters: \(Swift.String(describing: sourceParameters)), target: \(Swift.String(describing: target)), targetParameters: \(Swift.String(describing: targetParameters)), description: \"CONTENT_REDACTED\")"}
}

public struct UpdatePipeOutput: Swift.Sendable {
    /// The ARN of the pipe.
    public var arn: Swift.String?
    /// The time the pipe was created.
    public var creationTime: Foundation.Date?
    /// The state the pipe is in.
    public var currentState: PipesClientTypes.PipeState?
    /// The state the pipe should be in.
    public var desiredState: PipesClientTypes.RequestedPipeState?
    /// When the pipe was last updated, in [ISO-8601 format](https://www.w3.org/TR/NOTE-datetime) (YYYY-MM-DDThh:mm:ss.sTZD).
    public var lastModifiedTime: Foundation.Date?
    /// The name of the pipe.
    public var name: Swift.String?

    public init(
        arn: Swift.String? = nil,
        creationTime: Foundation.Date? = nil,
        currentState: PipesClientTypes.PipeState? = nil,
        desiredState: PipesClientTypes.RequestedPipeState? = nil,
        lastModifiedTime: Foundation.Date? = nil,
        name: Swift.String? = nil
    )
    {
        self.arn = arn
        self.creationTime = creationTime
        self.currentState = currentState
        self.desiredState = desiredState
        self.lastModifiedTime = lastModifiedTime
        self.name = name
    }
}

public struct TagResourceInput: Swift.Sendable {
    /// The ARN of the pipe.
    /// This member is required.
    public var resourceArn: Swift.String?
    /// The list of key-value pairs associated with the pipe.
    /// This member is required.
    public var tags: [Swift.String: Swift.String]?

    public init(
        resourceArn: Swift.String? = nil,
        tags: [Swift.String: Swift.String]? = nil
    )
    {
        self.resourceArn = resourceArn
        self.tags = tags
    }
}

extension TagResourceInput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "TagResourceInput(resourceArn: \(Swift.String(describing: resourceArn)), tags: [keys: \(Swift.String(describing: tags?.keys)), values: \"CONTENT_REDACTED\"])"}
}

public struct TagResourceOutput: Swift.Sendable {

    public init() { }
}

public struct UntagResourceInput: Swift.Sendable {
    /// The ARN of the pipe.
    /// This member is required.
    public var resourceArn: Swift.String?
    /// The list of tag keys to remove from the pipe.
    /// This member is required.
    public var tagKeys: [Swift.String]?

    public init(
        resourceArn: Swift.String? = nil,
        tagKeys: [Swift.String]? = nil
    )
    {
        self.resourceArn = resourceArn
        self.tagKeys = tagKeys
    }
}

public struct UntagResourceOutput: Swift.Sendable {

    public init() { }
}

extension CreatePipeInput {

    static func urlPathProvider(_ value: CreatePipeInput) -> Swift.String? {
        guard let name = value.name else {
            return nil
        }
        return "/v1/pipes/\(name.urlPercentEncoding())"
    }
}

extension DeletePipeInput {

    static func urlPathProvider(_ value: DeletePipeInput) -> Swift.String? {
        guard let name = value.name else {
            return nil
        }
        return "/v1/pipes/\(name.urlPercentEncoding())"
    }
}

extension DescribePipeInput {

    static func urlPathProvider(_ value: DescribePipeInput) -> Swift.String? {
        guard let name = value.name else {
            return nil
        }
        return "/v1/pipes/\(name.urlPercentEncoding())"
    }
}

extension ListPipesInput {

    static func urlPathProvider(_ value: ListPipesInput) -> Swift.String? {
        return "/v1/pipes"
    }
}

extension ListPipesInput {

    static func queryItemProvider(_ value: ListPipesInput) throws -> [Smithy.URIQueryItem] {
        var items = [Smithy.URIQueryItem]()
        if let namePrefix = value.namePrefix {
            let namePrefixQueryItem = Smithy.URIQueryItem(name: "NamePrefix".urlPercentEncoding(), value: Swift.String(namePrefix).urlPercentEncoding())
            items.append(namePrefixQueryItem)
        }
        if let targetPrefix = value.targetPrefix {
            let targetPrefixQueryItem = Smithy.URIQueryItem(name: "TargetPrefix".urlPercentEncoding(), value: Swift.String(targetPrefix).urlPercentEncoding())
            items.append(targetPrefixQueryItem)
        }
        if let sourcePrefix = value.sourcePrefix {
            let sourcePrefixQueryItem = Smithy.URIQueryItem(name: "SourcePrefix".urlPercentEncoding(), value: Swift.String(sourcePrefix).urlPercentEncoding())
            items.append(sourcePrefixQueryItem)
        }
        if let nextToken = value.nextToken {
            let nextTokenQueryItem = Smithy.URIQueryItem(name: "NextToken".urlPercentEncoding(), value: Swift.String(nextToken).urlPercentEncoding())
            items.append(nextTokenQueryItem)
        }
        if let desiredState = value.desiredState {
            let desiredStateQueryItem = Smithy.URIQueryItem(name: "DesiredState".urlPercentEncoding(), value: Swift.String(desiredState.rawValue).urlPercentEncoding())
            items.append(desiredStateQueryItem)
        }
        if let currentState = value.currentState {
            let currentStateQueryItem = Smithy.URIQueryItem(name: "CurrentState".urlPercentEncoding(), value: Swift.String(currentState.rawValue).urlPercentEncoding())
            items.append(currentStateQueryItem)
        }
        if let limit = value.limit {
            let limitQueryItem = Smithy.URIQueryItem(name: "Limit".urlPercentEncoding(), value: Swift.String(limit).urlPercentEncoding())
            items.append(limitQueryItem)
        }
        return items
    }
}

extension ListTagsForResourceInput {

    static func urlPathProvider(_ value: ListTagsForResourceInput) -> Swift.String? {
        guard let resourceArn = value.resourceArn else {
            return nil
        }
        return "/tags/\(resourceArn.urlPercentEncoding())"
    }
}

extension StartPipeInput {

    static func urlPathProvider(_ value: StartPipeInput) -> Swift.String? {
        guard let name = value.name else {
            return nil
        }
        return "/v1/pipes/\(name.urlPercentEncoding())/start"
    }
}

extension StopPipeInput {

    static func urlPathProvider(_ value: StopPipeInput) -> Swift.String? {
        guard let name = value.name else {
            return nil
        }
        return "/v1/pipes/\(name.urlPercentEncoding())/stop"
    }
}

extension TagResourceInput {

    static func urlPathProvider(_ value: TagResourceInput) -> Swift.String? {
        guard let resourceArn = value.resourceArn else {
            return nil
        }
        return "/tags/\(resourceArn.urlPercentEncoding())"
    }
}

extension UntagResourceInput {

    static func urlPathProvider(_ value: UntagResourceInput) -> Swift.String? {
        guard let resourceArn = value.resourceArn else {
            return nil
        }
        return "/tags/\(resourceArn.urlPercentEncoding())"
    }
}

extension UntagResourceInput {

    static func queryItemProvider(_ value: UntagResourceInput) throws -> [Smithy.URIQueryItem] {
        var items = [Smithy.URIQueryItem]()
        guard let tagKeys = value.tagKeys else {
            let message = "Creating a URL Query Item failed. tagKeys is required and must not be nil."
            throw Smithy.ClientError.unknownError(message)
        }
        tagKeys.forEach { queryItemValue in
            let queryItem = Smithy.URIQueryItem(name: "tagKeys".urlPercentEncoding(), value: Swift.String(queryItemValue).urlPercentEncoding())
            items.append(queryItem)
        }
        return items
    }
}

extension UpdatePipeInput {

    static func urlPathProvider(_ value: UpdatePipeInput) -> Swift.String? {
        guard let name = value.name else {
            return nil
        }
        return "/v1/pipes/\(name.urlPercentEncoding())"
    }
}

extension CreatePipeInput {

    static func write(value: CreatePipeInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Description"].write(value.description)
        try writer["DesiredState"].write(value.desiredState)
        try writer["Enrichment"].write(value.enrichment)
        try writer["EnrichmentParameters"].write(value.enrichmentParameters, with: PipesClientTypes.PipeEnrichmentParameters.write(value:to:))
        try writer["KmsKeyIdentifier"].write(value.kmsKeyIdentifier)
        try writer["LogConfiguration"].write(value.logConfiguration, with: PipesClientTypes.PipeLogConfigurationParameters.write(value:to:))
        try writer["RoleArn"].write(value.roleArn)
        try writer["Source"].write(value.source)
        try writer["SourceParameters"].write(value.sourceParameters, with: PipesClientTypes.PipeSourceParameters.write(value:to:))
        try writer["Tags"].writeMap(value.tags, valueWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        try writer["Target"].write(value.target)
        try writer["TargetParameters"].write(value.targetParameters, with: PipesClientTypes.PipeTargetParameters.write(value:to:))
    }
}

extension TagResourceInput {

    static func write(value: TagResourceInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["tags"].writeMap(value.tags, valueWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
    }
}

extension UpdatePipeInput {

    static func write(value: UpdatePipeInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Description"].write(value.description)
        try writer["DesiredState"].write(value.desiredState)
        try writer["Enrichment"].write(value.enrichment)
        try writer["EnrichmentParameters"].write(value.enrichmentParameters, with: PipesClientTypes.PipeEnrichmentParameters.write(value:to:))
        try writer["KmsKeyIdentifier"].write(value.kmsKeyIdentifier)
        try writer["LogConfiguration"].write(value.logConfiguration, with: PipesClientTypes.PipeLogConfigurationParameters.write(value:to:))
        try writer["RoleArn"].write(value.roleArn)
        try writer["SourceParameters"].write(value.sourceParameters, with: PipesClientTypes.UpdatePipeSourceParameters.write(value:to:))
        try writer["Target"].write(value.target)
        try writer["TargetParameters"].write(value.targetParameters, with: PipesClientTypes.PipeTargetParameters.write(value:to:))
    }
}

extension CreatePipeOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> CreatePipeOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = CreatePipeOutput()
        value.arn = try reader["Arn"].readIfPresent()
        value.creationTime = try reader["CreationTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.currentState = try reader["CurrentState"].readIfPresent()
        value.desiredState = try reader["DesiredState"].readIfPresent()
        value.lastModifiedTime = try reader["LastModifiedTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.name = try reader["Name"].readIfPresent()
        return value
    }
}

extension DeletePipeOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> DeletePipeOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = DeletePipeOutput()
        value.arn = try reader["Arn"].readIfPresent()
        value.creationTime = try reader["CreationTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.currentState = try reader["CurrentState"].readIfPresent()
        value.desiredState = try reader["DesiredState"].readIfPresent()
        value.lastModifiedTime = try reader["LastModifiedTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.name = try reader["Name"].readIfPresent()
        return value
    }
}

extension DescribePipeOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> DescribePipeOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = DescribePipeOutput()
        value.arn = try reader["Arn"].readIfPresent()
        value.creationTime = try reader["CreationTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.currentState = try reader["CurrentState"].readIfPresent()
        value.description = try reader["Description"].readIfPresent()
        value.desiredState = try reader["DesiredState"].readIfPresent()
        value.enrichment = try reader["Enrichment"].readIfPresent()
        value.enrichmentParameters = try reader["EnrichmentParameters"].readIfPresent(with: PipesClientTypes.PipeEnrichmentParameters.read(from:))
        value.kmsKeyIdentifier = try reader["KmsKeyIdentifier"].readIfPresent()
        value.lastModifiedTime = try reader["LastModifiedTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.logConfiguration = try reader["LogConfiguration"].readIfPresent(with: PipesClientTypes.PipeLogConfiguration.read(from:))
        value.name = try reader["Name"].readIfPresent()
        value.roleArn = try reader["RoleArn"].readIfPresent()
        value.source = try reader["Source"].readIfPresent()
        value.sourceParameters = try reader["SourceParameters"].readIfPresent(with: PipesClientTypes.PipeSourceParameters.read(from:))
        value.stateReason = try reader["StateReason"].readIfPresent()
        value.tags = try reader["Tags"].readMapIfPresent(valueReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        value.target = try reader["Target"].readIfPresent()
        value.targetParameters = try reader["TargetParameters"].readIfPresent(with: PipesClientTypes.PipeTargetParameters.read(from:))
        return value
    }
}

extension ListPipesOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> ListPipesOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = ListPipesOutput()
        value.nextToken = try reader["NextToken"].readIfPresent()
        value.pipes = try reader["Pipes"].readListIfPresent(memberReadingClosure: PipesClientTypes.Pipe.read(from:), memberNodeInfo: "member", isFlattened: false)
        return value
    }
}

extension ListTagsForResourceOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> ListTagsForResourceOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = ListTagsForResourceOutput()
        value.tags = try reader["tags"].readMapIfPresent(valueReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        return value
    }
}

extension StartPipeOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> StartPipeOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = StartPipeOutput()
        value.arn = try reader["Arn"].readIfPresent()
        value.creationTime = try reader["CreationTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.currentState = try reader["CurrentState"].readIfPresent()
        value.desiredState = try reader["DesiredState"].readIfPresent()
        value.lastModifiedTime = try reader["LastModifiedTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.name = try reader["Name"].readIfPresent()
        return value
    }
}

extension StopPipeOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> StopPipeOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = StopPipeOutput()
        value.arn = try reader["Arn"].readIfPresent()
        value.creationTime = try reader["CreationTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.currentState = try reader["CurrentState"].readIfPresent()
        value.desiredState = try reader["DesiredState"].readIfPresent()
        value.lastModifiedTime = try reader["LastModifiedTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.name = try reader["Name"].readIfPresent()
        return value
    }
}

extension TagResourceOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> TagResourceOutput {
        return TagResourceOutput()
    }
}

extension UntagResourceOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> UntagResourceOutput {
        return UntagResourceOutput()
    }
}

extension UpdatePipeOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> UpdatePipeOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = UpdatePipeOutput()
        value.arn = try reader["Arn"].readIfPresent()
        value.creationTime = try reader["CreationTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.currentState = try reader["CurrentState"].readIfPresent()
        value.desiredState = try reader["DesiredState"].readIfPresent()
        value.lastModifiedTime = try reader["LastModifiedTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.name = try reader["Name"].readIfPresent()
        return value
    }
}

enum CreatePipeOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalException": return try InternalException.makeError(baseError: baseError)
            case "NotFoundException": return try NotFoundException.makeError(baseError: baseError)
            case "ServiceQuotaExceededException": return try ServiceQuotaExceededException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum DeletePipeOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalException": return try InternalException.makeError(baseError: baseError)
            case "NotFoundException": return try NotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum DescribePipeOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "InternalException": return try InternalException.makeError(baseError: baseError)
            case "NotFoundException": return try NotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum ListPipesOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "InternalException": return try InternalException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum ListTagsForResourceOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "InternalException": return try InternalException.makeError(baseError: baseError)
            case "NotFoundException": return try NotFoundException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum StartPipeOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalException": return try InternalException.makeError(baseError: baseError)
            case "NotFoundException": return try NotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum StopPipeOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalException": return try InternalException.makeError(baseError: baseError)
            case "NotFoundException": return try NotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum TagResourceOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "InternalException": return try InternalException.makeError(baseError: baseError)
            case "NotFoundException": return try NotFoundException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum UntagResourceOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "InternalException": return try InternalException.makeError(baseError: baseError)
            case "NotFoundException": return try NotFoundException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum UpdatePipeOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.RestJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalException": return try InternalException.makeError(baseError: baseError)
            case "NotFoundException": return try NotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

extension ConflictException {

    static func makeError(baseError: AWSClientRuntime.RestJSONError) throws -> ConflictException {
        let reader = baseError.errorBodyReader
        var value = ConflictException()
        value.properties.message = try reader["message"].readIfPresent() ?? ""
        value.properties.resourceId = try reader["resourceId"].readIfPresent() ?? ""
        value.properties.resourceType = try reader["resourceType"].readIfPresent() ?? ""
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension ThrottlingException {

    static func makeError(baseError: AWSClientRuntime.RestJSONError) throws -> ThrottlingException {
        let reader = baseError.errorBodyReader
        let httpResponse = baseError.httpResponse
        var value = ThrottlingException()
        if let retryAfterSecondsHeaderValue = httpResponse.headers.value(for: "Retry-After") {
            value.properties.retryAfterSeconds = Swift.Int(retryAfterSecondsHeaderValue) ?? 0
        }
        value.properties.message = try reader["message"].readIfPresent() ?? ""
        value.properties.quotaCode = try reader["quotaCode"].readIfPresent()
        value.properties.serviceCode = try reader["serviceCode"].readIfPresent()
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension InternalException {

    static func makeError(baseError: AWSClientRuntime.RestJSONError) throws -> InternalException {
        let reader = baseError.errorBodyReader
        let httpResponse = baseError.httpResponse
        var value = InternalException()
        if let retryAfterSecondsHeaderValue = httpResponse.headers.value(for: "Retry-After") {
            value.properties.retryAfterSeconds = Swift.Int(retryAfterSecondsHeaderValue) ?? 0
        }
        value.properties.message = try reader["message"].readIfPresent() ?? ""
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension ValidationException {

    static func makeError(baseError: AWSClientRuntime.RestJSONError) throws -> ValidationException {
        let reader = baseError.errorBodyReader
        var value = ValidationException()
        value.properties.fieldList = try reader["fieldList"].readListIfPresent(memberReadingClosure: PipesClientTypes.ValidationExceptionField.read(from:), memberNodeInfo: "member", isFlattened: false)
        value.properties.message = try reader["message"].readIfPresent()
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension ServiceQuotaExceededException {

    static func makeError(baseError: AWSClientRuntime.RestJSONError) throws -> ServiceQuotaExceededException {
        let reader = baseError.errorBodyReader
        var value = ServiceQuotaExceededException()
        value.properties.message = try reader["message"].readIfPresent() ?? ""
        value.properties.quotaCode = try reader["quotaCode"].readIfPresent() ?? ""
        value.properties.resourceId = try reader["resourceId"].readIfPresent() ?? ""
        value.properties.resourceType = try reader["resourceType"].readIfPresent() ?? ""
        value.properties.serviceCode = try reader["serviceCode"].readIfPresent() ?? ""
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension NotFoundException {

    static func makeError(baseError: AWSClientRuntime.RestJSONError) throws -> NotFoundException {
        let reader = baseError.errorBodyReader
        var value = NotFoundException()
        value.properties.message = try reader["message"].readIfPresent()
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension PipesClientTypes.PipeSourceParameters {

    static func write(value: PipesClientTypes.PipeSourceParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["ActiveMQBrokerParameters"].write(value.activeMQBrokerParameters, with: PipesClientTypes.PipeSourceActiveMQBrokerParameters.write(value:to:))
        try writer["DynamoDBStreamParameters"].write(value.dynamoDBStreamParameters, with: PipesClientTypes.PipeSourceDynamoDBStreamParameters.write(value:to:))
        try writer["FilterCriteria"].write(value.filterCriteria, with: PipesClientTypes.FilterCriteria.write(value:to:))
        try writer["KinesisStreamParameters"].write(value.kinesisStreamParameters, with: PipesClientTypes.PipeSourceKinesisStreamParameters.write(value:to:))
        try writer["ManagedStreamingKafkaParameters"].write(value.managedStreamingKafkaParameters, with: PipesClientTypes.PipeSourceManagedStreamingKafkaParameters.write(value:to:))
        try writer["RabbitMQBrokerParameters"].write(value.rabbitMQBrokerParameters, with: PipesClientTypes.PipeSourceRabbitMQBrokerParameters.write(value:to:))
        try writer["SelfManagedKafkaParameters"].write(value.selfManagedKafkaParameters, with: PipesClientTypes.PipeSourceSelfManagedKafkaParameters.write(value:to:))
        try writer["SqsQueueParameters"].write(value.sqsQueueParameters, with: PipesClientTypes.PipeSourceSqsQueueParameters.write(value:to:))
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeSourceParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeSourceParameters()
        value.filterCriteria = try reader["FilterCriteria"].readIfPresent(with: PipesClientTypes.FilterCriteria.read(from:))
        value.kinesisStreamParameters = try reader["KinesisStreamParameters"].readIfPresent(with: PipesClientTypes.PipeSourceKinesisStreamParameters.read(from:))
        value.dynamoDBStreamParameters = try reader["DynamoDBStreamParameters"].readIfPresent(with: PipesClientTypes.PipeSourceDynamoDBStreamParameters.read(from:))
        value.sqsQueueParameters = try reader["SqsQueueParameters"].readIfPresent(with: PipesClientTypes.PipeSourceSqsQueueParameters.read(from:))
        value.activeMQBrokerParameters = try reader["ActiveMQBrokerParameters"].readIfPresent(with: PipesClientTypes.PipeSourceActiveMQBrokerParameters.read(from:))
        value.rabbitMQBrokerParameters = try reader["RabbitMQBrokerParameters"].readIfPresent(with: PipesClientTypes.PipeSourceRabbitMQBrokerParameters.read(from:))
        value.managedStreamingKafkaParameters = try reader["ManagedStreamingKafkaParameters"].readIfPresent(with: PipesClientTypes.PipeSourceManagedStreamingKafkaParameters.read(from:))
        value.selfManagedKafkaParameters = try reader["SelfManagedKafkaParameters"].readIfPresent(with: PipesClientTypes.PipeSourceSelfManagedKafkaParameters.read(from:))
        return value
    }
}

extension PipesClientTypes.PipeSourceSelfManagedKafkaParameters {

    static func write(value: PipesClientTypes.PipeSourceSelfManagedKafkaParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["AdditionalBootstrapServers"].writeList(value.additionalBootstrapServers, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["BatchSize"].write(value.batchSize)
        try writer["ConsumerGroupID"].write(value.consumerGroupID)
        try writer["Credentials"].write(value.credentials, with: PipesClientTypes.SelfManagedKafkaAccessConfigurationCredentials.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
        try writer["ServerRootCaCertificate"].write(value.serverRootCaCertificate)
        try writer["StartingPosition"].write(value.startingPosition)
        try writer["TopicName"].write(value.topicName)
        try writer["Vpc"].write(value.vpc, with: PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc.write(value:to:))
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeSourceSelfManagedKafkaParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeSourceSelfManagedKafkaParameters()
        value.topicName = try reader["TopicName"].readIfPresent() ?? ""
        value.startingPosition = try reader["StartingPosition"].readIfPresent()
        value.additionalBootstrapServers = try reader["AdditionalBootstrapServers"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.batchSize = try reader["BatchSize"].readIfPresent()
        value.maximumBatchingWindowInSeconds = try reader["MaximumBatchingWindowInSeconds"].readIfPresent()
        value.consumerGroupID = try reader["ConsumerGroupID"].readIfPresent()
        value.credentials = try reader["Credentials"].readIfPresent(with: PipesClientTypes.SelfManagedKafkaAccessConfigurationCredentials.read(from:))
        value.serverRootCaCertificate = try reader["ServerRootCaCertificate"].readIfPresent()
        value.vpc = try reader["Vpc"].readIfPresent(with: PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc.read(from:))
        return value
    }
}

extension PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc {

    static func write(value: PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["SecurityGroup"].writeList(value.securityGroup, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["Subnets"].writeList(value.subnets, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc()
        value.subnets = try reader["Subnets"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.securityGroup = try reader["SecurityGroup"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        return value
    }
}

extension PipesClientTypes.SelfManagedKafkaAccessConfigurationCredentials {

    static func write(value: PipesClientTypes.SelfManagedKafkaAccessConfigurationCredentials?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        switch value {
            case let .basicauth(basicauth):
                try writer["BasicAuth"].write(basicauth)
            case let .clientcertificatetlsauth(clientcertificatetlsauth):
                try writer["ClientCertificateTlsAuth"].write(clientcertificatetlsauth)
            case let .saslscram256auth(saslscram256auth):
                try writer["SaslScram256Auth"].write(saslscram256auth)
            case let .saslscram512auth(saslscram512auth):
                try writer["SaslScram512Auth"].write(saslscram512auth)
            case let .sdkUnknown(sdkUnknown):
                try writer["sdkUnknown"].write(sdkUnknown)
        }
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.SelfManagedKafkaAccessConfigurationCredentials {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        let name = reader.children.filter { $0.hasContent && $0.nodeInfo.name != "__type" }.first?.nodeInfo.name
        switch name {
            case "BasicAuth":
                return .basicauth(try reader["BasicAuth"].read())
            case "SaslScram512Auth":
                return .saslscram512auth(try reader["SaslScram512Auth"].read())
            case "SaslScram256Auth":
                return .saslscram256auth(try reader["SaslScram256Auth"].read())
            case "ClientCertificateTlsAuth":
                return .clientcertificatetlsauth(try reader["ClientCertificateTlsAuth"].read())
            default:
                return .sdkUnknown(name ?? "")
        }
    }
}

extension PipesClientTypes.PipeSourceManagedStreamingKafkaParameters {

    static func write(value: PipesClientTypes.PipeSourceManagedStreamingKafkaParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["ConsumerGroupID"].write(value.consumerGroupID)
        try writer["Credentials"].write(value.credentials, with: PipesClientTypes.MSKAccessCredentials.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
        try writer["StartingPosition"].write(value.startingPosition)
        try writer["TopicName"].write(value.topicName)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeSourceManagedStreamingKafkaParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeSourceManagedStreamingKafkaParameters()
        value.topicName = try reader["TopicName"].readIfPresent() ?? ""
        value.startingPosition = try reader["StartingPosition"].readIfPresent()
        value.batchSize = try reader["BatchSize"].readIfPresent()
        value.maximumBatchingWindowInSeconds = try reader["MaximumBatchingWindowInSeconds"].readIfPresent()
        value.consumerGroupID = try reader["ConsumerGroupID"].readIfPresent()
        value.credentials = try reader["Credentials"].readIfPresent(with: PipesClientTypes.MSKAccessCredentials.read(from:))
        return value
    }
}

extension PipesClientTypes.MSKAccessCredentials {

    static func write(value: PipesClientTypes.MSKAccessCredentials?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        switch value {
            case let .clientcertificatetlsauth(clientcertificatetlsauth):
                try writer["ClientCertificateTlsAuth"].write(clientcertificatetlsauth)
            case let .saslscram512auth(saslscram512auth):
                try writer["SaslScram512Auth"].write(saslscram512auth)
            case let .sdkUnknown(sdkUnknown):
                try writer["sdkUnknown"].write(sdkUnknown)
        }
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.MSKAccessCredentials {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        let name = reader.children.filter { $0.hasContent && $0.nodeInfo.name != "__type" }.first?.nodeInfo.name
        switch name {
            case "SaslScram512Auth":
                return .saslscram512auth(try reader["SaslScram512Auth"].read())
            case "ClientCertificateTlsAuth":
                return .clientcertificatetlsauth(try reader["ClientCertificateTlsAuth"].read())
            default:
                return .sdkUnknown(name ?? "")
        }
    }
}

extension PipesClientTypes.PipeSourceRabbitMQBrokerParameters {

    static func write(value: PipesClientTypes.PipeSourceRabbitMQBrokerParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["Credentials"].write(value.credentials, with: PipesClientTypes.MQBrokerAccessCredentials.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
        try writer["QueueName"].write(value.queueName)
        try writer["VirtualHost"].write(value.virtualHost)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeSourceRabbitMQBrokerParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeSourceRabbitMQBrokerParameters()
        value.credentials = try reader["Credentials"].readIfPresent(with: PipesClientTypes.MQBrokerAccessCredentials.read(from:))
        value.queueName = try reader["QueueName"].readIfPresent() ?? ""
        value.virtualHost = try reader["VirtualHost"].readIfPresent()
        value.batchSize = try reader["BatchSize"].readIfPresent()
        value.maximumBatchingWindowInSeconds = try reader["MaximumBatchingWindowInSeconds"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.MQBrokerAccessCredentials {

    static func write(value: PipesClientTypes.MQBrokerAccessCredentials?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        switch value {
            case let .basicauth(basicauth):
                try writer["BasicAuth"].write(basicauth)
            case let .sdkUnknown(sdkUnknown):
                try writer["sdkUnknown"].write(sdkUnknown)
        }
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.MQBrokerAccessCredentials {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        let name = reader.children.filter { $0.hasContent && $0.nodeInfo.name != "__type" }.first?.nodeInfo.name
        switch name {
            case "BasicAuth":
                return .basicauth(try reader["BasicAuth"].read())
            default:
                return .sdkUnknown(name ?? "")
        }
    }
}

extension PipesClientTypes.PipeSourceActiveMQBrokerParameters {

    static func write(value: PipesClientTypes.PipeSourceActiveMQBrokerParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["Credentials"].write(value.credentials, with: PipesClientTypes.MQBrokerAccessCredentials.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
        try writer["QueueName"].write(value.queueName)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeSourceActiveMQBrokerParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeSourceActiveMQBrokerParameters()
        value.credentials = try reader["Credentials"].readIfPresent(with: PipesClientTypes.MQBrokerAccessCredentials.read(from:))
        value.queueName = try reader["QueueName"].readIfPresent() ?? ""
        value.batchSize = try reader["BatchSize"].readIfPresent()
        value.maximumBatchingWindowInSeconds = try reader["MaximumBatchingWindowInSeconds"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PipeSourceSqsQueueParameters {

    static func write(value: PipesClientTypes.PipeSourceSqsQueueParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeSourceSqsQueueParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeSourceSqsQueueParameters()
        value.batchSize = try reader["BatchSize"].readIfPresent()
        value.maximumBatchingWindowInSeconds = try reader["MaximumBatchingWindowInSeconds"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PipeSourceDynamoDBStreamParameters {

    static func write(value: PipesClientTypes.PipeSourceDynamoDBStreamParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["DeadLetterConfig"].write(value.deadLetterConfig, with: PipesClientTypes.DeadLetterConfig.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
        try writer["MaximumRecordAgeInSeconds"].write(value.maximumRecordAgeInSeconds)
        try writer["MaximumRetryAttempts"].write(value.maximumRetryAttempts)
        try writer["OnPartialBatchItemFailure"].write(value.onPartialBatchItemFailure)
        try writer["ParallelizationFactor"].write(value.parallelizationFactor)
        try writer["StartingPosition"].write(value.startingPosition)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeSourceDynamoDBStreamParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeSourceDynamoDBStreamParameters()
        value.batchSize = try reader["BatchSize"].readIfPresent()
        value.deadLetterConfig = try reader["DeadLetterConfig"].readIfPresent(with: PipesClientTypes.DeadLetterConfig.read(from:))
        value.onPartialBatchItemFailure = try reader["OnPartialBatchItemFailure"].readIfPresent()
        value.maximumBatchingWindowInSeconds = try reader["MaximumBatchingWindowInSeconds"].readIfPresent()
        value.maximumRecordAgeInSeconds = try reader["MaximumRecordAgeInSeconds"].readIfPresent()
        value.maximumRetryAttempts = try reader["MaximumRetryAttempts"].readIfPresent()
        value.parallelizationFactor = try reader["ParallelizationFactor"].readIfPresent()
        value.startingPosition = try reader["StartingPosition"].readIfPresent() ?? .sdkUnknown("")
        return value
    }
}

extension PipesClientTypes.DeadLetterConfig {

    static func write(value: PipesClientTypes.DeadLetterConfig?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Arn"].write(value.arn)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.DeadLetterConfig {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.DeadLetterConfig()
        value.arn = try reader["Arn"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PipeSourceKinesisStreamParameters {

    static func write(value: PipesClientTypes.PipeSourceKinesisStreamParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["DeadLetterConfig"].write(value.deadLetterConfig, with: PipesClientTypes.DeadLetterConfig.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
        try writer["MaximumRecordAgeInSeconds"].write(value.maximumRecordAgeInSeconds)
        try writer["MaximumRetryAttempts"].write(value.maximumRetryAttempts)
        try writer["OnPartialBatchItemFailure"].write(value.onPartialBatchItemFailure)
        try writer["ParallelizationFactor"].write(value.parallelizationFactor)
        try writer["StartingPosition"].write(value.startingPosition)
        try writer["StartingPositionTimestamp"].writeTimestamp(value.startingPositionTimestamp, format: SmithyTimestamps.TimestampFormat.epochSeconds)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeSourceKinesisStreamParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeSourceKinesisStreamParameters()
        value.batchSize = try reader["BatchSize"].readIfPresent()
        value.deadLetterConfig = try reader["DeadLetterConfig"].readIfPresent(with: PipesClientTypes.DeadLetterConfig.read(from:))
        value.onPartialBatchItemFailure = try reader["OnPartialBatchItemFailure"].readIfPresent()
        value.maximumBatchingWindowInSeconds = try reader["MaximumBatchingWindowInSeconds"].readIfPresent()
        value.maximumRecordAgeInSeconds = try reader["MaximumRecordAgeInSeconds"].readIfPresent()
        value.maximumRetryAttempts = try reader["MaximumRetryAttempts"].readIfPresent()
        value.parallelizationFactor = try reader["ParallelizationFactor"].readIfPresent()
        value.startingPosition = try reader["StartingPosition"].readIfPresent() ?? .sdkUnknown("")
        value.startingPositionTimestamp = try reader["StartingPositionTimestamp"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        return value
    }
}

extension PipesClientTypes.FilterCriteria {

    static func write(value: PipesClientTypes.FilterCriteria?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Filters"].writeList(value.filters, memberWritingClosure: PipesClientTypes.Filter.write(value:to:), memberNodeInfo: "member", isFlattened: false)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.FilterCriteria {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.FilterCriteria()
        value.filters = try reader["Filters"].readListIfPresent(memberReadingClosure: PipesClientTypes.Filter.read(from:), memberNodeInfo: "member", isFlattened: false)
        return value
    }
}

extension PipesClientTypes.Filter {

    static func write(value: PipesClientTypes.Filter?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Pattern"].write(value.pattern)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.Filter {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.Filter()
        value.pattern = try reader["Pattern"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PipeEnrichmentParameters {

    static func write(value: PipesClientTypes.PipeEnrichmentParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["HttpParameters"].write(value.httpParameters, with: PipesClientTypes.PipeEnrichmentHttpParameters.write(value:to:))
        try writer["InputTemplate"].write(value.inputTemplate)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeEnrichmentParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeEnrichmentParameters()
        value.inputTemplate = try reader["InputTemplate"].readIfPresent()
        value.httpParameters = try reader["HttpParameters"].readIfPresent(with: PipesClientTypes.PipeEnrichmentHttpParameters.read(from:))
        return value
    }
}

extension PipesClientTypes.PipeEnrichmentHttpParameters {

    static func write(value: PipesClientTypes.PipeEnrichmentHttpParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["HeaderParameters"].writeMap(value.headerParameters, valueWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        try writer["PathParameterValues"].writeList(value.pathParameterValues, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["QueryStringParameters"].writeMap(value.queryStringParameters, valueWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeEnrichmentHttpParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeEnrichmentHttpParameters()
        value.pathParameterValues = try reader["PathParameterValues"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.headerParameters = try reader["HeaderParameters"].readMapIfPresent(valueReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        value.queryStringParameters = try reader["QueryStringParameters"].readMapIfPresent(valueReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        return value
    }
}

extension PipesClientTypes.PipeTargetParameters {

    static func write(value: PipesClientTypes.PipeTargetParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchJobParameters"].write(value.batchJobParameters, with: PipesClientTypes.PipeTargetBatchJobParameters.write(value:to:))
        try writer["CloudWatchLogsParameters"].write(value.cloudWatchLogsParameters, with: PipesClientTypes.PipeTargetCloudWatchLogsParameters.write(value:to:))
        try writer["EcsTaskParameters"].write(value.ecsTaskParameters, with: PipesClientTypes.PipeTargetEcsTaskParameters.write(value:to:))
        try writer["EventBridgeEventBusParameters"].write(value.eventBridgeEventBusParameters, with: PipesClientTypes.PipeTargetEventBridgeEventBusParameters.write(value:to:))
        try writer["HttpParameters"].write(value.httpParameters, with: PipesClientTypes.PipeTargetHttpParameters.write(value:to:))
        try writer["InputTemplate"].write(value.inputTemplate)
        try writer["KinesisStreamParameters"].write(value.kinesisStreamParameters, with: PipesClientTypes.PipeTargetKinesisStreamParameters.write(value:to:))
        try writer["LambdaFunctionParameters"].write(value.lambdaFunctionParameters, with: PipesClientTypes.PipeTargetLambdaFunctionParameters.write(value:to:))
        try writer["RedshiftDataParameters"].write(value.redshiftDataParameters, with: PipesClientTypes.PipeTargetRedshiftDataParameters.write(value:to:))
        try writer["SageMakerPipelineParameters"].write(value.sageMakerPipelineParameters, with: PipesClientTypes.PipeTargetSageMakerPipelineParameters.write(value:to:))
        try writer["SqsQueueParameters"].write(value.sqsQueueParameters, with: PipesClientTypes.PipeTargetSqsQueueParameters.write(value:to:))
        try writer["StepFunctionStateMachineParameters"].write(value.stepFunctionStateMachineParameters, with: PipesClientTypes.PipeTargetStateMachineParameters.write(value:to:))
        try writer["TimestreamParameters"].write(value.timestreamParameters, with: PipesClientTypes.PipeTargetTimestreamParameters.write(value:to:))
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetParameters()
        value.inputTemplate = try reader["InputTemplate"].readIfPresent()
        value.lambdaFunctionParameters = try reader["LambdaFunctionParameters"].readIfPresent(with: PipesClientTypes.PipeTargetLambdaFunctionParameters.read(from:))
        value.stepFunctionStateMachineParameters = try reader["StepFunctionStateMachineParameters"].readIfPresent(with: PipesClientTypes.PipeTargetStateMachineParameters.read(from:))
        value.kinesisStreamParameters = try reader["KinesisStreamParameters"].readIfPresent(with: PipesClientTypes.PipeTargetKinesisStreamParameters.read(from:))
        value.ecsTaskParameters = try reader["EcsTaskParameters"].readIfPresent(with: PipesClientTypes.PipeTargetEcsTaskParameters.read(from:))
        value.batchJobParameters = try reader["BatchJobParameters"].readIfPresent(with: PipesClientTypes.PipeTargetBatchJobParameters.read(from:))
        value.sqsQueueParameters = try reader["SqsQueueParameters"].readIfPresent(with: PipesClientTypes.PipeTargetSqsQueueParameters.read(from:))
        value.httpParameters = try reader["HttpParameters"].readIfPresent(with: PipesClientTypes.PipeTargetHttpParameters.read(from:))
        value.redshiftDataParameters = try reader["RedshiftDataParameters"].readIfPresent(with: PipesClientTypes.PipeTargetRedshiftDataParameters.read(from:))
        value.sageMakerPipelineParameters = try reader["SageMakerPipelineParameters"].readIfPresent(with: PipesClientTypes.PipeTargetSageMakerPipelineParameters.read(from:))
        value.eventBridgeEventBusParameters = try reader["EventBridgeEventBusParameters"].readIfPresent(with: PipesClientTypes.PipeTargetEventBridgeEventBusParameters.read(from:))
        value.cloudWatchLogsParameters = try reader["CloudWatchLogsParameters"].readIfPresent(with: PipesClientTypes.PipeTargetCloudWatchLogsParameters.read(from:))
        value.timestreamParameters = try reader["TimestreamParameters"].readIfPresent(with: PipesClientTypes.PipeTargetTimestreamParameters.read(from:))
        return value
    }
}

extension PipesClientTypes.PipeTargetTimestreamParameters {

    static func write(value: PipesClientTypes.PipeTargetTimestreamParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["DimensionMappings"].writeList(value.dimensionMappings, memberWritingClosure: PipesClientTypes.DimensionMapping.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["EpochTimeUnit"].write(value.epochTimeUnit)
        try writer["MultiMeasureMappings"].writeList(value.multiMeasureMappings, memberWritingClosure: PipesClientTypes.MultiMeasureMapping.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["SingleMeasureMappings"].writeList(value.singleMeasureMappings, memberWritingClosure: PipesClientTypes.SingleMeasureMapping.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["TimeFieldType"].write(value.timeFieldType)
        try writer["TimeValue"].write(value.timeValue)
        try writer["TimestampFormat"].write(value.timestampFormat)
        try writer["VersionValue"].write(value.versionValue)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetTimestreamParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetTimestreamParameters()
        value.timeValue = try reader["TimeValue"].readIfPresent() ?? ""
        value.epochTimeUnit = try reader["EpochTimeUnit"].readIfPresent()
        value.timeFieldType = try reader["TimeFieldType"].readIfPresent()
        value.timestampFormat = try reader["TimestampFormat"].readIfPresent()
        value.versionValue = try reader["VersionValue"].readIfPresent() ?? ""
        value.dimensionMappings = try reader["DimensionMappings"].readListIfPresent(memberReadingClosure: PipesClientTypes.DimensionMapping.read(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        value.singleMeasureMappings = try reader["SingleMeasureMappings"].readListIfPresent(memberReadingClosure: PipesClientTypes.SingleMeasureMapping.read(from:), memberNodeInfo: "member", isFlattened: false)
        value.multiMeasureMappings = try reader["MultiMeasureMappings"].readListIfPresent(memberReadingClosure: PipesClientTypes.MultiMeasureMapping.read(from:), memberNodeInfo: "member", isFlattened: false)
        return value
    }
}

extension PipesClientTypes.MultiMeasureMapping {

    static func write(value: PipesClientTypes.MultiMeasureMapping?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["MultiMeasureAttributeMappings"].writeList(value.multiMeasureAttributeMappings, memberWritingClosure: PipesClientTypes.MultiMeasureAttributeMapping.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["MultiMeasureName"].write(value.multiMeasureName)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.MultiMeasureMapping {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.MultiMeasureMapping()
        value.multiMeasureName = try reader["MultiMeasureName"].readIfPresent() ?? ""
        value.multiMeasureAttributeMappings = try reader["MultiMeasureAttributeMappings"].readListIfPresent(memberReadingClosure: PipesClientTypes.MultiMeasureAttributeMapping.read(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        return value
    }
}

extension PipesClientTypes.MultiMeasureAttributeMapping {

    static func write(value: PipesClientTypes.MultiMeasureAttributeMapping?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["MeasureValue"].write(value.measureValue)
        try writer["MeasureValueType"].write(value.measureValueType)
        try writer["MultiMeasureAttributeName"].write(value.multiMeasureAttributeName)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.MultiMeasureAttributeMapping {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.MultiMeasureAttributeMapping()
        value.measureValue = try reader["MeasureValue"].readIfPresent() ?? ""
        value.measureValueType = try reader["MeasureValueType"].readIfPresent() ?? .sdkUnknown("")
        value.multiMeasureAttributeName = try reader["MultiMeasureAttributeName"].readIfPresent() ?? ""
        return value
    }
}

extension PipesClientTypes.SingleMeasureMapping {

    static func write(value: PipesClientTypes.SingleMeasureMapping?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["MeasureName"].write(value.measureName)
        try writer["MeasureValue"].write(value.measureValue)
        try writer["MeasureValueType"].write(value.measureValueType)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.SingleMeasureMapping {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.SingleMeasureMapping()
        value.measureValue = try reader["MeasureValue"].readIfPresent() ?? ""
        value.measureValueType = try reader["MeasureValueType"].readIfPresent() ?? .sdkUnknown("")
        value.measureName = try reader["MeasureName"].readIfPresent() ?? ""
        return value
    }
}

extension PipesClientTypes.DimensionMapping {

    static func write(value: PipesClientTypes.DimensionMapping?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["DimensionName"].write(value.dimensionName)
        try writer["DimensionValue"].write(value.dimensionValue)
        try writer["DimensionValueType"].write(value.dimensionValueType)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.DimensionMapping {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.DimensionMapping()
        value.dimensionValue = try reader["DimensionValue"].readIfPresent() ?? ""
        value.dimensionValueType = try reader["DimensionValueType"].readIfPresent() ?? .sdkUnknown("")
        value.dimensionName = try reader["DimensionName"].readIfPresent() ?? ""
        return value
    }
}

extension PipesClientTypes.PipeTargetCloudWatchLogsParameters {

    static func write(value: PipesClientTypes.PipeTargetCloudWatchLogsParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["LogStreamName"].write(value.logStreamName)
        try writer["Timestamp"].write(value.timestamp)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetCloudWatchLogsParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetCloudWatchLogsParameters()
        value.logStreamName = try reader["LogStreamName"].readIfPresent()
        value.timestamp = try reader["Timestamp"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PipeTargetEventBridgeEventBusParameters {

    static func write(value: PipesClientTypes.PipeTargetEventBridgeEventBusParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["DetailType"].write(value.detailType)
        try writer["EndpointId"].write(value.endpointId)
        try writer["Resources"].writeList(value.resources, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["Source"].write(value.source)
        try writer["Time"].write(value.time)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetEventBridgeEventBusParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetEventBridgeEventBusParameters()
        value.endpointId = try reader["EndpointId"].readIfPresent()
        value.detailType = try reader["DetailType"].readIfPresent()
        value.source = try reader["Source"].readIfPresent()
        value.resources = try reader["Resources"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.time = try reader["Time"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PipeTargetSageMakerPipelineParameters {

    static func write(value: PipesClientTypes.PipeTargetSageMakerPipelineParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["PipelineParameterList"].writeList(value.pipelineParameterList, memberWritingClosure: PipesClientTypes.SageMakerPipelineParameter.write(value:to:), memberNodeInfo: "member", isFlattened: false)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetSageMakerPipelineParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetSageMakerPipelineParameters()
        value.pipelineParameterList = try reader["PipelineParameterList"].readListIfPresent(memberReadingClosure: PipesClientTypes.SageMakerPipelineParameter.read(from:), memberNodeInfo: "member", isFlattened: false)
        return value
    }
}

extension PipesClientTypes.SageMakerPipelineParameter {

    static func write(value: PipesClientTypes.SageMakerPipelineParameter?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Name"].write(value.name)
        try writer["Value"].write(value.value)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.SageMakerPipelineParameter {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.SageMakerPipelineParameter()
        value.name = try reader["Name"].readIfPresent() ?? ""
        value.value = try reader["Value"].readIfPresent() ?? ""
        return value
    }
}

extension PipesClientTypes.PipeTargetRedshiftDataParameters {

    static func write(value: PipesClientTypes.PipeTargetRedshiftDataParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Database"].write(value.database)
        try writer["DbUser"].write(value.dbUser)
        try writer["SecretManagerArn"].write(value.secretManagerArn)
        try writer["Sqls"].writeList(value.sqls, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["StatementName"].write(value.statementName)
        try writer["WithEvent"].write(value.withEvent)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetRedshiftDataParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetRedshiftDataParameters()
        value.secretManagerArn = try reader["SecretManagerArn"].readIfPresent()
        value.database = try reader["Database"].readIfPresent() ?? ""
        value.dbUser = try reader["DbUser"].readIfPresent()
        value.statementName = try reader["StatementName"].readIfPresent()
        value.withEvent = try reader["WithEvent"].readIfPresent() ?? false
        value.sqls = try reader["Sqls"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        return value
    }
}

extension PipesClientTypes.PipeTargetHttpParameters {

    static func write(value: PipesClientTypes.PipeTargetHttpParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["HeaderParameters"].writeMap(value.headerParameters, valueWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        try writer["PathParameterValues"].writeList(value.pathParameterValues, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["QueryStringParameters"].writeMap(value.queryStringParameters, valueWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetHttpParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetHttpParameters()
        value.pathParameterValues = try reader["PathParameterValues"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.headerParameters = try reader["HeaderParameters"].readMapIfPresent(valueReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        value.queryStringParameters = try reader["QueryStringParameters"].readMapIfPresent(valueReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        return value
    }
}

extension PipesClientTypes.PipeTargetSqsQueueParameters {

    static func write(value: PipesClientTypes.PipeTargetSqsQueueParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["MessageDeduplicationId"].write(value.messageDeduplicationId)
        try writer["MessageGroupId"].write(value.messageGroupId)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetSqsQueueParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetSqsQueueParameters()
        value.messageGroupId = try reader["MessageGroupId"].readIfPresent()
        value.messageDeduplicationId = try reader["MessageDeduplicationId"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PipeTargetBatchJobParameters {

    static func write(value: PipesClientTypes.PipeTargetBatchJobParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["ArrayProperties"].write(value.arrayProperties, with: PipesClientTypes.BatchArrayProperties.write(value:to:))
        try writer["ContainerOverrides"].write(value.containerOverrides, with: PipesClientTypes.BatchContainerOverrides.write(value:to:))
        try writer["DependsOn"].writeList(value.dependsOn, memberWritingClosure: PipesClientTypes.BatchJobDependency.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["JobDefinition"].write(value.jobDefinition)
        try writer["JobName"].write(value.jobName)
        try writer["Parameters"].writeMap(value.parameters, valueWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        try writer["RetryStrategy"].write(value.retryStrategy, with: PipesClientTypes.BatchRetryStrategy.write(value:to:))
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetBatchJobParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetBatchJobParameters()
        value.jobDefinition = try reader["JobDefinition"].readIfPresent() ?? ""
        value.jobName = try reader["JobName"].readIfPresent() ?? ""
        value.arrayProperties = try reader["ArrayProperties"].readIfPresent(with: PipesClientTypes.BatchArrayProperties.read(from:))
        value.retryStrategy = try reader["RetryStrategy"].readIfPresent(with: PipesClientTypes.BatchRetryStrategy.read(from:))
        value.containerOverrides = try reader["ContainerOverrides"].readIfPresent(with: PipesClientTypes.BatchContainerOverrides.read(from:))
        value.dependsOn = try reader["DependsOn"].readListIfPresent(memberReadingClosure: PipesClientTypes.BatchJobDependency.read(from:), memberNodeInfo: "member", isFlattened: false)
        value.parameters = try reader["Parameters"].readMapIfPresent(valueReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        return value
    }
}

extension PipesClientTypes.BatchJobDependency {

    static func write(value: PipesClientTypes.BatchJobDependency?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["JobId"].write(value.jobId)
        try writer["Type"].write(value.type)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.BatchJobDependency {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.BatchJobDependency()
        value.jobId = try reader["JobId"].readIfPresent()
        value.type = try reader["Type"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.BatchContainerOverrides {

    static func write(value: PipesClientTypes.BatchContainerOverrides?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Command"].writeList(value.command, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["Environment"].writeList(value.environment, memberWritingClosure: PipesClientTypes.BatchEnvironmentVariable.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["InstanceType"].write(value.instanceType)
        try writer["ResourceRequirements"].writeList(value.resourceRequirements, memberWritingClosure: PipesClientTypes.BatchResourceRequirement.write(value:to:), memberNodeInfo: "member", isFlattened: false)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.BatchContainerOverrides {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.BatchContainerOverrides()
        value.command = try reader["Command"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.environment = try reader["Environment"].readListIfPresent(memberReadingClosure: PipesClientTypes.BatchEnvironmentVariable.read(from:), memberNodeInfo: "member", isFlattened: false)
        value.instanceType = try reader["InstanceType"].readIfPresent()
        value.resourceRequirements = try reader["ResourceRequirements"].readListIfPresent(memberReadingClosure: PipesClientTypes.BatchResourceRequirement.read(from:), memberNodeInfo: "member", isFlattened: false)
        return value
    }
}

extension PipesClientTypes.BatchResourceRequirement {

    static func write(value: PipesClientTypes.BatchResourceRequirement?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Type"].write(value.type)
        try writer["Value"].write(value.value)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.BatchResourceRequirement {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.BatchResourceRequirement()
        value.type = try reader["Type"].readIfPresent() ?? .sdkUnknown("")
        value.value = try reader["Value"].readIfPresent() ?? ""
        return value
    }
}

extension PipesClientTypes.BatchEnvironmentVariable {

    static func write(value: PipesClientTypes.BatchEnvironmentVariable?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Name"].write(value.name)
        try writer["Value"].write(value.value)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.BatchEnvironmentVariable {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.BatchEnvironmentVariable()
        value.name = try reader["Name"].readIfPresent()
        value.value = try reader["Value"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.BatchRetryStrategy {

    static func write(value: PipesClientTypes.BatchRetryStrategy?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Attempts"].write(value.attempts)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.BatchRetryStrategy {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.BatchRetryStrategy()
        value.attempts = try reader["Attempts"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.BatchArrayProperties {

    static func write(value: PipesClientTypes.BatchArrayProperties?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Size"].write(value.size)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.BatchArrayProperties {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.BatchArrayProperties()
        value.size = try reader["Size"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PipeTargetEcsTaskParameters {

    static func write(value: PipesClientTypes.PipeTargetEcsTaskParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["CapacityProviderStrategy"].writeList(value.capacityProviderStrategy, memberWritingClosure: PipesClientTypes.CapacityProviderStrategyItem.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["EnableECSManagedTags"].write(value.enableECSManagedTags)
        try writer["EnableExecuteCommand"].write(value.enableExecuteCommand)
        try writer["Group"].write(value.group)
        try writer["LaunchType"].write(value.launchType)
        try writer["NetworkConfiguration"].write(value.networkConfiguration, with: PipesClientTypes.NetworkConfiguration.write(value:to:))
        try writer["Overrides"].write(value.overrides, with: PipesClientTypes.EcsTaskOverride.write(value:to:))
        try writer["PlacementConstraints"].writeList(value.placementConstraints, memberWritingClosure: PipesClientTypes.PlacementConstraint.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["PlacementStrategy"].writeList(value.placementStrategy, memberWritingClosure: PipesClientTypes.PlacementStrategy.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["PlatformVersion"].write(value.platformVersion)
        try writer["PropagateTags"].write(value.propagateTags)
        try writer["ReferenceId"].write(value.referenceId)
        try writer["Tags"].writeList(value.tags, memberWritingClosure: PipesClientTypes.Tag.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["TaskCount"].write(value.taskCount)
        try writer["TaskDefinitionArn"].write(value.taskDefinitionArn)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetEcsTaskParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetEcsTaskParameters()
        value.taskDefinitionArn = try reader["TaskDefinitionArn"].readIfPresent() ?? ""
        value.taskCount = try reader["TaskCount"].readIfPresent()
        value.launchType = try reader["LaunchType"].readIfPresent()
        value.networkConfiguration = try reader["NetworkConfiguration"].readIfPresent(with: PipesClientTypes.NetworkConfiguration.read(from:))
        value.platformVersion = try reader["PlatformVersion"].readIfPresent()
        value.group = try reader["Group"].readIfPresent()
        value.capacityProviderStrategy = try reader["CapacityProviderStrategy"].readListIfPresent(memberReadingClosure: PipesClientTypes.CapacityProviderStrategyItem.read(from:), memberNodeInfo: "member", isFlattened: false)
        value.enableECSManagedTags = try reader["EnableECSManagedTags"].readIfPresent() ?? false
        value.enableExecuteCommand = try reader["EnableExecuteCommand"].readIfPresent() ?? false
        value.placementConstraints = try reader["PlacementConstraints"].readListIfPresent(memberReadingClosure: PipesClientTypes.PlacementConstraint.read(from:), memberNodeInfo: "member", isFlattened: false)
        value.placementStrategy = try reader["PlacementStrategy"].readListIfPresent(memberReadingClosure: PipesClientTypes.PlacementStrategy.read(from:), memberNodeInfo: "member", isFlattened: false)
        value.propagateTags = try reader["PropagateTags"].readIfPresent()
        value.referenceId = try reader["ReferenceId"].readIfPresent()
        value.overrides = try reader["Overrides"].readIfPresent(with: PipesClientTypes.EcsTaskOverride.read(from:))
        value.tags = try reader["Tags"].readListIfPresent(memberReadingClosure: PipesClientTypes.Tag.read(from:), memberNodeInfo: "member", isFlattened: false)
        return value
    }
}

extension PipesClientTypes.Tag {

    static func write(value: PipesClientTypes.Tag?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Key"].write(value.key)
        try writer["Value"].write(value.value)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.Tag {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.Tag()
        value.key = try reader["Key"].readIfPresent() ?? ""
        value.value = try reader["Value"].readIfPresent() ?? ""
        return value
    }
}

extension PipesClientTypes.EcsTaskOverride {

    static func write(value: PipesClientTypes.EcsTaskOverride?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["ContainerOverrides"].writeList(value.containerOverrides, memberWritingClosure: PipesClientTypes.EcsContainerOverride.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["Cpu"].write(value.cpu)
        try writer["EphemeralStorage"].write(value.ephemeralStorage, with: PipesClientTypes.EcsEphemeralStorage.write(value:to:))
        try writer["ExecutionRoleArn"].write(value.executionRoleArn)
        try writer["InferenceAcceleratorOverrides"].writeList(value.inferenceAcceleratorOverrides, memberWritingClosure: PipesClientTypes.EcsInferenceAcceleratorOverride.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["Memory"].write(value.memory)
        try writer["TaskRoleArn"].write(value.taskRoleArn)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.EcsTaskOverride {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.EcsTaskOverride()
        value.containerOverrides = try reader["ContainerOverrides"].readListIfPresent(memberReadingClosure: PipesClientTypes.EcsContainerOverride.read(from:), memberNodeInfo: "member", isFlattened: false)
        value.cpu = try reader["Cpu"].readIfPresent()
        value.ephemeralStorage = try reader["EphemeralStorage"].readIfPresent(with: PipesClientTypes.EcsEphemeralStorage.read(from:))
        value.executionRoleArn = try reader["ExecutionRoleArn"].readIfPresent()
        value.inferenceAcceleratorOverrides = try reader["InferenceAcceleratorOverrides"].readListIfPresent(memberReadingClosure: PipesClientTypes.EcsInferenceAcceleratorOverride.read(from:), memberNodeInfo: "member", isFlattened: false)
        value.memory = try reader["Memory"].readIfPresent()
        value.taskRoleArn = try reader["TaskRoleArn"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.EcsInferenceAcceleratorOverride {

    static func write(value: PipesClientTypes.EcsInferenceAcceleratorOverride?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["deviceName"].write(value.deviceName)
        try writer["deviceType"].write(value.deviceType)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.EcsInferenceAcceleratorOverride {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.EcsInferenceAcceleratorOverride()
        value.deviceName = try reader["deviceName"].readIfPresent()
        value.deviceType = try reader["deviceType"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.EcsEphemeralStorage {

    static func write(value: PipesClientTypes.EcsEphemeralStorage?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["sizeInGiB"].write(value.sizeInGiB)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.EcsEphemeralStorage {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.EcsEphemeralStorage()
        value.sizeInGiB = try reader["sizeInGiB"].readIfPresent() ?? 0
        return value
    }
}

extension PipesClientTypes.EcsContainerOverride {

    static func write(value: PipesClientTypes.EcsContainerOverride?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["Command"].writeList(value.command, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["Cpu"].write(value.cpu)
        try writer["Environment"].writeList(value.environment, memberWritingClosure: PipesClientTypes.EcsEnvironmentVariable.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["EnvironmentFiles"].writeList(value.environmentFiles, memberWritingClosure: PipesClientTypes.EcsEnvironmentFile.write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["Memory"].write(value.memory)
        try writer["MemoryReservation"].write(value.memoryReservation)
        try writer["Name"].write(value.name)
        try writer["ResourceRequirements"].writeList(value.resourceRequirements, memberWritingClosure: PipesClientTypes.EcsResourceRequirement.write(value:to:), memberNodeInfo: "member", isFlattened: false)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.EcsContainerOverride {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.EcsContainerOverride()
        value.command = try reader["Command"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.cpu = try reader["Cpu"].readIfPresent()
        value.environment = try reader["Environment"].readListIfPresent(memberReadingClosure: PipesClientTypes.EcsEnvironmentVariable.read(from:), memberNodeInfo: "member", isFlattened: false)
        value.environmentFiles = try reader["EnvironmentFiles"].readListIfPresent(memberReadingClosure: PipesClientTypes.EcsEnvironmentFile.read(from:), memberNodeInfo: "member", isFlattened: false)
        value.memory = try reader["Memory"].readIfPresent()
        value.memoryReservation = try reader["MemoryReservation"].readIfPresent()
        value.name = try reader["Name"].readIfPresent()
        value.resourceRequirements = try reader["ResourceRequirements"].readListIfPresent(memberReadingClosure: PipesClientTypes.EcsResourceRequirement.read(from:), memberNodeInfo: "member", isFlattened: false)
        return value
    }
}

extension PipesClientTypes.EcsResourceRequirement {

    static func write(value: PipesClientTypes.EcsResourceRequirement?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["type"].write(value.type)
        try writer["value"].write(value.value)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.EcsResourceRequirement {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.EcsResourceRequirement()
        value.type = try reader["type"].readIfPresent() ?? .sdkUnknown("")
        value.value = try reader["value"].readIfPresent() ?? ""
        return value
    }
}

extension PipesClientTypes.EcsEnvironmentFile {

    static func write(value: PipesClientTypes.EcsEnvironmentFile?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["type"].write(value.type)
        try writer["value"].write(value.value)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.EcsEnvironmentFile {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.EcsEnvironmentFile()
        value.type = try reader["type"].readIfPresent() ?? .sdkUnknown("")
        value.value = try reader["value"].readIfPresent() ?? ""
        return value
    }
}

extension PipesClientTypes.EcsEnvironmentVariable {

    static func write(value: PipesClientTypes.EcsEnvironmentVariable?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["name"].write(value.name)
        try writer["value"].write(value.value)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.EcsEnvironmentVariable {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.EcsEnvironmentVariable()
        value.name = try reader["name"].readIfPresent()
        value.value = try reader["value"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PlacementStrategy {

    static func write(value: PipesClientTypes.PlacementStrategy?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["field"].write(value.field)
        try writer["type"].write(value.type)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PlacementStrategy {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PlacementStrategy()
        value.type = try reader["type"].readIfPresent()
        value.field = try reader["field"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PlacementConstraint {

    static func write(value: PipesClientTypes.PlacementConstraint?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["expression"].write(value.expression)
        try writer["type"].write(value.type)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PlacementConstraint {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PlacementConstraint()
        value.type = try reader["type"].readIfPresent()
        value.expression = try reader["expression"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.CapacityProviderStrategyItem {

    static func write(value: PipesClientTypes.CapacityProviderStrategyItem?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["base"].write(value.base)
        try writer["capacityProvider"].write(value.capacityProvider)
        try writer["weight"].write(value.weight)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.CapacityProviderStrategyItem {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.CapacityProviderStrategyItem()
        value.capacityProvider = try reader["capacityProvider"].readIfPresent() ?? ""
        value.weight = try reader["weight"].readIfPresent() ?? 0
        value.base = try reader["base"].readIfPresent() ?? 0
        return value
    }
}

extension PipesClientTypes.NetworkConfiguration {

    static func write(value: PipesClientTypes.NetworkConfiguration?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["awsvpcConfiguration"].write(value.awsvpcConfiguration, with: PipesClientTypes.AwsVpcConfiguration.write(value:to:))
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.NetworkConfiguration {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.NetworkConfiguration()
        value.awsvpcConfiguration = try reader["awsvpcConfiguration"].readIfPresent(with: PipesClientTypes.AwsVpcConfiguration.read(from:))
        return value
    }
}

extension PipesClientTypes.AwsVpcConfiguration {

    static func write(value: PipesClientTypes.AwsVpcConfiguration?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["AssignPublicIp"].write(value.assignPublicIp)
        try writer["SecurityGroups"].writeList(value.securityGroups, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["Subnets"].writeList(value.subnets, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.AwsVpcConfiguration {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.AwsVpcConfiguration()
        value.subnets = try reader["Subnets"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        value.securityGroups = try reader["SecurityGroups"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.assignPublicIp = try reader["AssignPublicIp"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PipeTargetKinesisStreamParameters {

    static func write(value: PipesClientTypes.PipeTargetKinesisStreamParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["PartitionKey"].write(value.partitionKey)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetKinesisStreamParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetKinesisStreamParameters()
        value.partitionKey = try reader["PartitionKey"].readIfPresent() ?? ""
        return value
    }
}

extension PipesClientTypes.PipeTargetStateMachineParameters {

    static func write(value: PipesClientTypes.PipeTargetStateMachineParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["InvocationType"].write(value.invocationType)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetStateMachineParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetStateMachineParameters()
        value.invocationType = try reader["InvocationType"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PipeTargetLambdaFunctionParameters {

    static func write(value: PipesClientTypes.PipeTargetLambdaFunctionParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["InvocationType"].write(value.invocationType)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeTargetLambdaFunctionParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeTargetLambdaFunctionParameters()
        value.invocationType = try reader["InvocationType"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.PipeLogConfiguration {

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.PipeLogConfiguration {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.PipeLogConfiguration()
        value.s3LogDestination = try reader["S3LogDestination"].readIfPresent(with: PipesClientTypes.S3LogDestination.read(from:))
        value.firehoseLogDestination = try reader["FirehoseLogDestination"].readIfPresent(with: PipesClientTypes.FirehoseLogDestination.read(from:))
        value.cloudwatchLogsLogDestination = try reader["CloudwatchLogsLogDestination"].readIfPresent(with: PipesClientTypes.CloudwatchLogsLogDestination.read(from:))
        value.level = try reader["Level"].readIfPresent()
        value.includeExecutionData = try reader["IncludeExecutionData"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosureBox<PipesClientTypes.IncludeExecutionDataOption>().read(from:), memberNodeInfo: "member", isFlattened: false)
        return value
    }
}

extension PipesClientTypes.CloudwatchLogsLogDestination {

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.CloudwatchLogsLogDestination {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.CloudwatchLogsLogDestination()
        value.logGroupArn = try reader["LogGroupArn"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.FirehoseLogDestination {

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.FirehoseLogDestination {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.FirehoseLogDestination()
        value.deliveryStreamArn = try reader["DeliveryStreamArn"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.S3LogDestination {

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.S3LogDestination {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.S3LogDestination()
        value.bucketName = try reader["BucketName"].readIfPresent()
        value.`prefix` = try reader["Prefix"].readIfPresent()
        value.bucketOwner = try reader["BucketOwner"].readIfPresent()
        value.outputFormat = try reader["OutputFormat"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.Pipe {

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.Pipe {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.Pipe()
        value.name = try reader["Name"].readIfPresent()
        value.arn = try reader["Arn"].readIfPresent()
        value.desiredState = try reader["DesiredState"].readIfPresent()
        value.currentState = try reader["CurrentState"].readIfPresent()
        value.stateReason = try reader["StateReason"].readIfPresent()
        value.creationTime = try reader["CreationTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.lastModifiedTime = try reader["LastModifiedTime"].readTimestampIfPresent(format: SmithyTimestamps.TimestampFormat.epochSeconds)
        value.source = try reader["Source"].readIfPresent()
        value.target = try reader["Target"].readIfPresent()
        value.enrichment = try reader["Enrichment"].readIfPresent()
        return value
    }
}

extension PipesClientTypes.ValidationExceptionField {

    static func read(from reader: SmithyJSON.Reader) throws -> PipesClientTypes.ValidationExceptionField {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = PipesClientTypes.ValidationExceptionField()
        value.name = try reader["name"].readIfPresent() ?? ""
        value.message = try reader["message"].readIfPresent() ?? ""
        return value
    }
}

extension PipesClientTypes.PipeLogConfigurationParameters {

    static func write(value: PipesClientTypes.PipeLogConfigurationParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["CloudwatchLogsLogDestination"].write(value.cloudwatchLogsLogDestination, with: PipesClientTypes.CloudwatchLogsLogDestinationParameters.write(value:to:))
        try writer["FirehoseLogDestination"].write(value.firehoseLogDestination, with: PipesClientTypes.FirehoseLogDestinationParameters.write(value:to:))
        try writer["IncludeExecutionData"].writeList(value.includeExecutionData, memberWritingClosure: SmithyReadWrite.WritingClosureBox<PipesClientTypes.IncludeExecutionDataOption>().write(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["Level"].write(value.level)
        try writer["S3LogDestination"].write(value.s3LogDestination, with: PipesClientTypes.S3LogDestinationParameters.write(value:to:))
    }
}

extension PipesClientTypes.CloudwatchLogsLogDestinationParameters {

    static func write(value: PipesClientTypes.CloudwatchLogsLogDestinationParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["LogGroupArn"].write(value.logGroupArn)
    }
}

extension PipesClientTypes.FirehoseLogDestinationParameters {

    static func write(value: PipesClientTypes.FirehoseLogDestinationParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["DeliveryStreamArn"].write(value.deliveryStreamArn)
    }
}

extension PipesClientTypes.S3LogDestinationParameters {

    static func write(value: PipesClientTypes.S3LogDestinationParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BucketName"].write(value.bucketName)
        try writer["BucketOwner"].write(value.bucketOwner)
        try writer["OutputFormat"].write(value.outputFormat)
        try writer["Prefix"].write(value.`prefix`)
    }
}

extension PipesClientTypes.UpdatePipeSourceParameters {

    static func write(value: PipesClientTypes.UpdatePipeSourceParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["ActiveMQBrokerParameters"].write(value.activeMQBrokerParameters, with: PipesClientTypes.UpdatePipeSourceActiveMQBrokerParameters.write(value:to:))
        try writer["DynamoDBStreamParameters"].write(value.dynamoDBStreamParameters, with: PipesClientTypes.UpdatePipeSourceDynamoDBStreamParameters.write(value:to:))
        try writer["FilterCriteria"].write(value.filterCriteria, with: PipesClientTypes.FilterCriteria.write(value:to:))
        try writer["KinesisStreamParameters"].write(value.kinesisStreamParameters, with: PipesClientTypes.UpdatePipeSourceKinesisStreamParameters.write(value:to:))
        try writer["ManagedStreamingKafkaParameters"].write(value.managedStreamingKafkaParameters, with: PipesClientTypes.UpdatePipeSourceManagedStreamingKafkaParameters.write(value:to:))
        try writer["RabbitMQBrokerParameters"].write(value.rabbitMQBrokerParameters, with: PipesClientTypes.UpdatePipeSourceRabbitMQBrokerParameters.write(value:to:))
        try writer["SelfManagedKafkaParameters"].write(value.selfManagedKafkaParameters, with: PipesClientTypes.UpdatePipeSourceSelfManagedKafkaParameters.write(value:to:))
        try writer["SqsQueueParameters"].write(value.sqsQueueParameters, with: PipesClientTypes.UpdatePipeSourceSqsQueueParameters.write(value:to:))
    }
}

extension PipesClientTypes.UpdatePipeSourceSelfManagedKafkaParameters {

    static func write(value: PipesClientTypes.UpdatePipeSourceSelfManagedKafkaParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["Credentials"].write(value.credentials, with: PipesClientTypes.SelfManagedKafkaAccessConfigurationCredentials.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
        try writer["ServerRootCaCertificate"].write(value.serverRootCaCertificate)
        try writer["Vpc"].write(value.vpc, with: PipesClientTypes.SelfManagedKafkaAccessConfigurationVpc.write(value:to:))
    }
}

extension PipesClientTypes.UpdatePipeSourceManagedStreamingKafkaParameters {

    static func write(value: PipesClientTypes.UpdatePipeSourceManagedStreamingKafkaParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["Credentials"].write(value.credentials, with: PipesClientTypes.MSKAccessCredentials.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
    }
}

extension PipesClientTypes.UpdatePipeSourceRabbitMQBrokerParameters {

    static func write(value: PipesClientTypes.UpdatePipeSourceRabbitMQBrokerParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["Credentials"].write(value.credentials, with: PipesClientTypes.MQBrokerAccessCredentials.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
    }
}

extension PipesClientTypes.UpdatePipeSourceActiveMQBrokerParameters {

    static func write(value: PipesClientTypes.UpdatePipeSourceActiveMQBrokerParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["Credentials"].write(value.credentials, with: PipesClientTypes.MQBrokerAccessCredentials.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
    }
}

extension PipesClientTypes.UpdatePipeSourceSqsQueueParameters {

    static func write(value: PipesClientTypes.UpdatePipeSourceSqsQueueParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
    }
}

extension PipesClientTypes.UpdatePipeSourceDynamoDBStreamParameters {

    static func write(value: PipesClientTypes.UpdatePipeSourceDynamoDBStreamParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["DeadLetterConfig"].write(value.deadLetterConfig, with: PipesClientTypes.DeadLetterConfig.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
        try writer["MaximumRecordAgeInSeconds"].write(value.maximumRecordAgeInSeconds)
        try writer["MaximumRetryAttempts"].write(value.maximumRetryAttempts)
        try writer["OnPartialBatchItemFailure"].write(value.onPartialBatchItemFailure)
        try writer["ParallelizationFactor"].write(value.parallelizationFactor)
    }
}

extension PipesClientTypes.UpdatePipeSourceKinesisStreamParameters {

    static func write(value: PipesClientTypes.UpdatePipeSourceKinesisStreamParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["BatchSize"].write(value.batchSize)
        try writer["DeadLetterConfig"].write(value.deadLetterConfig, with: PipesClientTypes.DeadLetterConfig.write(value:to:))
        try writer["MaximumBatchingWindowInSeconds"].write(value.maximumBatchingWindowInSeconds)
        try writer["MaximumRecordAgeInSeconds"].write(value.maximumRecordAgeInSeconds)
        try writer["MaximumRetryAttempts"].write(value.maximumRetryAttempts)
        try writer["OnPartialBatchItemFailure"].write(value.onPartialBatchItemFailure)
        try writer["ParallelizationFactor"].write(value.parallelizationFactor)
    }
}

public enum PipesClientTypes {}
