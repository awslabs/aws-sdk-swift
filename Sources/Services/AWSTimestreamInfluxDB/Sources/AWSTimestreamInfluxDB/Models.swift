//
// Copyright Amazon.com Inc. or its affiliates.
// All Rights Reserved.
//
// SPDX-License-Identifier: Apache-2.0
//

// Code generated by smithy-swift-codegen. DO NOT EDIT!

@_spi(SmithyReadWrite) import ClientRuntime
import class SmithyHTTPAPI.HTTPResponse
@_spi(SmithyReadWrite) import class SmithyJSON.Reader
@_spi(SmithyReadWrite) import class SmithyJSON.Writer
import enum ClientRuntime.ErrorFault
import enum SmithyReadWrite.ReaderError
@_spi(SmithyReadWrite) import enum SmithyReadWrite.ReadingClosures
@_spi(SmithyReadWrite) import enum SmithyReadWrite.WritingClosures
import protocol AWSClientRuntime.AWSServiceError
import protocol ClientRuntime.HTTPError
import protocol ClientRuntime.ModeledError
@_spi(SmithyReadWrite) import protocol SmithyReadWrite.SmithyReader
@_spi(SmithyReadWrite) import protocol SmithyReadWrite.SmithyWriter
@_spi(SmithyReadWrite) import struct AWSClientRuntime.AWSJSONError
@_spi(UnknownAWSHTTPServiceError) import struct AWSClientRuntime.UnknownAWSHTTPServiceError
@_spi(SmithyReadWrite) import struct SmithyReadWrite.ReadingClosureBox


public struct TagResourceOutput: Swift.Sendable {

    public init() { }
}

public struct UntagResourceOutput: Swift.Sendable {

    public init() { }
}

/// You do not have sufficient access to perform this action.
public struct AccessDeniedException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error, Swift.Sendable {

    public struct Properties: Swift.Sendable {
        /// This member is required.
        public internal(set) var message: Swift.String? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "AccessDeniedException" }
    public static var fault: ClientRuntime.ErrorFault { .client }
    public static var isRetryable: Swift.Bool { false }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil
    ) {
        self.properties.message = message
    }
}

/// The request conflicts with an existing resource in Timestream for InfluxDB.
public struct ConflictException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error, Swift.Sendable {

    public struct Properties: Swift.Sendable {
        /// This member is required.
        public internal(set) var message: Swift.String? = nil
        /// The identifier for the Timestream for InfluxDB resource associated with the request.
        /// This member is required.
        public internal(set) var resourceId: Swift.String? = nil
        /// The type of Timestream for InfluxDB resource associated with the request.
        /// This member is required.
        public internal(set) var resourceType: Swift.String? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "ConflictException" }
    public static var fault: ClientRuntime.ErrorFault { .client }
    public static var isRetryable: Swift.Bool { false }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil,
        resourceId: Swift.String? = nil,
        resourceType: Swift.String? = nil
    ) {
        self.properties.message = message
        self.properties.resourceId = resourceId
        self.properties.resourceType = resourceType
    }
}

/// The request processing has failed because of an unknown error, exception or failure.
public struct InternalServerException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error, Swift.Sendable {

    public struct Properties: Swift.Sendable {
        /// This member is required.
        public internal(set) var message: Swift.String? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "InternalServerException" }
    public static var fault: ClientRuntime.ErrorFault { .server }
    public static var isRetryable: Swift.Bool { true }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil
    ) {
        self.properties.message = message
    }
}

/// The requested resource was not found or does not exist.
public struct ResourceNotFoundException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error, Swift.Sendable {

    public struct Properties: Swift.Sendable {
        /// This member is required.
        public internal(set) var message: Swift.String? = nil
        /// The identifier for the Timestream for InfluxDB resource associated with the request.
        /// This member is required.
        public internal(set) var resourceId: Swift.String? = nil
        /// The type of Timestream for InfluxDB resource associated with the request.
        /// This member is required.
        public internal(set) var resourceType: Swift.String? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "ResourceNotFoundException" }
    public static var fault: ClientRuntime.ErrorFault { .client }
    public static var isRetryable: Swift.Bool { false }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil,
        resourceId: Swift.String? = nil,
        resourceType: Swift.String? = nil
    ) {
        self.properties.message = message
        self.properties.resourceId = resourceId
        self.properties.resourceType = resourceType
    }
}

/// The request exceeds the service quota.
public struct ServiceQuotaExceededException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error, Swift.Sendable {

    public struct Properties: Swift.Sendable {
        /// This member is required.
        public internal(set) var message: Swift.String? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "ServiceQuotaExceededException" }
    public static var fault: ClientRuntime.ErrorFault { .client }
    public static var isRetryable: Swift.Bool { false }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil
    ) {
        self.properties.message = message
    }
}

/// The request was denied due to request throttling.
public struct ThrottlingException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error, Swift.Sendable {

    public struct Properties: Swift.Sendable {
        /// This member is required.
        public internal(set) var message: Swift.String? = nil
        /// The number of seconds the caller should wait before retrying.
        public internal(set) var retryAfterSeconds: Swift.Int? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "ThrottlingException" }
    public static var fault: ClientRuntime.ErrorFault { .client }
    public static var isRetryable: Swift.Bool { true }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil,
        retryAfterSeconds: Swift.Int? = nil
    ) {
        self.properties.message = message
        self.properties.retryAfterSeconds = retryAfterSeconds
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum ValidationExceptionReason: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case fieldValidationFailed
        case other
        case sdkUnknown(Swift.String)

        public static var allCases: [ValidationExceptionReason] {
            return [
                .fieldValidationFailed,
                .other
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .fieldValidationFailed: return "FIELD_VALIDATION_FAILED"
            case .other: return "OTHER"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

/// The input fails to satisfy the constraints specified by Timestream for InfluxDB.
public struct ValidationException: ClientRuntime.ModeledError, AWSClientRuntime.AWSServiceError, ClientRuntime.HTTPError, Swift.Error, Swift.Sendable {

    public struct Properties: Swift.Sendable {
        /// This member is required.
        public internal(set) var message: Swift.String? = nil
        /// The reason that validation failed.
        /// This member is required.
        public internal(set) var reason: TimestreamInfluxDBClientTypes.ValidationExceptionReason? = nil
    }

    public internal(set) var properties = Properties()
    public static var typeName: Swift.String { "ValidationException" }
    public static var fault: ClientRuntime.ErrorFault { .client }
    public static var isRetryable: Swift.Bool { false }
    public static var isThrottling: Swift.Bool { false }
    public internal(set) var httpResponse = SmithyHTTPAPI.HTTPResponse()
    public internal(set) var message: Swift.String?
    public internal(set) var requestID: Swift.String?

    public init(
        message: Swift.String? = nil,
        reason: TimestreamInfluxDBClientTypes.ValidationExceptionReason? = nil
    ) {
        self.properties.message = message
        self.properties.reason = reason
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum DbInstanceType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case dbInflux12xlarge
        case dbInflux16xlarge
        case dbInflux24xlarge
        case dbInflux2xlarge
        case dbInflux4xlarge
        case dbInflux8xlarge
        case dbInfluxLarge
        case dbInfluxMedium
        case dbInfluxXlarge
        case sdkUnknown(Swift.String)

        public static var allCases: [DbInstanceType] {
            return [
                .dbInflux12xlarge,
                .dbInflux16xlarge,
                .dbInflux24xlarge,
                .dbInflux2xlarge,
                .dbInflux4xlarge,
                .dbInflux8xlarge,
                .dbInfluxLarge,
                .dbInfluxMedium,
                .dbInfluxXlarge
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .dbInflux12xlarge: return "db.influx.12xlarge"
            case .dbInflux16xlarge: return "db.influx.16xlarge"
            case .dbInflux24xlarge: return "db.influx.24xlarge"
            case .dbInflux2xlarge: return "db.influx.2xlarge"
            case .dbInflux4xlarge: return "db.influx.4xlarge"
            case .dbInflux8xlarge: return "db.influx.8xlarge"
            case .dbInfluxLarge: return "db.influx.large"
            case .dbInfluxMedium: return "db.influx.medium"
            case .dbInfluxXlarge: return "db.influx.xlarge"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum DbStorageType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case influxIoIncludedT1
        case influxIoIncludedT2
        case influxIoIncludedT3
        case sdkUnknown(Swift.String)

        public static var allCases: [DbStorageType] {
            return [
                .influxIoIncludedT1,
                .influxIoIncludedT2,
                .influxIoIncludedT3
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .influxIoIncludedT1: return "InfluxIOIncludedT1"
            case .influxIoIncludedT2: return "InfluxIOIncludedT2"
            case .influxIoIncludedT3: return "InfluxIOIncludedT3"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum ClusterDeploymentType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case multiNodeReadReplicas
        case sdkUnknown(Swift.String)

        public static var allCases: [ClusterDeploymentType] {
            return [
                .multiNodeReadReplicas
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .multiNodeReadReplicas: return "MULTI_NODE_READ_REPLICAS"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum FailoverMode: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case automatic
        case noFailover
        case sdkUnknown(Swift.String)

        public static var allCases: [FailoverMode] {
            return [
                .automatic,
                .noFailover
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .automatic: return "AUTOMATIC"
            case .noFailover: return "NO_FAILOVER"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    /// Configuration for S3 bucket log delivery.
    public struct S3Configuration: Swift.Sendable {
        /// The name of the S3 bucket to deliver logs to.
        /// This member is required.
        public var bucketName: Swift.String?
        /// Indicates whether log delivery to the S3 bucket is enabled.
        /// This member is required.
        public var enabled: Swift.Bool?

        public init(
            bucketName: Swift.String? = nil,
            enabled: Swift.Bool? = nil
        ) {
            self.bucketName = bucketName
            self.enabled = enabled
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
    public struct LogDeliveryConfiguration: Swift.Sendable {
        /// Configuration for S3 bucket log delivery.
        /// This member is required.
        public var s3Configuration: TimestreamInfluxDBClientTypes.S3Configuration?

        public init(
            s3Configuration: TimestreamInfluxDBClientTypes.S3Configuration? = nil
        ) {
            self.s3Configuration = s3Configuration
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum NetworkType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case dual
        case ipv4
        case sdkUnknown(Swift.String)

        public static var allCases: [NetworkType] {
            return [
                .dual,
                .ipv4
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .dual: return "DUAL"
            case .ipv4: return "IPV4"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

public struct CreateDbClusterInput: Swift.Sendable {
    /// The amount of storage to allocate for your DB storage type in GiB (gibibytes).
    public var allocatedStorage: Swift.Int?
    /// The name of the initial InfluxDB bucket. All InfluxDB data is stored in a bucket. A bucket combines the concept of a database and a retention period (the duration of time that each data point persists). A bucket belongs to an organization.
    public var bucket: Swift.String?
    /// The Timestream for InfluxDB DB instance type to run InfluxDB on.
    /// This member is required.
    public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
    /// The ID of the DB parameter group to assign to your DB cluster. DB parameter groups specify how the database is configured. For example, DB parameter groups can specify the limit for query concurrency.
    public var dbParameterGroupIdentifier: Swift.String?
    /// The Timestream for InfluxDB DB storage type to read and write InfluxDB data. You can choose between three different types of provisioned Influx IOPS Included storage according to your workload requirements:
    ///
    /// * Influx I/O Included 3000 IOPS
    ///
    /// * Influx I/O Included 12000 IOPS
    ///
    /// * Influx I/O Included 16000 IOPS
    public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
    /// Specifies the type of cluster to create.
    public var deploymentType: TimestreamInfluxDBClientTypes.ClusterDeploymentType?
    /// Specifies the behavior of failure recovery when the primary node of the cluster fails.
    public var failoverMode: TimestreamInfluxDBClientTypes.FailoverMode?
    /// Configuration for sending InfluxDB engine logs to a specified S3 bucket.
    public var logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration?
    /// The name that uniquely identifies the DB cluster when interacting with the Amazon Timestream for InfluxDB API and CLI commands. This name will also be a prefix included in the endpoint. DB cluster names must be unique per customer and per region.
    /// This member is required.
    public var name: Swift.String?
    /// Specifies whether the network type of the Timestream for InfluxDB cluster is IPv4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
    public var networkType: TimestreamInfluxDBClientTypes.NetworkType?
    /// The name of the initial organization for the initial admin user in InfluxDB. An InfluxDB organization is a workspace for a group of users.
    public var organization: Swift.String?
    /// The password of the initial admin user created in InfluxDB. This password will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a secret created in Secrets Manager in your account.
    public var password: Swift.String?
    /// The port number on which InfluxDB accepts connections. Valid Values: 1024-65535 Default: 8086 for InfluxDB v2, 8181 for InfluxDB v3 Constraints: The value can't be 2375-2376, 7788-7799, 8090, or 51678-51680
    public var port: Swift.Int?
    /// Configures the Timestream for InfluxDB cluster with a public IP to facilitate access from outside the VPC.
    public var publiclyAccessible: Swift.Bool?
    /// A list of key-value pairs to associate with the DB instance.
    public var tags: [Swift.String: Swift.String]?
    /// The username of the initial admin user created in InfluxDB. Must start with a letter and can't end with a hyphen or contain two consecutive hyphens. For example, my-user1. This username will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a secret created in Secrets Manager in your account.
    public var username: Swift.String?
    /// A list of VPC security group IDs to associate with the Timestream for InfluxDB cluster.
    /// This member is required.
    public var vpcSecurityGroupIds: [Swift.String]?
    /// A list of VPC subnet IDs to associate with the DB cluster. Provide at least two VPC subnet IDs in different Availability Zones when deploying with a Multi-AZ standby.
    /// This member is required.
    public var vpcSubnetIds: [Swift.String]?

    public init(
        allocatedStorage: Swift.Int? = nil,
        bucket: Swift.String? = nil,
        dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
        dbParameterGroupIdentifier: Swift.String? = nil,
        dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
        deploymentType: TimestreamInfluxDBClientTypes.ClusterDeploymentType? = nil,
        failoverMode: TimestreamInfluxDBClientTypes.FailoverMode? = nil,
        logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration? = nil,
        name: Swift.String? = nil,
        networkType: TimestreamInfluxDBClientTypes.NetworkType? = nil,
        organization: Swift.String? = nil,
        password: Swift.String? = nil,
        port: Swift.Int? = nil,
        publiclyAccessible: Swift.Bool? = nil,
        tags: [Swift.String: Swift.String]? = nil,
        username: Swift.String? = nil,
        vpcSecurityGroupIds: [Swift.String]? = nil,
        vpcSubnetIds: [Swift.String]? = nil
    ) {
        self.allocatedStorage = allocatedStorage
        self.bucket = bucket
        self.dbInstanceType = dbInstanceType
        self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
        self.dbStorageType = dbStorageType
        self.deploymentType = deploymentType
        self.failoverMode = failoverMode
        self.logDeliveryConfiguration = logDeliveryConfiguration
        self.name = name
        self.networkType = networkType
        self.organization = organization
        self.password = password
        self.port = port
        self.publiclyAccessible = publiclyAccessible
        self.tags = tags
        self.username = username
        self.vpcSecurityGroupIds = vpcSecurityGroupIds
        self.vpcSubnetIds = vpcSubnetIds
    }
}

extension CreateDbClusterInput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "CreateDbClusterInput(allocatedStorage: \(Swift.String(describing: allocatedStorage)), bucket: \(Swift.String(describing: bucket)), dbInstanceType: \(Swift.String(describing: dbInstanceType)), dbParameterGroupIdentifier: \(Swift.String(describing: dbParameterGroupIdentifier)), dbStorageType: \(Swift.String(describing: dbStorageType)), deploymentType: \(Swift.String(describing: deploymentType)), failoverMode: \(Swift.String(describing: failoverMode)), logDeliveryConfiguration: \(Swift.String(describing: logDeliveryConfiguration)), name: \(Swift.String(describing: name)), networkType: \(Swift.String(describing: networkType)), organization: \(Swift.String(describing: organization)), port: \(Swift.String(describing: port)), publiclyAccessible: \(Swift.String(describing: publiclyAccessible)), tags: \(Swift.String(describing: tags)), vpcSecurityGroupIds: \(Swift.String(describing: vpcSecurityGroupIds)), vpcSubnetIds: \(Swift.String(describing: vpcSubnetIds)), password: \"CONTENT_REDACTED\", username: \"CONTENT_REDACTED\")"}
}

extension TimestreamInfluxDBClientTypes {

    public enum ClusterStatus: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case available
        case creating
        case deleted
        case deleting
        case failed
        case maintenance
        case partiallyAvailable
        case rebooting
        case rebootFailed
        case updating
        case updatingInstanceType
        case sdkUnknown(Swift.String)

        public static var allCases: [ClusterStatus] {
            return [
                .available,
                .creating,
                .deleted,
                .deleting,
                .failed,
                .maintenance,
                .partiallyAvailable,
                .rebooting,
                .rebootFailed,
                .updating,
                .updatingInstanceType
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .available: return "AVAILABLE"
            case .creating: return "CREATING"
            case .deleted: return "DELETED"
            case .deleting: return "DELETING"
            case .failed: return "FAILED"
            case .maintenance: return "MAINTENANCE"
            case .partiallyAvailable: return "PARTIALLY_AVAILABLE"
            case .rebooting: return "REBOOTING"
            case .rebootFailed: return "REBOOT_FAILED"
            case .updating: return "UPDATING"
            case .updatingInstanceType: return "UPDATING_INSTANCE_TYPE"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

public struct CreateDbClusterOutput: Swift.Sendable {
    /// A service-generated unique identifier.
    public var dbClusterId: Swift.String?
    /// The status of the DB cluster.
    public var dbClusterStatus: TimestreamInfluxDBClientTypes.ClusterStatus?

    public init(
        dbClusterId: Swift.String? = nil,
        dbClusterStatus: TimestreamInfluxDBClientTypes.ClusterStatus? = nil
    ) {
        self.dbClusterId = dbClusterId
        self.dbClusterStatus = dbClusterStatus
    }
}

public struct DeleteDbClusterInput: Swift.Sendable {
    /// Service-generated unique identifier of the DB cluster.
    /// This member is required.
    public var dbClusterId: Swift.String?

    public init(
        dbClusterId: Swift.String? = nil
    ) {
        self.dbClusterId = dbClusterId
    }
}

public struct DeleteDbClusterOutput: Swift.Sendable {
    /// The status of the DB cluster.
    public var dbClusterStatus: TimestreamInfluxDBClientTypes.ClusterStatus?

    public init(
        dbClusterStatus: TimestreamInfluxDBClientTypes.ClusterStatus? = nil
    ) {
        self.dbClusterStatus = dbClusterStatus
    }
}

public struct GetDbClusterInput: Swift.Sendable {
    /// Service-generated unique identifier of the DB cluster to retrieve.
    /// This member is required.
    public var dbClusterId: Swift.String?

    public init(
        dbClusterId: Swift.String? = nil
    ) {
        self.dbClusterId = dbClusterId
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum EngineType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case influxdbV2
        case influxdbV3Core
        case influxdbV3Enterprise
        case sdkUnknown(Swift.String)

        public static var allCases: [EngineType] {
            return [
                .influxdbV2,
                .influxdbV3Core,
                .influxdbV3Enterprise
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .influxdbV2: return "INFLUXDB_V2"
            case .influxdbV3Core: return "INFLUXDB_V3_CORE"
            case .influxdbV3Enterprise: return "INFLUXDB_V3_ENTERPRISE"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

public struct GetDbClusterOutput: Swift.Sendable {
    /// The amount of storage allocated for your DB storage type (in gibibytes).
    public var allocatedStorage: Swift.Int?
    /// The Amazon Resource Name (ARN) of the DB cluster.
    /// This member is required.
    public var arn: Swift.String?
    /// The Timestream for InfluxDB instance type that InfluxDB runs on.
    public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
    /// The ID of the DB parameter group assigned to your DB cluster.
    public var dbParameterGroupIdentifier: Swift.String?
    /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
    public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
    /// Deployment type of the DB cluster.
    public var deploymentType: TimestreamInfluxDBClientTypes.ClusterDeploymentType?
    /// The endpoint used to connect to the Timestream for InfluxDB cluster for write and read operations.
    public var endpoint: Swift.String?
    /// The engine type of your DB cluster.
    public var engineType: TimestreamInfluxDBClientTypes.EngineType?
    /// The configured failover mode for the DB cluster.
    public var failoverMode: TimestreamInfluxDBClientTypes.FailoverMode?
    /// Service-generated unique identifier of the DB cluster to retrieve.
    /// This member is required.
    public var id: Swift.String?
    /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
    public var influxAuthParametersSecretArn: Swift.String?
    /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
    public var logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration?
    /// Customer-supplied name of the Timestream for InfluxDB cluster.
    /// This member is required.
    public var name: Swift.String?
    /// Specifies whether the network type of the Timestream for InfluxDB cluster is IPv4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
    public var networkType: TimestreamInfluxDBClientTypes.NetworkType?
    /// The port number on which InfluxDB accepts connections.
    public var port: Swift.Int?
    /// Indicates if the DB cluster has a public IP to facilitate access from outside the VPC.
    public var publiclyAccessible: Swift.Bool?
    /// The endpoint used to connect to the Timestream for InfluxDB cluster for read-only operations.
    public var readerEndpoint: Swift.String?
    /// The status of the DB cluster.
    public var status: TimestreamInfluxDBClientTypes.ClusterStatus?
    /// A list of VPC security group IDs associated with the DB cluster.
    public var vpcSecurityGroupIds: [Swift.String]?
    /// A list of VPC subnet IDs associated with the DB cluster.
    public var vpcSubnetIds: [Swift.String]?

    public init(
        allocatedStorage: Swift.Int? = nil,
        arn: Swift.String? = nil,
        dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
        dbParameterGroupIdentifier: Swift.String? = nil,
        dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
        deploymentType: TimestreamInfluxDBClientTypes.ClusterDeploymentType? = nil,
        endpoint: Swift.String? = nil,
        engineType: TimestreamInfluxDBClientTypes.EngineType? = nil,
        failoverMode: TimestreamInfluxDBClientTypes.FailoverMode? = nil,
        id: Swift.String? = nil,
        influxAuthParametersSecretArn: Swift.String? = nil,
        logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration? = nil,
        name: Swift.String? = nil,
        networkType: TimestreamInfluxDBClientTypes.NetworkType? = nil,
        port: Swift.Int? = nil,
        publiclyAccessible: Swift.Bool? = nil,
        readerEndpoint: Swift.String? = nil,
        status: TimestreamInfluxDBClientTypes.ClusterStatus? = nil,
        vpcSecurityGroupIds: [Swift.String]? = nil,
        vpcSubnetIds: [Swift.String]? = nil
    ) {
        self.allocatedStorage = allocatedStorage
        self.arn = arn
        self.dbInstanceType = dbInstanceType
        self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
        self.dbStorageType = dbStorageType
        self.deploymentType = deploymentType
        self.endpoint = endpoint
        self.engineType = engineType
        self.failoverMode = failoverMode
        self.id = id
        self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
        self.logDeliveryConfiguration = logDeliveryConfiguration
        self.name = name
        self.networkType = networkType
        self.port = port
        self.publiclyAccessible = publiclyAccessible
        self.readerEndpoint = readerEndpoint
        self.status = status
        self.vpcSecurityGroupIds = vpcSecurityGroupIds
        self.vpcSubnetIds = vpcSubnetIds
    }
}

public struct ListDbClustersInput: Swift.Sendable {
    /// The maximum number of items to return in the output. If the total number of items available is more than the value specified, a nextToken is provided in the output. To resume pagination, provide the nextToken value as an argument of a subsequent API invocation.
    public var maxResults: Swift.Int?
    /// The pagination token. To resume pagination, provide the nextToken value as an argument of a subsequent API invocation.
    public var nextToken: Swift.String?

    public init(
        maxResults: Swift.Int? = nil,
        nextToken: Swift.String? = nil
    ) {
        self.maxResults = maxResults
        self.nextToken = nextToken
    }
}

extension TimestreamInfluxDBClientTypes {

    /// Describes a summary of a Timestream for InfluxDB cluster.
    public struct DbClusterSummary: Swift.Sendable {
        /// The amount of storage allocated for your DB storage type (in gibibytes).
        public var allocatedStorage: Swift.Int?
        /// The Amazon Resource Name (ARN) of the DB cluster.
        /// This member is required.
        public var arn: Swift.String?
        /// The Timestream for InfluxDB DB instance type that InfluxDB runs on.
        public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
        /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
        public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
        /// Deployment type of the DB cluster
        public var deploymentType: TimestreamInfluxDBClientTypes.ClusterDeploymentType?
        /// The endpoint used to connect to the Timestream for InfluxDB cluster for write and read operations.
        public var endpoint: Swift.String?
        /// The engine type of your DB cluster.
        public var engineType: TimestreamInfluxDBClientTypes.EngineType?
        /// Service-generated unique identifier of the DB cluster to retrieve.
        /// This member is required.
        public var id: Swift.String?
        /// Customer supplied name of the Timestream for InfluxDB cluster.
        /// This member is required.
        public var name: Swift.String?
        /// Specifies whether the network type of the Timestream for InfluxDB Cluster is IPv4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public var networkType: TimestreamInfluxDBClientTypes.NetworkType?
        /// The port number on which InfluxDB accepts connections.
        public var port: Swift.Int?
        /// The endpoint used to connect to the Timestream for InfluxDB cluster for read-only operations.
        public var readerEndpoint: Swift.String?
        /// The status of the DB cluster.
        public var status: TimestreamInfluxDBClientTypes.ClusterStatus?

        public init(
            allocatedStorage: Swift.Int? = nil,
            arn: Swift.String? = nil,
            dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
            dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
            deploymentType: TimestreamInfluxDBClientTypes.ClusterDeploymentType? = nil,
            endpoint: Swift.String? = nil,
            engineType: TimestreamInfluxDBClientTypes.EngineType? = nil,
            id: Swift.String? = nil,
            name: Swift.String? = nil,
            networkType: TimestreamInfluxDBClientTypes.NetworkType? = nil,
            port: Swift.Int? = nil,
            readerEndpoint: Swift.String? = nil,
            status: TimestreamInfluxDBClientTypes.ClusterStatus? = nil
        ) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.dbInstanceType = dbInstanceType
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.engineType = engineType
            self.id = id
            self.name = name
            self.networkType = networkType
            self.port = port
            self.readerEndpoint = readerEndpoint
            self.status = status
        }
    }
}

public struct ListDbClustersOutput: Swift.Sendable {
    /// A list of Timestream for InfluxDB cluster summaries.
    /// This member is required.
    public var items: [TimestreamInfluxDBClientTypes.DbClusterSummary]?
    /// Token from a previous call of the operation. When this value is provided, the service returns results from where the previous response left off.
    public var nextToken: Swift.String?

    public init(
        items: [TimestreamInfluxDBClientTypes.DbClusterSummary]? = nil,
        nextToken: Swift.String? = nil
    ) {
        self.items = items
        self.nextToken = nextToken
    }
}

public struct ListDbInstancesForClusterInput: Swift.Sendable {
    /// Service-generated unique identifier of the DB cluster.
    /// This member is required.
    public var dbClusterId: Swift.String?
    /// The maximum number of items to return in the output. If the total number of items available is more than the value specified, a nextToken is provided in the output. To resume pagination, provide the nextToken value as an argument of a subsequent API invocation.
    public var maxResults: Swift.Int?
    /// The pagination token. To resume pagination, provide the nextToken value as an argument of a subsequent API invocation.
    public var nextToken: Swift.String?

    public init(
        dbClusterId: Swift.String? = nil,
        maxResults: Swift.Int? = nil,
        nextToken: Swift.String? = nil
    ) {
        self.dbClusterId = dbClusterId
        self.maxResults = maxResults
        self.nextToken = nextToken
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum DeploymentType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case singleAz
        case withMultiazStandby
        case sdkUnknown(Swift.String)

        public static var allCases: [DeploymentType] {
            return [
                .singleAz,
                .withMultiazStandby
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .singleAz: return "SINGLE_AZ"
            case .withMultiazStandby: return "WITH_MULTIAZ_STANDBY"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum InstanceMode: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case compact
        case ingest
        case primary
        case process
        case query
        case replica
        case standby
        case sdkUnknown(Swift.String)

        public static var allCases: [InstanceMode] {
            return [
                .compact,
                .ingest,
                .primary,
                .process,
                .query,
                .replica,
                .standby
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .compact: return "COMPACT"
            case .ingest: return "INGEST"
            case .primary: return "PRIMARY"
            case .process: return "PROCESS"
            case .query: return "QUERY"
            case .replica: return "REPLICA"
            case .standby: return "STANDBY"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum Status: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case available
        case creating
        case deleted
        case deleting
        case failed
        case maintenance
        case modifying
        case rebooting
        case rebootFailed
        case updating
        case updatingDeploymentType
        case updatingInstanceType
        case sdkUnknown(Swift.String)

        public static var allCases: [Status] {
            return [
                .available,
                .creating,
                .deleted,
                .deleting,
                .failed,
                .maintenance,
                .modifying,
                .rebooting,
                .rebootFailed,
                .updating,
                .updatingDeploymentType,
                .updatingInstanceType
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .available: return "AVAILABLE"
            case .creating: return "CREATING"
            case .deleted: return "DELETED"
            case .deleting: return "DELETING"
            case .failed: return "FAILED"
            case .maintenance: return "MAINTENANCE"
            case .modifying: return "MODIFYING"
            case .rebooting: return "REBOOTING"
            case .rebootFailed: return "REBOOT_FAILED"
            case .updating: return "UPDATING"
            case .updatingDeploymentType: return "UPDATING_DEPLOYMENT_TYPE"
            case .updatingInstanceType: return "UPDATING_INSTANCE_TYPE"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    /// Contains a summary of a DB instance belonging to a DB cluster.
    public struct DbInstanceForClusterSummary: Swift.Sendable {
        /// The amount of storage allocated for your DB storage type in GiB (gibibytes).
        public var allocatedStorage: Swift.Int?
        /// The Amazon Resource Name (ARN) of the DB instance.
        /// This member is required.
        public var arn: Swift.String?
        /// The Timestream for InfluxDB instance type to run InfluxDB on.
        public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
        /// The storage type for your DB instance.
        public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
        /// Specifies the deployment type if applicable.
        public var deploymentType: TimestreamInfluxDBClientTypes.DeploymentType?
        /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
        public var endpoint: Swift.String?
        /// The service-generated unique identifier of the DB instance.
        /// This member is required.
        public var id: Swift.String?
        /// Specifies the DB instance's role in the cluster.
        public var instanceMode: TimestreamInfluxDBClientTypes.InstanceMode?
        /// Specifies the DB instance's roles in the cluster.
        public var instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]?
        /// A service-generated name for the DB instance based on the customer-supplied name for the DB cluster.
        /// This member is required.
        public var name: Swift.String?
        /// Specifies whether the network type of the Timestream for InfluxDB instance is IPv4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public var networkType: TimestreamInfluxDBClientTypes.NetworkType?
        /// The port number on which InfluxDB accepts connections.
        public var port: Swift.Int?
        /// The status of the DB instance.
        public var status: TimestreamInfluxDBClientTypes.Status?

        public init(
            allocatedStorage: Swift.Int? = nil,
            arn: Swift.String? = nil,
            dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
            dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
            deploymentType: TimestreamInfluxDBClientTypes.DeploymentType? = nil,
            endpoint: Swift.String? = nil,
            id: Swift.String? = nil,
            instanceMode: TimestreamInfluxDBClientTypes.InstanceMode? = nil,
            instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]? = nil,
            name: Swift.String? = nil,
            networkType: TimestreamInfluxDBClientTypes.NetworkType? = nil,
            port: Swift.Int? = nil,
            status: TimestreamInfluxDBClientTypes.Status? = nil
        ) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.dbInstanceType = dbInstanceType
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.id = id
            self.instanceMode = instanceMode
            self.instanceModes = instanceModes
            self.name = name
            self.networkType = networkType
            self.port = port
            self.status = status
        }
    }
}

public struct ListDbInstancesForClusterOutput: Swift.Sendable {
    /// A list of Timestream for InfluxDB instance summaries belonging to the cluster.
    /// This member is required.
    public var items: [TimestreamInfluxDBClientTypes.DbInstanceForClusterSummary]?
    /// Token from a previous call of the operation. When this value is provided, the service returns results from where the previous response left off.
    public var nextToken: Swift.String?

    public init(
        items: [TimestreamInfluxDBClientTypes.DbInstanceForClusterSummary]? = nil,
        nextToken: Swift.String? = nil
    ) {
        self.items = items
        self.nextToken = nextToken
    }
}

public struct RebootDbClusterInput: Swift.Sendable {
    /// Service-generated unique identifier of the DB cluster to reboot.
    /// This member is required.
    public var dbClusterId: Swift.String?
    /// A list of service-generated unique DB Instance Ids belonging to the DB Cluster to reboot.
    public var instanceIds: [Swift.String]?

    public init(
        dbClusterId: Swift.String? = nil,
        instanceIds: [Swift.String]? = nil
    ) {
        self.dbClusterId = dbClusterId
        self.instanceIds = instanceIds
    }
}

public struct RebootDbClusterOutput: Swift.Sendable {
    /// The status of the DB Cluster.
    public var dbClusterStatus: TimestreamInfluxDBClientTypes.ClusterStatus?

    public init(
        dbClusterStatus: TimestreamInfluxDBClientTypes.ClusterStatus? = nil
    ) {
        self.dbClusterStatus = dbClusterStatus
    }
}

public struct UpdateDbClusterInput: Swift.Sendable {
    /// Service-generated unique identifier of the DB cluster to update.
    /// This member is required.
    public var dbClusterId: Swift.String?
    /// Update the DB cluster to use the specified DB instance Type.
    public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
    /// Update the DB cluster to use the specified DB parameter group.
    public var dbParameterGroupIdentifier: Swift.String?
    /// Update the DB cluster's failover behavior.
    public var failoverMode: TimestreamInfluxDBClientTypes.FailoverMode?
    /// The log delivery configuration to apply to the DB cluster.
    public var logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration?
    /// Update the DB cluster to use the specified port.
    public var port: Swift.Int?

    public init(
        dbClusterId: Swift.String? = nil,
        dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
        dbParameterGroupIdentifier: Swift.String? = nil,
        failoverMode: TimestreamInfluxDBClientTypes.FailoverMode? = nil,
        logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration? = nil,
        port: Swift.Int? = nil
    ) {
        self.dbClusterId = dbClusterId
        self.dbInstanceType = dbInstanceType
        self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
        self.failoverMode = failoverMode
        self.logDeliveryConfiguration = logDeliveryConfiguration
        self.port = port
    }
}

public struct UpdateDbClusterOutput: Swift.Sendable {
    /// The status of the DB cluster.
    public var dbClusterStatus: TimestreamInfluxDBClientTypes.ClusterStatus?

    public init(
        dbClusterStatus: TimestreamInfluxDBClientTypes.ClusterStatus? = nil
    ) {
        self.dbClusterStatus = dbClusterStatus
    }
}

public struct CreateDbInstanceInput: Swift.Sendable {
    /// The amount of storage to allocate for your DB storage type in GiB (gibibytes).
    /// This member is required.
    public var allocatedStorage: Swift.Int?
    /// The name of the initial InfluxDB bucket. All InfluxDB data is stored in a bucket. A bucket combines the concept of a database and a retention period (the duration of time that each data point persists). A bucket belongs to an organization.
    public var bucket: Swift.String?
    /// The Timestream for InfluxDB DB instance type to run InfluxDB on.
    /// This member is required.
    public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
    /// The id of the DB parameter group to assign to your DB instance. DB parameter groups specify how the database is configured. For example, DB parameter groups can specify the limit for query concurrency.
    public var dbParameterGroupIdentifier: Swift.String?
    /// The Timestream for InfluxDB DB storage type to read and write InfluxDB data. You can choose between 3 different types of provisioned Influx IOPS included storage according to your workloads requirements:
    ///
    /// * Influx IO Included 3000 IOPS
    ///
    /// * Influx IO Included 12000 IOPS
    ///
    /// * Influx IO Included 16000 IOPS
    public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
    /// Specifies whether the DB instance will be deployed as a standalone instance or with a Multi-AZ standby for high availability.
    public var deploymentType: TimestreamInfluxDBClientTypes.DeploymentType?
    /// Configuration for sending InfluxDB engine logs to a specified S3 bucket.
    public var logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration?
    /// The name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands. This name will also be a prefix included in the endpoint. DB instance names must be unique per customer and per region.
    /// This member is required.
    public var name: Swift.String?
    /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
    public var networkType: TimestreamInfluxDBClientTypes.NetworkType?
    /// The name of the initial organization for the initial admin user in InfluxDB. An InfluxDB organization is a workspace for a group of users.
    public var organization: Swift.String?
    /// The password of the initial admin user created in InfluxDB v2. This password will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a Secret created in Secrets Manager in your account.
    /// This member is required.
    public var password: Swift.String?
    /// The port number on which InfluxDB accepts connections. Valid Values: 1024-65535 Default: 8086 Constraints: The value can't be 2375-2376, 7788-7799, 8090, or 51678-51680
    public var port: Swift.Int?
    /// Configures the DB instance with a public IP to facilitate access.
    public var publiclyAccessible: Swift.Bool?
    /// A list of key-value pairs to associate with the DB instance.
    public var tags: [Swift.String: Swift.String]?
    /// The username of the initial admin user created in InfluxDB. Must start with a letter and can't end with a hyphen or contain two consecutive hyphens. For example, my-user1. This username will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a Secret created in Amazon Secrets Manager in your account.
    public var username: Swift.String?
    /// A list of VPC security group IDs to associate with the DB instance.
    /// This member is required.
    public var vpcSecurityGroupIds: [Swift.String]?
    /// A list of VPC subnet IDs to associate with the DB instance. Provide at least two VPC subnet IDs in different availability zones when deploying with a Multi-AZ standby.
    /// This member is required.
    public var vpcSubnetIds: [Swift.String]?

    public init(
        allocatedStorage: Swift.Int? = nil,
        bucket: Swift.String? = nil,
        dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
        dbParameterGroupIdentifier: Swift.String? = nil,
        dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
        deploymentType: TimestreamInfluxDBClientTypes.DeploymentType? = nil,
        logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration? = nil,
        name: Swift.String? = nil,
        networkType: TimestreamInfluxDBClientTypes.NetworkType? = nil,
        organization: Swift.String? = nil,
        password: Swift.String? = nil,
        port: Swift.Int? = nil,
        publiclyAccessible: Swift.Bool? = nil,
        tags: [Swift.String: Swift.String]? = nil,
        username: Swift.String? = nil,
        vpcSecurityGroupIds: [Swift.String]? = nil,
        vpcSubnetIds: [Swift.String]? = nil
    ) {
        self.allocatedStorage = allocatedStorage
        self.bucket = bucket
        self.dbInstanceType = dbInstanceType
        self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
        self.dbStorageType = dbStorageType
        self.deploymentType = deploymentType
        self.logDeliveryConfiguration = logDeliveryConfiguration
        self.name = name
        self.networkType = networkType
        self.organization = organization
        self.password = password
        self.port = port
        self.publiclyAccessible = publiclyAccessible
        self.tags = tags
        self.username = username
        self.vpcSecurityGroupIds = vpcSecurityGroupIds
        self.vpcSubnetIds = vpcSubnetIds
    }
}

extension CreateDbInstanceInput: Swift.CustomDebugStringConvertible {
    public var debugDescription: Swift.String {
        "CreateDbInstanceInput(allocatedStorage: \(Swift.String(describing: allocatedStorage)), bucket: \(Swift.String(describing: bucket)), dbInstanceType: \(Swift.String(describing: dbInstanceType)), dbParameterGroupIdentifier: \(Swift.String(describing: dbParameterGroupIdentifier)), dbStorageType: \(Swift.String(describing: dbStorageType)), deploymentType: \(Swift.String(describing: deploymentType)), logDeliveryConfiguration: \(Swift.String(describing: logDeliveryConfiguration)), name: \(Swift.String(describing: name)), networkType: \(Swift.String(describing: networkType)), organization: \(Swift.String(describing: organization)), port: \(Swift.String(describing: port)), publiclyAccessible: \(Swift.String(describing: publiclyAccessible)), tags: \(Swift.String(describing: tags)), vpcSecurityGroupIds: \(Swift.String(describing: vpcSecurityGroupIds)), vpcSubnetIds: \(Swift.String(describing: vpcSubnetIds)), password: \"CONTENT_REDACTED\", username: \"CONTENT_REDACTED\")"}
}

public struct CreateDbInstanceOutput: Swift.Sendable {
    /// The amount of storage allocated for your DB storage type (in gibibytes).
    public var allocatedStorage: Swift.Int?
    /// The Amazon Resource Name (ARN) of the DB instance.
    /// This member is required.
    public var arn: Swift.String?
    /// The Availability Zone in which the DB instance resides.
    public var availabilityZone: Swift.String?
    /// Specifies the DbCluster to which this DbInstance belongs to.
    public var dbClusterId: Swift.String?
    /// The Timestream for InfluxDB instance type that InfluxDB runs on.
    public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
    /// The id of the DB parameter group assigned to your DB instance.
    public var dbParameterGroupIdentifier: Swift.String?
    /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
    public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
    /// Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.
    public var deploymentType: TimestreamInfluxDBClientTypes.DeploymentType?
    /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
    public var endpoint: Swift.String?
    /// A service-generated unique identifier.
    /// This member is required.
    public var id: Swift.String?
    /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
    public var influxAuthParametersSecretArn: Swift.String?
    /// Specifies the DbInstance's role in the cluster.
    public var instanceMode: TimestreamInfluxDBClientTypes.InstanceMode?
    /// Specifies the DbInstance's roles in the cluster.
    public var instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]?
    /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
    public var logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration?
    /// The customer-supplied name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
    /// This member is required.
    public var name: Swift.String?
    /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
    public var networkType: TimestreamInfluxDBClientTypes.NetworkType?
    /// The port number on which InfluxDB accepts connections. The default value is 8086.
    public var port: Swift.Int?
    /// Indicates if the DB instance has a public IP to facilitate access.
    public var publiclyAccessible: Swift.Bool?
    /// The Availability Zone in which the standby instance is located when deploying with a MultiAZ standby instance.
    public var secondaryAvailabilityZone: Swift.String?
    /// The status of the DB instance.
    public var status: TimestreamInfluxDBClientTypes.Status?
    /// A list of VPC security group IDs associated with the DB instance.
    public var vpcSecurityGroupIds: [Swift.String]?
    /// A list of VPC subnet IDs associated with the DB instance.
    /// This member is required.
    public var vpcSubnetIds: [Swift.String]?

    public init(
        allocatedStorage: Swift.Int? = nil,
        arn: Swift.String? = nil,
        availabilityZone: Swift.String? = nil,
        dbClusterId: Swift.String? = nil,
        dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
        dbParameterGroupIdentifier: Swift.String? = nil,
        dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
        deploymentType: TimestreamInfluxDBClientTypes.DeploymentType? = nil,
        endpoint: Swift.String? = nil,
        id: Swift.String? = nil,
        influxAuthParametersSecretArn: Swift.String? = nil,
        instanceMode: TimestreamInfluxDBClientTypes.InstanceMode? = nil,
        instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]? = nil,
        logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration? = nil,
        name: Swift.String? = nil,
        networkType: TimestreamInfluxDBClientTypes.NetworkType? = nil,
        port: Swift.Int? = nil,
        publiclyAccessible: Swift.Bool? = nil,
        secondaryAvailabilityZone: Swift.String? = nil,
        status: TimestreamInfluxDBClientTypes.Status? = nil,
        vpcSecurityGroupIds: [Swift.String]? = nil,
        vpcSubnetIds: [Swift.String]? = nil
    ) {
        self.allocatedStorage = allocatedStorage
        self.arn = arn
        self.availabilityZone = availabilityZone
        self.dbClusterId = dbClusterId
        self.dbInstanceType = dbInstanceType
        self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
        self.dbStorageType = dbStorageType
        self.deploymentType = deploymentType
        self.endpoint = endpoint
        self.id = id
        self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
        self.instanceMode = instanceMode
        self.instanceModes = instanceModes
        self.logDeliveryConfiguration = logDeliveryConfiguration
        self.name = name
        self.networkType = networkType
        self.port = port
        self.publiclyAccessible = publiclyAccessible
        self.secondaryAvailabilityZone = secondaryAvailabilityZone
        self.status = status
        self.vpcSecurityGroupIds = vpcSecurityGroupIds
        self.vpcSubnetIds = vpcSubnetIds
    }
}

public struct DeleteDbInstanceInput: Swift.Sendable {
    /// The id of the DB instance.
    /// This member is required.
    public var identifier: Swift.String?

    public init(
        identifier: Swift.String? = nil
    ) {
        self.identifier = identifier
    }
}

public struct DeleteDbInstanceOutput: Swift.Sendable {
    /// The amount of storage allocated for your DB storage type (in gibibytes).
    public var allocatedStorage: Swift.Int?
    /// The Amazon Resource Name (ARN) of the DB instance.
    /// This member is required.
    public var arn: Swift.String?
    /// The Availability Zone in which the DB instance resides.
    public var availabilityZone: Swift.String?
    /// Specifies the DbCluster to which this DbInstance belongs to.
    public var dbClusterId: Swift.String?
    /// The Timestream for InfluxDB instance type that InfluxDB runs on.
    public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
    /// The id of the DB parameter group assigned to your DB instance.
    public var dbParameterGroupIdentifier: Swift.String?
    /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
    public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
    /// Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.
    public var deploymentType: TimestreamInfluxDBClientTypes.DeploymentType?
    /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
    public var endpoint: Swift.String?
    /// A service-generated unique identifier.
    /// This member is required.
    public var id: Swift.String?
    /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
    public var influxAuthParametersSecretArn: Swift.String?
    /// Specifies the DbInstance's role in the cluster.
    public var instanceMode: TimestreamInfluxDBClientTypes.InstanceMode?
    /// Specifies the DbInstance's roles in the cluster.
    public var instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]?
    /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
    public var logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration?
    /// The customer-supplied name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
    /// This member is required.
    public var name: Swift.String?
    /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
    public var networkType: TimestreamInfluxDBClientTypes.NetworkType?
    /// The port number on which InfluxDB accepts connections.
    public var port: Swift.Int?
    /// Indicates if the DB instance has a public IP to facilitate access.
    public var publiclyAccessible: Swift.Bool?
    /// The Availability Zone in which the standby instance is located when deploying with a MultiAZ standby instance.
    public var secondaryAvailabilityZone: Swift.String?
    /// The status of the DB instance.
    public var status: TimestreamInfluxDBClientTypes.Status?
    /// A list of VPC security group IDs associated with the DB instance.
    public var vpcSecurityGroupIds: [Swift.String]?
    /// A list of VPC subnet IDs associated with the DB instance.
    /// This member is required.
    public var vpcSubnetIds: [Swift.String]?

    public init(
        allocatedStorage: Swift.Int? = nil,
        arn: Swift.String? = nil,
        availabilityZone: Swift.String? = nil,
        dbClusterId: Swift.String? = nil,
        dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
        dbParameterGroupIdentifier: Swift.String? = nil,
        dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
        deploymentType: TimestreamInfluxDBClientTypes.DeploymentType? = nil,
        endpoint: Swift.String? = nil,
        id: Swift.String? = nil,
        influxAuthParametersSecretArn: Swift.String? = nil,
        instanceMode: TimestreamInfluxDBClientTypes.InstanceMode? = nil,
        instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]? = nil,
        logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration? = nil,
        name: Swift.String? = nil,
        networkType: TimestreamInfluxDBClientTypes.NetworkType? = nil,
        port: Swift.Int? = nil,
        publiclyAccessible: Swift.Bool? = nil,
        secondaryAvailabilityZone: Swift.String? = nil,
        status: TimestreamInfluxDBClientTypes.Status? = nil,
        vpcSecurityGroupIds: [Swift.String]? = nil,
        vpcSubnetIds: [Swift.String]? = nil
    ) {
        self.allocatedStorage = allocatedStorage
        self.arn = arn
        self.availabilityZone = availabilityZone
        self.dbClusterId = dbClusterId
        self.dbInstanceType = dbInstanceType
        self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
        self.dbStorageType = dbStorageType
        self.deploymentType = deploymentType
        self.endpoint = endpoint
        self.id = id
        self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
        self.instanceMode = instanceMode
        self.instanceModes = instanceModes
        self.logDeliveryConfiguration = logDeliveryConfiguration
        self.name = name
        self.networkType = networkType
        self.port = port
        self.publiclyAccessible = publiclyAccessible
        self.secondaryAvailabilityZone = secondaryAvailabilityZone
        self.status = status
        self.vpcSecurityGroupIds = vpcSecurityGroupIds
        self.vpcSubnetIds = vpcSubnetIds
    }
}

public struct GetDbInstanceInput: Swift.Sendable {
    /// The id of the DB instance.
    /// This member is required.
    public var identifier: Swift.String?

    public init(
        identifier: Swift.String? = nil
    ) {
        self.identifier = identifier
    }
}

public struct GetDbInstanceOutput: Swift.Sendable {
    /// The amount of storage allocated for your DB storage type (in gibibytes).
    public var allocatedStorage: Swift.Int?
    /// The Amazon Resource Name (ARN) of the DB instance.
    /// This member is required.
    public var arn: Swift.String?
    /// The Availability Zone in which the DB instance resides.
    public var availabilityZone: Swift.String?
    /// Specifies the DbCluster to which this DbInstance belongs to.
    public var dbClusterId: Swift.String?
    /// The Timestream for InfluxDB instance type that InfluxDB runs on.
    public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
    /// The id of the DB parameter group assigned to your DB instance.
    public var dbParameterGroupIdentifier: Swift.String?
    /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
    public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
    /// Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.
    public var deploymentType: TimestreamInfluxDBClientTypes.DeploymentType?
    /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
    public var endpoint: Swift.String?
    /// A service-generated unique identifier.
    /// This member is required.
    public var id: Swift.String?
    /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
    public var influxAuthParametersSecretArn: Swift.String?
    /// Specifies the DbInstance's role in the cluster.
    public var instanceMode: TimestreamInfluxDBClientTypes.InstanceMode?
    /// Specifies the DbInstance's roles in the cluster.
    public var instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]?
    /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
    public var logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration?
    /// The customer-supplied name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
    /// This member is required.
    public var name: Swift.String?
    /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
    public var networkType: TimestreamInfluxDBClientTypes.NetworkType?
    /// The port number on which InfluxDB accepts connections.
    public var port: Swift.Int?
    /// Indicates if the DB instance has a public IP to facilitate access.
    public var publiclyAccessible: Swift.Bool?
    /// The Availability Zone in which the standby instance is located when deploying with a MultiAZ standby instance.
    public var secondaryAvailabilityZone: Swift.String?
    /// The status of the DB instance.
    public var status: TimestreamInfluxDBClientTypes.Status?
    /// A list of VPC security group IDs associated with the DB instance.
    public var vpcSecurityGroupIds: [Swift.String]?
    /// A list of VPC subnet IDs associated with the DB instance.
    /// This member is required.
    public var vpcSubnetIds: [Swift.String]?

    public init(
        allocatedStorage: Swift.Int? = nil,
        arn: Swift.String? = nil,
        availabilityZone: Swift.String? = nil,
        dbClusterId: Swift.String? = nil,
        dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
        dbParameterGroupIdentifier: Swift.String? = nil,
        dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
        deploymentType: TimestreamInfluxDBClientTypes.DeploymentType? = nil,
        endpoint: Swift.String? = nil,
        id: Swift.String? = nil,
        influxAuthParametersSecretArn: Swift.String? = nil,
        instanceMode: TimestreamInfluxDBClientTypes.InstanceMode? = nil,
        instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]? = nil,
        logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration? = nil,
        name: Swift.String? = nil,
        networkType: TimestreamInfluxDBClientTypes.NetworkType? = nil,
        port: Swift.Int? = nil,
        publiclyAccessible: Swift.Bool? = nil,
        secondaryAvailabilityZone: Swift.String? = nil,
        status: TimestreamInfluxDBClientTypes.Status? = nil,
        vpcSecurityGroupIds: [Swift.String]? = nil,
        vpcSubnetIds: [Swift.String]? = nil
    ) {
        self.allocatedStorage = allocatedStorage
        self.arn = arn
        self.availabilityZone = availabilityZone
        self.dbClusterId = dbClusterId
        self.dbInstanceType = dbInstanceType
        self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
        self.dbStorageType = dbStorageType
        self.deploymentType = deploymentType
        self.endpoint = endpoint
        self.id = id
        self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
        self.instanceMode = instanceMode
        self.instanceModes = instanceModes
        self.logDeliveryConfiguration = logDeliveryConfiguration
        self.name = name
        self.networkType = networkType
        self.port = port
        self.publiclyAccessible = publiclyAccessible
        self.secondaryAvailabilityZone = secondaryAvailabilityZone
        self.status = status
        self.vpcSecurityGroupIds = vpcSecurityGroupIds
        self.vpcSubnetIds = vpcSubnetIds
    }
}

public struct ListDbInstancesInput: Swift.Sendable {
    /// The maximum number of items to return in the output. If the total number of items available is more than the value specified, a NextToken is provided in the output. To resume pagination, provide the NextToken value as argument of a subsequent API invocation.
    public var maxResults: Swift.Int?
    /// The pagination token. To resume pagination, provide the NextToken value as argument of a subsequent API invocation.
    public var nextToken: Swift.String?

    public init(
        maxResults: Swift.Int? = nil,
        nextToken: Swift.String? = nil
    ) {
        self.maxResults = maxResults
        self.nextToken = nextToken
    }
}

extension TimestreamInfluxDBClientTypes {

    /// Contains a summary of a DB instance.
    public struct DbInstanceSummary: Swift.Sendable {
        /// The amount of storage to allocate for your DbStorageType in GiB (gibibytes).
        public var allocatedStorage: Swift.Int?
        /// The Amazon Resource Name (ARN) of the DB instance.
        /// This member is required.
        public var arn: Swift.String?
        /// The Timestream for InfluxDB instance type to run InfluxDB on.
        public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
        /// The storage type for your DB instance.
        public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
        /// Single-Instance or with a MultiAZ Standby for High availability.
        public var deploymentType: TimestreamInfluxDBClientTypes.DeploymentType?
        /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
        public var endpoint: Swift.String?
        /// The service-generated unique identifier of the DB instance.
        /// This member is required.
        public var id: Swift.String?
        /// This customer-supplied name uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
        /// This member is required.
        public var name: Swift.String?
        /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public var networkType: TimestreamInfluxDBClientTypes.NetworkType?
        /// The port number on which InfluxDB accepts connections.
        public var port: Swift.Int?
        /// The status of the DB instance.
        public var status: TimestreamInfluxDBClientTypes.Status?

        public init(
            allocatedStorage: Swift.Int? = nil,
            arn: Swift.String? = nil,
            dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
            dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
            deploymentType: TimestreamInfluxDBClientTypes.DeploymentType? = nil,
            endpoint: Swift.String? = nil,
            id: Swift.String? = nil,
            name: Swift.String? = nil,
            networkType: TimestreamInfluxDBClientTypes.NetworkType? = nil,
            port: Swift.Int? = nil,
            status: TimestreamInfluxDBClientTypes.Status? = nil
        ) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.dbInstanceType = dbInstanceType
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.id = id
            self.name = name
            self.networkType = networkType
            self.port = port
            self.status = status
        }
    }
}

public struct ListDbInstancesOutput: Swift.Sendable {
    /// A list of Timestream for InfluxDB DB instance summaries.
    /// This member is required.
    public var items: [TimestreamInfluxDBClientTypes.DbInstanceSummary]?
    /// Token from a previous call of the operation. When this value is provided, the service returns results from where the previous response left off.
    public var nextToken: Swift.String?

    public init(
        items: [TimestreamInfluxDBClientTypes.DbInstanceSummary]? = nil,
        nextToken: Swift.String? = nil
    ) {
        self.items = items
        self.nextToken = nextToken
    }
}

public struct RebootDbInstanceInput: Swift.Sendable {
    /// The id of the DB instance to reboot.
    /// This member is required.
    public var identifier: Swift.String?

    public init(
        identifier: Swift.String? = nil
    ) {
        self.identifier = identifier
    }
}

public struct RebootDbInstanceOutput: Swift.Sendable {
    /// The amount of storage allocated for your DB storage type (in gibibytes).
    public var allocatedStorage: Swift.Int?
    /// The Amazon Resource Name (ARN) of the DB instance.
    /// This member is required.
    public var arn: Swift.String?
    /// The Availability Zone in which the DB instance resides.
    public var availabilityZone: Swift.String?
    /// Specifies the DbCluster to which this DbInstance belongs to.
    public var dbClusterId: Swift.String?
    /// The Timestream for InfluxDB instance type that InfluxDB runs on.
    public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
    /// The id of the DB parameter group assigned to your DB instance.
    public var dbParameterGroupIdentifier: Swift.String?
    /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
    public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
    /// Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.
    public var deploymentType: TimestreamInfluxDBClientTypes.DeploymentType?
    /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
    public var endpoint: Swift.String?
    /// A service-generated unique identifier.
    /// This member is required.
    public var id: Swift.String?
    /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
    public var influxAuthParametersSecretArn: Swift.String?
    /// Specifies the DbInstance's role in the cluster.
    public var instanceMode: TimestreamInfluxDBClientTypes.InstanceMode?
    /// Specifies the DbInstance's roles in the cluster.
    public var instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]?
    /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
    public var logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration?
    /// The customer-supplied name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
    /// This member is required.
    public var name: Swift.String?
    /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
    public var networkType: TimestreamInfluxDBClientTypes.NetworkType?
    /// The port number on which InfluxDB accepts connections.
    public var port: Swift.Int?
    /// Indicates if the DB instance has a public IP to facilitate access.
    public var publiclyAccessible: Swift.Bool?
    /// The Availability Zone in which the standby instance is located when deploying with a MultiAZ standby instance.
    public var secondaryAvailabilityZone: Swift.String?
    /// The status of the DB instance.
    public var status: TimestreamInfluxDBClientTypes.Status?
    /// A list of VPC security group IDs associated with the DB instance.
    public var vpcSecurityGroupIds: [Swift.String]?
    /// A list of VPC subnet IDs associated with the DB instance.
    /// This member is required.
    public var vpcSubnetIds: [Swift.String]?

    public init(
        allocatedStorage: Swift.Int? = nil,
        arn: Swift.String? = nil,
        availabilityZone: Swift.String? = nil,
        dbClusterId: Swift.String? = nil,
        dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
        dbParameterGroupIdentifier: Swift.String? = nil,
        dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
        deploymentType: TimestreamInfluxDBClientTypes.DeploymentType? = nil,
        endpoint: Swift.String? = nil,
        id: Swift.String? = nil,
        influxAuthParametersSecretArn: Swift.String? = nil,
        instanceMode: TimestreamInfluxDBClientTypes.InstanceMode? = nil,
        instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]? = nil,
        logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration? = nil,
        name: Swift.String? = nil,
        networkType: TimestreamInfluxDBClientTypes.NetworkType? = nil,
        port: Swift.Int? = nil,
        publiclyAccessible: Swift.Bool? = nil,
        secondaryAvailabilityZone: Swift.String? = nil,
        status: TimestreamInfluxDBClientTypes.Status? = nil,
        vpcSecurityGroupIds: [Swift.String]? = nil,
        vpcSubnetIds: [Swift.String]? = nil
    ) {
        self.allocatedStorage = allocatedStorage
        self.arn = arn
        self.availabilityZone = availabilityZone
        self.dbClusterId = dbClusterId
        self.dbInstanceType = dbInstanceType
        self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
        self.dbStorageType = dbStorageType
        self.deploymentType = deploymentType
        self.endpoint = endpoint
        self.id = id
        self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
        self.instanceMode = instanceMode
        self.instanceModes = instanceModes
        self.logDeliveryConfiguration = logDeliveryConfiguration
        self.name = name
        self.networkType = networkType
        self.port = port
        self.publiclyAccessible = publiclyAccessible
        self.secondaryAvailabilityZone = secondaryAvailabilityZone
        self.status = status
        self.vpcSecurityGroupIds = vpcSecurityGroupIds
        self.vpcSubnetIds = vpcSubnetIds
    }
}

public struct UpdateDbInstanceInput: Swift.Sendable {
    /// The amount of storage to allocate for your DB storage type (in gibibytes).
    public var allocatedStorage: Swift.Int?
    /// The Timestream for InfluxDB DB instance type to run InfluxDB on.
    public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
    /// The id of the DB parameter group to assign to your DB instance. DB parameter groups specify how the database is configured. For example, DB parameter groups can specify the limit for query concurrency.
    public var dbParameterGroupIdentifier: Swift.String?
    /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
    public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
    /// Specifies whether the DB instance will be deployed as a standalone instance or with a Multi-AZ standby for high availability.
    public var deploymentType: TimestreamInfluxDBClientTypes.DeploymentType?
    /// The id of the DB instance.
    /// This member is required.
    public var identifier: Swift.String?
    /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
    public var logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration?
    /// The port number on which InfluxDB accepts connections. If you change the Port value, your database restarts immediately. Valid Values: 1024-65535 Default: 8086 Constraints: The value can't be 2375-2376, 7788-7799, 8090, or 51678-51680
    public var port: Swift.Int?

    public init(
        allocatedStorage: Swift.Int? = nil,
        dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
        dbParameterGroupIdentifier: Swift.String? = nil,
        dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
        deploymentType: TimestreamInfluxDBClientTypes.DeploymentType? = nil,
        identifier: Swift.String? = nil,
        logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration? = nil,
        port: Swift.Int? = nil
    ) {
        self.allocatedStorage = allocatedStorage
        self.dbInstanceType = dbInstanceType
        self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
        self.dbStorageType = dbStorageType
        self.deploymentType = deploymentType
        self.identifier = identifier
        self.logDeliveryConfiguration = logDeliveryConfiguration
        self.port = port
    }
}

public struct UpdateDbInstanceOutput: Swift.Sendable {
    /// The amount of storage allocated for your DB storage type (in gibibytes).
    public var allocatedStorage: Swift.Int?
    /// The Amazon Resource Name (ARN) of the DB instance.
    /// This member is required.
    public var arn: Swift.String?
    /// The Availability Zone in which the DB instance resides.
    public var availabilityZone: Swift.String?
    /// Specifies the DbCluster to which this DbInstance belongs to.
    public var dbClusterId: Swift.String?
    /// The Timestream for InfluxDB instance type that InfluxDB runs on.
    public var dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType?
    /// The id of the DB parameter group assigned to your DB instance.
    public var dbParameterGroupIdentifier: Swift.String?
    /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
    public var dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType?
    /// Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.
    public var deploymentType: TimestreamInfluxDBClientTypes.DeploymentType?
    /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
    public var endpoint: Swift.String?
    /// A service-generated unique identifier.
    /// This member is required.
    public var id: Swift.String?
    /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
    public var influxAuthParametersSecretArn: Swift.String?
    /// Specifies the DbInstance's role in the cluster.
    public var instanceMode: TimestreamInfluxDBClientTypes.InstanceMode?
    /// Specifies the DbInstance's roles in the cluster.
    public var instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]?
    /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
    public var logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration?
    /// This customer-supplied name uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
    /// This member is required.
    public var name: Swift.String?
    /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
    public var networkType: TimestreamInfluxDBClientTypes.NetworkType?
    /// The port number on which InfluxDB accepts connections.
    public var port: Swift.Int?
    /// Indicates if the DB instance has a public IP to facilitate access.
    public var publiclyAccessible: Swift.Bool?
    /// The Availability Zone in which the standby instance is located when deploying with a MultiAZ standby instance.
    public var secondaryAvailabilityZone: Swift.String?
    /// The status of the DB instance.
    public var status: TimestreamInfluxDBClientTypes.Status?
    /// A list of VPC security group IDs associated with the DB instance.
    public var vpcSecurityGroupIds: [Swift.String]?
    /// A list of VPC subnet IDs associated with the DB instance.
    /// This member is required.
    public var vpcSubnetIds: [Swift.String]?

    public init(
        allocatedStorage: Swift.Int? = nil,
        arn: Swift.String? = nil,
        availabilityZone: Swift.String? = nil,
        dbClusterId: Swift.String? = nil,
        dbInstanceType: TimestreamInfluxDBClientTypes.DbInstanceType? = nil,
        dbParameterGroupIdentifier: Swift.String? = nil,
        dbStorageType: TimestreamInfluxDBClientTypes.DbStorageType? = nil,
        deploymentType: TimestreamInfluxDBClientTypes.DeploymentType? = nil,
        endpoint: Swift.String? = nil,
        id: Swift.String? = nil,
        influxAuthParametersSecretArn: Swift.String? = nil,
        instanceMode: TimestreamInfluxDBClientTypes.InstanceMode? = nil,
        instanceModes: [TimestreamInfluxDBClientTypes.InstanceMode]? = nil,
        logDeliveryConfiguration: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration? = nil,
        name: Swift.String? = nil,
        networkType: TimestreamInfluxDBClientTypes.NetworkType? = nil,
        port: Swift.Int? = nil,
        publiclyAccessible: Swift.Bool? = nil,
        secondaryAvailabilityZone: Swift.String? = nil,
        status: TimestreamInfluxDBClientTypes.Status? = nil,
        vpcSecurityGroupIds: [Swift.String]? = nil,
        vpcSubnetIds: [Swift.String]? = nil
    ) {
        self.allocatedStorage = allocatedStorage
        self.arn = arn
        self.availabilityZone = availabilityZone
        self.dbClusterId = dbClusterId
        self.dbInstanceType = dbInstanceType
        self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
        self.dbStorageType = dbStorageType
        self.deploymentType = deploymentType
        self.endpoint = endpoint
        self.id = id
        self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
        self.instanceMode = instanceMode
        self.instanceModes = instanceModes
        self.logDeliveryConfiguration = logDeliveryConfiguration
        self.name = name
        self.networkType = networkType
        self.port = port
        self.publiclyAccessible = publiclyAccessible
        self.secondaryAvailabilityZone = secondaryAvailabilityZone
        self.status = status
        self.vpcSecurityGroupIds = vpcSecurityGroupIds
        self.vpcSubnetIds = vpcSubnetIds
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum DurationType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case days
        case hours
        case milliseconds
        case minutes
        case seconds
        case sdkUnknown(Swift.String)

        public static var allCases: [DurationType] {
            return [
                .days,
                .hours,
                .milliseconds,
                .minutes,
                .seconds
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .days: return "days"
            case .hours: return "hours"
            case .milliseconds: return "milliseconds"
            case .minutes: return "minutes"
            case .seconds: return "seconds"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    /// Duration for InfluxDB parameters in Timestream for InfluxDB.
    public struct Duration: Swift.Sendable {
        /// The type of duration for InfluxDB parameters.
        /// This member is required.
        public var durationType: TimestreamInfluxDBClientTypes.DurationType?
        /// The value of duration for InfluxDB parameters.
        /// This member is required.
        public var value: Swift.Int?

        public init(
            durationType: TimestreamInfluxDBClientTypes.DurationType? = nil,
            value: Swift.Int? = nil
        ) {
            self.durationType = durationType
            self.value = value
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum LogLevel: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case debug
        case error
        case info
        case sdkUnknown(Swift.String)

        public static var allCases: [LogLevel] {
            return [
                .debug,
                .error,
                .info
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .debug: return "debug"
            case .error: return "error"
            case .info: return "info"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum TracingType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case disabled
        case jaeger
        case log
        case sdkUnknown(Swift.String)

        public static var allCases: [TracingType] {
            return [
                .disabled,
                .jaeger,
                .log
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .disabled: return "disabled"
            case .jaeger: return "jaeger"
            case .log: return "log"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    /// All the customer-modifiable InfluxDB v2 parameters in Timestream for InfluxDB.
    public struct InfluxDBv2Parameters: Swift.Sendable {
        /// Include option to show detailed logs for Flux queries. Default: false
        public var fluxLogEnabled: Swift.Bool?
        /// Maximum duration the server should keep established connections alive while waiting for new requests. Set to 0 for no timeout. Default: 3 minutes
        public var httpIdleTimeout: TimestreamInfluxDBClientTypes.Duration?
        /// Maximum duration the server should try to read HTTP headers for new requests. Set to 0 for no timeout. Default: 10 seconds
        public var httpReadHeaderTimeout: TimestreamInfluxDBClientTypes.Duration?
        /// Maximum duration the server should try to read the entirety of new requests. Set to 0 for no timeout. Default: 0
        public var httpReadTimeout: TimestreamInfluxDBClientTypes.Duration?
        /// Maximum duration the server should spend processing and responding to write requests. Set to 0 for no timeout. Default: 0
        public var httpWriteTimeout: TimestreamInfluxDBClientTypes.Duration?
        /// Maximum number of group by time buckets a SELECT statement can create. 0 allows an unlimited number of buckets. Default: 0
        public var influxqlMaxSelectBuckets: Swift.Int?
        /// Maximum number of points a SELECT statement can process. 0 allows an unlimited number of points. InfluxDB checks the point count every second (so queries exceeding the maximum arent immediately aborted). Default: 0
        public var influxqlMaxSelectPoint: Swift.Int?
        /// Maximum number of series a SELECT statement can return. 0 allows an unlimited number of series. Default: 0
        public var influxqlMaxSelectSeries: Swift.Int?
        /// Log output level. InfluxDB outputs log entries with severity levels greater than or equal to the level specified. Default: info
        public var logLevel: TimestreamInfluxDBClientTypes.LogLevel?
        /// Disable the HTTP /metrics endpoint which exposes [internal InfluxDB metrics](https://docs.influxdata.com/influxdb/v2/reference/internals/metrics/). Default: false
        public var metricsDisabled: Swift.Bool?
        /// Disable the task scheduler. If problematic tasks prevent InfluxDB from starting, use this option to start InfluxDB without scheduling or executing tasks. Default: false
        public var noTasks: Swift.Bool?
        /// Disable the /debug/pprof HTTP endpoint. This endpoint provides runtime profiling data and can be helpful when debugging. Default: true
        public var pprofDisabled: Swift.Bool?
        /// Number of queries allowed to execute concurrently. Setting to 0 allows an unlimited number of concurrent queries. Default: 0
        public var queryConcurrency: Swift.Int?
        /// Initial bytes of memory allocated for a query. Default: 0
        public var queryInitialMemoryBytes: Swift.Int?
        /// Maximum number of queries allowed in execution queue. When queue limit is reached, new queries are rejected. Setting to 0 allows an unlimited number of queries in the queue. Default: 0
        public var queryMaxMemoryBytes: Swift.Int?
        /// Maximum bytes of memory allowed for a single query. Must be greater or equal to queryInitialMemoryBytes. Default: 0
        public var queryMemoryBytes: Swift.Int?
        /// Maximum number of queries allowed in execution queue. When queue limit is reached, new queries are rejected. Setting to 0 allows an unlimited number of queries in the queue. Default: 0
        public var queryQueueSize: Swift.Int?
        /// Specifies the Time to Live (TTL) in minutes for newly created user sessions. Default: 60
        public var sessionLength: Swift.Int?
        /// Disables automatically extending a users session TTL on each request. By default, every request sets the sessions expiration time to five minutes from now. When disabled, sessions expire after the specified [session length](https://docs.influxdata.com/influxdb/v2/reference/config-options/#session-length) and the user is redirected to the login page, even if recently active. Default: false
        public var sessionRenewDisabled: Swift.Bool?
        /// Maximum size (in bytes) a shards cache can reach before it starts rejecting writes. Must be greater than storageCacheSnapShotMemorySize and lower than instances total memory capacity. We recommend setting it to below 15% of the total memory capacity. Default: 1073741824
        public var storageCacheMaxMemorySize: Swift.Int?
        /// Size (in bytes) at which the storage engine will snapshot the cache and write it to a TSM file to make more memory available. Must not be greater than storageCacheMaxMemorySize. Default: 26214400
        public var storageCacheSnapshotMemorySize: Swift.Int?
        /// Duration at which the storage engine will snapshot the cache and write it to a new TSM file if the shard hasnt received writes or deletes. Default: 10 minutes
        public var storageCacheSnapshotWriteColdDuration: TimestreamInfluxDBClientTypes.Duration?
        /// Duration at which the storage engine will compact all TSM files in a shard if it hasn't received writes or deletes. Default: 4 hours
        public var storageCompactFullWriteColdDuration: TimestreamInfluxDBClientTypes.Duration?
        /// Rate limit (in bytes per second) that TSM compactions can write to disk. Default: 50331648
        public var storageCompactThroughputBurst: Swift.Int?
        /// Maximum number of full and level compactions that can run concurrently. A value of 0 results in 50% of runtime.GOMAXPROCS(0) used at runtime. Any number greater than zero limits compactions to that value. This setting does not apply to cache snapshotting. Default: 0
        public var storageMaxConcurrentCompactions: Swift.Int?
        /// Size (in bytes) at which an index write-ahead log (WAL) file will compact into an index file. Lower sizes will cause log files to be compacted more quickly and result in lower heap usage at the expense of write throughput. Default: 1048576
        public var storageMaxIndexLogFileSize: Swift.Int?
        /// Skip field size validation on incoming write requests. Default: false
        public var storageNoValidateFieldSize: Swift.Bool?
        /// Interval of retention policy enforcement checks. Must be greater than 0. Default: 30 minutes
        public var storageRetentionCheckInterval: TimestreamInfluxDBClientTypes.Duration?
        /// Maximum number of snapshot compactions that can run concurrently across all series partitions in a database. Default: 0
        public var storageSeriesFileMaxConcurrentSnapshotCompactions: Swift.Int?
        /// Size of the internal cache used in the TSI index to store previously calculated series results. Cached results are returned quickly rather than needing to be recalculated when a subsequent query with the same tag key/value predicate is executed. Setting this value to 0 will disable the cache and may decrease query performance. Default: 100
        public var storageSeriesIdSetCacheSize: Swift.Int?
        /// Maximum number writes to the WAL directory to attempt at the same time. Setting this value to 0 results in number of processing units available x2. Default: 0
        public var storageWalMaxConcurrentWrites: Swift.Int?
        /// Maximum amount of time a write request to the WAL directory will wait when the [maximum number of concurrent active writes to the WAL directory has been met](https://docs.influxdata.com/influxdb/v2/reference/config-options/#storage-wal-max-concurrent-writes). Set to 0 to disable the timeout. Default: 10 minutes
        public var storageWalMaxWriteDelay: TimestreamInfluxDBClientTypes.Duration?
        /// Enable tracing in InfluxDB and specifies the tracing type. Tracing is disabled by default.
        public var tracingType: TimestreamInfluxDBClientTypes.TracingType?
        /// Disable the InfluxDB user interface (UI). The UI is enabled by default. Default: false
        public var uiDisabled: Swift.Bool?

        public init(
            fluxLogEnabled: Swift.Bool? = nil,
            httpIdleTimeout: TimestreamInfluxDBClientTypes.Duration? = nil,
            httpReadHeaderTimeout: TimestreamInfluxDBClientTypes.Duration? = nil,
            httpReadTimeout: TimestreamInfluxDBClientTypes.Duration? = nil,
            httpWriteTimeout: TimestreamInfluxDBClientTypes.Duration? = nil,
            influxqlMaxSelectBuckets: Swift.Int? = nil,
            influxqlMaxSelectPoint: Swift.Int? = nil,
            influxqlMaxSelectSeries: Swift.Int? = nil,
            logLevel: TimestreamInfluxDBClientTypes.LogLevel? = nil,
            metricsDisabled: Swift.Bool? = nil,
            noTasks: Swift.Bool? = nil,
            pprofDisabled: Swift.Bool? = nil,
            queryConcurrency: Swift.Int? = nil,
            queryInitialMemoryBytes: Swift.Int? = nil,
            queryMaxMemoryBytes: Swift.Int? = nil,
            queryMemoryBytes: Swift.Int? = nil,
            queryQueueSize: Swift.Int? = nil,
            sessionLength: Swift.Int? = nil,
            sessionRenewDisabled: Swift.Bool? = nil,
            storageCacheMaxMemorySize: Swift.Int? = nil,
            storageCacheSnapshotMemorySize: Swift.Int? = nil,
            storageCacheSnapshotWriteColdDuration: TimestreamInfluxDBClientTypes.Duration? = nil,
            storageCompactFullWriteColdDuration: TimestreamInfluxDBClientTypes.Duration? = nil,
            storageCompactThroughputBurst: Swift.Int? = nil,
            storageMaxConcurrentCompactions: Swift.Int? = nil,
            storageMaxIndexLogFileSize: Swift.Int? = nil,
            storageNoValidateFieldSize: Swift.Bool? = nil,
            storageRetentionCheckInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            storageSeriesFileMaxConcurrentSnapshotCompactions: Swift.Int? = nil,
            storageSeriesIdSetCacheSize: Swift.Int? = nil,
            storageWalMaxConcurrentWrites: Swift.Int? = nil,
            storageWalMaxWriteDelay: TimestreamInfluxDBClientTypes.Duration? = nil,
            tracingType: TimestreamInfluxDBClientTypes.TracingType? = nil,
            uiDisabled: Swift.Bool? = nil
        ) {
            self.fluxLogEnabled = fluxLogEnabled
            self.httpIdleTimeout = httpIdleTimeout
            self.httpReadHeaderTimeout = httpReadHeaderTimeout
            self.httpReadTimeout = httpReadTimeout
            self.httpWriteTimeout = httpWriteTimeout
            self.influxqlMaxSelectBuckets = influxqlMaxSelectBuckets
            self.influxqlMaxSelectPoint = influxqlMaxSelectPoint
            self.influxqlMaxSelectSeries = influxqlMaxSelectSeries
            self.logLevel = logLevel
            self.metricsDisabled = metricsDisabled
            self.noTasks = noTasks
            self.pprofDisabled = pprofDisabled
            self.queryConcurrency = queryConcurrency
            self.queryInitialMemoryBytes = queryInitialMemoryBytes
            self.queryMaxMemoryBytes = queryMaxMemoryBytes
            self.queryMemoryBytes = queryMemoryBytes
            self.queryQueueSize = queryQueueSize
            self.sessionLength = sessionLength
            self.sessionRenewDisabled = sessionRenewDisabled
            self.storageCacheMaxMemorySize = storageCacheMaxMemorySize
            self.storageCacheSnapshotMemorySize = storageCacheSnapshotMemorySize
            self.storageCacheSnapshotWriteColdDuration = storageCacheSnapshotWriteColdDuration
            self.storageCompactFullWriteColdDuration = storageCompactFullWriteColdDuration
            self.storageCompactThroughputBurst = storageCompactThroughputBurst
            self.storageMaxConcurrentCompactions = storageMaxConcurrentCompactions
            self.storageMaxIndexLogFileSize = storageMaxIndexLogFileSize
            self.storageNoValidateFieldSize = storageNoValidateFieldSize
            self.storageRetentionCheckInterval = storageRetentionCheckInterval
            self.storageSeriesFileMaxConcurrentSnapshotCompactions = storageSeriesFileMaxConcurrentSnapshotCompactions
            self.storageSeriesIdSetCacheSize = storageSeriesIdSetCacheSize
            self.storageWalMaxConcurrentWrites = storageWalMaxConcurrentWrites
            self.storageWalMaxWriteDelay = storageWalMaxWriteDelay
            self.tracingType = tracingType
            self.uiDisabled = uiDisabled
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum DataFusionRuntimeType: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case multiThread
        case multiThreadAlt
        case sdkUnknown(Swift.String)

        public static var allCases: [DataFusionRuntimeType] {
            return [
                .multiThread,
                .multiThreadAlt
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .multiThread: return "multi-thread"
            case .multiThreadAlt: return "multi-thread-alt"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    /// Percent or Absolute Long for InfluxDB parameters
    public enum PercentOrAbsoluteLong: Swift.Sendable {
        /// Percent for InfluxDB parameters.
        case percent(Swift.String)
        /// Absolute long for InfluxDB parameters.
        case absolute(Swift.Int)
        case sdkUnknown(Swift.String)
    }
}

extension TimestreamInfluxDBClientTypes {

    public enum LogFormats: Swift.Sendable, Swift.Equatable, Swift.RawRepresentable, Swift.CaseIterable, Swift.Hashable {
        case full
        case sdkUnknown(Swift.String)

        public static var allCases: [LogFormats] {
            return [
                .full
            ]
        }

        public init?(rawValue: Swift.String) {
            let value = Self.allCases.first(where: { $0.rawValue == rawValue })
            self = value ?? Self.sdkUnknown(rawValue)
        }

        public var rawValue: Swift.String {
            switch self {
            case .full: return "full"
            case let .sdkUnknown(s): return s
            }
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    /// All the customer-modifiable InfluxDB v3 Core parameters in Timestream for InfluxDB.
    public struct InfluxDBv3CoreParameters: Swift.Sendable {
        /// Provides custom configuration to DataFusion as a comma-separated list of key:value pairs.
        public var dataFusionConfig: Swift.String?
        /// When multiple parquet files are required in a sorted way (deduplication for example), specifies the maximum fanout. Default: 1000
        public var dataFusionMaxParquetFanout: Swift.Int?
        /// Sets the maximum number of DataFusion runtime threads to use.
        public var dataFusionNumThreads: Swift.Int?
        /// Disables the LIFO slot of the DataFusion runtime.
        public var dataFusionRuntimeDisableLifoSlot: Swift.Bool?
        /// Sets the number of scheduler ticks after which the scheduler of the DataFusion tokio runtime polls for external eventsfor example: timers, I/O.
        public var dataFusionRuntimeEventInterval: Swift.Int?
        /// Sets the number of scheduler ticks after which the scheduler of the DataFusion runtime polls the global task queue.
        public var dataFusionRuntimeGlobalQueueInterval: Swift.Int?
        /// Specifies the limit for additional threads spawned by the DataFusion runtime.
        public var dataFusionRuntimeMaxBlockingThreads: Swift.Int?
        /// Configures the maximum number of events processed per tick by the tokio DataFusion runtime.
        public var dataFusionRuntimeMaxIoEventsPerTick: Swift.Int?
        /// Sets a custom timeout for a thread in the blocking pool of the tokio DataFusion runtime.
        public var dataFusionRuntimeThreadKeepAlive: TimestreamInfluxDBClientTypes.Duration?
        /// Sets the thread priority for tokio DataFusion runtime workers. Default: 10
        public var dataFusionRuntimeThreadPriority: Swift.Int?
        /// Specifies the DataFusion tokio runtime type. Default: multi-thread
        public var dataFusionRuntimeType: TimestreamInfluxDBClientTypes.DataFusionRuntimeType?
        /// Uses a cached parquet loader when reading parquet files from the object store.
        public var dataFusionUseCachedParquetLoader: Swift.Bool?
        /// Specifies the grace period before permanently deleting data. Default: 24h
        public var deleteGracePeriod: TimestreamInfluxDBClientTypes.Duration?
        /// Disables the in-memory Parquet cache. By default, the cache is enabled.
        public var disableParquetMemCache: Swift.Bool?
        /// Specifies the interval to evict expired entries from the distinct value cache, expressed as a human-readable durationfor example: 20s, 1m, 1h. Default: 10s
        public var distinctCacheEvictionInterval: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies the size of memory pool used during query execution. Can be given as absolute value in bytes or as a percentage of the total available memoryfor example: 8000000000 or 10%. Default: 20%
        public var execMemPoolBytes: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong?
        /// Specifies the threshold for the internal memory buffer. Supports either a percentage (portion of available memory) or absolute value in MBfor example: 70% or 100 Default: 70%
        public var forceSnapshotMemThreshold: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong?
        /// Specifies the duration that Parquet files are arranged into. Data timestamps land each row into a file of this duration. Supported durations are 1m, 5m, and 10m. These files are known as generation 1 files that the compactor in InfluxDB 3 Enterprise can merge into larger generations. Default: 10m
        public var gen1Duration: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies how far back to look when creating generation 1 Parquet files. Default: 24h
        public var gen1LookbackDuration: TimestreamInfluxDBClientTypes.Duration?
        /// Sets the default duration for hard deletion of data. Default: 90d
        public var hardDeleteDefaultDuration: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies the interval to evict expired entries from the Last-N-Value cache, expressed as a human-readable durationfor example: 20s, 1m, 1h. Default: 10s
        public var lastCacheEvictionInterval: TimestreamInfluxDBClientTypes.Duration?
        /// Sets the filter directive for logs.
        public var logFilter: Swift.String?
        /// Defines the message format for logs. Default: full
        public var logFormat: TimestreamInfluxDBClientTypes.LogFormats?
        /// Specifies the maximum size of HTTP requests. Default: 10485760
        public var maxHttpRequestSize: Swift.Int?
        /// Sets the interval to check if the in-memory Parquet cache needs to be pruned. Default: 1s
        public var parquetMemCachePruneInterval: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies the percentage of entries to prune during a prune operation on the in-memory Parquet cache. Default: 0.1
        public var parquetMemCachePrunePercentage: Swift.Float?
        /// Specifies the time window for caching recent Parquet files in memory. Default: 5h
        public var parquetMemCacheQueryPathDuration: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies the size of the in-memory Parquet cache in megabytes or percentage of total available memory. Default: 20%
        public var parquetMemCacheSize: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong?
        /// Specifies the interval to prefetch into the Parquet cache during compaction. Default: 3d
        public var preemptiveCacheAge: TimestreamInfluxDBClientTypes.Duration?
        /// Limits the number of Parquet files a query can access. If a query attempts to read more than this limit, InfluxDB 3 returns an error. Default: 432
        public var queryFileLimit: Swift.Int?
        /// Defines the size of the query log. Up to this many queries remain in the log before older queries are evicted to make room for new ones. Default: 1000
        public var queryLogSize: Swift.Int?
        /// The interval at which retention policies are checked and enforced. Enter as a human-readable timefor example: 30m or 1h. Default: 30m
        public var retentionCheckInterval: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies the number of snapshotted WAL files to retain in the object store. Flushing the WAL files does not clear the WAL files immediately; they are deleted when the number of snapshotted WAL files exceeds this number. Default: 300
        public var snapshottedWalFilesToKeep: Swift.Int?
        /// Limits the concurrency level for table index cache operations. Default: 8
        public var tableIndexCacheConcurrencyLimit: Swift.Int?
        /// Specifies the maximum number of entries in the table index cache. Default: 1000
        public var tableIndexCacheMaxEntries: Swift.Int?
        /// Specifies the maximum number of write requests that can be buffered before a flush must be executed and succeed. Default: 100000
        public var walMaxWriteBufferSize: Swift.Int?
        /// Concurrency limit during WAL replay. Setting this number too high can lead to OOM. The default is dynamically determined. Default: max(num_cpus, 10)
        public var walReplayConcurrencyLimit: Swift.Int?
        /// Determines whether WAL replay should fail when encountering errors. Default: false
        public var walReplayFailOnError: Swift.Bool?
        /// Defines the number of WAL files to attempt to remove in a snapshot. This, multiplied by the interval, determines how often snapshots are taken. Default: 600
        public var walSnapshotSize: Swift.Int?

        public init(
            dataFusionConfig: Swift.String? = nil,
            dataFusionMaxParquetFanout: Swift.Int? = nil,
            dataFusionNumThreads: Swift.Int? = nil,
            dataFusionRuntimeDisableLifoSlot: Swift.Bool? = nil,
            dataFusionRuntimeEventInterval: Swift.Int? = nil,
            dataFusionRuntimeGlobalQueueInterval: Swift.Int? = nil,
            dataFusionRuntimeMaxBlockingThreads: Swift.Int? = nil,
            dataFusionRuntimeMaxIoEventsPerTick: Swift.Int? = nil,
            dataFusionRuntimeThreadKeepAlive: TimestreamInfluxDBClientTypes.Duration? = nil,
            dataFusionRuntimeThreadPriority: Swift.Int? = nil,
            dataFusionRuntimeType: TimestreamInfluxDBClientTypes.DataFusionRuntimeType? = nil,
            dataFusionUseCachedParquetLoader: Swift.Bool? = nil,
            deleteGracePeriod: TimestreamInfluxDBClientTypes.Duration? = nil,
            disableParquetMemCache: Swift.Bool? = nil,
            distinctCacheEvictionInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            execMemPoolBytes: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong? = nil,
            forceSnapshotMemThreshold: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong? = nil,
            gen1Duration: TimestreamInfluxDBClientTypes.Duration? = nil,
            gen1LookbackDuration: TimestreamInfluxDBClientTypes.Duration? = nil,
            hardDeleteDefaultDuration: TimestreamInfluxDBClientTypes.Duration? = nil,
            lastCacheEvictionInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            logFilter: Swift.String? = nil,
            logFormat: TimestreamInfluxDBClientTypes.LogFormats? = nil,
            maxHttpRequestSize: Swift.Int? = nil,
            parquetMemCachePruneInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            parquetMemCachePrunePercentage: Swift.Float? = nil,
            parquetMemCacheQueryPathDuration: TimestreamInfluxDBClientTypes.Duration? = nil,
            parquetMemCacheSize: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong? = nil,
            preemptiveCacheAge: TimestreamInfluxDBClientTypes.Duration? = nil,
            queryFileLimit: Swift.Int? = nil,
            queryLogSize: Swift.Int? = nil,
            retentionCheckInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            snapshottedWalFilesToKeep: Swift.Int? = nil,
            tableIndexCacheConcurrencyLimit: Swift.Int? = nil,
            tableIndexCacheMaxEntries: Swift.Int? = nil,
            walMaxWriteBufferSize: Swift.Int? = nil,
            walReplayConcurrencyLimit: Swift.Int? = nil,
            walReplayFailOnError: Swift.Bool? = nil,
            walSnapshotSize: Swift.Int? = nil
        ) {
            self.dataFusionConfig = dataFusionConfig
            self.dataFusionMaxParquetFanout = dataFusionMaxParquetFanout
            self.dataFusionNumThreads = dataFusionNumThreads
            self.dataFusionRuntimeDisableLifoSlot = dataFusionRuntimeDisableLifoSlot
            self.dataFusionRuntimeEventInterval = dataFusionRuntimeEventInterval
            self.dataFusionRuntimeGlobalQueueInterval = dataFusionRuntimeGlobalQueueInterval
            self.dataFusionRuntimeMaxBlockingThreads = dataFusionRuntimeMaxBlockingThreads
            self.dataFusionRuntimeMaxIoEventsPerTick = dataFusionRuntimeMaxIoEventsPerTick
            self.dataFusionRuntimeThreadKeepAlive = dataFusionRuntimeThreadKeepAlive
            self.dataFusionRuntimeThreadPriority = dataFusionRuntimeThreadPriority
            self.dataFusionRuntimeType = dataFusionRuntimeType
            self.dataFusionUseCachedParquetLoader = dataFusionUseCachedParquetLoader
            self.deleteGracePeriod = deleteGracePeriod
            self.disableParquetMemCache = disableParquetMemCache
            self.distinctCacheEvictionInterval = distinctCacheEvictionInterval
            self.execMemPoolBytes = execMemPoolBytes
            self.forceSnapshotMemThreshold = forceSnapshotMemThreshold
            self.gen1Duration = gen1Duration
            self.gen1LookbackDuration = gen1LookbackDuration
            self.hardDeleteDefaultDuration = hardDeleteDefaultDuration
            self.lastCacheEvictionInterval = lastCacheEvictionInterval
            self.logFilter = logFilter
            self.logFormat = logFormat
            self.maxHttpRequestSize = maxHttpRequestSize
            self.parquetMemCachePruneInterval = parquetMemCachePruneInterval
            self.parquetMemCachePrunePercentage = parquetMemCachePrunePercentage
            self.parquetMemCacheQueryPathDuration = parquetMemCacheQueryPathDuration
            self.parquetMemCacheSize = parquetMemCacheSize
            self.preemptiveCacheAge = preemptiveCacheAge
            self.queryFileLimit = queryFileLimit
            self.queryLogSize = queryLogSize
            self.retentionCheckInterval = retentionCheckInterval
            self.snapshottedWalFilesToKeep = snapshottedWalFilesToKeep
            self.tableIndexCacheConcurrencyLimit = tableIndexCacheConcurrencyLimit
            self.tableIndexCacheMaxEntries = tableIndexCacheMaxEntries
            self.walMaxWriteBufferSize = walMaxWriteBufferSize
            self.walReplayConcurrencyLimit = walReplayConcurrencyLimit
            self.walReplayFailOnError = walReplayFailOnError
            self.walSnapshotSize = walSnapshotSize
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    /// All the customer-modifiable InfluxDB v3 Enterprise parameters in Timestream for InfluxDB.
    public struct InfluxDBv3EnterpriseParameters: Swift.Sendable {
        /// Defines how often the catalog synchronizes across cluster nodes. Default: 10s
        public var catalogSyncInterval: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies how often the compactor checks for new compaction work to perform. Default: 10s
        public var compactionCheckInterval: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies the amount of time that the compactor waits after finishing a compaction run to delete files marked as needing deletion during that compaction run. Default: 10m
        public var compactionCleanupWait: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies the duration of the first level of compaction (gen2). Later levels of compaction are multiples of this duration. This value should be equal to or greater than the gen1 duration. Default: 20m
        public var compactionGen2Duration: TimestreamInfluxDBClientTypes.Duration?
        /// Sets the maximum number of files included in any compaction plan. Default: 500
        public var compactionMaxNumFilesPerPlan: Swift.Int?
        /// Specifies a comma-separated list of multiples defining the duration of each level of compaction. The number of elements in the list determines the number of compaction levels. The first element specifies the duration of the first level (gen3); subsequent levels are multiples of the previous level. Default: 3,4,6,5
        public var compactionMultipliers: Swift.String?
        /// Specifies the soft limit for the number of rows per file that the compactor writes. The compactor may write more rows than this limit. Default: 1000000
        public var compactionRowLimit: Swift.Int?
        /// Provides custom configuration to DataFusion as a comma-separated list of key:value pairs.
        public var dataFusionConfig: Swift.String?
        /// When multiple parquet files are required in a sorted way (deduplication for example), specifies the maximum fanout. Default: 1000
        public var dataFusionMaxParquetFanout: Swift.Int?
        /// Sets the maximum number of DataFusion runtime threads to use.
        public var dataFusionNumThreads: Swift.Int?
        /// Disables the LIFO slot of the DataFusion runtime.
        public var dataFusionRuntimeDisableLifoSlot: Swift.Bool?
        /// Sets the number of scheduler ticks after which the scheduler of the DataFusion tokio runtime polls for external eventsfor example: timers, I/O.
        public var dataFusionRuntimeEventInterval: Swift.Int?
        /// Sets the number of scheduler ticks after which the scheduler of the DataFusion runtime polls the global task queue.
        public var dataFusionRuntimeGlobalQueueInterval: Swift.Int?
        /// Specifies the limit for additional threads spawned by the DataFusion runtime.
        public var dataFusionRuntimeMaxBlockingThreads: Swift.Int?
        /// Configures the maximum number of events processed per tick by the tokio DataFusion runtime.
        public var dataFusionRuntimeMaxIoEventsPerTick: Swift.Int?
        /// Sets a custom timeout for a thread in the blocking pool of the tokio DataFusion runtime.
        public var dataFusionRuntimeThreadKeepAlive: TimestreamInfluxDBClientTypes.Duration?
        /// Sets the thread priority for tokio DataFusion runtime workers. Default: 10
        public var dataFusionRuntimeThreadPriority: Swift.Int?
        /// Specifies the DataFusion tokio runtime type. Default: multi-thread
        public var dataFusionRuntimeType: TimestreamInfluxDBClientTypes.DataFusionRuntimeType?
        /// Uses a cached parquet loader when reading parquet files from the object store.
        public var dataFusionUseCachedParquetLoader: Swift.Bool?
        /// Specifies if the compactor instance should be a standalone instance or not.
        /// This member is required.
        public var dedicatedCompactor: Swift.Bool?
        /// Specifies the grace period before permanently deleting data. Default: 24h
        public var deleteGracePeriod: TimestreamInfluxDBClientTypes.Duration?
        /// Disables the in-memory Parquet cache. By default, the cache is enabled.
        public var disableParquetMemCache: Swift.Bool?
        /// Specifies the interval to evict expired entries from the distinct value cache, expressed as a human-readable durationfor example: 20s, 1m, 1h. Default: 10s
        public var distinctCacheEvictionInterval: TimestreamInfluxDBClientTypes.Duration?
        /// Disables populating the distinct value cache from historical data. If disabled, the cache is still populated with data from the write-ahead log (WAL).
        public var distinctValueCacheDisableFromHistory: Swift.Bool?
        /// Specifies the size of memory pool used during query execution. Can be given as absolute value in bytes or as a percentage of the total available memoryfor example: 8000000000 or 10%. Default: 20%
        public var execMemPoolBytes: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong?
        /// Specifies the threshold for the internal memory buffer. Supports either a percentage (portion of available memory) or absolute value in MBfor example: 70% or 100 Default: 70%
        public var forceSnapshotMemThreshold: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong?
        /// Specifies the duration that Parquet files are arranged into. Data timestamps land each row into a file of this duration. Supported durations are 1m, 5m, and 10m. These files are known as generation 1 files, which the compactor can merge into larger generations. Default: 10m
        public var gen1Duration: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies how far back to look when creating generation 1 Parquet files. Default: 24h
        public var gen1LookbackDuration: TimestreamInfluxDBClientTypes.Duration?
        /// Sets the default duration for hard deletion of data. Default: 90d
        public var hardDeleteDefaultDuration: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies number of instances in the DbCluster which can both ingest and query.
        /// This member is required.
        public var ingestQueryInstances: Swift.Int?
        /// Specifies the interval to evict expired entries from the Last-N-Value cache, expressed as a human-readable durationfor example: 20s, 1m, 1h. Default: 10s
        public var lastCacheEvictionInterval: TimestreamInfluxDBClientTypes.Duration?
        /// Disables populating the last-N-value cache from historical data. If disabled, the cache is still populated with data from the write-ahead log (WAL).
        public var lastValueCacheDisableFromHistory: Swift.Bool?
        /// Sets the filter directive for logs.
        public var logFilter: Swift.String?
        /// Defines the message format for logs. Default: full
        public var logFormat: TimestreamInfluxDBClientTypes.LogFormats?
        /// Specifies the maximum size of HTTP requests. Default: 10485760
        public var maxHttpRequestSize: Swift.Int?
        /// Sets the interval to check if the in-memory Parquet cache needs to be pruned. Default: 1s
        public var parquetMemCachePruneInterval: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies the percentage of entries to prune during a prune operation on the in-memory Parquet cache. Default: 0.1
        public var parquetMemCachePrunePercentage: Swift.Float?
        /// Specifies the time window for caching recent Parquet files in memory. Default: 5h
        public var parquetMemCacheQueryPathDuration: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies the size of the in-memory Parquet cache in megabytes or percentage of total available memory. Default: 20%
        public var parquetMemCacheSize: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong?
        /// Specifies the interval to prefetch into the Parquet cache during compaction. Default: 3d
        public var preemptiveCacheAge: TimestreamInfluxDBClientTypes.Duration?
        /// Limits the number of Parquet files a query can access. If a query attempts to read more than this limit, InfluxDB 3 returns an error. Default: 432
        public var queryFileLimit: Swift.Int?
        /// Defines the size of the query log. Up to this many queries remain in the log before older queries are evicted to make room for new ones. Default: 1000
        public var queryLogSize: Swift.Int?
        /// Specifies number of instances in the DbCluster which can only query.
        /// This member is required.
        public var queryOnlyInstances: Swift.Int?
        /// Specifies the interval at which data replication occurs between cluster nodes. Default: 250ms
        public var replicationInterval: TimestreamInfluxDBClientTypes.Duration?
        /// The interval at which retention policies are checked and enforced. Enter as a human-readable timefor example: 30m or 1h. Default: 30m
        public var retentionCheckInterval: TimestreamInfluxDBClientTypes.Duration?
        /// Specifies the number of snapshotted WAL files to retain in the object store. Flushing the WAL files does not clear the WAL files immediately; they are deleted when the number of snapshotted WAL files exceeds this number. Default: 300
        public var snapshottedWalFilesToKeep: Swift.Int?
        /// Limits the concurrency level for table index cache operations. Default: 8
        public var tableIndexCacheConcurrencyLimit: Swift.Int?
        /// Specifies the maximum number of entries in the table index cache. Default: 1000
        public var tableIndexCacheMaxEntries: Swift.Int?
        /// Specifies the maximum number of write requests that can be buffered before a flush must be executed and succeed. Default: 100000
        public var walMaxWriteBufferSize: Swift.Int?
        /// Concurrency limit during WAL replay. Setting this number too high can lead to OOM. The default is dynamically determined. Default: max(num_cpus, 10)
        public var walReplayConcurrencyLimit: Swift.Int?
        /// Determines whether WAL replay should fail when encountering errors. Default: false
        public var walReplayFailOnError: Swift.Bool?
        /// Defines the number of WAL files to attempt to remove in a snapshot. This, multiplied by the interval, determines how often snapshots are taken. Default: 600
        public var walSnapshotSize: Swift.Int?

        public init(
            catalogSyncInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            compactionCheckInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            compactionCleanupWait: TimestreamInfluxDBClientTypes.Duration? = nil,
            compactionGen2Duration: TimestreamInfluxDBClientTypes.Duration? = nil,
            compactionMaxNumFilesPerPlan: Swift.Int? = nil,
            compactionMultipliers: Swift.String? = nil,
            compactionRowLimit: Swift.Int? = nil,
            dataFusionConfig: Swift.String? = nil,
            dataFusionMaxParquetFanout: Swift.Int? = nil,
            dataFusionNumThreads: Swift.Int? = nil,
            dataFusionRuntimeDisableLifoSlot: Swift.Bool? = nil,
            dataFusionRuntimeEventInterval: Swift.Int? = nil,
            dataFusionRuntimeGlobalQueueInterval: Swift.Int? = nil,
            dataFusionRuntimeMaxBlockingThreads: Swift.Int? = nil,
            dataFusionRuntimeMaxIoEventsPerTick: Swift.Int? = nil,
            dataFusionRuntimeThreadKeepAlive: TimestreamInfluxDBClientTypes.Duration? = nil,
            dataFusionRuntimeThreadPriority: Swift.Int? = nil,
            dataFusionRuntimeType: TimestreamInfluxDBClientTypes.DataFusionRuntimeType? = nil,
            dataFusionUseCachedParquetLoader: Swift.Bool? = nil,
            dedicatedCompactor: Swift.Bool? = nil,
            deleteGracePeriod: TimestreamInfluxDBClientTypes.Duration? = nil,
            disableParquetMemCache: Swift.Bool? = nil,
            distinctCacheEvictionInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            distinctValueCacheDisableFromHistory: Swift.Bool? = nil,
            execMemPoolBytes: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong? = nil,
            forceSnapshotMemThreshold: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong? = nil,
            gen1Duration: TimestreamInfluxDBClientTypes.Duration? = nil,
            gen1LookbackDuration: TimestreamInfluxDBClientTypes.Duration? = nil,
            hardDeleteDefaultDuration: TimestreamInfluxDBClientTypes.Duration? = nil,
            ingestQueryInstances: Swift.Int? = nil,
            lastCacheEvictionInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            lastValueCacheDisableFromHistory: Swift.Bool? = nil,
            logFilter: Swift.String? = nil,
            logFormat: TimestreamInfluxDBClientTypes.LogFormats? = nil,
            maxHttpRequestSize: Swift.Int? = nil,
            parquetMemCachePruneInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            parquetMemCachePrunePercentage: Swift.Float? = nil,
            parquetMemCacheQueryPathDuration: TimestreamInfluxDBClientTypes.Duration? = nil,
            parquetMemCacheSize: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong? = nil,
            preemptiveCacheAge: TimestreamInfluxDBClientTypes.Duration? = nil,
            queryFileLimit: Swift.Int? = nil,
            queryLogSize: Swift.Int? = nil,
            queryOnlyInstances: Swift.Int? = nil,
            replicationInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            retentionCheckInterval: TimestreamInfluxDBClientTypes.Duration? = nil,
            snapshottedWalFilesToKeep: Swift.Int? = nil,
            tableIndexCacheConcurrencyLimit: Swift.Int? = nil,
            tableIndexCacheMaxEntries: Swift.Int? = nil,
            walMaxWriteBufferSize: Swift.Int? = nil,
            walReplayConcurrencyLimit: Swift.Int? = nil,
            walReplayFailOnError: Swift.Bool? = nil,
            walSnapshotSize: Swift.Int? = nil
        ) {
            self.catalogSyncInterval = catalogSyncInterval
            self.compactionCheckInterval = compactionCheckInterval
            self.compactionCleanupWait = compactionCleanupWait
            self.compactionGen2Duration = compactionGen2Duration
            self.compactionMaxNumFilesPerPlan = compactionMaxNumFilesPerPlan
            self.compactionMultipliers = compactionMultipliers
            self.compactionRowLimit = compactionRowLimit
            self.dataFusionConfig = dataFusionConfig
            self.dataFusionMaxParquetFanout = dataFusionMaxParquetFanout
            self.dataFusionNumThreads = dataFusionNumThreads
            self.dataFusionRuntimeDisableLifoSlot = dataFusionRuntimeDisableLifoSlot
            self.dataFusionRuntimeEventInterval = dataFusionRuntimeEventInterval
            self.dataFusionRuntimeGlobalQueueInterval = dataFusionRuntimeGlobalQueueInterval
            self.dataFusionRuntimeMaxBlockingThreads = dataFusionRuntimeMaxBlockingThreads
            self.dataFusionRuntimeMaxIoEventsPerTick = dataFusionRuntimeMaxIoEventsPerTick
            self.dataFusionRuntimeThreadKeepAlive = dataFusionRuntimeThreadKeepAlive
            self.dataFusionRuntimeThreadPriority = dataFusionRuntimeThreadPriority
            self.dataFusionRuntimeType = dataFusionRuntimeType
            self.dataFusionUseCachedParquetLoader = dataFusionUseCachedParquetLoader
            self.dedicatedCompactor = dedicatedCompactor
            self.deleteGracePeriod = deleteGracePeriod
            self.disableParquetMemCache = disableParquetMemCache
            self.distinctCacheEvictionInterval = distinctCacheEvictionInterval
            self.distinctValueCacheDisableFromHistory = distinctValueCacheDisableFromHistory
            self.execMemPoolBytes = execMemPoolBytes
            self.forceSnapshotMemThreshold = forceSnapshotMemThreshold
            self.gen1Duration = gen1Duration
            self.gen1LookbackDuration = gen1LookbackDuration
            self.hardDeleteDefaultDuration = hardDeleteDefaultDuration
            self.ingestQueryInstances = ingestQueryInstances
            self.lastCacheEvictionInterval = lastCacheEvictionInterval
            self.lastValueCacheDisableFromHistory = lastValueCacheDisableFromHistory
            self.logFilter = logFilter
            self.logFormat = logFormat
            self.maxHttpRequestSize = maxHttpRequestSize
            self.parquetMemCachePruneInterval = parquetMemCachePruneInterval
            self.parquetMemCachePrunePercentage = parquetMemCachePrunePercentage
            self.parquetMemCacheQueryPathDuration = parquetMemCacheQueryPathDuration
            self.parquetMemCacheSize = parquetMemCacheSize
            self.preemptiveCacheAge = preemptiveCacheAge
            self.queryFileLimit = queryFileLimit
            self.queryLogSize = queryLogSize
            self.queryOnlyInstances = queryOnlyInstances
            self.replicationInterval = replicationInterval
            self.retentionCheckInterval = retentionCheckInterval
            self.snapshottedWalFilesToKeep = snapshottedWalFilesToKeep
            self.tableIndexCacheConcurrencyLimit = tableIndexCacheConcurrencyLimit
            self.tableIndexCacheMaxEntries = tableIndexCacheMaxEntries
            self.walMaxWriteBufferSize = walMaxWriteBufferSize
            self.walReplayConcurrencyLimit = walReplayConcurrencyLimit
            self.walReplayFailOnError = walReplayFailOnError
            self.walSnapshotSize = walSnapshotSize
        }
    }
}

extension TimestreamInfluxDBClientTypes {

    /// The parameters that comprise the parameter group.
    public enum Parameters: Swift.Sendable {
        /// All the customer-modifiable InfluxDB v2 parameters in Timestream for InfluxDB.
        case influxdbv2(TimestreamInfluxDBClientTypes.InfluxDBv2Parameters)
        /// All the customer-modifiable InfluxDB v3 Core parameters in Timestream for InfluxDB.
        case influxdbv3core(TimestreamInfluxDBClientTypes.InfluxDBv3CoreParameters)
        /// All the customer-modifiable InfluxDB v3 Enterprise parameters in Timestream for InfluxDB.
        case influxdbv3enterprise(TimestreamInfluxDBClientTypes.InfluxDBv3EnterpriseParameters)
        case sdkUnknown(Swift.String)
    }
}

public struct CreateDbParameterGroupInput: Swift.Sendable {
    /// A description of the DB parameter group.
    public var description: Swift.String?
    /// The name of the DB parameter group. The name must be unique per customer and per region.
    /// This member is required.
    public var name: Swift.String?
    /// A list of the parameters that comprise the DB parameter group.
    public var parameters: TimestreamInfluxDBClientTypes.Parameters?
    /// A list of key-value pairs to associate with the DB parameter group.
    public var tags: [Swift.String: Swift.String]?

    public init(
        description: Swift.String? = nil,
        name: Swift.String? = nil,
        parameters: TimestreamInfluxDBClientTypes.Parameters? = nil,
        tags: [Swift.String: Swift.String]? = nil
    ) {
        self.description = description
        self.name = name
        self.parameters = parameters
        self.tags = tags
    }
}

public struct CreateDbParameterGroupOutput: Swift.Sendable {
    /// The Amazon Resource Name (ARM) of the DB parameter group.
    /// This member is required.
    public var arn: Swift.String?
    /// The description of the DB parameter group.
    public var description: Swift.String?
    /// A service-generated unique identifier.
    /// This member is required.
    public var id: Swift.String?
    /// The customer-supplied name that uniquely identifies the DB parameter group when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
    /// This member is required.
    public var name: Swift.String?
    /// A list of the parameters that comprise the DB parameter group.
    public var parameters: TimestreamInfluxDBClientTypes.Parameters?

    public init(
        arn: Swift.String? = nil,
        description: Swift.String? = nil,
        id: Swift.String? = nil,
        name: Swift.String? = nil,
        parameters: TimestreamInfluxDBClientTypes.Parameters? = nil
    ) {
        self.arn = arn
        self.description = description
        self.id = id
        self.name = name
        self.parameters = parameters
    }
}

public struct GetDbParameterGroupInput: Swift.Sendable {
    /// The id of the DB parameter group.
    /// This member is required.
    public var identifier: Swift.String?

    public init(
        identifier: Swift.String? = nil
    ) {
        self.identifier = identifier
    }
}

public struct GetDbParameterGroupOutput: Swift.Sendable {
    /// The Amazon Resource Name (ARN) of the DB parameter group.
    /// This member is required.
    public var arn: Swift.String?
    /// A description of the DB parameter group.
    public var description: Swift.String?
    /// A service-generated unique identifier.
    /// This member is required.
    public var id: Swift.String?
    /// The customer-supplied name that uniquely identifies the DB parameter group when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
    /// This member is required.
    public var name: Swift.String?
    /// The parameters that comprise the DB parameter group.
    public var parameters: TimestreamInfluxDBClientTypes.Parameters?

    public init(
        arn: Swift.String? = nil,
        description: Swift.String? = nil,
        id: Swift.String? = nil,
        name: Swift.String? = nil,
        parameters: TimestreamInfluxDBClientTypes.Parameters? = nil
    ) {
        self.arn = arn
        self.description = description
        self.id = id
        self.name = name
        self.parameters = parameters
    }
}

public struct ListDbParameterGroupsInput: Swift.Sendable {
    /// The maximum number of items to return in the output. If the total number of items available is more than the value specified, a NextToken is provided in the output. To resume pagination, provide the NextToken value as argument of a subsequent API invocation.
    public var maxResults: Swift.Int?
    /// The pagination token. To resume pagination, provide the NextToken value as argument of a subsequent API invocation.
    public var nextToken: Swift.String?

    public init(
        maxResults: Swift.Int? = nil,
        nextToken: Swift.String? = nil
    ) {
        self.maxResults = maxResults
        self.nextToken = nextToken
    }
}

extension TimestreamInfluxDBClientTypes {

    /// Contains a summary of a DB parameter group.
    public struct DbParameterGroupSummary: Swift.Sendable {
        /// The Amazon Resource Name (ARN) of the DB parameter group.
        /// This member is required.
        public var arn: Swift.String?
        /// A description of the DB parameter group.
        public var description: Swift.String?
        /// A service-generated unique identifier.
        /// This member is required.
        public var id: Swift.String?
        /// This customer-supplied name uniquely identifies the parameter group.
        /// This member is required.
        public var name: Swift.String?

        public init(
            arn: Swift.String? = nil,
            description: Swift.String? = nil,
            id: Swift.String? = nil,
            name: Swift.String? = nil
        ) {
            self.arn = arn
            self.description = description
            self.id = id
            self.name = name
        }
    }
}

public struct ListDbParameterGroupsOutput: Swift.Sendable {
    /// A list of Timestream for InfluxDB DB parameter group summaries.
    /// This member is required.
    public var items: [TimestreamInfluxDBClientTypes.DbParameterGroupSummary]?
    /// Token from a previous call of the operation. When this value is provided, the service returns results from where the previous response left off.
    public var nextToken: Swift.String?

    public init(
        items: [TimestreamInfluxDBClientTypes.DbParameterGroupSummary]? = nil,
        nextToken: Swift.String? = nil
    ) {
        self.items = items
        self.nextToken = nextToken
    }
}

public struct ListTagsForResourceInput: Swift.Sendable {
    /// The Amazon Resource Name (ARN) of the tagged resource.
    /// This member is required.
    public var resourceArn: Swift.String?

    public init(
        resourceArn: Swift.String? = nil
    ) {
        self.resourceArn = resourceArn
    }
}

public struct ListTagsForResourceOutput: Swift.Sendable {
    /// A list of tags used to categorize and track resources.
    public var tags: [Swift.String: Swift.String]?

    public init(
        tags: [Swift.String: Swift.String]? = nil
    ) {
        self.tags = tags
    }
}

public struct TagResourceInput: Swift.Sendable {
    /// The Amazon Resource Name (ARN) of the tagged resource.
    /// This member is required.
    public var resourceArn: Swift.String?
    /// A list of tags used to categorize and track resources.
    /// This member is required.
    public var tags: [Swift.String: Swift.String]?

    public init(
        resourceArn: Swift.String? = nil,
        tags: [Swift.String: Swift.String]? = nil
    ) {
        self.resourceArn = resourceArn
        self.tags = tags
    }
}

public struct UntagResourceInput: Swift.Sendable {
    /// The Amazon Resource Name (ARN) of the tagged resource.
    /// This member is required.
    public var resourceArn: Swift.String?
    /// The keys used to identify the tags.
    /// This member is required.
    public var tagKeys: [Swift.String]?

    public init(
        resourceArn: Swift.String? = nil,
        tagKeys: [Swift.String]? = nil
    ) {
        self.resourceArn = resourceArn
        self.tagKeys = tagKeys
    }
}

extension CreateDbClusterInput {

    static func urlPathProvider(_ value: CreateDbClusterInput) -> Swift.String? {
        return "/"
    }
}

extension CreateDbInstanceInput {

    static func urlPathProvider(_ value: CreateDbInstanceInput) -> Swift.String? {
        return "/"
    }
}

extension CreateDbParameterGroupInput {

    static func urlPathProvider(_ value: CreateDbParameterGroupInput) -> Swift.String? {
        return "/"
    }
}

extension DeleteDbClusterInput {

    static func urlPathProvider(_ value: DeleteDbClusterInput) -> Swift.String? {
        return "/"
    }
}

extension DeleteDbInstanceInput {

    static func urlPathProvider(_ value: DeleteDbInstanceInput) -> Swift.String? {
        return "/"
    }
}

extension GetDbClusterInput {

    static func urlPathProvider(_ value: GetDbClusterInput) -> Swift.String? {
        return "/"
    }
}

extension GetDbInstanceInput {

    static func urlPathProvider(_ value: GetDbInstanceInput) -> Swift.String? {
        return "/"
    }
}

extension GetDbParameterGroupInput {

    static func urlPathProvider(_ value: GetDbParameterGroupInput) -> Swift.String? {
        return "/"
    }
}

extension ListDbClustersInput {

    static func urlPathProvider(_ value: ListDbClustersInput) -> Swift.String? {
        return "/"
    }
}

extension ListDbInstancesInput {

    static func urlPathProvider(_ value: ListDbInstancesInput) -> Swift.String? {
        return "/"
    }
}

extension ListDbInstancesForClusterInput {

    static func urlPathProvider(_ value: ListDbInstancesForClusterInput) -> Swift.String? {
        return "/"
    }
}

extension ListDbParameterGroupsInput {

    static func urlPathProvider(_ value: ListDbParameterGroupsInput) -> Swift.String? {
        return "/"
    }
}

extension ListTagsForResourceInput {

    static func urlPathProvider(_ value: ListTagsForResourceInput) -> Swift.String? {
        return "/"
    }
}

extension RebootDbClusterInput {

    static func urlPathProvider(_ value: RebootDbClusterInput) -> Swift.String? {
        return "/"
    }
}

extension RebootDbInstanceInput {

    static func urlPathProvider(_ value: RebootDbInstanceInput) -> Swift.String? {
        return "/"
    }
}

extension TagResourceInput {

    static func urlPathProvider(_ value: TagResourceInput) -> Swift.String? {
        return "/"
    }
}

extension UntagResourceInput {

    static func urlPathProvider(_ value: UntagResourceInput) -> Swift.String? {
        return "/"
    }
}

extension UpdateDbClusterInput {

    static func urlPathProvider(_ value: UpdateDbClusterInput) -> Swift.String? {
        return "/"
    }
}

extension UpdateDbInstanceInput {

    static func urlPathProvider(_ value: UpdateDbInstanceInput) -> Swift.String? {
        return "/"
    }
}

extension CreateDbClusterInput {

    static func write(value: CreateDbClusterInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["allocatedStorage"].write(value.allocatedStorage)
        try writer["bucket"].write(value.bucket)
        try writer["dbInstanceType"].write(value.dbInstanceType)
        try writer["dbParameterGroupIdentifier"].write(value.dbParameterGroupIdentifier)
        try writer["dbStorageType"].write(value.dbStorageType)
        try writer["deploymentType"].write(value.deploymentType)
        try writer["failoverMode"].write(value.failoverMode)
        try writer["logDeliveryConfiguration"].write(value.logDeliveryConfiguration, with: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration.write(value:to:))
        try writer["name"].write(value.name)
        try writer["networkType"].write(value.networkType)
        try writer["organization"].write(value.organization)
        try writer["password"].write(value.password)
        try writer["port"].write(value.port)
        try writer["publiclyAccessible"].write(value.publiclyAccessible)
        try writer["tags"].writeMap(value.tags, valueWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        try writer["username"].write(value.username)
        try writer["vpcSecurityGroupIds"].writeList(value.vpcSecurityGroupIds, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["vpcSubnetIds"].writeList(value.vpcSubnetIds, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
    }
}

extension CreateDbInstanceInput {

    static func write(value: CreateDbInstanceInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["allocatedStorage"].write(value.allocatedStorage)
        try writer["bucket"].write(value.bucket)
        try writer["dbInstanceType"].write(value.dbInstanceType)
        try writer["dbParameterGroupIdentifier"].write(value.dbParameterGroupIdentifier)
        try writer["dbStorageType"].write(value.dbStorageType)
        try writer["deploymentType"].write(value.deploymentType)
        try writer["logDeliveryConfiguration"].write(value.logDeliveryConfiguration, with: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration.write(value:to:))
        try writer["name"].write(value.name)
        try writer["networkType"].write(value.networkType)
        try writer["organization"].write(value.organization)
        try writer["password"].write(value.password)
        try writer["port"].write(value.port)
        try writer["publiclyAccessible"].write(value.publiclyAccessible)
        try writer["tags"].writeMap(value.tags, valueWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        try writer["username"].write(value.username)
        try writer["vpcSecurityGroupIds"].writeList(value.vpcSecurityGroupIds, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
        try writer["vpcSubnetIds"].writeList(value.vpcSubnetIds, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
    }
}

extension CreateDbParameterGroupInput {

    static func write(value: CreateDbParameterGroupInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["description"].write(value.description)
        try writer["name"].write(value.name)
        try writer["parameters"].write(value.parameters, with: TimestreamInfluxDBClientTypes.Parameters.write(value:to:))
        try writer["tags"].writeMap(value.tags, valueWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
    }
}

extension DeleteDbClusterInput {

    static func write(value: DeleteDbClusterInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["dbClusterId"].write(value.dbClusterId)
    }
}

extension DeleteDbInstanceInput {

    static func write(value: DeleteDbInstanceInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["identifier"].write(value.identifier)
    }
}

extension GetDbClusterInput {

    static func write(value: GetDbClusterInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["dbClusterId"].write(value.dbClusterId)
    }
}

extension GetDbInstanceInput {

    static func write(value: GetDbInstanceInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["identifier"].write(value.identifier)
    }
}

extension GetDbParameterGroupInput {

    static func write(value: GetDbParameterGroupInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["identifier"].write(value.identifier)
    }
}

extension ListDbClustersInput {

    static func write(value: ListDbClustersInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["maxResults"].write(value.maxResults)
        try writer["nextToken"].write(value.nextToken)
    }
}

extension ListDbInstancesInput {

    static func write(value: ListDbInstancesInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["maxResults"].write(value.maxResults)
        try writer["nextToken"].write(value.nextToken)
    }
}

extension ListDbInstancesForClusterInput {

    static func write(value: ListDbInstancesForClusterInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["dbClusterId"].write(value.dbClusterId)
        try writer["maxResults"].write(value.maxResults)
        try writer["nextToken"].write(value.nextToken)
    }
}

extension ListDbParameterGroupsInput {

    static func write(value: ListDbParameterGroupsInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["maxResults"].write(value.maxResults)
        try writer["nextToken"].write(value.nextToken)
    }
}

extension ListTagsForResourceInput {

    static func write(value: ListTagsForResourceInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["resourceArn"].write(value.resourceArn)
    }
}

extension RebootDbClusterInput {

    static func write(value: RebootDbClusterInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["dbClusterId"].write(value.dbClusterId)
        try writer["instanceIds"].writeList(value.instanceIds, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
    }
}

extension RebootDbInstanceInput {

    static func write(value: RebootDbInstanceInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["identifier"].write(value.identifier)
    }
}

extension TagResourceInput {

    static func write(value: TagResourceInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["resourceArn"].write(value.resourceArn)
        try writer["tags"].writeMap(value.tags, valueWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
    }
}

extension UntagResourceInput {

    static func write(value: UntagResourceInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["resourceArn"].write(value.resourceArn)
        try writer["tagKeys"].writeList(value.tagKeys, memberWritingClosure: SmithyReadWrite.WritingClosures.writeString(value:to:), memberNodeInfo: "member", isFlattened: false)
    }
}

extension UpdateDbClusterInput {

    static func write(value: UpdateDbClusterInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["dbClusterId"].write(value.dbClusterId)
        try writer["dbInstanceType"].write(value.dbInstanceType)
        try writer["dbParameterGroupIdentifier"].write(value.dbParameterGroupIdentifier)
        try writer["failoverMode"].write(value.failoverMode)
        try writer["logDeliveryConfiguration"].write(value.logDeliveryConfiguration, with: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration.write(value:to:))
        try writer["port"].write(value.port)
    }
}

extension UpdateDbInstanceInput {

    static func write(value: UpdateDbInstanceInput?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["allocatedStorage"].write(value.allocatedStorage)
        try writer["dbInstanceType"].write(value.dbInstanceType)
        try writer["dbParameterGroupIdentifier"].write(value.dbParameterGroupIdentifier)
        try writer["dbStorageType"].write(value.dbStorageType)
        try writer["deploymentType"].write(value.deploymentType)
        try writer["identifier"].write(value.identifier)
        try writer["logDeliveryConfiguration"].write(value.logDeliveryConfiguration, with: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration.write(value:to:))
        try writer["port"].write(value.port)
    }
}

extension CreateDbClusterOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> CreateDbClusterOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = CreateDbClusterOutput()
        value.dbClusterId = try reader["dbClusterId"].readIfPresent()
        value.dbClusterStatus = try reader["dbClusterStatus"].readIfPresent()
        return value
    }
}

extension CreateDbInstanceOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> CreateDbInstanceOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = CreateDbInstanceOutput()
        value.allocatedStorage = try reader["allocatedStorage"].readIfPresent()
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.availabilityZone = try reader["availabilityZone"].readIfPresent()
        value.dbClusterId = try reader["dbClusterId"].readIfPresent()
        value.dbInstanceType = try reader["dbInstanceType"].readIfPresent()
        value.dbParameterGroupIdentifier = try reader["dbParameterGroupIdentifier"].readIfPresent()
        value.dbStorageType = try reader["dbStorageType"].readIfPresent()
        value.deploymentType = try reader["deploymentType"].readIfPresent()
        value.endpoint = try reader["endpoint"].readIfPresent()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.influxAuthParametersSecretArn = try reader["influxAuthParametersSecretArn"].readIfPresent()
        value.instanceMode = try reader["instanceMode"].readIfPresent()
        value.instanceModes = try reader["instanceModes"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosureBox<TimestreamInfluxDBClientTypes.InstanceMode>().read(from:), memberNodeInfo: "member", isFlattened: false)
        value.logDeliveryConfiguration = try reader["logDeliveryConfiguration"].readIfPresent(with: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration.read(from:))
        value.name = try reader["name"].readIfPresent() ?? ""
        value.networkType = try reader["networkType"].readIfPresent()
        value.port = try reader["port"].readIfPresent()
        value.publiclyAccessible = try reader["publiclyAccessible"].readIfPresent()
        value.secondaryAvailabilityZone = try reader["secondaryAvailabilityZone"].readIfPresent()
        value.status = try reader["status"].readIfPresent()
        value.vpcSecurityGroupIds = try reader["vpcSecurityGroupIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.vpcSubnetIds = try reader["vpcSubnetIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        return value
    }
}

extension CreateDbParameterGroupOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> CreateDbParameterGroupOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = CreateDbParameterGroupOutput()
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.description = try reader["description"].readIfPresent()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.name = try reader["name"].readIfPresent() ?? ""
        value.parameters = try reader["parameters"].readIfPresent(with: TimestreamInfluxDBClientTypes.Parameters.read(from:))
        return value
    }
}

extension DeleteDbClusterOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> DeleteDbClusterOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = DeleteDbClusterOutput()
        value.dbClusterStatus = try reader["dbClusterStatus"].readIfPresent()
        return value
    }
}

extension DeleteDbInstanceOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> DeleteDbInstanceOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = DeleteDbInstanceOutput()
        value.allocatedStorage = try reader["allocatedStorage"].readIfPresent()
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.availabilityZone = try reader["availabilityZone"].readIfPresent()
        value.dbClusterId = try reader["dbClusterId"].readIfPresent()
        value.dbInstanceType = try reader["dbInstanceType"].readIfPresent()
        value.dbParameterGroupIdentifier = try reader["dbParameterGroupIdentifier"].readIfPresent()
        value.dbStorageType = try reader["dbStorageType"].readIfPresent()
        value.deploymentType = try reader["deploymentType"].readIfPresent()
        value.endpoint = try reader["endpoint"].readIfPresent()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.influxAuthParametersSecretArn = try reader["influxAuthParametersSecretArn"].readIfPresent()
        value.instanceMode = try reader["instanceMode"].readIfPresent()
        value.instanceModes = try reader["instanceModes"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosureBox<TimestreamInfluxDBClientTypes.InstanceMode>().read(from:), memberNodeInfo: "member", isFlattened: false)
        value.logDeliveryConfiguration = try reader["logDeliveryConfiguration"].readIfPresent(with: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration.read(from:))
        value.name = try reader["name"].readIfPresent() ?? ""
        value.networkType = try reader["networkType"].readIfPresent()
        value.port = try reader["port"].readIfPresent()
        value.publiclyAccessible = try reader["publiclyAccessible"].readIfPresent()
        value.secondaryAvailabilityZone = try reader["secondaryAvailabilityZone"].readIfPresent()
        value.status = try reader["status"].readIfPresent()
        value.vpcSecurityGroupIds = try reader["vpcSecurityGroupIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.vpcSubnetIds = try reader["vpcSubnetIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        return value
    }
}

extension GetDbClusterOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> GetDbClusterOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = GetDbClusterOutput()
        value.allocatedStorage = try reader["allocatedStorage"].readIfPresent()
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.dbInstanceType = try reader["dbInstanceType"].readIfPresent()
        value.dbParameterGroupIdentifier = try reader["dbParameterGroupIdentifier"].readIfPresent()
        value.dbStorageType = try reader["dbStorageType"].readIfPresent()
        value.deploymentType = try reader["deploymentType"].readIfPresent()
        value.endpoint = try reader["endpoint"].readIfPresent()
        value.engineType = try reader["engineType"].readIfPresent()
        value.failoverMode = try reader["failoverMode"].readIfPresent()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.influxAuthParametersSecretArn = try reader["influxAuthParametersSecretArn"].readIfPresent()
        value.logDeliveryConfiguration = try reader["logDeliveryConfiguration"].readIfPresent(with: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration.read(from:))
        value.name = try reader["name"].readIfPresent() ?? ""
        value.networkType = try reader["networkType"].readIfPresent()
        value.port = try reader["port"].readIfPresent()
        value.publiclyAccessible = try reader["publiclyAccessible"].readIfPresent()
        value.readerEndpoint = try reader["readerEndpoint"].readIfPresent()
        value.status = try reader["status"].readIfPresent()
        value.vpcSecurityGroupIds = try reader["vpcSecurityGroupIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.vpcSubnetIds = try reader["vpcSubnetIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        return value
    }
}

extension GetDbInstanceOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> GetDbInstanceOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = GetDbInstanceOutput()
        value.allocatedStorage = try reader["allocatedStorage"].readIfPresent()
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.availabilityZone = try reader["availabilityZone"].readIfPresent()
        value.dbClusterId = try reader["dbClusterId"].readIfPresent()
        value.dbInstanceType = try reader["dbInstanceType"].readIfPresent()
        value.dbParameterGroupIdentifier = try reader["dbParameterGroupIdentifier"].readIfPresent()
        value.dbStorageType = try reader["dbStorageType"].readIfPresent()
        value.deploymentType = try reader["deploymentType"].readIfPresent()
        value.endpoint = try reader["endpoint"].readIfPresent()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.influxAuthParametersSecretArn = try reader["influxAuthParametersSecretArn"].readIfPresent()
        value.instanceMode = try reader["instanceMode"].readIfPresent()
        value.instanceModes = try reader["instanceModes"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosureBox<TimestreamInfluxDBClientTypes.InstanceMode>().read(from:), memberNodeInfo: "member", isFlattened: false)
        value.logDeliveryConfiguration = try reader["logDeliveryConfiguration"].readIfPresent(with: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration.read(from:))
        value.name = try reader["name"].readIfPresent() ?? ""
        value.networkType = try reader["networkType"].readIfPresent()
        value.port = try reader["port"].readIfPresent()
        value.publiclyAccessible = try reader["publiclyAccessible"].readIfPresent()
        value.secondaryAvailabilityZone = try reader["secondaryAvailabilityZone"].readIfPresent()
        value.status = try reader["status"].readIfPresent()
        value.vpcSecurityGroupIds = try reader["vpcSecurityGroupIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.vpcSubnetIds = try reader["vpcSubnetIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        return value
    }
}

extension GetDbParameterGroupOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> GetDbParameterGroupOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = GetDbParameterGroupOutput()
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.description = try reader["description"].readIfPresent()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.name = try reader["name"].readIfPresent() ?? ""
        value.parameters = try reader["parameters"].readIfPresent(with: TimestreamInfluxDBClientTypes.Parameters.read(from:))
        return value
    }
}

extension ListDbClustersOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> ListDbClustersOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = ListDbClustersOutput()
        value.items = try reader["items"].readListIfPresent(memberReadingClosure: TimestreamInfluxDBClientTypes.DbClusterSummary.read(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        value.nextToken = try reader["nextToken"].readIfPresent()
        return value
    }
}

extension ListDbInstancesOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> ListDbInstancesOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = ListDbInstancesOutput()
        value.items = try reader["items"].readListIfPresent(memberReadingClosure: TimestreamInfluxDBClientTypes.DbInstanceSummary.read(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        value.nextToken = try reader["nextToken"].readIfPresent()
        return value
    }
}

extension ListDbInstancesForClusterOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> ListDbInstancesForClusterOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = ListDbInstancesForClusterOutput()
        value.items = try reader["items"].readListIfPresent(memberReadingClosure: TimestreamInfluxDBClientTypes.DbInstanceForClusterSummary.read(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        value.nextToken = try reader["nextToken"].readIfPresent()
        return value
    }
}

extension ListDbParameterGroupsOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> ListDbParameterGroupsOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = ListDbParameterGroupsOutput()
        value.items = try reader["items"].readListIfPresent(memberReadingClosure: TimestreamInfluxDBClientTypes.DbParameterGroupSummary.read(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        value.nextToken = try reader["nextToken"].readIfPresent()
        return value
    }
}

extension ListTagsForResourceOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> ListTagsForResourceOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = ListTagsForResourceOutput()
        value.tags = try reader["tags"].readMapIfPresent(valueReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), keyNodeInfo: "key", valueNodeInfo: "value", isFlattened: false)
        return value
    }
}

extension RebootDbClusterOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> RebootDbClusterOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = RebootDbClusterOutput()
        value.dbClusterStatus = try reader["dbClusterStatus"].readIfPresent()
        return value
    }
}

extension RebootDbInstanceOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> RebootDbInstanceOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = RebootDbInstanceOutput()
        value.allocatedStorage = try reader["allocatedStorage"].readIfPresent()
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.availabilityZone = try reader["availabilityZone"].readIfPresent()
        value.dbClusterId = try reader["dbClusterId"].readIfPresent()
        value.dbInstanceType = try reader["dbInstanceType"].readIfPresent()
        value.dbParameterGroupIdentifier = try reader["dbParameterGroupIdentifier"].readIfPresent()
        value.dbStorageType = try reader["dbStorageType"].readIfPresent()
        value.deploymentType = try reader["deploymentType"].readIfPresent()
        value.endpoint = try reader["endpoint"].readIfPresent()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.influxAuthParametersSecretArn = try reader["influxAuthParametersSecretArn"].readIfPresent()
        value.instanceMode = try reader["instanceMode"].readIfPresent()
        value.instanceModes = try reader["instanceModes"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosureBox<TimestreamInfluxDBClientTypes.InstanceMode>().read(from:), memberNodeInfo: "member", isFlattened: false)
        value.logDeliveryConfiguration = try reader["logDeliveryConfiguration"].readIfPresent(with: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration.read(from:))
        value.name = try reader["name"].readIfPresent() ?? ""
        value.networkType = try reader["networkType"].readIfPresent()
        value.port = try reader["port"].readIfPresent()
        value.publiclyAccessible = try reader["publiclyAccessible"].readIfPresent()
        value.secondaryAvailabilityZone = try reader["secondaryAvailabilityZone"].readIfPresent()
        value.status = try reader["status"].readIfPresent()
        value.vpcSecurityGroupIds = try reader["vpcSecurityGroupIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.vpcSubnetIds = try reader["vpcSubnetIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        return value
    }
}

extension TagResourceOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> TagResourceOutput {
        return TagResourceOutput()
    }
}

extension UntagResourceOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> UntagResourceOutput {
        return UntagResourceOutput()
    }
}

extension UpdateDbClusterOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> UpdateDbClusterOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = UpdateDbClusterOutput()
        value.dbClusterStatus = try reader["dbClusterStatus"].readIfPresent()
        return value
    }
}

extension UpdateDbInstanceOutput {

    static func httpOutput(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> UpdateDbInstanceOutput {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let reader = responseReader
        var value = UpdateDbInstanceOutput()
        value.allocatedStorage = try reader["allocatedStorage"].readIfPresent()
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.availabilityZone = try reader["availabilityZone"].readIfPresent()
        value.dbClusterId = try reader["dbClusterId"].readIfPresent()
        value.dbInstanceType = try reader["dbInstanceType"].readIfPresent()
        value.dbParameterGroupIdentifier = try reader["dbParameterGroupIdentifier"].readIfPresent()
        value.dbStorageType = try reader["dbStorageType"].readIfPresent()
        value.deploymentType = try reader["deploymentType"].readIfPresent()
        value.endpoint = try reader["endpoint"].readIfPresent()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.influxAuthParametersSecretArn = try reader["influxAuthParametersSecretArn"].readIfPresent()
        value.instanceMode = try reader["instanceMode"].readIfPresent()
        value.instanceModes = try reader["instanceModes"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosureBox<TimestreamInfluxDBClientTypes.InstanceMode>().read(from:), memberNodeInfo: "member", isFlattened: false)
        value.logDeliveryConfiguration = try reader["logDeliveryConfiguration"].readIfPresent(with: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration.read(from:))
        value.name = try reader["name"].readIfPresent() ?? ""
        value.networkType = try reader["networkType"].readIfPresent()
        value.port = try reader["port"].readIfPresent()
        value.publiclyAccessible = try reader["publiclyAccessible"].readIfPresent()
        value.secondaryAvailabilityZone = try reader["secondaryAvailabilityZone"].readIfPresent()
        value.status = try reader["status"].readIfPresent()
        value.vpcSecurityGroupIds = try reader["vpcSecurityGroupIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false)
        value.vpcSubnetIds = try reader["vpcSubnetIds"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosures.readString(from:), memberNodeInfo: "member", isFlattened: false) ?? []
        return value
    }
}

enum CreateDbClusterOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ServiceQuotaExceededException": return try ServiceQuotaExceededException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum CreateDbInstanceOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ServiceQuotaExceededException": return try ServiceQuotaExceededException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum CreateDbParameterGroupOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ServiceQuotaExceededException": return try ServiceQuotaExceededException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum DeleteDbClusterOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum DeleteDbInstanceOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum GetDbClusterOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum GetDbInstanceOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum GetDbParameterGroupOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum ListDbClustersOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum ListDbInstancesOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum ListDbInstancesForClusterOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum ListDbParameterGroupsOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum ListTagsForResourceOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum RebootDbClusterOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum RebootDbInstanceOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum TagResourceOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ServiceQuotaExceededException": return try ServiceQuotaExceededException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum UntagResourceOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum UpdateDbClusterOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

enum UpdateDbInstanceOutputError {

    static func httpError(from httpResponse: SmithyHTTPAPI.HTTPResponse) async throws -> Swift.Error {
        let data = try await httpResponse.data()
        let responseReader = try SmithyJSON.Reader.from(data: data)
        let baseError = try AWSClientRuntime.AWSJSONError(httpResponse: httpResponse, responseReader: responseReader, noErrorWrapping: false)
        if let error = baseError.customError() { return error }
        switch baseError.code {
            case "AccessDeniedException": return try AccessDeniedException.makeError(baseError: baseError)
            case "ConflictException": return try ConflictException.makeError(baseError: baseError)
            case "InternalServerException": return try InternalServerException.makeError(baseError: baseError)
            case "ResourceNotFoundException": return try ResourceNotFoundException.makeError(baseError: baseError)
            case "ThrottlingException": return try ThrottlingException.makeError(baseError: baseError)
            case "ValidationException": return try ValidationException.makeError(baseError: baseError)
            default: return try AWSClientRuntime.UnknownAWSHTTPServiceError.makeError(baseError: baseError)
        }
    }
}

extension AccessDeniedException {

    static func makeError(baseError: AWSClientRuntime.AWSJSONError) throws -> AccessDeniedException {
        let reader = baseError.errorBodyReader
        var value = AccessDeniedException()
        value.properties.message = try reader["message"].readIfPresent() ?? ""
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension ConflictException {

    static func makeError(baseError: AWSClientRuntime.AWSJSONError) throws -> ConflictException {
        let reader = baseError.errorBodyReader
        var value = ConflictException()
        value.properties.message = try reader["message"].readIfPresent() ?? ""
        value.properties.resourceId = try reader["resourceId"].readIfPresent() ?? ""
        value.properties.resourceType = try reader["resourceType"].readIfPresent() ?? ""
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension InternalServerException {

    static func makeError(baseError: AWSClientRuntime.AWSJSONError) throws -> InternalServerException {
        let reader = baseError.errorBodyReader
        var value = InternalServerException()
        value.properties.message = try reader["message"].readIfPresent() ?? ""
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension ResourceNotFoundException {

    static func makeError(baseError: AWSClientRuntime.AWSJSONError) throws -> ResourceNotFoundException {
        let reader = baseError.errorBodyReader
        var value = ResourceNotFoundException()
        value.properties.message = try reader["message"].readIfPresent() ?? ""
        value.properties.resourceId = try reader["resourceId"].readIfPresent() ?? ""
        value.properties.resourceType = try reader["resourceType"].readIfPresent() ?? ""
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension ServiceQuotaExceededException {

    static func makeError(baseError: AWSClientRuntime.AWSJSONError) throws -> ServiceQuotaExceededException {
        let reader = baseError.errorBodyReader
        var value = ServiceQuotaExceededException()
        value.properties.message = try reader["message"].readIfPresent() ?? ""
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension ThrottlingException {

    static func makeError(baseError: AWSClientRuntime.AWSJSONError) throws -> ThrottlingException {
        let reader = baseError.errorBodyReader
        let httpResponse = baseError.httpResponse
        var value = ThrottlingException()
        if let retryAfterSecondsHeaderValue = httpResponse.headers.value(for: "Retry-After") {
            value.properties.retryAfterSeconds = Swift.Int(retryAfterSecondsHeaderValue) ?? 0
        }
        value.properties.message = try reader["message"].readIfPresent() ?? ""
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension ValidationException {

    static func makeError(baseError: AWSClientRuntime.AWSJSONError) throws -> ValidationException {
        let reader = baseError.errorBodyReader
        var value = ValidationException()
        value.properties.message = try reader["message"].readIfPresent() ?? ""
        value.properties.reason = try reader["reason"].readIfPresent() ?? .sdkUnknown("")
        value.httpResponse = baseError.httpResponse
        value.requestID = baseError.requestID
        value.message = baseError.message
        return value
    }
}

extension TimestreamInfluxDBClientTypes.LogDeliveryConfiguration {

    static func write(value: TimestreamInfluxDBClientTypes.LogDeliveryConfiguration?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["s3Configuration"].write(value.s3Configuration, with: TimestreamInfluxDBClientTypes.S3Configuration.write(value:to:))
    }

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.LogDeliveryConfiguration {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = TimestreamInfluxDBClientTypes.LogDeliveryConfiguration()
        value.s3Configuration = try reader["s3Configuration"].readIfPresent(with: TimestreamInfluxDBClientTypes.S3Configuration.read(from:))
        return value
    }
}

extension TimestreamInfluxDBClientTypes.S3Configuration {

    static func write(value: TimestreamInfluxDBClientTypes.S3Configuration?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["bucketName"].write(value.bucketName)
        try writer["enabled"].write(value.enabled)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.S3Configuration {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = TimestreamInfluxDBClientTypes.S3Configuration()
        value.bucketName = try reader["bucketName"].readIfPresent() ?? ""
        value.enabled = try reader["enabled"].readIfPresent() ?? false
        return value
    }
}

extension TimestreamInfluxDBClientTypes.Parameters {

    static func write(value: TimestreamInfluxDBClientTypes.Parameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        switch value {
            case let .influxdbv2(influxdbv2):
                try writer["InfluxDBv2"].write(influxdbv2, with: TimestreamInfluxDBClientTypes.InfluxDBv2Parameters.write(value:to:))
            case let .influxdbv3core(influxdbv3core):
                try writer["InfluxDBv3Core"].write(influxdbv3core, with: TimestreamInfluxDBClientTypes.InfluxDBv3CoreParameters.write(value:to:))
            case let .influxdbv3enterprise(influxdbv3enterprise):
                try writer["InfluxDBv3Enterprise"].write(influxdbv3enterprise, with: TimestreamInfluxDBClientTypes.InfluxDBv3EnterpriseParameters.write(value:to:))
            case let .sdkUnknown(sdkUnknown):
                try writer["sdkUnknown"].write(sdkUnknown)
        }
    }

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.Parameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        let name = reader.children.filter { $0.hasContent && $0.nodeInfo.name != "__type" }.first?.nodeInfo.name
        switch name {
            case "InfluxDBv2":
                return .influxdbv2(try reader["InfluxDBv2"].read(with: TimestreamInfluxDBClientTypes.InfluxDBv2Parameters.read(from:)))
            case "InfluxDBv3Core":
                return .influxdbv3core(try reader["InfluxDBv3Core"].read(with: TimestreamInfluxDBClientTypes.InfluxDBv3CoreParameters.read(from:)))
            case "InfluxDBv3Enterprise":
                return .influxdbv3enterprise(try reader["InfluxDBv3Enterprise"].read(with: TimestreamInfluxDBClientTypes.InfluxDBv3EnterpriseParameters.read(from:)))
            default:
                return .sdkUnknown(name ?? "")
        }
    }
}

extension TimestreamInfluxDBClientTypes.InfluxDBv3EnterpriseParameters {

    static func write(value: TimestreamInfluxDBClientTypes.InfluxDBv3EnterpriseParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["catalogSyncInterval"].write(value.catalogSyncInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["compactionCheckInterval"].write(value.compactionCheckInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["compactionCleanupWait"].write(value.compactionCleanupWait, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["compactionGen2Duration"].write(value.compactionGen2Duration, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["compactionMaxNumFilesPerPlan"].write(value.compactionMaxNumFilesPerPlan)
        try writer["compactionMultipliers"].write(value.compactionMultipliers)
        try writer["compactionRowLimit"].write(value.compactionRowLimit)
        try writer["dataFusionConfig"].write(value.dataFusionConfig)
        try writer["dataFusionMaxParquetFanout"].write(value.dataFusionMaxParquetFanout)
        try writer["dataFusionNumThreads"].write(value.dataFusionNumThreads)
        try writer["dataFusionRuntimeDisableLifoSlot"].write(value.dataFusionRuntimeDisableLifoSlot)
        try writer["dataFusionRuntimeEventInterval"].write(value.dataFusionRuntimeEventInterval)
        try writer["dataFusionRuntimeGlobalQueueInterval"].write(value.dataFusionRuntimeGlobalQueueInterval)
        try writer["dataFusionRuntimeMaxBlockingThreads"].write(value.dataFusionRuntimeMaxBlockingThreads)
        try writer["dataFusionRuntimeMaxIoEventsPerTick"].write(value.dataFusionRuntimeMaxIoEventsPerTick)
        try writer["dataFusionRuntimeThreadKeepAlive"].write(value.dataFusionRuntimeThreadKeepAlive, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["dataFusionRuntimeThreadPriority"].write(value.dataFusionRuntimeThreadPriority)
        try writer["dataFusionRuntimeType"].write(value.dataFusionRuntimeType)
        try writer["dataFusionUseCachedParquetLoader"].write(value.dataFusionUseCachedParquetLoader)
        try writer["dedicatedCompactor"].write(value.dedicatedCompactor)
        try writer["deleteGracePeriod"].write(value.deleteGracePeriod, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["disableParquetMemCache"].write(value.disableParquetMemCache)
        try writer["distinctCacheEvictionInterval"].write(value.distinctCacheEvictionInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["distinctValueCacheDisableFromHistory"].write(value.distinctValueCacheDisableFromHistory)
        try writer["execMemPoolBytes"].write(value.execMemPoolBytes, with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.write(value:to:))
        try writer["forceSnapshotMemThreshold"].write(value.forceSnapshotMemThreshold, with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.write(value:to:))
        try writer["gen1Duration"].write(value.gen1Duration, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["gen1LookbackDuration"].write(value.gen1LookbackDuration, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["hardDeleteDefaultDuration"].write(value.hardDeleteDefaultDuration, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["ingestQueryInstances"].write(value.ingestQueryInstances)
        try writer["lastCacheEvictionInterval"].write(value.lastCacheEvictionInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["lastValueCacheDisableFromHistory"].write(value.lastValueCacheDisableFromHistory)
        try writer["logFilter"].write(value.logFilter)
        try writer["logFormat"].write(value.logFormat)
        try writer["maxHttpRequestSize"].write(value.maxHttpRequestSize)
        try writer["parquetMemCachePruneInterval"].write(value.parquetMemCachePruneInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["parquetMemCachePrunePercentage"].write(value.parquetMemCachePrunePercentage)
        try writer["parquetMemCacheQueryPathDuration"].write(value.parquetMemCacheQueryPathDuration, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["parquetMemCacheSize"].write(value.parquetMemCacheSize, with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.write(value:to:))
        try writer["preemptiveCacheAge"].write(value.preemptiveCacheAge, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["queryFileLimit"].write(value.queryFileLimit)
        try writer["queryLogSize"].write(value.queryLogSize)
        try writer["queryOnlyInstances"].write(value.queryOnlyInstances)
        try writer["replicationInterval"].write(value.replicationInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["retentionCheckInterval"].write(value.retentionCheckInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["snapshottedWalFilesToKeep"].write(value.snapshottedWalFilesToKeep)
        try writer["tableIndexCacheConcurrencyLimit"].write(value.tableIndexCacheConcurrencyLimit)
        try writer["tableIndexCacheMaxEntries"].write(value.tableIndexCacheMaxEntries)
        try writer["walMaxWriteBufferSize"].write(value.walMaxWriteBufferSize)
        try writer["walReplayConcurrencyLimit"].write(value.walReplayConcurrencyLimit)
        try writer["walReplayFailOnError"].write(value.walReplayFailOnError)
        try writer["walSnapshotSize"].write(value.walSnapshotSize)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.InfluxDBv3EnterpriseParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = TimestreamInfluxDBClientTypes.InfluxDBv3EnterpriseParameters()
        value.queryFileLimit = try reader["queryFileLimit"].readIfPresent()
        value.queryLogSize = try reader["queryLogSize"].readIfPresent()
        value.logFilter = try reader["logFilter"].readIfPresent()
        value.logFormat = try reader["logFormat"].readIfPresent()
        value.dataFusionNumThreads = try reader["dataFusionNumThreads"].readIfPresent()
        value.dataFusionRuntimeType = try reader["dataFusionRuntimeType"].readIfPresent()
        value.dataFusionRuntimeDisableLifoSlot = try reader["dataFusionRuntimeDisableLifoSlot"].readIfPresent()
        value.dataFusionRuntimeEventInterval = try reader["dataFusionRuntimeEventInterval"].readIfPresent()
        value.dataFusionRuntimeGlobalQueueInterval = try reader["dataFusionRuntimeGlobalQueueInterval"].readIfPresent()
        value.dataFusionRuntimeMaxBlockingThreads = try reader["dataFusionRuntimeMaxBlockingThreads"].readIfPresent()
        value.dataFusionRuntimeMaxIoEventsPerTick = try reader["dataFusionRuntimeMaxIoEventsPerTick"].readIfPresent()
        value.dataFusionRuntimeThreadKeepAlive = try reader["dataFusionRuntimeThreadKeepAlive"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.dataFusionRuntimeThreadPriority = try reader["dataFusionRuntimeThreadPriority"].readIfPresent()
        value.dataFusionMaxParquetFanout = try reader["dataFusionMaxParquetFanout"].readIfPresent()
        value.dataFusionUseCachedParquetLoader = try reader["dataFusionUseCachedParquetLoader"].readIfPresent()
        value.dataFusionConfig = try reader["dataFusionConfig"].readIfPresent()
        value.maxHttpRequestSize = try reader["maxHttpRequestSize"].readIfPresent()
        value.forceSnapshotMemThreshold = try reader["forceSnapshotMemThreshold"].readIfPresent(with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.read(from:))
        value.walSnapshotSize = try reader["walSnapshotSize"].readIfPresent()
        value.walMaxWriteBufferSize = try reader["walMaxWriteBufferSize"].readIfPresent()
        value.snapshottedWalFilesToKeep = try reader["snapshottedWalFilesToKeep"].readIfPresent()
        value.preemptiveCacheAge = try reader["preemptiveCacheAge"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.parquetMemCachePrunePercentage = try reader["parquetMemCachePrunePercentage"].readIfPresent()
        value.parquetMemCachePruneInterval = try reader["parquetMemCachePruneInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.disableParquetMemCache = try reader["disableParquetMemCache"].readIfPresent()
        value.parquetMemCacheQueryPathDuration = try reader["parquetMemCacheQueryPathDuration"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.lastCacheEvictionInterval = try reader["lastCacheEvictionInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.distinctCacheEvictionInterval = try reader["distinctCacheEvictionInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.gen1Duration = try reader["gen1Duration"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.execMemPoolBytes = try reader["execMemPoolBytes"].readIfPresent(with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.read(from:))
        value.parquetMemCacheSize = try reader["parquetMemCacheSize"].readIfPresent(with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.read(from:))
        value.walReplayFailOnError = try reader["walReplayFailOnError"].readIfPresent()
        value.walReplayConcurrencyLimit = try reader["walReplayConcurrencyLimit"].readIfPresent()
        value.tableIndexCacheMaxEntries = try reader["tableIndexCacheMaxEntries"].readIfPresent()
        value.tableIndexCacheConcurrencyLimit = try reader["tableIndexCacheConcurrencyLimit"].readIfPresent()
        value.gen1LookbackDuration = try reader["gen1LookbackDuration"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.retentionCheckInterval = try reader["retentionCheckInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.deleteGracePeriod = try reader["deleteGracePeriod"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.hardDeleteDefaultDuration = try reader["hardDeleteDefaultDuration"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.ingestQueryInstances = try reader["ingestQueryInstances"].readIfPresent() ?? 0
        value.queryOnlyInstances = try reader["queryOnlyInstances"].readIfPresent() ?? 0
        value.dedicatedCompactor = try reader["dedicatedCompactor"].readIfPresent() ?? false
        value.compactionRowLimit = try reader["compactionRowLimit"].readIfPresent()
        value.compactionMaxNumFilesPerPlan = try reader["compactionMaxNumFilesPerPlan"].readIfPresent()
        value.compactionGen2Duration = try reader["compactionGen2Duration"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.compactionMultipliers = try reader["compactionMultipliers"].readIfPresent()
        value.compactionCleanupWait = try reader["compactionCleanupWait"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.compactionCheckInterval = try reader["compactionCheckInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.lastValueCacheDisableFromHistory = try reader["lastValueCacheDisableFromHistory"].readIfPresent()
        value.distinctValueCacheDisableFromHistory = try reader["distinctValueCacheDisableFromHistory"].readIfPresent()
        value.replicationInterval = try reader["replicationInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.catalogSyncInterval = try reader["catalogSyncInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        return value
    }
}

extension TimestreamInfluxDBClientTypes.Duration {

    static func write(value: TimestreamInfluxDBClientTypes.Duration?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["durationType"].write(value.durationType)
        try writer["value"].write(value.value)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.Duration {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = TimestreamInfluxDBClientTypes.Duration()
        value.durationType = try reader["durationType"].readIfPresent() ?? .sdkUnknown("")
        value.value = try reader["value"].readIfPresent() ?? 0
        return value
    }
}

extension TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong {

    static func write(value: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        switch value {
            case let .absolute(absolute):
                try writer["absolute"].write(absolute)
            case let .percent(percent):
                try writer["percent"].write(percent)
            case let .sdkUnknown(sdkUnknown):
                try writer["sdkUnknown"].write(sdkUnknown)
        }
    }

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        let name = reader.children.filter { $0.hasContent && $0.nodeInfo.name != "__type" }.first?.nodeInfo.name
        switch name {
            case "percent":
                return .percent(try reader["percent"].read())
            case "absolute":
                return .absolute(try reader["absolute"].read())
            default:
                return .sdkUnknown(name ?? "")
        }
    }
}

extension TimestreamInfluxDBClientTypes.InfluxDBv3CoreParameters {

    static func write(value: TimestreamInfluxDBClientTypes.InfluxDBv3CoreParameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["dataFusionConfig"].write(value.dataFusionConfig)
        try writer["dataFusionMaxParquetFanout"].write(value.dataFusionMaxParquetFanout)
        try writer["dataFusionNumThreads"].write(value.dataFusionNumThreads)
        try writer["dataFusionRuntimeDisableLifoSlot"].write(value.dataFusionRuntimeDisableLifoSlot)
        try writer["dataFusionRuntimeEventInterval"].write(value.dataFusionRuntimeEventInterval)
        try writer["dataFusionRuntimeGlobalQueueInterval"].write(value.dataFusionRuntimeGlobalQueueInterval)
        try writer["dataFusionRuntimeMaxBlockingThreads"].write(value.dataFusionRuntimeMaxBlockingThreads)
        try writer["dataFusionRuntimeMaxIoEventsPerTick"].write(value.dataFusionRuntimeMaxIoEventsPerTick)
        try writer["dataFusionRuntimeThreadKeepAlive"].write(value.dataFusionRuntimeThreadKeepAlive, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["dataFusionRuntimeThreadPriority"].write(value.dataFusionRuntimeThreadPriority)
        try writer["dataFusionRuntimeType"].write(value.dataFusionRuntimeType)
        try writer["dataFusionUseCachedParquetLoader"].write(value.dataFusionUseCachedParquetLoader)
        try writer["deleteGracePeriod"].write(value.deleteGracePeriod, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["disableParquetMemCache"].write(value.disableParquetMemCache)
        try writer["distinctCacheEvictionInterval"].write(value.distinctCacheEvictionInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["execMemPoolBytes"].write(value.execMemPoolBytes, with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.write(value:to:))
        try writer["forceSnapshotMemThreshold"].write(value.forceSnapshotMemThreshold, with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.write(value:to:))
        try writer["gen1Duration"].write(value.gen1Duration, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["gen1LookbackDuration"].write(value.gen1LookbackDuration, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["hardDeleteDefaultDuration"].write(value.hardDeleteDefaultDuration, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["lastCacheEvictionInterval"].write(value.lastCacheEvictionInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["logFilter"].write(value.logFilter)
        try writer["logFormat"].write(value.logFormat)
        try writer["maxHttpRequestSize"].write(value.maxHttpRequestSize)
        try writer["parquetMemCachePruneInterval"].write(value.parquetMemCachePruneInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["parquetMemCachePrunePercentage"].write(value.parquetMemCachePrunePercentage)
        try writer["parquetMemCacheQueryPathDuration"].write(value.parquetMemCacheQueryPathDuration, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["parquetMemCacheSize"].write(value.parquetMemCacheSize, with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.write(value:to:))
        try writer["preemptiveCacheAge"].write(value.preemptiveCacheAge, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["queryFileLimit"].write(value.queryFileLimit)
        try writer["queryLogSize"].write(value.queryLogSize)
        try writer["retentionCheckInterval"].write(value.retentionCheckInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["snapshottedWalFilesToKeep"].write(value.snapshottedWalFilesToKeep)
        try writer["tableIndexCacheConcurrencyLimit"].write(value.tableIndexCacheConcurrencyLimit)
        try writer["tableIndexCacheMaxEntries"].write(value.tableIndexCacheMaxEntries)
        try writer["walMaxWriteBufferSize"].write(value.walMaxWriteBufferSize)
        try writer["walReplayConcurrencyLimit"].write(value.walReplayConcurrencyLimit)
        try writer["walReplayFailOnError"].write(value.walReplayFailOnError)
        try writer["walSnapshotSize"].write(value.walSnapshotSize)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.InfluxDBv3CoreParameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = TimestreamInfluxDBClientTypes.InfluxDBv3CoreParameters()
        value.queryFileLimit = try reader["queryFileLimit"].readIfPresent()
        value.queryLogSize = try reader["queryLogSize"].readIfPresent()
        value.logFilter = try reader["logFilter"].readIfPresent()
        value.logFormat = try reader["logFormat"].readIfPresent()
        value.dataFusionNumThreads = try reader["dataFusionNumThreads"].readIfPresent()
        value.dataFusionRuntimeType = try reader["dataFusionRuntimeType"].readIfPresent()
        value.dataFusionRuntimeDisableLifoSlot = try reader["dataFusionRuntimeDisableLifoSlot"].readIfPresent()
        value.dataFusionRuntimeEventInterval = try reader["dataFusionRuntimeEventInterval"].readIfPresent()
        value.dataFusionRuntimeGlobalQueueInterval = try reader["dataFusionRuntimeGlobalQueueInterval"].readIfPresent()
        value.dataFusionRuntimeMaxBlockingThreads = try reader["dataFusionRuntimeMaxBlockingThreads"].readIfPresent()
        value.dataFusionRuntimeMaxIoEventsPerTick = try reader["dataFusionRuntimeMaxIoEventsPerTick"].readIfPresent()
        value.dataFusionRuntimeThreadKeepAlive = try reader["dataFusionRuntimeThreadKeepAlive"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.dataFusionRuntimeThreadPriority = try reader["dataFusionRuntimeThreadPriority"].readIfPresent()
        value.dataFusionMaxParquetFanout = try reader["dataFusionMaxParquetFanout"].readIfPresent()
        value.dataFusionUseCachedParquetLoader = try reader["dataFusionUseCachedParquetLoader"].readIfPresent()
        value.dataFusionConfig = try reader["dataFusionConfig"].readIfPresent()
        value.maxHttpRequestSize = try reader["maxHttpRequestSize"].readIfPresent()
        value.forceSnapshotMemThreshold = try reader["forceSnapshotMemThreshold"].readIfPresent(with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.read(from:))
        value.walSnapshotSize = try reader["walSnapshotSize"].readIfPresent()
        value.walMaxWriteBufferSize = try reader["walMaxWriteBufferSize"].readIfPresent()
        value.snapshottedWalFilesToKeep = try reader["snapshottedWalFilesToKeep"].readIfPresent()
        value.preemptiveCacheAge = try reader["preemptiveCacheAge"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.parquetMemCachePrunePercentage = try reader["parquetMemCachePrunePercentage"].readIfPresent()
        value.parquetMemCachePruneInterval = try reader["parquetMemCachePruneInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.disableParquetMemCache = try reader["disableParquetMemCache"].readIfPresent()
        value.parquetMemCacheQueryPathDuration = try reader["parquetMemCacheQueryPathDuration"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.lastCacheEvictionInterval = try reader["lastCacheEvictionInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.distinctCacheEvictionInterval = try reader["distinctCacheEvictionInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.gen1Duration = try reader["gen1Duration"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.execMemPoolBytes = try reader["execMemPoolBytes"].readIfPresent(with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.read(from:))
        value.parquetMemCacheSize = try reader["parquetMemCacheSize"].readIfPresent(with: TimestreamInfluxDBClientTypes.PercentOrAbsoluteLong.read(from:))
        value.walReplayFailOnError = try reader["walReplayFailOnError"].readIfPresent()
        value.walReplayConcurrencyLimit = try reader["walReplayConcurrencyLimit"].readIfPresent()
        value.tableIndexCacheMaxEntries = try reader["tableIndexCacheMaxEntries"].readIfPresent()
        value.tableIndexCacheConcurrencyLimit = try reader["tableIndexCacheConcurrencyLimit"].readIfPresent()
        value.gen1LookbackDuration = try reader["gen1LookbackDuration"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.retentionCheckInterval = try reader["retentionCheckInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.deleteGracePeriod = try reader["deleteGracePeriod"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.hardDeleteDefaultDuration = try reader["hardDeleteDefaultDuration"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        return value
    }
}

extension TimestreamInfluxDBClientTypes.InfluxDBv2Parameters {

    static func write(value: TimestreamInfluxDBClientTypes.InfluxDBv2Parameters?, to writer: SmithyJSON.Writer) throws {
        guard let value else { return }
        try writer["fluxLogEnabled"].write(value.fluxLogEnabled)
        try writer["httpIdleTimeout"].write(value.httpIdleTimeout, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["httpReadHeaderTimeout"].write(value.httpReadHeaderTimeout, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["httpReadTimeout"].write(value.httpReadTimeout, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["httpWriteTimeout"].write(value.httpWriteTimeout, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["influxqlMaxSelectBuckets"].write(value.influxqlMaxSelectBuckets)
        try writer["influxqlMaxSelectPoint"].write(value.influxqlMaxSelectPoint)
        try writer["influxqlMaxSelectSeries"].write(value.influxqlMaxSelectSeries)
        try writer["logLevel"].write(value.logLevel)
        try writer["metricsDisabled"].write(value.metricsDisabled)
        try writer["noTasks"].write(value.noTasks)
        try writer["pprofDisabled"].write(value.pprofDisabled)
        try writer["queryConcurrency"].write(value.queryConcurrency)
        try writer["queryInitialMemoryBytes"].write(value.queryInitialMemoryBytes)
        try writer["queryMaxMemoryBytes"].write(value.queryMaxMemoryBytes)
        try writer["queryMemoryBytes"].write(value.queryMemoryBytes)
        try writer["queryQueueSize"].write(value.queryQueueSize)
        try writer["sessionLength"].write(value.sessionLength)
        try writer["sessionRenewDisabled"].write(value.sessionRenewDisabled)
        try writer["storageCacheMaxMemorySize"].write(value.storageCacheMaxMemorySize)
        try writer["storageCacheSnapshotMemorySize"].write(value.storageCacheSnapshotMemorySize)
        try writer["storageCacheSnapshotWriteColdDuration"].write(value.storageCacheSnapshotWriteColdDuration, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["storageCompactFullWriteColdDuration"].write(value.storageCompactFullWriteColdDuration, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["storageCompactThroughputBurst"].write(value.storageCompactThroughputBurst)
        try writer["storageMaxConcurrentCompactions"].write(value.storageMaxConcurrentCompactions)
        try writer["storageMaxIndexLogFileSize"].write(value.storageMaxIndexLogFileSize)
        try writer["storageNoValidateFieldSize"].write(value.storageNoValidateFieldSize)
        try writer["storageRetentionCheckInterval"].write(value.storageRetentionCheckInterval, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["storageSeriesFileMaxConcurrentSnapshotCompactions"].write(value.storageSeriesFileMaxConcurrentSnapshotCompactions)
        try writer["storageSeriesIdSetCacheSize"].write(value.storageSeriesIdSetCacheSize)
        try writer["storageWalMaxConcurrentWrites"].write(value.storageWalMaxConcurrentWrites)
        try writer["storageWalMaxWriteDelay"].write(value.storageWalMaxWriteDelay, with: TimestreamInfluxDBClientTypes.Duration.write(value:to:))
        try writer["tracingType"].write(value.tracingType)
        try writer["uiDisabled"].write(value.uiDisabled)
    }

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.InfluxDBv2Parameters {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = TimestreamInfluxDBClientTypes.InfluxDBv2Parameters()
        value.fluxLogEnabled = try reader["fluxLogEnabled"].readIfPresent()
        value.logLevel = try reader["logLevel"].readIfPresent()
        value.noTasks = try reader["noTasks"].readIfPresent()
        value.queryConcurrency = try reader["queryConcurrency"].readIfPresent()
        value.queryQueueSize = try reader["queryQueueSize"].readIfPresent()
        value.tracingType = try reader["tracingType"].readIfPresent()
        value.metricsDisabled = try reader["metricsDisabled"].readIfPresent()
        value.httpIdleTimeout = try reader["httpIdleTimeout"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.httpReadHeaderTimeout = try reader["httpReadHeaderTimeout"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.httpReadTimeout = try reader["httpReadTimeout"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.httpWriteTimeout = try reader["httpWriteTimeout"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.influxqlMaxSelectBuckets = try reader["influxqlMaxSelectBuckets"].readIfPresent()
        value.influxqlMaxSelectPoint = try reader["influxqlMaxSelectPoint"].readIfPresent()
        value.influxqlMaxSelectSeries = try reader["influxqlMaxSelectSeries"].readIfPresent()
        value.pprofDisabled = try reader["pprofDisabled"].readIfPresent()
        value.queryInitialMemoryBytes = try reader["queryInitialMemoryBytes"].readIfPresent()
        value.queryMaxMemoryBytes = try reader["queryMaxMemoryBytes"].readIfPresent()
        value.queryMemoryBytes = try reader["queryMemoryBytes"].readIfPresent()
        value.sessionLength = try reader["sessionLength"].readIfPresent()
        value.sessionRenewDisabled = try reader["sessionRenewDisabled"].readIfPresent()
        value.storageCacheMaxMemorySize = try reader["storageCacheMaxMemorySize"].readIfPresent()
        value.storageCacheSnapshotMemorySize = try reader["storageCacheSnapshotMemorySize"].readIfPresent()
        value.storageCacheSnapshotWriteColdDuration = try reader["storageCacheSnapshotWriteColdDuration"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.storageCompactFullWriteColdDuration = try reader["storageCompactFullWriteColdDuration"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.storageCompactThroughputBurst = try reader["storageCompactThroughputBurst"].readIfPresent()
        value.storageMaxConcurrentCompactions = try reader["storageMaxConcurrentCompactions"].readIfPresent()
        value.storageMaxIndexLogFileSize = try reader["storageMaxIndexLogFileSize"].readIfPresent()
        value.storageNoValidateFieldSize = try reader["storageNoValidateFieldSize"].readIfPresent()
        value.storageRetentionCheckInterval = try reader["storageRetentionCheckInterval"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.storageSeriesFileMaxConcurrentSnapshotCompactions = try reader["storageSeriesFileMaxConcurrentSnapshotCompactions"].readIfPresent()
        value.storageSeriesIdSetCacheSize = try reader["storageSeriesIdSetCacheSize"].readIfPresent()
        value.storageWalMaxConcurrentWrites = try reader["storageWalMaxConcurrentWrites"].readIfPresent()
        value.storageWalMaxWriteDelay = try reader["storageWalMaxWriteDelay"].readIfPresent(with: TimestreamInfluxDBClientTypes.Duration.read(from:))
        value.uiDisabled = try reader["uiDisabled"].readIfPresent()
        return value
    }
}

extension TimestreamInfluxDBClientTypes.DbClusterSummary {

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.DbClusterSummary {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = TimestreamInfluxDBClientTypes.DbClusterSummary()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.name = try reader["name"].readIfPresent() ?? ""
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.status = try reader["status"].readIfPresent()
        value.endpoint = try reader["endpoint"].readIfPresent()
        value.readerEndpoint = try reader["readerEndpoint"].readIfPresent()
        value.port = try reader["port"].readIfPresent()
        value.deploymentType = try reader["deploymentType"].readIfPresent()
        value.dbInstanceType = try reader["dbInstanceType"].readIfPresent()
        value.networkType = try reader["networkType"].readIfPresent()
        value.dbStorageType = try reader["dbStorageType"].readIfPresent()
        value.allocatedStorage = try reader["allocatedStorage"].readIfPresent()
        value.engineType = try reader["engineType"].readIfPresent()
        return value
    }
}

extension TimestreamInfluxDBClientTypes.DbInstanceSummary {

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.DbInstanceSummary {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = TimestreamInfluxDBClientTypes.DbInstanceSummary()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.name = try reader["name"].readIfPresent() ?? ""
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.status = try reader["status"].readIfPresent()
        value.endpoint = try reader["endpoint"].readIfPresent()
        value.port = try reader["port"].readIfPresent()
        value.networkType = try reader["networkType"].readIfPresent()
        value.dbInstanceType = try reader["dbInstanceType"].readIfPresent()
        value.dbStorageType = try reader["dbStorageType"].readIfPresent()
        value.allocatedStorage = try reader["allocatedStorage"].readIfPresent()
        value.deploymentType = try reader["deploymentType"].readIfPresent()
        return value
    }
}

extension TimestreamInfluxDBClientTypes.DbInstanceForClusterSummary {

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.DbInstanceForClusterSummary {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = TimestreamInfluxDBClientTypes.DbInstanceForClusterSummary()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.name = try reader["name"].readIfPresent() ?? ""
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.status = try reader["status"].readIfPresent()
        value.endpoint = try reader["endpoint"].readIfPresent()
        value.port = try reader["port"].readIfPresent()
        value.networkType = try reader["networkType"].readIfPresent()
        value.dbInstanceType = try reader["dbInstanceType"].readIfPresent()
        value.dbStorageType = try reader["dbStorageType"].readIfPresent()
        value.allocatedStorage = try reader["allocatedStorage"].readIfPresent()
        value.deploymentType = try reader["deploymentType"].readIfPresent()
        value.instanceMode = try reader["instanceMode"].readIfPresent()
        value.instanceModes = try reader["instanceModes"].readListIfPresent(memberReadingClosure: SmithyReadWrite.ReadingClosureBox<TimestreamInfluxDBClientTypes.InstanceMode>().read(from:), memberNodeInfo: "member", isFlattened: false)
        return value
    }
}

extension TimestreamInfluxDBClientTypes.DbParameterGroupSummary {

    static func read(from reader: SmithyJSON.Reader) throws -> TimestreamInfluxDBClientTypes.DbParameterGroupSummary {
        guard reader.hasContent else { throw SmithyReadWrite.ReaderError.requiredValueNotPresent }
        var value = TimestreamInfluxDBClientTypes.DbParameterGroupSummary()
        value.id = try reader["id"].readIfPresent() ?? ""
        value.name = try reader["name"].readIfPresent() ?? ""
        value.arn = try reader["arn"].readIfPresent() ?? ""
        value.description = try reader["description"].readIfPresent()
        return value
    }
}

public enum TimestreamInfluxDBClientTypes {}
